### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/001_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p01 12. CloudFormation - Service Role.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以这里有一点你需要了解关于云形成和安全的事情
所以云形成可以使用服务角色
它们是什么
它们是你创建的角色
它们是专门为云形成设计的
它们允许云形成实际上创建
更新和删除堆叠资源
如果你想给用户能力去实际创建、更新和删除堆叠资源
但是他们没有直接操作资源的权限
那么你会做就是使用服务角色
例如我们定义了一个模板和我们自己的
I am权限 作为用户在云形成中做动作
我们有I am pass角色
我们也创建了一个服务角色我们将其专门用于云形成
这个服务角色有s3 starbucket权限
例如创建
更新和删除一个桶
所以这里云形成能够创建这个s3桶
多亏了它的服务角色
因为用户能够将该角色传递给云形成
所以安全性用例是
如果你想实现最小权限原则
你不想给用户所有创建堆叠资源的权限
只有调用云形成服务角色的权限
为了这工作记住用户必须有名为I am pastoral的权限
这是授予aws s特定服务角色的必要权限
让我来给你展示一个云形成的I am角色的例子
所以如果你去I am
然后你去I am的角色部分
我们将创建一个角色
它是为aws服务
服务是云形成下一个为权限策略
我将给你s3全权
只是为了有一个专门的s3角色
仅仅是一个例子
点击下一步 我将其命名为demo for cfn with s3 capabilities
所以这个角色允许云形成做任何事情与s3
所以这个角色已经创建了
如果我去云形成并创建一个堆叠
我将使用我一个现有的模板
我不需要任何很复杂的东西
我们不会深入研究
所以我称之为demo roll conne
如你所见在这里权限
有一个I am roll
这个是可选的 所以如果我不指定
但如果我想指定一个i am角色
我可以查看用于cfn的s3能力的演示角色
这个角色将被用于所有堆栈操作
但这一个会，因为它只配备了亚马逊s3权限
那么实际上我的堆栈将失败
因为我的堆栈实际上是在创建e c two实例
但这里实际上定义了权限
如果你想为云形成使用i角色
就是这样
我希望你喜欢它 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/002_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p02 13. CloudFormation - Capabilities.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


最后你需要了解云形成能力
所以我们有一个名为我是的能力
我是 所以你需要给云形成能力
每当你的配置文件将要创建或更新我是资源
例如当你创建一个我是用户
一个角色 一个组
一个策略 以及如此
通过你的云形成模板
所以你指定名为我是
如果资源有名称
否则 仅能力
我是
我们之所以这样做是因为
我们希望明确承认云形成将要创建
我是资源我们有能力扩展
这是当你的云形成模板包括宏和嵌套堆栈
或堆栈在堆栈中进行动态转换
在这里我们承认模板可能在部署前更改
最后如果你在启动模板时获得权限不足异常
这意味着云形成模板需要权限
但你没有承认他们
因此作为安全措施
你需要重新
做模板上传和启动
这次使用这些权限
这只是你API调用中额外的参数
或AWS控制面板中勾选框
所以这里有三个权限
Ammo 我将向你展示一个云形成模板
实际上正在创建IAM角色及其名称
这是一个真实名称
我的客户真实名称
它使用管理策略
这是亚马逊
EC two全权访问
所以我们处理Ammo
因此如果我们创建这个堆栈并上传模板文件
即权限点yamo
我将其命名为演示
我是下一个并滚动到底部下一个并滚动到底部
如你所见
有一个确认声明说你需要拥有这个权限
他说是的
我确认云形成Mike将使用自定义名称创建我是资源
因此我们提供了确认的能力
实际上可以运行这个模板并创建这个角色
如果我们不做这件事
那么提交将失败，正如你所看到的
但如果我们做了这件事
那么我们说，嘿
我理解其中的风险
我理解我们正在创建
我正在云形成中创建资源
就是这样 这就是我想向你们展示的一切，好的 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/003_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p03 14. CloudFormation - Deletion Policy.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来谈谈云形成删除策略
删除策略是一个设置
您可以将其应用于云形成模板中的资源
这允许您控制在资源从云形成模板中删除时
或当云形成堆栈被删除时，资源的处理方式
这是为您实际保存和备份资源的一种方式
默认情况下，当我们删除一个云形成模板时
模板中的所有资源也会被删除
这意味着默认的删除策略是删除
所以你不必指定它
因为它是默认设置
有时候你想指定以非常明确的方式表明东西正在被删除
但是所以这里是一个例子
我们有一个e C Two实例
正如你所见，删除策略是删除
这意味着e
C 当云形成堆栈被删除时，两个实例将被删除
好的 这里有另一个例子
我们有一个s三桶，并且我们有一个删除策略等于删除
所以，所有事情可能应该正常工作
但实际上
如果你有一个入口桶
这是一个例外
你有一个删除政策
相等 删除它
只有在s三号桶是空的情况下才会起作用
如果s三号桶不是空的
那么删除将失败
所以解决这个问题的方法
如果你想要的话，要么手动删除s三号桶中的所有内容
然后继续删除您的云形成模板
或者你需要实现一个自定义资源
来实际删除s三号桶中的所有内容
在自动删除s三号桶之前
我们来谈谈删除策略保留
所以对于零售稀释策略
实际上是指定了您希望在云形成模板中保存的资源
例如 这里有一个Dynamo DB表
我们知道，默认情况下，当我删除我的云形成模板时，它将被删除
但可能我们实际上想保留它
保留表中的数据
因为我们关心这张表的数据
因此，我们会在最后指定删除策略保留
所以我即使删除我的云形成模板
这个Dynamo TB表将保持不变
这对任何资源都适用
最后，你需要了解的最后一个删除策略是快照
这是为了在删除资源之前创建一个最终的快照
它支持EBS卷
Elastic Cache复制组
RDS数据库 实例数据库集群Red Shift
Neptune 文档DB
也许更多
想法是，你将在最下面指定
当然，删除策略快照
所以RDS的这个实例数据库将被删除
但在实例消失之前将创建一个最后的快照
所以这非常有助于备份和安全目的
让我们看看
在这个文件删除策略ammo中
有一个安全组
删除策略是保留
这意味着如果我删除我的确认堆栈
这个安全组应该保持不变
有一个EBS卷
删除策略是快照
这意味着在删除堆栈时
卷应该消失
但在创建快照之前
让我们通过创建一个堆栈来验证这种行为
并上传模板文件
被删除策略
下一个删除策略演示是堆栈的名称
滚动到下一个并提交
所以这创建了我的云形成堆栈
它将由两个资源组成
我们有一个EBS卷
然后我们有一个E C
两个安全组
所以现在它们都被创建了，我堆栈已经完全创建
让我们删除它
让我们删除堆栈并查看事件
我们看到这里
我的安全组有一个删除跳过
这是因为我们指定了一个删除策略保留
所以 如果我想删除这个安全组
如你所见 它还在这里
如果我想删除它
我需要手动删除它
因为我告诉云形成
不要现在删除它
关于ebs卷
它已经被删除
但如果我去到事件中
结果是创建了一个快照并且成功了
这里是快照id
因此如果我去我的快照中
我有一个新的1GB快照刚刚创建
从我的ebs卷
但我的ebs卷如你所见已经消失了
如果你想要完全清理
请确保也手动删除这个快照
请确保也删除安全组
如果你愿意 就是这样
我们看到了删除策略的力量
我希望你喜欢 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/004_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p04 15. CloudFormation - Stack Policy.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来做一个关于云形成堆栈政策的快速讲座
当你有一个云形成堆栈时，默认情况下
任何操作都将允许在所有资源上进行
你可以按照你的意愿更改你的堆栈
但有时你可能想保护你的堆栈免受更新
或者你的堆栈的一部分免受更新
这就是堆栈政策发挥作用的地方
堆栈政策是相邻的文档
它们定义了在堆栈更新期间对特定资源允许的更新操作
这里有一个例子，其中第一个声明是说允许对所有内容进行更新
这意味着您云形成堆栈中的所有内容都可以更新
第二部分是说拒绝对生产数据库进行更新
这意味着您云形成堆栈中名为生产数据库的任何内容
都将受到任何类型更新的保护
因此，默认情况下
那么您的生产数据库是安全的
堆栈政策的目标是您需要保护资源免受无意的更新
当您设置堆栈策略时，默认情况下
所有资源都将受到保护
因此，您需要的是对其进行明确的允许
您希望被允许更新的资源
就是这样 你应该知道足够多来回答
考试中可能会有一个问题
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/005_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p05 16. CloudFormation - Termination Protection.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以这是一个非常快速的讲座
但是为了防止意外删除你的云形成堆栈
你必须使用终止保护
我现在将在控制台中向您展示如何启用它
让我为您创建一个堆栈
我将上传并单击文件名
只是e c two然后demo下一个
向下滚动下一个
然后实际上传这个
好的 这是我的堆栈
我现在将要做的事情
是编辑终止保护
正如您所看到的，目前它处于非活动状态
但我将启用此终止保护
现在已成功更改
所以我在这里的堆栈
如果我尝试删除它
这是不可能的
它说堆栈中的终止保护已启用
在我删除它之前，我必须先禁用终止保护
所以现在这是一个防止意外删除的安全措施
如果我有编辑终止保护的必要权限
我可以禁用它
然后从那里我可以实际删除我的云形成堆栈
就是这样 您已经看到了终止保护
我希望您喜欢它 我将在下次讲座中见到您
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/006_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p06 17. CloudFormation - Custom Resources.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈云形成自定义资源
正如我们所说
许多资源由云形成支持
但你可以使用自定义资源来定义那些尚未由云形成支持的资源
或者定义自定义部署逻辑，用于那些可能不在云形成范围内的资源
例如，你自己的本地资源或第三方资源
或者如果你想在云形成堆栈的创建、更新和删除阶段运行自定义脚本
通过Lambda函数
我再给你一个例子，运行一个Lambda函数
在mt和s三桶中被删除之前
这是一个常见的考试问题
所以定义一个自定义资源
你在模板中定义它
它的类型是自定义colin col
它是由我自定义资源类型名称支持的
它由lambda函数支持
这是最常见的一种，或者ns主题
那么如何定义一个自定义资源
我将只介绍lambda自定义资源
因为它是最常见的
所以我们有一个自定义资源类型为自定义
我的lambda资源
然后在属性中我们有一个服务令牌
服务令牌要么是你的lambda函数arn或者是你的ssa
它们必须在同一地区
想法是，这个lambda函数将拥有自己的逻辑来为您的客户资源提供服务
或者做它需要的任何事情
多亏了输入数据参数
您可以向lambda函数提供输入值
所以使用案例 例如
如我所说 是从S3桶中删除内容
因为事实证明，无法从Cloud Formation中删除非空的行桶
所以首先必须删除其中的所有对象
然后删除桶
您使用自定义资源
想法是当自定义资源被删除时
将运行API调用实际删除您的S3桶
所以这里是一个例子，当我们在云形成中运行删除堆栈时
然后由lambda函数支持的自定义资源将运行API调用
来清空您的S3桶
然后只有在您的S3桶被清空之后
云形成才会尝试删除您的S3桶，一切都将正常工作
这是考试角度上最常见的用例
这是我想要通过图表向您展示的
我希望您喜欢它 我将在下一节课见到您
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/007_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p07 18. CloudFormation - StackSets.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈确认堆栈集
想法是您想要创建
更新 或删除跨多个账户和地区的堆栈
所有在一个操作或模板中
所以从管理员账户中，您将取得一个模板
并将它创建一个堆栈集
并且这个堆栈集将允许您在多个账户和多个地区部署堆栈
这就是为什么它被称为堆栈集
当您更新堆栈集时
所有目标账户和目标地区的堆栈实例
也将被更新
所以它真的是一次性的
您可以应用到您想要的账户中
但最常见的用例之一是实际上应用到所有账户
在AWS组织中
这是AWS的一组账户
在组织中
只有管理员账户或被指定为管理员才能创建堆栈集
当然 否则将是混乱和安全风险
好的 就是这样
您只需要在高层次上了解堆栈集的概念
就是这样 希望您喜欢它 我将在下一节课见到您
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/008_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p08 01. AWS Integration & Messaging - Section Introduction.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们已经完美地部署了一个应用程序，使用列表中的最佳库存进行自动化
由云形成支持
并且完全监控，如果你要部署多个应用程序怎么办
它们需要相互通信
我们将看到在aws上你可以进行的通信和集成模式
我们将学习关于sqs
这实际上是aws最古老的服务
以及s and s和kinesis
如果你需要对大数据进行实时流处理
这个部分实际上是一个深入的探索
因为考试会问你很多问题
尤其是关于sqs的
所以请注意 让我们开始练习，让我们学习如何将我们的应用程序集成在一起
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/009_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p09 02. Introduction to Messaging.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


欢迎来到AWS集成和消息部分的介绍
这个部分有点酷
因为我们将看到如何协调我们不同服务之间的东西
使用中间件，所以在这个部分
基本上当我们开始部署多个应用程序时
它们不可避免地必须相互通信
好的 您的服务需要共享信息
共享数据 因此，将有两种应用程序通信的方式
将有同步通信
因此，您的应用程序将直接与其他您的应用程序连接
例如 我们有
嗯 你知道 我们在线销售一些东西，我们有一个购买服务
当某物被购买时
我们需要与发货服务交谈以发送刚刚购买的项目
正如您在这里看到的
我的购买服务和我的物流服务直接相连
因此有一些同步通信正在发生
我的bansynservice说嘿
发生了一些事情
物流服务 去做
好的 另一种类型的集成和模式将是异步或基于事件的
因此会有一个中间件称为队列或称为其他东西
基本上它将连接您的应用程序
所以这次银行服务说嘿
某物买了某物
某人买了某物
所以我要把它放入队列中
就是这样
并且物流服务说嘿
Q最近有什么东西被买吗
队列将返回该元素
因此物流服务可以做它想做的任何事情
所以你可以看到这里
购买服务和运输服务没有直接联系
它们之间有一个队列
因此它们没有直接沟通
这就是异步
应用程序之间的同步可能会有点问题
有时因为如果一个服务压倒了另一个
因为突然出现了购买激增
或者无论什么原因都可能是大问题
对吧 所以如果你需要编码
例如 我们有一个视频编码服务，我们需要编码一千个视频
但通常只有十
我们的编码服务将不堪重负
我们将出现故障
当你有这些突然的流量高峰时
或者你无法预测任何事情
那么通常最好解耦你的应用程序
并且让解耦层为你扩展
在这种情况下，这可能是SQS用于队列模型
这可能是S用于发布/订阅模型
这可能是Kinesis
如果你进行实时流式传输
并且你有大量数据
所以我们将在本节中学习所有这些
我们将学习到这些三样东西现在可以使用这些三样东西，我们的服务可以扩展
你知道，独立地与SQS和Kinesis
并且这三样东西也会很好扩展
真的，真的很好
这就是整个范式
所以我们将开始学习这些三种技术在本讲中 所以下一讲见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/010_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p10 03. Amazon SQS - Standard Queues Overview.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们来谈谈 sqs，sqs 的核心是一个队列
因为 sqs 是一个非常简单的队列服务
所以我们有一个 sqs 队列
并且它将包含消息，为了包含消息
嗯 必须有什么东西将我们的消息发送到 sqs 队列
并且任何发送消息的东西被称为生产者
所以我们可以有一个生产者
但也可以有多个
你可以有多个生产者发送多个消息到 sqs 队列
消息可以是你想要的任何内容
例如 它可以是处理订单或处理视频
你创建的任何消息都会进入队列
然后需要有什么东西从队列中处理消息并接收它们
它被称为消费者
消费者将从队列中拉取消息
这意味着它们会问队列
你有消息给我么
队列说，是的 在这里
消费者会拉取这些消息并获得一些信息
然后使用这些消息进行处理，并将其从队列中删除
你可能有多个消费者从 sqs 队列中消费消息
队列服务在这里作为一个缓冲
以解耦你的生产者和消费者
现在 sqs 是一个很复杂的服务
我们会深入探讨
但第一个提供者是称为 Amazon SQS 标准队列
在 AWS 的历史上
它是最老的服务之一
它是 AWS 最早的服务之一
它有十年以上的历史
所以它的工作方式已经很成熟了
它是一个完全管理的服务
并且它将用于解耦应用
所以只要你在考试中看到应用解耦
就想到 Amazon SQS
为什么 sqs 这么好
嗯 我们可以获得无限的吞吐量
这意味着你可以每秒发送任意数量的消息
并且队列也可以有你想要的任意数量的消息
所以没有吞吐量的限制，也没有队列中消息的数量限制
每个消息都是短暂的
这意味着默认情况下消息将在队列中保存四天
并且消息在队列中最大保留时间是十四天
这意味着一旦你将消息发送到队列
它必须在消费者处被读取并从队列中删除
在处理完成后的保留期内
否则它将会被丢失
然后我们会有低延迟
所以 sqs 意味着
嗯 这意味着无论何时你向 sqs 发送或读取消息
你将会得到很快的反馈
在发布和接收时不超过十毫秒
在 sqs 中的消息必须很小
它们必须小于 256 KB
sqs 是一个队列服务 所以你可以看到高吞吐量
高并发等
因此它有可能出现重复消息
这意味着
例如 有时消息会被发送到两次
这就是为什么它被称为至少一次交付
如果你继续编写应用程序
你需要考虑到这一点
它也可能出现消息顺序混乱
这意味着它是尽力而为
顺序 我们将看到 sqs 还有一种处理方式
可以解决这个问题
但我们稍后会讨论
所以让我们回到消息生产者
消息最多可达 256 KB 被发送到 sqs
生产者如何发送
他们如何发送
他们使用 sdk 软件开发工具包
通过 api 发送消息到 sqs
称为 send message
非常简单
消息将被写入 它将被持久化到 sqs
直到消费者读取并删除该消息
这表示消息已被处理
我们知道保留时间
生产消息的用例是什么
例如
你想要处理一个订单 例如包裹
然后寄送给发送者
所以你想在自己的时间做这件事
你将向 sqs 发送一条消息
可能包含一些信息
例如订单号
客户ID
以及你可能想要的任何属性
例如 地址等等
然后，你的消费者，也就是需要编写的应用程序，必须自己处理这个消息
所以再次确认，sql标准持有者有无限的吞吐量
我们已经看到了生产者，现在让我们看看消费者
所以消费者
它们是你需要编写的一些应用程序
这些应用程序可以运行在e
C
两个实例上 两个实例 所以在aws上，你的虚拟服务器
但它们也可以在你自己的
本地服务器上运行
如果你愿意
或者我们还没有看到
但它们也可以在aws的lambda函数上运行
lambda在本课程中我们会看到 它是一种无服务器计算类型的服务
嗯 这意味着你可以直接从lambda读取消息
稍后会在本课程中看到
不要担心 所以回到关于e的简单用例
C 两个实例 我们的队列有一个消费者，消费者从sqs拉取消息
这意味着消费者会询问队列
你有没有消息给我
消费者一次可能会收到多达10条消息
所以如果有消息在sqs
它将收到一个有效的回复
这里显示的是正在等待你的消息
然后消费者
你的代码有责任处理这些消息
例如 将一些订单插入到rds数据库中
所以你会继续前进
对于每个订单，你将将其插入到你的rds数据库中
这显然是你必须用代码写的事情
然后因为这些消息已经被处理
因为它们已经被接收并插入到亚马逊RDS数据库中
您的消费者将使用删除消息API删除队列中的这些消息
这将确保没有其他消费者能够看到这些消息
因此，消息处理已完成
所以现在我们可以扩大规模
我们可以同时拥有多个消费者
因此，您的SQS可以拥有多个消费者，这些消费者将并行接收和处理这些消息
这里我们有三个实例
C 两个实例 因此每个消费者在调用poll函数时将接收到不同的消息集
如果某个消息没有被消费者及时处理
它将被其他消费者接收
这就是为什么我们有至少一次交付
这也是我们拥有最佳努力消息顺序的地方
如我所说 当消费者处理完消息后
它们必须删除这些消息
否则其他消费者将看到这些消息
因此这意味着使用SQS
如果我们需要增加吞吐量
因为我们有更多的消息
然后我们可以添加消费者并进行水平扩展来提高处理能力。
所以，如果你记得我们说过的话
这是一个使用 sqs 与你的自动扩展组或 asg 的完美用例
那么这意味着什么，嗯
这意味着你的客户将运行在e上
C 两个实例在一个自动扩展组内
他们将会从sqs立方体中拉出信息
但是现在你的自动扩展组必须在某种指标上扩展
并且我们可以使用的指标是队列长度
它被称为近似消息数量
这是一个云指标 在任何SQS中可用的指标
我们可以设置一个警报
例如，当队列长度超过某一水平时
请设置云监控警报
并且这个警报应该增加我的自动扩展组的容量x
这将确保您在SQS中的消息的数量越多，容量就越大
可能是因为你们的网站上订单激增
更多的e C 由您的自动扩展组提供两个实例
您将相应地以更高的吞吐量处理这些消息
这是一个在考试中常见的集成
Sqs再次
用例是解耦应用程序，因此应用程序层
所以 例如 我们来举一个处理视频的应用的例子
我们可以有一个单一的大型应用，称为
它被称为前端 它会处理请求
每当视频需要处理时
它会进行处理并将结果插入到s3存储桶中
问题是处理可能需要很长时间
如果你在前端层这样做，可能会减缓你的网站
所以，你可以解耦你的应用程序，在这里说
等一下 处理文件的请求和实际处理文件的操作可以在两个不同的应用程序中进行，因此每当您处理一个文件请求时，您会将消息发送到SQS队列中
当你处理请求时，处理文件的操作会在SQS队列中进行
您可以创建一个名为后台处理应用的第二处理层
它将在自己的自动扩展组中接收这些消息，处理这些视频并将其插入到S3存储桶中
我们可以根据前端的需求进行扩展
我们可以根据后端的需求进行扩展
但这是独立的
因为SQS具有无限的吞吐量
它有一个发送的消息数量，基于队列
那么你就真的很安全
这是一个坚固且可扩展的架构类型
对于你的前端
你可以使用最佳类型的E
C 两种实例或架构，用于你的前端和后端
也许如果你在进行一些视频处理
你可以使用一些e
C 两个实例拥有GPU
图形处理单元
因为你知道，这种实例类型对于执行这种工作负载来说是最优的
所以这就是考试中会出现的那种建筑风格
并且你被期望知道
这是SQS的一个令人惊叹和巨大的用例
最终 sqs 安全
所以我们在传输过程中使用http安全协议对消息进行加密
我们使用KMS密钥对数据进行静态加密
如果我们想要
我们可以进行客户端加密
但这意味着客户端必须进行加密和解密
这不是SQS原生支持的
访问控制策略将能够控制对SQS API的访问
I策略将能够控制对SQS API的访问
但我们也有SQS访问策略
这与S3桶策略类似
当你想要跨账户访问 sqsq 时，它们非常有帮助
或者当你想允许其他服务
例如，我们很快就会看到的 ns
或者允许 amazon s three 向 sq sq 写入
例如，使用 s three 事件
这就是 sqs 的总结
我希望你喜欢它 我会在下一节课见到你 进行一些练习
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/011_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p11 04. SQS - Standard Queue Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来练习亚马逊 sqs
所以我们要去 sqs 控制台，然后创建一个队列
正如你所看到的，我们可以在 sqs 中设置两种类型的队列
我们有标准队列和 fifo 队列，我将使用标准队列
名称将是 demo q
我们将在后续课程中看到 fifo 的配置
所有这些我们都将在未来的讲座中看到
可见性 超时
交付 延迟等待时间
保留期 我们将使用四天
最大尺寸将达到256KB
这是SQS加密的最大允许值
我们有几种加密选项
我们可以完全禁用队列的加密
默认情况下，我们将使用Amazon SQS密钥进行加密
它被称为SSC SQS
加密类型 这与我们在亚马逊S3中的SSC射线类似
这就是服务器端加密的一种选项
另一个是用 km
这就是我们必须选择客户主密钥的地方
因此我们可以选择默认的cmk的 uh
AWS被称为Elia
AWS（Amazon Web Services） Sq
然后我们可以定义一个数据密钥重用周期，这可能是五分钟
例如 这是为了限制对kms的api调用次数
但这并不是很重要
所以让我们保持加密为亚马逊sqs
密钥ssc
sqs 好的，下一个
我们有一个访问策略
这个访问策略可以使用这些提示来定义
所以我们可以说嘿 谁可以访问这个队列
只有队列所有者可以发送消息
或者我可能想指定一个账户列表
用户和角色
然后再次指定接收者
只有我 队列所有者或指定的账户
用户和角色
这将生成一个json文档
这个json文档
如你所见，看起来与我们之前看到的非常相似
亚马逊与亚马逊S3桶策略免费
这是SQS的资源策略
它与驱动器和Delta队列的工作非常相似
稍后会看到 目前
一切正常 让我们创建一个队列
队列已成功创建
现在我们可以从中发送和接收消息
在这个UI中我们有很多不同的板
但我们想要去顶部
右边点击发送和接收消息
这里有一个发送消息的设施
然后在底部接收它们
如您所见，当前队列中
没有可用的消息
但如果我在消息正文中输入 weld
然后发送消息
您可以看到消息已发送，准备接收
现在我们有一个可用的消息
一个，在这里
一旦我点击拉取消息
消息会出现
让我们看看
我点击拉取消息
是的 我们确实收到了这条消息在这里
如您所见，我们有一个消息ID
如果您想查看消息的内容
我点击消息详情
我可以获取一些信息
这里有很多关于消息的元数据
例如 消息的哈希值，谁发送了它
它接收了多少次
目前只有一次
因为我们 这是消息第一次处理的次数，大小以字节计
如果我们想去读取正文
我们可以看到之前发送的内容
你好，世界 正如您所见
在这里 刚刚读取的消息
如果我们为消息创建了属性
我们没有查看消息属性面板
我们可以创建键值并对其进行读取
非常简单 您发送消息并读取它时，会得到完全相同的消息
您会得到完全相同的消息
但我们已经解耦
因为生产者发送了一些信息
而消费者现在收到了那个信息
我们可以看到消息被接收了两次
因为我们没有
嗯 在足够的时间内处理它
所以30秒后消息回到了队列中我们又收到了它
所以如果我拉取5条消息
收到的消息计数是3
所以又被读了一次
所以为了完成这个消息
因为假设我们已经处理了这个hello world消息
我将点击它
然后我将点击删除
并且通过从队列中删除消息
我们已经向SQS信号了消息已成功处理
因此队列中可用的消息为零
如果我们再拉取一次
我们不会再收到相同的消息
因为我们已经删除它
所以你开始看到队列的力量
我们可以发送多次不同的消息
hello world等等你可以随意尝试
这就是你如何设置消息属性
但这不在考试范围之内
在这里你将接收这些消息
你可以接收多个消息
所以如果我们发送hello world
我们将再次发送那个消息
和hello world two
例如
并发送那个消息和hello world three 无论你想要什么
实际上在那个消息中 正如我们所看到的
嗯
一旦我刷新这个窗口 我们可以看到可用的消息数量是3
所以如果我拉取5条消息
我将得到3条可用的消息
再次你可以将它们全部取走并删除以向SQS信号它们已经被处理
相当容易
但你已经看到了生产者和消费者的力量现在回到队列
还有一些选项
我们可以看到它 所以我们可以编辑这个队列以编辑我们所看到的所有配置
或者你可以清空队列
这将删除队列中的所有消息
所以要删除所有消息你需要输入purge
他们会继续删除一切
当你进行开发时这非常有帮助
但我认为你不应该在生产环境中这样做
然后你会得到一些关于监控的信息
例如这里 这将给你提供一些关于队列中消息数量的信息
这是消息中最老消息的大致年龄
这可能是另一种扩展你 sqsq 的方式
如果你有一个自动扫描的组从它读取等等
最后访问策略
这是谁可以访问队列
以及如何加密
这是我们为 sqsq 定义的服务器端加密
例如我们现在正在使用 ssc sqs 作为我们的加密方案
但我们可以编辑它
最后死信队列重试状态
这是有关的
如果你设置了一个死信队列
这就是本讲座的内容 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/012_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p12 05. SQS Queue Access Policy.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈sqs q访问策略
sqs q访问策略有两个很好的用例
它们与s3存储桶策略相似，因为它们是资源策略
所以json 我是策略，你将直接添加到你的sqs队列
第一个用例是允许跨账户访问
假设你有一个队列在一个账户中
另一个账户需要访问该队列
也许它有一个e C 两个实例
所以为了能够让e
C 两个实例能够跨账户拉取消息
你需要做的是创建一个队列访问策略，看起来像这样
并且将其附加到第一个账户中的sqsq
这个q访问策略将允许aws为主体
one one two two two two two three three three three
这代表了右侧的账户
在sqs接收消息在这个资源这里
所以这些账户
这个队列访问策略实际上允许你的e
C 两个实例从另一个账户中的sqsq拉取消息
sqs q访问策略的另一个用例是
例如 当你有一个s3存储桶
并且它会将事件通知发布到一个sqsq
例如，你将一个对象上传到s3存储桶
你想要自动获得一个消息发送到sqsq
如你所见 sqsq需要给s3存储桶权限
来写一个消息给它
因此我们需要我们自己的sqs q访问策略，看起来像这样
如果你看详细信息
例如 操作是sqs发送消息
原则是星星
所以来自任何账户
只要条件是存储桶的来源代表s3存储桶
名为bucket one
并且来源账户需要 是s3存储桶的所有者
一旦你有了这个
然后s3存储桶被允许写入一个sqsq
这是很重要的，因为考试会测试你
例如 为了跨账户访问写入到sqsq需要什么
或者发布s3事件通知
这就是全部
现在我们来创建一个队列并设置一个sqsq访问策略
所以我将此命名为来自S3的事件
因为我们将设置一个S3事件通知
以便进入这个SQS
我将保留其他所有默认设置
正如我们所见，SQS访问策略在这里，并且这里
我们可以定义哪些服务可以将数据发送到我们的SQS
如果我们选择基本方法
那么我们可以选择只有队列所有者可以向我们的SQS发送数据
这将代表这个
或者我们可以选择只指定账户
这里是用户和角色
这就是跨账户访问之一
对于谁能向队列发送消息
我们有相同的对话对于谁能从队列接收消息
好的 这对我们来说没有用于Amazon S3
或者我们可以选择高级并编写我们自己的SQS访问策略
所以与此同时我只是选择基本
向你展示开始时事情不会工作
然后我们修改它
然后我们看看事情之后会工作
所以我们将创建这个队列
现在我将进入Amazon S3
好的 我将创建一个S3桶
并且从S3桶设置事件通知将数据发送到我们的SQS
让我们创建一个跨域的QS Q
嗯 访问策略
我将点击创建桶
好的 所以这里它
然后我将进入属性
滚动到底部
找到我们的事件通知
我将创建一个事件通知
我将其命名为新对象
对于所有前缀
所有后缀
对于事件类型
我们将选择所有对象
创建事件，完美
滚动到底部
目的地将是一个SQS Q
我们需要从SQS中选择
我们找到事件来自S3
点击 保存更改
正如我们所见，我们得到一个错误
因为现在无法验证以下目的地配置
所以我们需要做的是进入这个访问策略
我们需要修改它
以便允许我们的s三桶写入我们的sqsq
为此我们可以直接进入文档
并看看是否能找到我们的策略
所以我们将进行简单的谷歌搜索s三事件进入sqs访问策略
这将给我们我们需要的访问权限
好的完美
我们有事件通知
然后我将进入亚马逊sqs以授予权限
我们开始配置 sqs 和 s
然后我们将添加这个
这是我们需要为 sqsq 设置的策略文档
我将复制它
编辑这个并将它粘贴
我们需要更改以包含 q n
让我在这里做一个小的肮脏编辑
资源 qarn 必须从这里复制
并将其粘贴在那里
好的，然后我们需要说明条件是 air in
源桶名称必须一致
就像我们的源桶
让我们找到我们的源桶名称
在这里我们复制到策略中
源账户所有者
是我们现在的账户
我在这里
找到我的账户ID
在这里
复制并粘贴
所以这项政策和我需要删除旧的一个
所以这项政策允许我们的s三桶发送消息到我们的sqsq
相当不错
我们将保存这个并且它不是有效的json
因为我在使用
我漏掉了一个逗号
点击保存
这就是我们在这里所做的，所以现在我们有了这个新政策
让我们看看是否能够保存我们的事件通知
是的我们可以，所以这已成功完成
实际上，如果你进入亚马逊SQS，准备发送和接收消息，
只有一个消息是可用的，
我们可以拉取它，
查看它并确认该测试事件是由亚马逊SQS发送的，
将其发送到我们的SQS，
这就是这个实践操作的全部内容，
我们可以， 如果我们想上传一条消息，
将文件上传到亚马逊S3并显示在SQS中，
但我想向你展示的是，通过修改访问策略，
我们提供了从rs三桶到我们的sqsq的访问权限
这就是我们想要的效果
这就是这节课的全部内容 希望你喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/013_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p13 06. SQS - Message Visibility Timeout.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈一个重要的概念，称为消息可见性超时
当一条消息被消费者拉取
它将对其他消费者不可见
让我们以一个例子来说明
我们有时间从左到右流逝
我们有一个消费者执行接收消息的请求
因此，消息将从队列中返回
现在，可见性超时开始
默认情况下，消息可见性超时为30秒
这意味着在这30秒内，消息必须被处理
好的 如果你这样做
这意味着如果相同或其他消费者进行消息请求API调用
那么消息将不会返回
并且在超时窗口内再次进行调用
消息将不会返回，因此实际上
在可见性超时期间
该消息对其他消费者不可见
但在可见性超时到期后
如果消息未被删除
然后这条消息将被称为引号放回队列中
因此，另一个消费者或同一消费者在做接收消息API调用时会再次收到这条消息
与以前一样的这条消息
所以这是非常重要的理解
如你所见
当我们接收到一条消息时
它在可见性超时期间变得不可见
如果我们看一下同样的图表
我们注意到的是
如果我们在可见性时间窗口内未处理一条消息
然后它会被处理两次
这可能是正确的
因为它会被两个不同的消费者接收
或者由同一个消费者处理两次
因此，如果消费者正在积极处理一条消息
但知道它需要更多的时间来处理消息
因为否则它将超出可见性超时窗口
有一个叫做更改消息可见性的API
因此，如果消费者知道一条消息需要更多的时间来处理
并且你不想处理该消息两次
然后消费者应该调用更改消息API来告诉sqs
嘿 暂时不要使那个消息可见
好的 我只需要再多一点时间来处理这个消息
那么如何设置这个消息的可见性超时呢
如果你设置一个非常高的默认值
假设是我们的，消费者崩溃了
那么直到这个消息重新出现需要几个小时
重新变为可见
如果你将其设置为一个非常低的值，那么这将花费很多时间
比如几秒钟 如果消费者因为某种原因没有时间处理消息
那么这条消息会被不同的消费者多次读取
你可能会得到重复的处理
所以，想法是，可见性超时应该设置为对您的应用程序合理的值
并且您的消费者应该编程，如果它们需要更多的时间
那么它们应该调用更改消息的可见性API
以获得更多的时间并增加该可见窗口的超时
但从考试角度来看，理解这个概念是非常重要的
因为会有那样的场景
所以让我们进入控制台看看这在实践中是如何工作的
所以我要打开两个发送和接收消息的窗口
只是为了向你展示这是如何工作的
所以在第一个窗口
我将输入一个hello welds
它将被发送到队列中
如果你记得队列有一个默认的超时为30秒
所以将要发生的事情是我有两个消费者
我有第一个窗口和第二个窗口消费者
所以我要读第一个窗口的消息
现在我们拉取消息
我的消息出现在这里
已经收到
如果我进入我的第二个消费者并拉取消息
如你所见
这个消息没有出现在这里
它没有出现的原因是我们还在这个消息的可见窗口内
这个消息的超时
因此在这三十秒内这个消息正被这个消费者处理
这个消费者在这里看不到它
但让我们假设我们停止拉取
好的 所以我们不删除消息
我们知道这个消息会在某个时间点超时
会发生的是，是的
我已经在这里的第二个窗口
在第二个消费者 这是第二个消费者
然后消息已经被接收
因为它被放回了队列中
现在假设我们做对了一些事情
我们删除了那条消息
然后我们完全处理了那条消息
但请记住那条消息被接收了两次
我说接收次数是两次
所以你需要理解这个可见性窗口是如何工作的
而这是一个很好的演示
现在 如果你想改变这个默认设置
你可以做的事情是去编辑
然后为可见性超时设置
你可以将默认值设置为零秒
这绝对不推荐，到十二小时
我认为三十秒是足够的
但是再次 记住，如果消费者需要更多时间来处理消息
你应该调用更改消息的可见性API来编辑那条消息的可见性，增加值
所以这是另一个
消费者将不会看到这条消息
第一个消费者将得到足够的时间来处理那条消息
相应地
就是这样 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/014_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p14 07. SQS - Dead Letter Queues.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈SQS中的死信队列
设想一个场景
消费者在可见性超时期间未能处理消息
我们知道消息会自动回到队列中
消费者读取了一条消息
可能出现了故障
可能时间不够
消息回到队列中
如果这种情况经常发生
这可能是个问题
例如 我们再次读取消息
可能消息有问题
可能消费者无法理解消息
或者无法处理消息
那么消息会回到队列中
又会重复发生
我们再次从SQS读取消息
又会回到队列中
我们可以设置一个阈值，限制这种情况发生的次数
但这种失败循环可能是个大问题
但我们可以设置一个最大接收阈值
如果超过这个阈值
我们可以告诉SQS
这条消息看起来有点奇怪
看起来被处理了太多次，仍未成功
因此将其发送到死信队列中，队列中包含该消息
以便稍后处理
因此消息将从第一个队列移除，发送到第二个队列
我们为何有死信队列
嗯 死信队列对于调试非常有用
如果消息进入队列
因为它是SQS，你必须处理它
但至少给你时间理解发生了什么 有几点需要注意，死信队列必须是标准队列
以及死信队列的标准队列也必须是标准队列
最后，由于我们有死信队列
你需要确保消息在从队列过期之前被处理
因此，设置一个较长的时间，例如14天的保留期，是很好的主意
在死信队列中
下一个用于管理您的死信队列的功能是重定向到源功能 这是一个功能，帮助您消费死信队列中的消息
以了解它们存在的问题
因此，您现在拥有消息
知道它们没有在源队列中被处理
因此它们处于死信队列中
您将进行手动检查和调试这些消息
然后你会修复你的消费者代码
理解为什么消息没有被处理，即使消息是正确的
然后你可以做的就是从死信队列中重新派发消息到源队列
SQS队列
这将发生什么
是消费者可以重新处理这个消息
甚至不知道消息进入了队列
然后消息处理已经完成
这是一个酷功能
所以现在让我们进入控制台 所以我可以向你展示死信队列功能
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/015_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p15 08. SQS - Dead Letter Queues - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们开始创建一个死信队列，用于我的演示队列
所以我称之为演示队列
Dlq
我会滚动向下
因为这是一个死信队列
我想要给自己足够的时间来保留和分析消息
所以我会有一个14天的消息保留期
好的，完美
那么让我们滚动向下
我们将有一个默认的加密启用
一切都看起来不错
我们将创建这个队列
所以现在这个队列已成功创建
让我们打开一个新标签并进入我的演示队列的配置
在这里我将编辑队列本身
可见性超时需要设置为非常慢
非常低 对不起，我要在演示中稍微快一点
所以我们将其设置为5秒读取消息3次非常快
然后如果我滚动到死信队列下面
我可以启用它
我可以选择死
演示
Q Dq
Sq sq
作为我的死信
现在我们需要指定最大接收
这是消息应该在被放入死信队列之前应该被接收的次数
为了更快
我们说3 所以消息在第四次被读取并放回队列时
那么它将最终进入我的sqs死信队列
那么让我们保存这个
并且我们很好
所以现在我将去我的死信队列
我将开始接收消息并开始拉取消息
而现在 当然在我的死信队列中我们没有任何消息
但是让我们去我的普通队列
我将发送和接收消息
这将是hello world毒丸
因为它实际上会让我的消费应用失败
所以这就是它被称为毒丸的原因
但我们没有消费应用
这只是一个消费应用本身
那么让我们发送消息
消息已发送
现在让我们拉取消息
所以这里我们正在接收消息，第一次接收
然后五秒后我们将第二次接收它
然后五秒后我们将第三次接收它
正如你看到的
然后消息被接收三次后
因为它总是被放回队列中
它不会被删除
然后消息将被发送到dlq
所以让我们现在验证一下
如果我现在停止拉取
然后我尝试再次拉取新消息
我将看到不再接收消息
所以消息去哪里了
如果我们进入dlq本身
这是我的dq，正如你所见，我正在拉取消息
我现在在我的dq中看到了消息
这条消息 如果我点击它作为dlq
我可以说 我可以查看这条消息
这条消息是我的主应用程序崩溃的原因
最后 让我看看如何从dlq将消息重发到第一个队列中，以防
例如 我们修复了消费应用程序
在我的dlq中
我将在这里的右上角
有一个开始 Dl q q redrive
我们说，嘿
这是一个dlq并且你收到了消息
所以我们想要重新驱动这些消息到源队列
我们只需点击此选项进行速度控制
我们可以系统优化
然后我们可以检查消息，如果我们想要的话
然后我们只需点击dlq redrive
所以它被称为dlq redrive任务
如果我在这里查看
我已经看到它已成功完成
这意味着如果我回到我的演示
队列源队列，发送和接收消息并拉取消息
正如你所见，消息又出现了这里，因此重发工作
我希望这给你们提供了一个好的了解死信队列如何工作的概述
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/016_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p16 09. SQS - Delay Queues.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈延迟队列
所以队列是用来延迟消息的
这样消费者不会立即看到它们
默认情况下这可以延迟至多15分钟
延迟参数是0秒
这意味着只要你将消息发送到sqsq
消息将立即可供读取
但你可以在队列级别设置默认值
说所有消息都应该延迟x秒
或者每次发送消息时
你可以设置每条消息的延迟
如果你想要的话，可以使用延迟秒参数
所以我们有一个队列
生产者会向队列发送消息
例如 队列
例如，队列有默认值，说明消息应该延迟多久
例如，可能是30秒，所以在30秒后
当消费者从队列中拉取消息时
它将看到该消息并成功接收它
让我们进入控制台，看看这在实践中是如何工作的
所以回到qs
我将创建一个队列
我将其命名为delay q
如您所见
我们有一个新的设置叫做交付延迟
默认值为0秒
但我们可以将其设置为15分钟
所以我将此设置为10秒
这样消息将在消费者读取之前等待10秒
好的，其余部分将保持标准
我将继续点击创建队列
现在我的延迟队列已经创建
我将继续发送和接收消息
现在输入一个随机消息
如您所见，默认情况下
交付延迟已经创建到控制台
它说10秒
但我们可以覆盖它
例如，您可以说30
或者我们可以说0
或者更长
但我们将保持默认的10秒
所以我将开始拉取消息
如您所见，没有消息被接收，我现在立即发送一条消息
我们需要等待10秒
12345678910
现在消息应该在我的消费者中出现
这里它 已经过去了10秒
正如你所看到的 发送和实际交付消息之间存在一段时间延迟
对于某些用例
这可能是您需要的，也可能是您希望拥有的
作为一名认证的aws人员
您应该知道这种功能存在
这就是一个非常简短的演示
但我希望这对您有所帮助 下次讲座再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/017_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p17 10. SQS - Certified Developer concepts.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈一些你需要了解的关于sqs的概念
但更多的是从开发者的角度
首先一个叫做长拉取
所以当一个消费者从sqs请求一条消息
它有选择等待
取消等待 等待新到达的消息
如果队列突然变空
这就是长拉取
让我们来看一个例子
我们有一个空队列sqsq
消费者向sqsq发送请求
现在我们可以选择等待
等待是可以的，对吧
因为没消息
这意味着在等待期间如果有消息进入sqsq
那么消息将被消费者接收
那么为什么我们做长轮询呢
我们做长轮询 因为我们向sqsq发送的API请求更少
在上面我们知道，一旦消息到达 sqsq，
然后 sqsq 会将其发送给消费者
因此我们提高了效率
因为我们减少了 API 调用
因此减少了 CPU 循环
我们也降低了延迟
因为只要消息被您的 sqsq 接收
它就会被您的消费者接收，所以长轮询是显而易见的
您可以将长轮询设置为一秒到二十秒之间
但二十秒是首选
为什么不 总的来说
在你的应用中建议使用长轮询到短轮询
所以你会在考试中看到
一些问题 可能告诉你消费者对sqsq做了太多调用
这会消耗你的资金和cpu周期
可能增加延迟
那么长轮询将是选项
长轮询可以在队列级别启用
所以Q级设置
或者在API调用级别
所以每当你的消费者通过Polling调用SQSQ时
使用接收消息
等待时间 秒
参数
我们需要检查的第二件事是SQS扩展客户端
正如我们所知，最大消息限制为256KB
那么我们如何将大消息发送到您的SQSQ
例如 对于1GB的消息，我们可以使用一个叫做sqs extended clients的java库
这个库可以做一些非常简单的事情，你可以在任何其他语言中实现
它的想法是使用亚马逊的免费存储桶作为存储大量数据的仓库
所以第二个例子中，你的生产者想要向sqs发送一个大型消息
但首先会发生的是，这个大型消息实际上会存储在亚马逊的s3中
然后发送到sqs的是一个小的元数据消息
8: 但首先会发生的是，这个大型消息实际上会存储在亚马逊的s3中
9: 然后发送到sqs的是一个小的元数据消息 10: 10: 但首先会发生的是，这个大型消息实际上会存储在亚马逊的s3中
这指向了你在亚马逊免费桶中的大型消息
因此，sqsq将包含小消息
而你的亚马逊三桶将包含大型对象
当你的消费者使用此库从sqsq读取时
使用sqs扩展客户端
它将消费这个小元数据消息
这将告诉消费者
嘿 去亚马逊免费获取这个大消息
消费者将能够读取并从s三中检索大型消息
所以，这种模式的典型用例是如果你正在处理视频文件
你不需要将整个视频文件发送到SQS
你将视频文件上传到你的亚马逊免费存储桶
然后你发送一条小消息，指向那个视频文件的指针，发送到你的SQS队列
这允许你通过节奏模式真正地适应任何消息的大小
最后，你可能会看到一些API调用或由考试给出的
所以，这些只是正常的API调用，你应该现在理解
但我们来了解一下它们
所以，创建队列用于创建一个队列
你可以使用消息保留期这个参数
设置消息在队列中保留多久后删除
队列用于删除队列
同时删除队列中的所有消息
Perqueue是一个API调用
用于同时删除队列中的所有消息
当我们发送消息时
我们使用发送消息API
如果我们想发送延迟消息
我们可以使用延迟秒参数来接收消息并进行轮询和删除
消息在由消费者处理后将被删除
当你收到一条消息时，默认情况下，
可以设置参数，
最大消息数被设置为1，
这意味着你每次只接收一条消息，
但在SQS中，你可以一次接收多达10条消息，
因此，你可以为接收的消息设置接收消息API的最大消息数参数，
将其设置为10，以便一次接收多条消息，
接收消息的等待时间，
秒数告诉消费者在从队列获取响应之前需要等待多长时间，
这与启用长轮询和更改消息可见性是等效的
用于更改消息的超时设置
如果您需要更多时间来处理消息
如果您想使用批量API调用
您可以这样做以发送消息
删除消息以及更改消息可见性
这可以减少您发送到API的API调用数量
从而帮助降低成本
就是这样，现在 让我们看看如何在AWS中实现长轮询
所以我们进入我们的演示队列，我们将编辑我们的演示队列的设置
正如我们所看到的
接收消息的等待时间是零
这被称为短轮询
但我们可以将其设置为零到二十秒之间
所以只要设置它为一
您就启用了长轮询
我们将其设置为二十
这意味着您应该等待最多二十秒来接收消息
如果队列是空的
所以我将只是应用设置
所以我将保存我的队列配置
然后我将进入我的发送和接收消息
在这里我将开始一个消费者
现在，这个消费者正在做长轮询
因为它在队列级别被设置
这意味着只有一次API调用
它正在等待来自SQS的消息
因为目前没有消息 但如果我说Hello World并点击发送
我一点击，消息就被我的消费者接收了
这是非常低的延迟
因为我的消费者处于长轮询模式
它正在等待来自SQS的消息
多亏了设置的消息超时
所以之前我们设置的那个
就是这样，非常简单的演示
但希望这有意义 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/018_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p18 11. SQS - FIFO Queues.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来谈谈SQS中可用的另一种队列类型，即亚马逊的
SQS FIFO队列
FIFO意味着先进先出
这意味着消息将按顺序在队列中排序
第一个到达队列的消息将是第一个离开队列的消息
因此，我们可以获得更多的顺序保证，比我们从标准队列可以获得的
让我们以一个生产者将消息发送到您的SQS为例
第一个消息和第二个
第三个和第四个
由于我们有一个SQS FIFO队列
然后消费者将从SQS中拉取消息
I/O Q 并且消费者将以完全相同的顺序接收消息
由于我们有这样的
关于顺序的限制和保证，这个SQS的吞吐量是有限的
因此，如果您不批处理，您将获得每秒300条消息的吞吐量
或者如果您发送消息批次
您可以获得每秒高达3000条消息的吞吐量
但由于FIFO队列
我们获得了更多的保证和限制
因此，通过允许SQS删除重复项的功能，我们具有恰好一次发送能力
我们也知道消息将由消费者按顺序处理
因此，FIFO队列是您应该看到的，每当您有解耦
但也需要维护消息的顺序，并且确保您不在SQS中发送太多消息
并且您符合这些吞吐量
约束
限制
好的 那么让我们去创建我们的第一个FIFO队列
让我们去创建一个队列
我将创建一个FIFO队列
正如你所看到的，它是按顺序交付的
并且消息顺序得到保留
好的 我将其命名为demo_q_fifo
你必须以.fifo结尾
否则你将无法创建这个队列
它必须以.fifo结尾
如果我们查看配置
它看起来与以前非常相似
但我们有一个更多的设置叫做基于内容的去重
这是为了去重消息
如果相同的消息在很短的五分钟窗口内被发送了两次
访问策略将保持不变，加密
等等将保持不变
所以我将创建这个队列
现在我去看发送和接收消息
我们可以看一下消息体
我们可以说hello
焊接一个
然后我必须指定一个消息组id
我将其命名为demo
我们将在整个过程中使用相同的消息组id
这个demo发送了，并且有一个去重id
对不起 我将其标记为消息1
所以我说id1发送这个消息
我将hello world发送到相同的消息组id
我将其标记为去重2
然后消息啊
第三个消息，我将其标记为3
最后第四个消息，我将其标记为4
好的 所以现在消息已经发送并且准备好了接收
所以我们有四个消息可用
如果我拉取四个消息
我们看看所有消息
如果我看看这个
实际上顺序错了
如果我看最后一个
它是第一个 它说hello world1
如果我看第二个消息
我有第三个消息可用
我有一个3和第四个消息
我将有hello world4
所以 这是由于FIFO队列保证你收到消息的顺序
然后你继续删除这些消息
然后你就完成了，所以
就是这样 我希望这对你有帮助 我将在下次讲座再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/019_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p19 12. SQS - FIFO Queues Advanced.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们看看一些SQS FIFO的高级概念
第一个是去重
有一个去重间隔是5分钟
这意味着如果您在两分钟内发送两次相同的消息
那么第二次消息将被拒绝
有两种去重方法
第一种称为基于内容的去重
当您将消息发送到SQS时
会计算一个哈希值
使用消息的正文使用哈希256方法
如果遇到两次相同的消息正文
相同的哈希值将相同
因此第二次消息将被拒绝
或者您可以在发送消息时显式提供消息去重ID
如果遇到相同的去重ID
那么消息将被拒绝
那么让我们看看SQS FIFO
我们生成一个Hello World消息并启用基于内容的去重
在这种情况下
SQS FIFO将生成消息的哈希值
这可能看起来像这样
如果生产者发送完全相同的消息
它将被哈希到完全相同的哈希值
SQS FIFO将知道这一点
因此第二次消息将被拒绝
我们需要看的第二个测试概念是消息分组
如果您在SQS FIFO中为消息组ID指定相同的值
这是您发送消息到FIFO Q时的必填参数
那么只有一个消费者并且所有消息将对该消费者按顺序
但如果您只需要消息级别的顺序
则应为消息组ID指定不同的值
想法是具有共同消息组ID的消息
将在组内按顺序
每个组ID将有一个不同的消费者
您可以在SQS FIFO中启用并行处理
但跨组的顺序无法保证
例如 假设我们有
我们有一个FIFO Q并将消息分组为三个组
A B和C
然后我们有一个消费者为组A
然后我们有另一个组
B1 B2 B3 B4
我们可以为该组再添加一个消费者
例如对于客户组C
我们有C1和C2
想法是 例如
有时您可能不需要所有消息的总顺序
但您需要为特定客户ID的消息顺序
对于那个特定的客户ID，你可以使用这个作为你的消息组ID
这意味着你可以有你应用程序中所有用户那么多的消费者
对于每个用户，消息将按顺序排列，多亏了SQS的五个Q保证
让我们编辑它
我将启用基于内容的去重
去重ID将作为消息SHA256计算
谢谢SQS的五个Q保证
让我们编辑它
我将启用基于内容的去重
去重ID将作为消息SHA256计算
所以我点击保存
现在我们开始
让我们去发送和接收消息
我将发送消息
给消息组发一条消息，你好，世界
我们暂时将其保留为演示，目前
结束 我们可以看到，消息重复是可选的
因为我们已启用内容基的重复消除
所以发送那条消息
正如你所见，消息已发送并准备好接收
可用的消息是1
但如果我再次发送那条消息，一遍又一遍，一遍又一遍
将要保持的消息数量仍然是1
因为那条消息已经被sqs看到了
因此有一些去重操作正在发生
但如果我发送一条不同的消息
例如 你好世界2
那么第二条消息在这里的sqs fifo中就会可用
所以我们可以看到这里发生了去重
但是例如如果我写了另一条消息并且我使用你的去重这些
例如你自己的去重令牌
所以123
然后您再次发送该消息
多亏了我们指定了相同的去重ID
那么您在sqs fifo中只会看到这些消息的其中之一
我想向您展示的另一件事是组
所以这不是很容易展示的东西
但想法是 例如，如果我们有一个用户买了一个苹果
并且它的消息组ID是用户123
然后我将删除这个消息通知ID
然后用户买了一个香蕉
然后用户买了草莓
因为这些消息共享相同的消息组ID
那么对于该用户来说，它们将按顺序排列
用户123
但如果我现在发送一个用户买了一个苹果和一个苹果
这将显示为绿色
一个绿色的苹果 并且我们指定一个不同的消息组id
所以用户二三四
现在，对这些用户二三四的消息将按顺序排列
所以现在在我的sqs五四q中
我可以同时运行多个消费者
每个消费者将从不同的消息组中消费
id好
就是这样 现在
当你完成时 你可以只是拉取消息并查看
但我会继续删除它们
就是这样 我希望你喜欢它 我会在下次讲座中见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/020_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p20 13. Amazon SNS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在让我们谈谈亚马逊的
所以，如果你这次想发送一条消息，让许多
许多不同的接收者
所以，你可以有一个直接的集成，
例如，一个购买服务应用程序可以发送电子邮件通知
然后向欺诈服务发送一条消息
向您的运输服务发送一条消息
甚至可能向一个sqsq发送一条消息
这是因为每次您需要添加新的接收服务时
您需要创建并编写该集成
相反 你可能想做的是叫做发布订阅(pub sub)
想法是购买服务会将消息发送到ns主题
这将发布一个消息到主题
并且该主题会有许多订阅者
每个订阅者都能从canes主题接收消息
并将其作为自己的
因此这也是另一种称为发布订阅(pub sub)的模式
因此，在亚马逊s中，事件生产者只会将消息发送到一个特定的主题
而事件接收者或订阅者想要接收主题通知
因此，每个订阅者在你的主题中
将收到发送到该主题的所有消息
除非你使用过滤器
这是一种过滤消息的功能
当然也是可能的
你可以在每个主题上获得多少订阅者
你可以达到1200万
加上每个主题的订阅数，所以相当多
这个数字可能会随时间变化
但它不会实时更新 这个幻灯片只是为了给你一个概述，你可以获得多少订阅者
在你的账户中，你可以获得最多十万个主题
你也可以增加这个限制
这可能会改变，但再次
只是为了给你一个限制的想法
但你永远不会在限制的本身上进行测试，所以对于s
你将发布两个订阅者
他们可以是什么，嗯
你可以直接从s发送电子邮件
你可以发送短信和移动通知
你也可以直接将数据发送到指定的http或https端点
但SNS也与特定的AWS服务集成
例如，将消息直接发送到队列的SQS
或者将消息发送到Lambda以执行某些代码
或者在消息接收后查看Firehose以发送数据
例如，数据可以发送到Amazon Kinesis Firehose
例如 Amazon S3或Redshift等许多服务都可以接收数据
因此，数据可以直接发送到S3
以便进行云监控
自动扫描 组通知
变化的云形态
预算 S
三个桶 Dms
Lambda Dynamodb
R s事件 等等
这样你就不必记住它们
但是只要AWS中有任何类型的通知
这些服务会将通知发送到指定的主题
那么如何将消息发布到A和S
您使用主题
发布SDK
因此您创建一个主题
然后您创建订阅
或者一个或多个订阅
您发布到主题
所有订阅者将自动检索该消息
或者有一种称为直接发布
用于移动应用的SDK 您需要创建一个平台应用
平台端点
您发布到平台端点
在谷歌方面，工作方式是
GCM
苹果 Aps或亚马逊ADM
这是你移动应用接收通知的不同方式，关于安全性
Amazon S的安全性与SQS相同
因此它默认具有飞行中加密
使用KMS密钥进行静态加密，客户端进行加密
如果您的客户想要发送一些加密的消息到S
但是 这取决于您的客户
责任在于客户端进行加密和解密，关于访问
控制和策略将是安全的核心
因为所有Snapis都将由策略控制
您可以定义S访问策略
它们与S3桶策略非常相似
并且它们非常有用，当您想要跨账户访问NS主题时
或者允许其他服务
例如，您的S射线事件写入NS主题
就是这样
我希望你喜欢它 我将在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/021_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈s s plus sqs扇出模式
想法是您希望消息发送给多个sqs qs
但如果您分别将每个消息发送给每个sqs qs
可能会出现一些问题
例如 如果您的应用程序在中间崩溃
如果他们的交付失败
或者您在后续添加了更多的sqs qs
因此我们想要使用最终模式
想法是您将向s主题推送一次
然后您将订阅您想要的所有sqs qs到该主题
这些是订阅者
他们将接收发送到s的所有消息
例如
我们有一个购买服务，希望将消息发送到两个sqs qs 它将会这样做
它将将消息发送到s主题
而q's是该主题的订阅者
这样欺诈服务和航运服务可以从他们自己的sqs qs读取所有消息
这种模式的想法是完全解耦的
并且没有数据丢失
sqs将给您提供数据持久性
以及处理延迟和作业重试
并且使用这种模式
我们可以随着时间的推移添加更多的sqs cues作为ns主题的订阅者
为此
我们需要确保您的sqs qs访问策略
正如我们所看到的
允许您的主题向您的sns写入
向您的sqs qs因此再次
这是使用队列访问策略的另一个用例
并且我们有跨区域交付
因此从一个区域中的s主题向另一个区域中的sqs qs发送消息是完全可能的
如果安全允许
接下来
那么我们如何使用这种模式用于其他目的
例如
s three事件发送到多个队列 因此s three事件规则的一个限制是
对于组合事件类型
例如
一个对象正在被创建和前缀 例如images
您只能拥有一个s three事件规则
但如果您希望将相同的s three事件通知发送到多个sqs qs
在这种情况下，您将使用enite模式例如
我们有s three对象创作为事件出现在s three桶中
并将此事件发送到s主题
我们有s three对象创事件出现在s three桶中
并将此事件发送到s主题
我们将为主题订阅许多sqs队列作为有限模式
但我们也可以订阅其他类型的应用程序
电子邮件 Lambda函数
等等
然后，我们从中得到的是，亚马逊三中发生的事件的消息将发送到多个不同的目的地
多播模式使得这一点成为可能
另一种架构是您可以直接从s将数据发送到亚马逊三，通过kinesis数据火烈鸟
通过kinesis数据火烈鸟，您可以直接将数据发送到s3
所以因为S直接与KDF集成
那么您的购买服务可以将数据发送到S主题
然后您可以看到数据流
KDF将接收该信息
然后您可以将数据从KDF发送到您的Amazon S3桶
或者更确切地说
任何特定于KDF的目的地
这允许您以灵活的方式
您可能希望将主题中的消息持久化
所以我们也可以将有限模式应用于FIFO主题
所以亚马逊有一个FIFO或FIFO的能力
这是先进先出
这给主题中的消息排序
所以生产者发送消息一二
三四 目前订阅者只能是sqs FIFO队列
接收消息一二
三四按顺序
所以FIFO的想法是我们得到与sqsvo相同的功能
我们得到按消息组ID排序
我们使用去重ID或基于内容的去重来消除重复
Sqs标准和FIFO队列都可以作为订阅者
在吞吐量方面
你受到限制 你获得的吞吐量与SqsV4相同
为什么我们需要这个呢？如果你需要使用SqsV4进行广播，
所以你需要广播、排序和去重
银行服务将数据发送到SVO主题
然后它会广播到两个SqsFIFO队列
欺诈服务和物流服务也可以从FIFO队列读取
SMS的最后一个特性，对于扇出模式来说非常有用，那就是你可以在SMS中进行消息过滤
那么消息过滤是什么
它是用于过滤发送到US主题的消息的邻接策略
订阅
因此，如果订阅没有过滤策略
它将接收所有消息
这是默认行为
但是，当我们设置消息过滤策略时，会发生什么
所以我们有一个购买服务
它将交易发送到s主题
例如 交易看起来有一个订单号作为产品
例如 一支铅笔
数量
和当前状态
我们想要创建一个sqq
仅限已下订单
不包括其他 仅限已下订单
因此，我们将订阅sqq到sms主题
我们将在json中应用过滤策略
我们在策略中指定我们希望状态等于已下
只有匹配的消息
策略将进入xqs2
然后我们可以有一个sqq用于取消订单
因此，我们可以为我们的取消订单创建自己的过滤策略
并且来自同一主题的消息将进入sqs cube
已下订单和取消订单
sqs将不会具有相同的消息
我们也可以使用相同的过滤策略
取消的一则用于创建取消订单的电子邮件订阅
我们可以有一个过滤策略用于拒绝订单
例如 并且作为另一个sqq
或者我们可以创建一个sqq没有过滤策略
以便从该主题获取所有消息
使用所有这些有限模式和消息过滤
Fifo队列和Fifo主题
我们拥有大量的不同可能性
考试将尝试测试所有这些
这就是本讲座的全部内容 我希望你喜欢它 我将在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/022_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p22 15. SNS Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来练习使用s
我们将进入简单通知服务并创建我们的第一个主题
我将其命名为我的第一个主题
然后点击下一步
创建主题的两种方式
它可以是标准主题
你将创建这个
这是尽力而为
消息排序至少一次消息交付
最高吞吐量以每秒发布数计
并且 sqs lambda http m
电子邮件和移动应用程序端点可以从此主题读取
或者我们看到我们可以创建一个s fifo主题
并且这是为了严格保持消息的顺序，确保消息只被送达一次
高达每秒三百个发布者的高吞吐量
并且唯一能订阅一个先进先出（FIFO）的东西
话题是一个sqsq
在这种情况下 如果我们有FIFO
我们可以看到，猪的名字必须以点fifo结尾
所以我们将使用标准
然后我们将使用我的第一个主题作为名称
我们可以在主题中加密消息
我们可以设置一个访问策略
访问策略将定义谁和什么可以写入主题
这与s3桶策略相似
这与sq s访问策略相似
好的 想法是，使用此访问策略
例如 我们可以设置一个免费的桶，将事件写入到短信主题中
然后主题可以将数据发送到SQS等
因此，访问策略需要允许STHREE桶写入我们的主题
所以，我现在将使用基本
因为我们不需要做任何复杂的事情
然后我们不会设置任何这些
然后我们点击创建主题
所以我的第一个主题已经创建
正如我们所见，目前我们没有任何订阅
所以我们需要创建我们的第一个订阅
所以我要创建一个
我们选择协议
所以它可以是kinesis数据
火烈鸟 SQS
Lambda邮件
JSON HTTP http s和ms
好的 你必须记住那些参加考试的人
但要让它非常简单
我们将首先使用邮件，实际上在这个实际操作中我们只使用邮件
现在我们需要使用电子邮件地址上的端点
我将使用stefan the teacher @ melena or dot com
这只是一个服务，供我获得一个临时的电子邮件
所以我输入stefan the teacher
嗯，然后点击go
然后我会得到一个公共的收件箱，它将从这个地址接收邮件
好的 所以我们要创建这个
正如我们看到的这里
我们可以设置一个订阅过滤器策略
这是可选的
但通过此策略我们可以过滤将要发送到订阅的消息
这可能非常有帮助
如果你有很多订阅者
他们只需要接收你SQ发送到主题中的消息子集
但我们现在不会设置它
所以我们会创建一个订阅
现在我们需要
嗯 验证订阅
正如你所看到的
它目前正在等待确认，所以要确认它
我将进入我的邮件
我收到了一封电子邮件
通过点击此确认订阅
我将确认我的订阅
好吧，我们继续 现在我刷新这个页面
我应该看到的是我的订阅在这里被确认
这完美
再次 如果我点击我的订阅
我可以查看它
看到它将向这个端点发送电子邮件
如果我想这样做
我可以有一个订阅过滤策略
但现在我们没有任何消息
因为我们希望所有发送到我的主题的消息都能直接进入这个描述
现在让我们做一个测试
我们将发布一条消息
我将输入一个结构
我说你好
焊接 这是非常常见的
当我们测试一些服务时
然后发布消息
所以消息已经发布到我的第一个主题中
所以我应该看到的是
如果我回到我的电子邮件并去我的 uh
公开消息 所以回到收件箱
我应该看到是的
一个通知消息直接来自
S 说
你好，世界 他们容易
非常酷 它只表明 s 在为我们工作
所以这完美 我们准备好了
如果我们想要实现 sqs 扇出模式
我们需要选择 sqs 并设置许多
许多不同的队列作为我们主题的订阅接收者
是的 这就是 s
当你完成 删除订阅
然后回到左边的主题
然后点击删除
删除我然后您就走了
这就是 ea s 我希望你喜欢它 我会在下一节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/023_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p23 16. Kinesis Overview.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


欢迎来到关于kinesis的这一部分
所以，你能通过认证开发者考试是某些东西你需要深入了解
所以我将花很多时间描述每个服务是如何工作的
以真正给你那种深入的专业知识
以便让你在考试中拿到最多的分数
所以让我们从kinesis的概述开始
你可以将系统活动收集起来
在实时处理和分析流数据
所以实时数据可以是任何东西
例如应用程序日志
度量 网站点击流
iOS遥测数据
只要数据生成速度快
并且在实时这被视为实时数据流
所以有四个服务组成kinesis
有kinesis数据流将深入探索捕获、处理和存储数据流
有kinesis数据火候将数据流加载到aws的数据存储中
但也在aws之外
有kinesis数据分析用于分析数据流
使用sql语言或Apache Flink
最后，考试中不会显示的服务是
但值得提及的是Kinesis视频流，用于捕获、处理和存储视频流
这仅仅是一个非常高层次的概述
在下一讲中 我们将逐一探索这些服务
并确保我们对它们有足够的了解 所以我在下一讲中见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/024_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p24 17. Kinesis Data Streams Overview.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以第一个服务你需要了解的是
你可以看到数据流并且你可以看到数据流
这是你系统流式传输大数据的一种方式
所以kinesis数据流由多个分片组成，分片按顺序编号，从1到n
从1到2 一直到编号n
这是您需要在开始时配置的东西
所以当你开始使用kinesis数据流时
你说：嗨 我想要一个包含6个分片的流
因此数据将分布在所有分片上
好的 分片将定义您的流容量
在摄入和消费率方面
所以现在
我们先从这个开始 然后我们有生产者
生产者将数据发送到kinesis数据流
生产者可以是多种形式
它们可以是应用程序
它们可以是客户端
例如桌面和移动客户端
它们可以依赖AWS SDK在非常低的级别
或者使用更高级的kinesis生产者库kpl
我们将在下一讲中对生产者进行更深入的了解
或者它是服务器上的kinesis代理，用于将数据流
例如，将应用程序日志流式传输到kinesis数据流
所以所有这些生产者都做同样的事情，它们依赖于SDK在非常低的级别 并将记录发送到kinesis到流
所以记录在根本上由两件事物组成
它由分区键组成
并且它由数据块或值组成，最大值为1MB
分区键将确定记录将发送到哪个分片
而数据块是值本身
所以当生产者将数据发送到
你可以看到数据流时
它们可以以每秒1MB或每秒1000条消息的速度发送数据
如果你有6个分片，你将得到6MB/秒或6,000条消息的总秒数
好的 一旦数据被发送到kinesis数据流中
它可以被多个消费者消费
这些消费者也可以有多种形式
我们将在本节中详细探讨它们
所以，我们有应用程序 它们可能依赖于SDK
或者它们可能依赖于更高级的库
我们将在本节中详细探讨它们
所以，我们有应用程序
它们可能依赖于SDK
或者它们可能依赖于更高级的库
或者从高层次来看，kinesis客户端库
所以kcl它们可以是lambda函数
如果你想在kinesis数据流上实现无服务器处理
它也可以是 你能看到数据火炬车
正如我们在本节中看到的
或者你可以帮助数据分析
所以当消费者接收到一个记录
它再次接收到分区键
还有序列号
它代表了记录在分片中的位置
以及数据块
因此数据本身
现在我们有不同的消费模式来处理kinesis数据流
我们有每个分片共享的2兆字节/秒的吞吐量
好的 或者你每条消费者得到2兆字节/秒
如果你启用了增强型消费者模式
增强型扇出 所以我们将在本节中更详细地查看它
所以再次，生产者发送数据
你可以看到数据流
它保持在那里一段时间
然后由许多不同消费者读取
好的 一些属性
你可以看到数据流 第一个是保留时间可以设置为一天到三百六十五
五天 这意味着默认情况下你有重新处理或重放数据的能力
一旦数据被插入到kinesis中
它无法被删除
这就是不可变性
另外，当你将消息发送到kinesis数据流时
你添加一个分区键
具有相同分区键的消息将发送到同一个分片
并且这给你提供了基于键的排序
对于生产者，你可以使用SDK发送数据
你可以使用kpl或kag库
对于消费者，你可以编写自己的
所以kinesis客户端库kcl或SDK
或者你可以使用aws管理的消费者
例如aos lambda
你可以是数据火炬车
或者你可以帮助数据分析
对于容量模式，你有两个选项
第一个是kinesis数据流的历史容量模式
它被称为预定容量模式
所以你选择一个预定的分片数量
然后你可以手动扩展或使用API
每个碎片
你能看到流将每秒获得1兆字节
或者每秒1,000条记录
然后对于输出吞吐量
每个碎片将获得每秒2兆字节
这适用于经典或扇出消费者
您还需要为每个碎片按小时支付费用
因此您需要在事先考虑很多
这就是为什么它被称为预留模式
但第二种模式是一种新的模式
被称为按需模式
在这种模式下，您不需要预留或管理容量
这意味着容量将随时间调整
按需 您将获得默认的容量预留
这是4兆字节/秒或4,000条记录/秒
然后进行自动扩展
基于过去30天的观察到的吞吐量峰值
在这种模式下，您仍然需要按流/小时和按入/出数据付费
每千字节 所以这是不同定价模式
如果您不知道您的容量事件，选择按需
但如果您可以规划容量事件
您应该选择预留模式
对于Kenny的数据流，安全性
它部署在区域中
因此您可以控制对碎片的写入和读取访问
使用IAM策略
有在飞行中的加密
使用HTTPS和存储中的加密
使用KMS
您可以在客户端侧实现自己的数据加密和解密
称为客户端加密
这更难实现
因为您需要自己加密和解密数据
但这增强了安全性
VPC端点适用于Kinesis
这允许您直接从私有子网中的EC two实例访问Kinesis
而不通过互联网 最后，所有API调用都可以使用CloudTrail进行监控
这就是Kinesis数据流的概述
我希望你喜欢它
我将在下次讲座中更深入地探讨 所有移动部件 你能看到数据流
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/025_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p25 18. Kinesis Producers.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在让我们谈谈如何将数据放入kinesi
我们将利用Kinesis生产者来实现这一点。
因此它们被用来将我们的数据流中的数据发送出去
并且一个数据记录 正如我们所说
由分区键内的分片内的唯一序列号组成
分区键也是
我们必须指定哪一个
当我们将记录放入流中
并且数据块可以高达一兆字节
生产者可以是从 sdk 到创建一个非常简单的生产者的任何东西
使用Kinesis生产库
KPL（王者荣耀职业联赛） 它支持多种语言，如C
加加或Java
它是建立在sdk之上的
但是，它提供了一些高级功能作为API
所以 例如 批量处理
压缩和重试
Kinesis代理是另一种将数据发送到Kinesis的方式
它基于Kinesis库构建
这将用于监控日志文件并将它们流式传输到您的Can
我们使用数据流来考虑吞吐量
我们已经知道这一点 我们可以得到每秒一兆字节或每秒每个扇区一千个记录
将数据发送到Kinesis的API称为Put Record API
如果我们使用预记录API进行批处理
我们可以降低成本从而增加吞吐量
这是做kinesis产生的名人已经为我们做的事情
所以如果我们看看生产者的一面
我们有一个流，假设有六个分区
我们有一些生产者
例如物联网设备
它们将以每秒一兆字节的速度发送数据
或者每秒每ch十或一千条记录
假设我们有一个设备id 111222333
所以它会产生一些数据
我们选择将分区键选为设备id
所以你可以看到分区键在这种情况下是一个设备ID
那么会发生什么？它会通过一个哈希函数
这是一个数学函数，它会作为输入
分区键
并确定将数据发送到哪个碎片
例如，它发送到碎片1
感谢哈希函数
这意味着所有共享相同分区键的数据
将发送到同一碎片
所以所有设备ID的数据都将结束在碎片1上
如果你有一个第二设备ID，有一个不同的设备ID，那么就是四四四四
四五 六六
那么数据块将具有不同的分区键
但它将通过相同的哈希函数
这次哈希函数可能决定将此数据发送到分区二
这意味着设备ID会将所有数据发送到分区二
这就是如何产生
两个可以帮助数据流分区键
正如你所见，如果一台设备非常活跃并发送大量数据
可能会淹没一个分区
此外 你需要确保你的分区键分布得很好，以避免热点分区的概念
因为这样你将有一个分区的吞吐量比其它的多
这会带来一些不平衡
所以你需要考虑一个权重
你有一个分布式分区键
例如 如果你有六个分区和1万个用户
用户ID分布得很好
但如果你有六个分区并且只看Chrome
Firefox和Safari作为网络浏览器
并且网络浏览器的名称作为分区键
那么它会非常热
可能对于Chrome 因为世界上有很多Chrome用户，而不是Firefox或Safari
谁知道呢 所以你需要确保使用分布式分区键
这导致了超额提供吞吐量异常
当我们从我们的应用程序产生数据流时
我们知道我们可以每秒产生1MB或每秒1000个记录
并且只要我们这样做
一切都好
但如果我们开始向一个分区过度产生
我们会得到一个异常
因为我们超过了提供的吞吐量
所以我们得到一个提供的吞吐量超额异常
解决这个问题的方法一是确保你正在使用一个高度分布式的分区键
因为如果不这样 那么这个异常会发生很多
我们需要实现重试与指数后退
以确保我们可以重试这些异常
并且这在考试中会出现
最后你需要扩展分区
也许被称为分区分裂以将分区一分为二
并增加吞吐量
并且我们将在将来的讲座中看到分区分裂
但是，通过增加碎片的数量
这可以帮助解决吞吐量异常
显然，因为如果你从六个碎片增加到七个碎片
我们在字符串中又多了一个兆字节/秒
这就是这节课的内容
希望你喜欢 我将在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/026_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p26 19. Kinesis Consumers.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈使用kinesis data streams的消费者
消费者从流中获取记录并进行处理
消费者可以是lambda函数
它们可以是数据分析
你可以看到火喉
使用SDK的自定义消费者，有两种模式
经典或增强型扇出和kinesis客户端库
这是一个用于简化从数据流中读取的库
我有一个专门的讲座，关于kinesis客户端库
所以让我们讨论经典共享扇出消费者和增强型消费者之间的区别
当你以经典的共享吞吐量方式为你的用户编写代码时
你有一个拥有许多切片的Kinesis数据流
并且你可以在每个切片上获得每秒2兆字节的吞吐量，所有消费者共享
这意味着如果你查看切片1
仅作为例子
我们可以编写一个消费者应用程序a
它将发出获取记录API调用从切片1获取记录
但我们可能有许多不同的应用程序
从同一个Kinesis数据流读取
因此，消费者应用程序b也会发出获取记录的调用
API调用 消费者应用C也会发出获取记录的请求，涉及所有消费者
在这种情况下，他们都共享每秒两兆字节的数据
涉及所有消费者
这意味着在这种情况下，我们三个消费者共享每秒两兆字节的数据
这意味着每个消费者最多可以获取大约660
6千字节每秒的数据
因此，我们可以看到，消费者数量的上限是有限的
我们添加的消费者应用程序数量越多，可以观察到的流越多
我们将有越多的吞吐量限制
这使我们进入了AWS最近引入的一种新的消费模式
这种模式被称为增强型扇出消费者
在这种情况下，我们每消费者每分区可以获得每秒2兆字节
这不是所有消费者的
这是每消费者每分区
这意味着消费者应用程序A
我们将使用名为订阅分区的新API
这将使分区发送数据
以每秒2兆字节的速度将数据推送到我们的消费者应用程序A
如果第二个消费者应用程序B选择另一个订阅分区
然后，这款消费者应用也会收到由分片推送的数据
以每秒两兆字节的速度将数据推送到消费者应用
因此消费者可以看到，正如我们所看到的
我们有三个消费者应用
对于这一个分片，我们获得了每秒六兆字节的吞吐量
在第一种模型中，我们有一个拉取模型
在第二种模型中，我们有一个推送模型
所以，让我们总结一下经典的共享扇出消费者拉取模型
它给你一个较低的
当你有较少的消费应用时，这是一个好的选择
读取吞吐量每秒每帧为两兆字节，所有消费者共享
每分区的最大获取记录数为5次
每秒API调用
API调用延迟大约为200毫秒
当你希望最小化成本时，可以使用此功能
消费者将直接从Canny获取记录
API调用 返回数据最大可达10兆字节
如果超过10,000条记录，则会在5秒内限制
因此，如果我们使用增强型扇出消费者
这是一个推送方法
我们可以从同一个流中获取多个消费应用
每个消费者将每分区每秒获得2兆字节
延迟将大大降低
因为分区本身会将数据推送到我们的消费者，所以延迟为17毫秒
成本更高
这是aws中会花费更多的特性
数据
如我所说 使用HTTP2流式传输方法进行推送
最后，每天最多可以运行五个消费者应用
你可以通过在aws上提交一张票来增加这个数量
最后，我们还没有深入研究lambda
但这是你在不使用服务器的情况下消费数据的一种方式
我们有kinesis流，并且说它有三个分区
所以我们将有lambda函数
它们的作用是处理记录并将记录保存到dynamodb中
这是一个无服务器的数据库
所以lambda函数将调用
获取批次到流
数据将按分区键发送到我们的lambda函数进行处理
lambda函数随后可以将数据发送到o db
我们有一种使用无服务器机制处理流的方式
所以在这个例子中
lambda函数支持经典和增强型扇出消费模式
你可以选择你想要从数据流中消费数据的方式
它会以批处理的方式读取记录
你可以配置批处理大小和批处理窗口
如果在处理过程中出现错误
lambda函数会重试直到成功
或者数据将在
可以查看数据流
您也可以同时处理每个碎片最多十个批次
所以我们将在lambda中查看
在lambda函数中查看详细信息
所以不要太担心 如果你不理解我刚才说的话
但是，尽管如此 我们已经在kinesis数据流中看到了消费者
让我们继续进行实践，真正获得些实践经验 你能看到数据流吗 所以下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/027_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p27 20. Kinesis Data Streams Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们开始练习吧
你能帮助数据流吗
我将打开罐装服务并创建我们的第一个
你能看到数据流吗 正如我们所见，这里有三个选项
我们可以使用数据流
数据火炬或数据分析
但我们目前只知道数据流
那么我们开始吧 我们获取一些关于定价的信息
那就是每片我们支付零点
零一五美元每小时
好的 然后有发送数据到kinesis数据流的成本
所以我们创建一个数据流
让我们给我们的流起个名字叫demo stream
然后我们必须定义数据流容量
正如你所见，我们有两种模式
我们有 按需模式和预留模式
在按需模式下
你不必考虑容量
它将自动为你扩展
因此最大吞吐量为每秒200兆字节
和每秒20万条记录
最大容量为每秒400兆字节的消费者
如果您使用增强型扇出选项
按需模式为吞吐量定价模型
但没有免费层
好的 在预留模式下也没有免费层
在预留模式下，您需要分配扇区
因此有扇区估算工具
如果您想了解您需要多少扇区基于
您每秒发送的记录数量
以及记录的大小
以及您有多少消费者
好的 但在我们的例子中
我们将设置一个扇区
一个扇区给我们每秒1兆字节的写入
和每秒2兆字节的读取
当然，如果您有10个扇区
所有事情都会乘以10
好的，一个扇区对我们做演示足够了
这也是我们能得到的最便宜的选项
如果您不想为此支付任何费用
那么不要参加这个实践课程，因为你会为你的扇区支付一些费用
尽管我们会处理并迅速删除它
所以当你准备好
你只需点击创建数据流
然后你等待流被创建
我们的流现在已经成功创建
在应用方面我们可以看到
我们有生产者 我们被推荐了三个选项
kinesis代理
SDK或kinesis生产库
这些都可以在github上找到
这是一个将数据从应用程序服务器流式传输到的方法
你可以使用这个数据流
SDK免费开发生产者到很低的级别
kpl是为了你开发生产者到一个很高的级别有一个更好的API
在消费者方面我们得到
你可以看到数据分析
你可以看到数据火枪
或kis客户端库或lambda
这不是这里显示的选项
好的 我们得到一些关于我们的
监控信息 你可以看到数据流 所以你可以看到我们发送的记录
我们可以看配置
如果你想扩展流
我们可以说我们想要多少
我们可以从一到说五扩展我们的canis在流
我们可以添加一些标签
然后我们可以使用增强的扇出并配置它
如果我们想要有一些消费者应用程序利用增强的扇出能力
但现在让我们保持简单
我们只想写和读我们的流
所以我们想要使用SDK生产消费
所以因此我们要打开一个cli
让我们使用云壳
因为它很有趣 所以我要点击云壳在这里
这是铃铛图标旁边的图标
这会为我打开
一个命令行界面在aws作为一个替代
你可以使用你自己的终端或cli
如果它已经配置 但我喜欢切换东西
这个我真的很喜欢因为没有多少配置
至少创建环境
第一次可能需要一些时间
云壳在aws是免费的
所以没有在这里
与此同时
在kinesis
打开kinesis数据流中的sh文件，我们将使用这个整体
所以，向流中写入命令有两种类型
根据你的cli版本，通常你已经安装了版本二
但你可能无意中安装了版本一
然后你获取版本
你只需输入aws version并粘贴
然后你会得到一些关于aws cli版本的信息，所以，在云shell中
将要安装的cli版本是版本二
如你所见
cli版本二点一六
我们将使用cli命令版本二
但如果你想使用版本一
那么你将使用这些命令
好的 现在我们可以开始了
我们首先要做的事情是将记录发送到我们的kinesis数据流中
为此有一个名为put record和put records的api
我们需要指定一个流名
例如，我没有将我的流命名为test
我命名为demo stream
所以我们需要在cli命令中更改这一点
但你明白了
然后你指定数据的分区键
你设置 所以user one并且记住，具有相同分区键的数据将发送到同一扇区
但我们只有一块扇区
所以这不重要
然后数据本身
用户注册
最后，因为我们正在写一些文本数据
我们需要说这个选项
cli二进制格式
raw n base sixty four out
好的 所以让我们粘贴这个命令
所以复制并粘贴
但让我先编辑流名以确保它是demo stream
云shell会自动配置为你自己的i凭据
所以它将继承你的i凭据
并且我们也将使用默认区域
它在哪个区域启动 所以us east one我按回车
现在我得到一个成功的消息
所以消息发送到了扇区id零零零零零零
这是他们的第一个扇区
消息的序列号在这里
如果我再做一次
我将得到一个第二条消息
带有成功的
所以，我们可以做用户注册
我们可以混合消息
然后用户登录
然后可能用户注销
所以我们只是 我们只是向kinesis数据流发送几条消息，完美
所以我要清除这个
如果你稍等片刻，然后进入监控并查看流指标
我会让它在一个小时内
你会在这里看到一个写入记录
但是需要一些时间才能让云观察指标更新
但是你在这里可以看到
好的 接下来我们希望能够从我们的kinesis数据流中消费
为了做到这一点 我们将首先创建
描述流以获取有关此流构成的一些信息
因为我们需要从特定的分片消费
因为它正在演示
我将按下回车键
正如你所看到的
我们有流描述
我们有一个名为 shard id zero zero zero zero zero 的片段
所以我们需要将这一点铭记在心
以便能够从流中读取
当你使用 CLI、SDK 时，在最低层次上
你需要指定你从哪个片段读取
但如果你使用 Kinesis 客户库
这一切都由库本身处理
但我们使用 CLI
所以我们必须指定片段 ID
所以我按q退出这个
我将会消费一些数据
所以我将运行这里的命令，让我清除这个
这里有两件事需要注意
第一 我需要更改流名
我从中消费 所以demo stream是一个流
然后shard iterator类型是trim horizon
这意味着你将从流的开始读取
所以，它将读取从开始发送的所有记录
另一种选择就是确保只接收从那一刻起发送的记录
从新发布开始，无论怎样
所以我要按回车
然后这将给我一个分片迭代器 这个分片迭代器可以用来
我们消费记录
所以下一个API是 你可以获取记录吗
流迭代器
然后我们只需指定这里的整个字符串
所以，我现在使用低级API描述流，进行消费的方式
获取流迭代器并获取记录，使用的是共享消费模型
这不是使用增强型扇出
在我看来，应该使用Kinesis客户端库
消费者库，以便你真正可以利用它
并且有一个很好的API来实现
但这是低级的
所以点击并按下Kinesis获取记录
然后我们从中获得一批记录
所以我们有记录一在这里
这是patchi用户一
我们有一些数据在这里
但它是base64编码的
我们又有另一个数据base64编码
我们得到一些时间戳信息
另一个数据base64编码
然后我按下Enter
它会稍微向下移动
一些更多的base64编码的数据，所以只是为了确保我们可以读取数据
我可以去网站
在线base64解码
我将把这个数据粘贴在这里
到base64解码并点击解码
这给我们用户注册
如果我粘贴第二种类型的数据
这将给我用户登录
这就是我们发送的内容
那太好了 一切都正常工作
然后你可以看到
这里有一个下一个流迭代器参数
所以下次我们消费时
我们需要指定这个下一个流迭代器参数来消费
我们从哪里停止消费
所以这是在你代码中需要迭代的东西
但在低级别上
我们已经将数据发送到can see数据流并消费来自Kenny的数据流
这太棒了
我们也同时使用了云Shell
我认为这非常有用
这就是这个演示的全部内容
保持流打开，因为我们将在下一秒使用Kinesis数据
Firehose
我会在下一节课见到你 再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/028_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p28 21. Kinesis Client Library.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在让我们讨论一下
你能理解气候变化吗
所以这是一个考试可能会问你一个问题
所以让我们看看它是如何工作的
并且问题 这是一个Java库，帮助您从Kinesis数据流中读取记录
与共享读取工作负载的分布式应用程序一起使用
每个分片只被一个KCL实例读取
这意味着如果您有四个分片
您将最多有四个KCL实例
如果您有六个分片 您将最多有六个KCL实例
如果我只说您已经准备好参加考试
但我想解释它确切的工作方式
这样您就可以了解KCL库的工作方式
库将从我们的Kinesis数据流中读取
读取进度将记录在DynamoDB中
因此，您运行Cassia的应用程序需要访问DynamoDB
它将能够
多亏了DynamoDB，您可以跟踪其他KCL应用程序的工作者 并分享分片中的工作
您可以看到我可以在任何地方运行
但您可以在E
C上运行
C实例，带有E C实例角色
您的Elastic Beanstalk应用程序 或者在本地服务器上运行
只要它们具有正确的凭据
记录将按顺序读取
并且在分片级别上，当然
Kinesis库有两种版本
版本一仅支持共享消费者，版本二KCL支持共享和增强型最终消费者远程
因此，如果我们看四个分片进入流
我们可以有一个DynamoDB表来检查进度
并且我们可以运行两个KCL应用程序，同一个相容应用程序
运行在两个不同的E
C实例上
多亏了DynamoDB，他们将知道如何共享工作
第一个KCL应用程序将从分片1和2读取 第二个KCL应用程序将从分片3和4读取
现在，应用程序从数据流中读取的进度
将记录在DynamoDB中
例如，如果其中一个应用程序崩溃
那么DynamoDB和KCL应用程序将知道应用程序将崩溃
现在，应用程序从数据流中读取的进度
将记录在DynamoDB中
因此，如果一个应用程序崩溃
那么DynamoDB和KCL应用程序将知道应用程序将崩溃
现在，应用程序从数据流中读取的进度
因此，从其他碎片中读取将从检查点处继续
即使你扩展规模，这也会起作用
所以，如果你有四个碎片
而现在你运行四个kcl应用程序
那么它将从每个碎片中读取一个
因此，进度将从dynamodb中恢复并再次检查点
所以你可以看到这是如何工作的，对吧
但我们不能拥有更多的kcl应用程序和碎片，因为
否则一个将什么也不做，所以如果你想按比例读取kinesis
你可以扩展kinesis并添加六个碎片
所以现在我们还有四个kl应用程序
但现在我们有六个碎片在kinesis数据流中
因此，他们将检测到这种变化
并且与an mob一起工作
他们将再次将工作分配给每个kcl应用程序和碎片分配
这意味着一旦我们有六个尝试在kinesis数据流中
那么我们就可以有六个ccl应用程序
从中读取并将进度检查点为mobb
如果你理解了这一点
那么你就可以为考试回答问题
这就是这节课的内容 我希望你喜欢它 我将在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/029_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p29 22. Kinesis Operations.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以，关于如何扩展kinesis的简短讲座
我们谈论的是分片拆分和分片合并
分片拆分用于将一个分片拆分为两个
这意味着我们有更多的分片
因此，用于增加流能力
如果我们通过拆分分片添加更多分片
我们将获得一个额外的每秒百万字节的吞吐量
因此，用于 例如
当你想要分割一个热点分片时
例如 分片2非常热
大量的数据发送到它
我们将拆分分片
我们将得到分片4和5
通过这些新的分片
我们已经将流吞吐量从每秒三千万字节
增加到每秒四千万字节
因此，我们增加了容量
当然 但是，因为我们是根据分片的数量来构建的
我们还增加了kinesis数据流的成本
旧的分片将不再写入
因此，分片2将不再写入
并且旧数据将在一段时间后过期
因此，根据您的保留期
从一天到365天
您需要等待这么长时间
然后数据将过期
最后，将删除分片
没有自动扩展kinesis数据流
尽管您可以找到一种方法来创建自己的自动扩展
并且有解决方案架构
但是，没有设置可以自动扩展kinesis数据流
因此，您需要手动增加或减少容量
并且您不能在一次操作中将分片拆分为两个以上的分片
如果您需要这样做
您需要执行多次分片拆分
分片合并是分片拆分的相反操作
因此，您意识到您想要减少容量并节省成本
在这种情况下，您可以将两个低流量分片分组
因此，冷分片并将它们合并为一个新分片
因此，例如 分片1和4合并为分片6
并且用于减少容量和成本
然后，旧的分片将不再写入
并且一旦数据过期，将删除分片
在分片中 您不能在一次操作中将两个以上的分片合并
并且分片拆分和分片合并
你已经知道如何扩展和缩小Kinesis
就是这样 这就是你所需要知道的全部
我希望你喜欢这节课 我会在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/030_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p30 23. Kinesis Data Firehose Overview.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来学习一个新的服务，kinesis data firehose
这是一个非常有帮助的服务，可以从生产者那里获取数据，生产者
可以是我们所看到的数据流的一切
所以应用程序客户端SDK在所有情况下
代理都可以将数据发送到kinesis data firehose
但是，你也可以看到数据流可以发送到数据火炬
Amazon云观察日志和事件可以发送到kis数据火炬
所有这些应用程序都将数据发送到kinesis数据火炬
然后，我可以选择使用lambda函数转换数据，但这是可选的
但是，这不是必须的
一旦数据被转换（可选）
然后它可以分批写入目的地
所以你可以看到数据火喉
从源头获取数据
通常最常见的是canis数据流
并将数据写入目的地
无需编写任何代码
因为火喉知道如何写入数据
肯尼的数据火喉有三种目的地类型
第一类是aws目的地
你必须把它们记在心里
第一个是亚马逊S3
你可以将所有数据写入亚马逊S3
第二个是亚马逊红移
这是一个数据仓库数据库
要做到这一点
首先将数据写入亚马逊S3
然后您可以看到数据火炬将发出复制命令
这个复制命令将把数据从亚马逊S3复制到亚马逊红移
在AWS的最后一个目的地叫做亚马逊开放搜索
也有一些第三方合作伙伴的目的地
所以你可以看到数据流可以向datadog发送数据
Splunk 新 relic mongodb
并且这个列表可能会随着时间的推移越来越大
所以我不会更新这个
如果有新的合伙人
但是只是你知道 有一些合作伙伴可以看到数据
我托管可以向发送数据
或者最后如果你有自己的API具有HTTP端点
这是为了将数据发送到Kennis的数据管道中
将数据发送到自定义目的地
好的 一旦数据发送到所有这些目的地
您有两个选项 您也可以将所有数据发送到S3桶
作为备份
或者只将未能写入这些目的地的数据发送到失败的
S3桶
所以总结一下Kinesis数据
Firehose 是一个完全管理的服务
因此没有管理
自动扩展
并且是无服务器的 因此不需要管理服务器
您可以将数据发送到 AWS 的目的地
例如 Redshift
亚马逊 S3 和 Open Search
第三方合作伙伴
例如 Plank MongoDB
Datadog New Relic
等等
并且可以发送到任何 HTTP 终端
您将只支付通过 Firehose 传输的数据费用
因此这是一个非常好的数据
嗯 紧迫模型
并且是接近实时的
为什么,因为我们将数据以批处理方式从 Firehose 写入到目的地
因此会有缓冲间隔
要么是零秒并且您已禁用缓冲
或者您将其设置为更高的数字
然后您会有缓冲并且可以设置高达 900 秒
并且如果您有缓冲
您也应该指定缓冲大小
因此最小值为 1 MB
并且可以设置为更高的值
因此如果您有缓冲
这使得数据 Firehose 成为接近实时的服务
并且如果您没有缓冲
如果您的缓冲间隔为零秒
仍然会被认为是接近实时的
因为它需要几秒将数据发送到目的地
它支持多种数据格式
转换 压缩和压缩
并且您可以使用 Lambda 编写自己的数据转换
如果您需要的话 最后您可以将所有失败的数据或所有数据发送到备份 S3 桶
因此考试中通常会问到一个问题是理解何时使用
您可以看到数据流
以及您可以看到数据 Firehose
因此对于您来说应该很容易
如果您密切关注
但是让我们总结一下 您可以看到数据流是一个流式服务，用于大规模摄入数据
并且您需要编写自己的定制代码来生产者和消费者
这是真实时间，所以200毫秒或70毫秒
您需要自己管理扩展
您需要执行分区分裂和合并以增加规模和吞吐量
您还需要支付您所配置的能力的费用
数据存储在数据流中可以是1到365天
这允许多个消费者从同一流中读取
它还支持重放功能
而您可以看到数据火炬是一个摄入服务
将数据导入S3、Redshift、OpenSearch或第三方自定义HTTP
这是完全管理的
无需管理服务器 这接近实时
所以记住接近实时是一个关键词
您需要在考试问题中查看
有自动扩展
因此您无需担心
您只需支付通过数量
您可以看到数据火炬
没有数据存储
因此您无法从Kis数据火炬中重放数据
是的 它不支持重放能力
这就是概述的全部
您可以看到数据火炬
我希望这有道理 我将在下次讲座见到您
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/031_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p31 24. Kinesis Data Firehose Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 让我们练习使用kinesis数据火烈鸟
使用交付流
所以我点击交付流
在这里我可以创建一个交付流
在这里我们有详细的图表说明这个数据
如何工作 所以我们从生产者中摄入数据
这些生产者可以是kinesis数据流
这是我们的使用案例
或者可以通过kinesis数据代理进行直接插入
这些代理
其他服务
例如云观察 物联网核心
Ibridge 等等
以及使用SDK通过你自己的应用程序发送数据
一旦我们摄入了数据
我们可以转换
使用lambda函数转换它 这可以用来做很多事情
例如转换记录格式等等
然后将数据加载到目标存储中
所以我们有亚马逊s3
亚马逊开放搜索服务
这是elasticsearch被重命名的
以及亚马逊红移和各种类型的http终点
所以在这个例子中
我们的来源将是kinesis数据流
而目的地将是亚马逊s3
但请注意我们有开源服务
所以elasticsearch红移s3
你需要记住这三个
然后我们有一些第三方服务
所以你不需要记住所有或任何
但请记住有第三方服务
或任何自定义http终点
你可以选择
所以我们选择亚马逊s3
对于来源我们需要浏览并选择我们的流
所以我们有ar流在这里
这很好 然后交付名称会自动生成
这很好
现在我们进入转换和转换记录部分
这是可选的
但我们想使用lambda转换社会工作者吗
在这里我们可以转换过滤
解压缩转换源记录
所以这些函数只是代码片段
你可以在aws中运行它们
它们可以在数据被kinesis数据发送到firehose之前执行任何操作
所以这非常有用 如果你启用了它
那么你需要选择一个lambda函数
好的，下一个
转换记录格式选项
所以根据你将数据发送到的地方
这可能有用，可以将这些记录转换为parquet或orc
基于某些高级选项
这不是本课程的范围
但请记住，你可以使用kinesis data firehose转换记录格式
现在，这更详细地涉及aws的数据和分析认证
目前
只需知道在高层次上，你可以转换记录格式
下一个，我们需要选择一个目的地 所以我们可以选择我们之前创建的s three桶
或者创建一个新的
对我来说
我已经创建了一个s three桶
所以我会使用这个
所以demo firehose stefan v three
我会选择这个
但请随意创建一个新的桶或者选择一个现有的
你想要分区吗
现在，我们会说没有
免费桶前缀
所以我们想要一个数据前缀
现在，我们不需要
我们也想要一个错误输出前缀
如果我们需要
如果我们想要一个错误前缀
但是再次 我们现在不需要
我们会保持非常简单 现在更重要的是缓冲提示，压缩和加密
所以缓冲是kinesis data firehose在将数据发送到目标之前积累记录的方式 在将数据发送到目标之前，kinesis会写5兆字节的数据到缓冲区
默认情况下 然后发送到目标，比如amazon s three
你可以调整缓冲大小
现在，你可以调整缓冲大小
以适应你的需求
所以，你可以根据你的需求调整缓冲大小
以适应你的需求
所以，你可以根据你的需求调整缓冲大小
以适应你的需求
所以，你可以根据你的需求调整缓冲大小
缓冲区对于1和2个8兆字节更有效率
如果你想获得更大的缓冲区大小和更高的效率或较小的缓冲区大小
如果你想以最快的速度传递数据
那么我们将其设置为1
然后是缓冲间隔
所以这是多快
如果缓冲区没有填满
应该多快 应该将其flush到目标
所以如果你选择为1秒
它将等待5分钟来填充缓冲区大小
但如果在5分钟后缓冲区仍未填满
那么它仍然会被刷新
因此如果我们设置一个较低的缓冲接口
例如60秒
我们可以保证最多每60秒
缓冲区将被刷新到亚马逊云
如果我们设置一个非常长的缓冲区大小
例如
900秒 然后我们需要等待
我认为在缓冲被冲入亚马逊街之前需要等待15分钟
所以需要等待更长的时间
为了这次演示的目的
我们不想有效率 我们希望快速
所以我们选择60秒
这是下一个最小值
我们希望启用压缩和加密
以便可以在目标中压缩记录
例如使用gzip或snappy压缩
支持gzip或snappy的压缩
想法是您将
嗯 节省一些空间
因为你在将数据存储到亚马逊S3之前会压缩数据
从而节省一些成本
你也想对你的记录进行加密
是或不是
有一些高级设置
但是，对你来说非常重要的是，你需要看到这项权限
所以这将会自动创建
一个名为此的角色
并且这个i am角色将具有写入到亚马逊所需的所有权限
S free 这就是
火候是如何能够写入目标桶的
并且从数据流中读取
所以让我们创建这个交付流
并且它是活跃的
所以我们可以看一些指标
所以更多的数据会通过肯尼的数据
如果我用 这些指标会越多
这在生产中非常有帮助
你可以查看配置
但我们已经做过了
然后我们可以看看空气日志的目的地
目前这是云日志
好的 所以我们这里有一个
你能看到数据流吗
我们需要测试数据流过它
所以你可以使用这里的测试数据来测试它是否进入亚马逊s3
但我们不想使用这个
实际上因为我们有亚马逊can数据流
让我们也使用这个
所以我的案例数据流在这里被命名为demo stream
我们将向其发送更多数据
因为我们已经创建了火喉输送流
即使过去有一些数据发送到了肯尼斯数据流
实际上在设置火喉后你需要发送新数据才能使火喉活跃
那么我们就使用云外壳
我们将使用这里的命令
所以我们必须修改这个
并确保你有正确的流名称
我今天有demo流
你注册
这是好的 然后粘贴这个命令
我们按回车
数据已发送
所以我们有用户注册
然后我们有用户登录
然后我们会有用户
注意
好的 所以有三条记录已经发送
我现在可以做的是进入亚马逊s三
看看它们是否出现在亚马逊的s3中
让我们进入三台控制台
我要输入火栓
我找到了我的桶
如你所见 目前我的桶中没有任何对象
那是因为感谢的数据
火栓有一个60秒的缓冲区
所以我们需要等待60秒，直到数据被加载到亚马逊s3中
所以让我们等等 我将暂停视频
好的 已经超过六十秒了
所以我要刷新
如你所见，物品已经出现在我的亚马逊免费桶中，我可以点击
点击点击，它会按日期等分类
在这里我有记录
所以我可以点击它
点击打开，然后打开我用文本编辑器
点击打开并用文本编辑器打开
正如你所看到的，并不是非常有趣
但我们有一个用户注册
用户登录和用户注销在同一个文本文件中
所以kenny of herhose正在运行并且运行得很好
这就是这节课的内容
我希望你喜欢它 只是为了清理它
请确保
嗯 首先删除第一个交付流
所以你需要输入名称
然后你就有了
然后最重要的是删除演示流本身
因为你让它运行
那么它每小时都会花费你钱
好的 这就是这节课的内容 我希望你喜欢它 我会在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/032_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p32 25. Kinesis Data Analytics.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈kinesis数据分析
它有两种形式
有一种适合SQL应用
另一种适合Apache Flink
我们先来谈谈第一种
即kinesis数据分析用于SQL应用
它位于中心
它能够读取的两种数据源是kinesis数据流
和kinesis数据火炬
你可以从两者中读取
然后你可以使用SQL语句来执行你的真实时间分析
你也可能通过从亚马逊引用它来加入一些参考数据。
三个水桶 这将会
例如 允许您实时丰富数据
然后你可以将数据发送到各种目的地
并且有两个它们
第一个是kinesis数据流
因此你可以从一个小型的数据分析中创建一个流
实时查询
或者可以直接发送到Kinesis数据火烈鸟
每个都有自己的用例
如果你直接发送到Kinesis数据火烈鸟
然后你可以发送到亚马逊is三
亚马逊红移或亚马逊开放搜索
或者任何其他火烈鸟目的地
而如果你将其发送到Kinesis数据流
你可以对数据流进行实时处理使用AWS
Lambda或您在运行的任何应用程序
E C 两个实例
所以记住这个图表
这是SQL应用程序的索引
如果我们深入细节
如我所说 两个来源只能看到流和火炬
您可以使用Amazon S3的数据进行丰富
这是一个完全托管的服务
你没有配置任何服务器
有自动杀死功能
你实际上为通过kinesis数据分析在输出方面支付费用
如我所说 你可以进入kenny数据流
或者kinesis数据火炬
用例可以是做时间序列和数据分析
实时仪表板或实时指标
这就是第一种完成的数据
第二种是kinesis数据分析为apache flink
正如名字所暗示的
你可以在服务中使用实际的Apache链接
如果你使用Flink
你可以使用Java、Scala甚至SQL编写你的应用程序来处理和分析
分析流数据
你可能说，好吧 这和以前一样
不是吗 但它不是
Link是需要你编写为代码的特殊应用程序
好的 它允许你实际上可以在集群上运行这些Flink应用程序
那是在Kinesis Data Analytics中专注于它
但这一切都在幕后
通过Apache Link，你可以从两个主要的数据源中读取数据。
你可以从kis数据流或亚马逊mks读取
因此，通过此服务，您可以在aws上管理的集群上运行任何flink应用程序。
想法是，这个链接将比标准SQL强大得多
所以，如果你需要高级查询能力或者读取数据
因此，要从其他服务获取流数据
或者他说嗯
你能看到流或亚马逊msk吗
这是aws管理的kafka
然后你会使用这个服务
所以使用这个服务，你将获得计算资源的自动配置
并行计算和自动扩展
你将获得应用程序备份
它们是在检查点和快照中实现的
你可以使用任何Apache链接编程功能
并且只是为了让你知道
与链接 你可以只从Kenny的数据流和亚马逊MSK读取
你不能从Canis数据Firehose读取
如果你需要从
Can you see数据Firehose读取
那么你必须使用Kinesis数据分析（SQL）
好的 这就是这节课的内容 我希望你喜欢它 我会在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/033_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p33 26. Data Ordering for Kinesis vs SQS FIFO.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们来一次讲座，讲讲数据是如何为kinesis和sqs进行排序的
第五，因为尽管这些技术看起来相似，有一些相似的能力
它们实际上非常
非常不同 那么让我们来做一个小案例研究
想象你有一百辆卡车在路上
每辆卡车都有一个卡车id
所以卡车一，卡车二一直到卡车一百，它们在路上
它们会定期将gps数据发送到aws
我们希望以每辆卡车的顺序消费那个数据
以便我们能够准确地跟踪它们的移动
我们希望知道它们的顺序，很明显
所以我们应该如何将数据发送到kinesis
答案应该是使用分区键
并且那个分区键的值是卡车id
所以卡车一会发送分区键
卡车一，卡车二会发送分区键
卡车二
等等 因为如果我们指定相同的分区键
那么相同的键总是指向同一个分区
让我们看一张图
以便更好地理解这一点
所以我们有我们的候选流
它有三个分区
一、二和三
为了简化事情
我不会显示一百辆卡车
但五个应该足够
所以我们有五辆卡车
它们在路上
它们将数据发送到kinesis
如我所说
我们选择分区键为卡车id 这意味着我的卡车一
当它发送gps数据时
它会发送它到
你能帮我设置分区键卡车一吗
kinesis会说
好的 分区键卡车一
我会哈希它
我的意思是它会进行计算
在这个例子中，它计算出卡车一应该进入分区一
所以数据会进入分区一
然后卡车二会发送它的数据
并且我们发送分区键卡车二
kinesis会查看这个分区键并说，我已经哈希了它
现在看起来你应该进入分区二
对于分区来说，卡车三也是一样的
所以卡车三会在路上，并且将其作为分区键发送
但这次，kinesis数据流服务会将卡车三作为键进行哈希
并说你应该去分区一
这没问题 它只是说不一定非得是分区三
它只是说这个分区键应该去分区一
对于卡车四来说，不是这样
它会去分区三，而对于卡车五来说
它会去分区二
所以现在我们有一个重新分区的概念，它被称为分区
它是基于每个卡车的分区键在每个分区上的名称
因为卡车一总是发送相同的分区键，即卡车一
那么数据总是去同一个分区，依此类推
卡车一的下一个数据点会在分区一
卡车三的下一个数据点也会在分区一，依此类推
所以每当卡车一发送数据
它会在分区一
而蓝色卡车，即分区三发送数据时
也会在分区一
因为我们指定使用相同的分区键
所以这里我们看到
卡车一和三的数据总是会在分区一
如果我们看分区二
只有卡车二和五的数据会在分区二
如果看分区三
在这个例子中
只有卡车四会将其数据发送到分区三
现在假设你有一百辆卡车，可能有五个分区
那么每个分区平均有二十辆卡车
但没有直接的联系
你不能告诉每辆卡车和每个分区
kinesis必须将分区键哈希以确定去哪个分区
想法是只要我们有一个稳定的分区键
那么每辆卡车都会发送到同一个分区
因此我们在每个分区的卡车数据是有序的
明白了吗？接下来
我们谈论的是sqs，所以对于sqs标准
正如我们所知，没有有序
这就是我们有sqs fifo
这是先进先出
如果我们在sqs fifo中不使用组ID
那么所有消息都将按发送顺序消费
并且我们只能拥有一个客户
在这个例子中我们有一堆选项
它们被发送到我们的sqs五q
并且按发送顺序接收
消费者会收到它们
正如我们所见，这里只有一个消费者
它消费了两批消息
第一个然后是第二个
正如我们所见，这是一个第一和第一
很容易理解
所以我们只能一个消费者
如果我们有卡车
那么所有的卡车都会发送数据到一个fifo q
但他们只能一个消费者
你想要消息被分组当他们彼此相关
所以为此我们可以使用一个组id
这与kinesis的分区键概念非常相似
所以现在使用组id
我们的fifo q会有两个组的fifo
并且对于每个组你定义
你可以有一个不同的消费者
在这个例子我们有两个组
组a和组b和两个消费者
消费者一和二可以独立阅读
组一和组二
所以这里的想法是，我们拥有的组id越多
我们可以有越多的消费者
这与kinesis是一个完全不同的模型
让我们看看 如果我们有can you uses versus sqs
我们有一百辆卡车
五个kinesis shard和一个sqs
五个四q 所以如果我们有kinesis数据流
那么平均你会有约二十辆卡车每扇区
感谢哈希
所以每辆卡车会被指定一个扇区并且会永远留在那里
卡车会在每个扇区内部有序
但我们可以同时拥有的最大消费者数量只能五个
因为我们有五个扇区并且我们需要一个消费者每个扇区这样他们能看到流
不过 因为它有五个扇区可以接收高达五兆字节每秒的数据
这是目前相当高的吞吐量
关于sqs fifo
你只能一个sqs five for q
好的 你不定义扇区或分区或任何东西
你只是有一个sqs five for q
并且因为我们有一百辆卡车
那么我们可以创建一百个组id
每个等于卡车id
并且这意味着因为我们有一百个组id
我们可以有高达一百个消费者
好的 每个消费者会连接到一个特定的组id
至于规模作为qs
五个人可以每秒处理三百零三封消息，或者三千封消息
如果我们使用批处理
所以这些都是不同模型的概念，生产，和排序
所以你必须记住，这取决于用例
有时候使用SQS FIFO会更好
如果你想要根据组ID的数量动态地设置消费者数量
有时候使用Can数据流会更好
如果你有一万辆卡车
你需要发送大量数据
并且在Can数据流中需要按分区排序数据
我希望这对你有帮助
我知道理解这些事情可能会很复杂
它们比较低级
但考试开始问你这些问题
所以我想让你非常清楚地理解这将意味着什么 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/034_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p34 27. SQS vs SNS vs Kinesis.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 所以你必须理解sqs和kinesis之间的区别
sqs有一个模型，其中消费者通过从sqs请求消息来拉取数据
一旦数据被处理
然后消费者必须从队列中删除它
这样其他消费者再也无法读取它
你可以有任意多的工作者
所以任意多的消费者
他们都一起工作来消费和删除队列中的所有消息
你不需要提前配置吞吐量，因为它是一个管理服务
它可以迅速扩展到数万个消息
如果启用了FIFO队列，则可以保证消息的顺序
类似于先进先出的队列
您还可以为每个消息设置延迟
如果您想让消息在队列中消费后过一段时间才出现
例如 我们查看S和S，延迟为30秒
这是一个不同的模式
这是一个发布/订阅模型
您可以将其推送给多个订阅者
他们会收到你发送的消息的副本
你可以每主题获得1200万5000订阅者
一旦数据发送到s
它不会持久
这意味着如果它没有被送达
你有可能失去它
所以它是一个 up 如我所说
你可以扩展到数万个主题
你不需要预置吞吐量
如果你想把它与SQS结合，
你可以通过扇出架构模式来实现这一点，
你可以将SQS与它结合，
或者你可以将S和S FIFO主题与SQS结合，
FIFO队列，
好的， 最后，Kinesis有两种消费模式，
你有标准模式，消费者从Kinesis中拉取数据，
在这种情况下，您每扇区可获得2兆字节/秒，
或者如果您使用增强型扇出类型的消费机制
你有qq
Kinesis 抱歉那将数据推入您的消费者
在这种情况下，您每分区每消费者可获得每秒2兆字节
这将为您提供更高的吞吐量
并使您能够有更多的应用程序从Kinesis流中读取数据
您有可能重放数据
因为数据在存储中被保留
您可以查看数据流
因此它可以用于实时使用
大数据分析和etl
你将在分区级别上获得排序
你需要提前指定每个kinesis数据流你想要的分区数量
所以你需要为自己扩展分区
数据将在x天后过期
在录制时
这是大约1到365天的数据保留期
在容量模式下
我们有两种模式 在提供模式下，我们需要提前指定
我们想要的分区数量
你可以看到流吗
或者在按需容量模式下，分区数量由
你可以为我们直接看到流吗
好的 这就是夏季讲座的全部内容 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/035_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p35 01. AWS Monitoring - Section Introduction.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的
我们有我们的应用程序
它在云端 它在运行
你的项目经理在凌晨两点给你打电话，说它不再运行了
发生了什么？
我们已经部署了应用程序 但我们忘记了开启监控
监控非常重要
它会确保你的应用程序以正确的方式运行
你可以看到日志发生了什么
可以看到指标 可以看到追踪
可以看到审计谁在你的基础设施中做了什么
这部分非常重要
因为作为一个开发者
我从不部署应用程序而不启用某种形式的监控
我知道你对监控很感兴趣 让我们开始
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/036_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p36 02. Monitoring Overview in AWS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 欢迎来到监控部分
故障排除和审计
我们将学习云监控
X 射线和云跟踪
对我来说，这是本节中最令人兴奋的部分
为什么监控很重要
我想你知道答案，但我喜欢大声说出来
我们知道如何部署应用程序
我们已经看到了如何安全地自动做
使用基础设施即代码，并利用最佳AOS组件
我们知道如何进行部署
我们不知道的是，一旦我们的应用程序部署完成
我们的用户并不真正关心我们是如何做到的
他们不关心我们是否使用了弹性豆荚
他们不关心我们是否使用了基础设施即代码
虽然我们这样做很好
这是一项工程成就
但用户并不关心
用户只关心应用程序是否正常工作
所以我们要解决的问题是
例如 延迟会
应用程序延迟会随时间增加
为什么停机
你知道 如果发生停机
嗯 我们的客户体验不应该下降
好的 它应该仍然很好 这就是我们部署高可用性东西的原因
然后如果用户联系IT部门或抱怨，那就是真的很糟糕
我们不想由我们的用户通知我们问题的存在
我们想能够在问题发生之前进行故障排除和修复
我们内部能否防止问题在发生之前发生
或者如果他们发生了 我们能否在我们用户之前看到他们
我们也监控性能和成本
我们能否看看趋势，了解事情如何扩展
在断电模式方面
我们可以学到什么，以及如何改进
多亏了这个监控
对我来说，监控现在真的很重要
在aws他们的cloudwatch和cloudwatch允许你收集指标
它允许你收集日志
监控和分析日志文件
事件以发送通知
当您环境中某些事情发生时，警报
实时反应
到度量 事件和日志
然后我们有x射线和x射线是一种新的服务，不是很流行
但我认为它是最棒的之一
它允许您调试应用程序性能和错误
所以我们可以看到延迟
我们可以实时看到错误
它允许我们做一些非常酷的事情
称为微服务分布式跟踪
如果你有很多服务
做很多事情并相互调用
或者如果你与许多组件交互
例如
MySQL和MongoDB
等 那么你能够看到你的应用程序如何进行调用
以及它们花费的时间 你可以追踪回每一个步骤，这真是太好了
云轨迹允许您进行API调用的内部监控
以及您用户对资源所做的更改
总的来说
这三种技术结合在一起，为您提供了一个非常坚实的组合来监控EUS
我们将在本节学习这些技术 所以下一节课见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/037_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p37 03. CloudWatch Metrics.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 我们已经在课程中看到了云观察
但让我们快速总结一下
首先我观察指标
它将为 ados 中的每个服务提供指标
你需要理解指标的含义
通常指标的名称会给你一个很好的指示
例如 CPU利用率网络
然后根据指标的行为
它给你一个服务行为的想法
你可以根据这个进行一些故障排除
指标属于名称通道
然后你有一个维度，这是一个指标的属性
例如实例
Id环境 等等等等
指标会有时间戳
你可以创建云仪表板指标
在这门课程中，我们已经看到了 e
C 两个指标 例如
我们还看到了 e
C 两个详细监控 所以我们知道，默认情况下 e
C 两个实例每五分钟会有指标
但如果你为成本启用详细监控
这是额外的 然后你将获得每分钟的指标数据
如果你启用了这个
然后例如 你将能够更快地响应 e
C 两个实例的更改指标 这对你的 assg 有一些好处
如果你想更快地扩展和收缩
这个功能允许你获得十个详细监控指标
需要注意的是， e
C 两个内存使用 所以，你的RAM不会被默认推送
它需要从实例作为自定义指标推送
我们将很快看到这是如何推送自定义指标的
当你在云中
观察仪表板在左边
这里有指标，你可以找到所有的指标
正如你所看到的，我们看到了所有命名空间中的指标
所以如果你看一下 我们基于服务
例如 Elb
自动扩展 E b s
E C 两个e s 等等
所以这里有很多信息给你
所以我们可以点击e
C 两个我们可以有一个实例指标
只看一个指标
我将输入信用查看cpu
嗯 信用余额
例如 我将取这个实例这是很久以前
然后我将要做的是我选择自定义范围
这将是一个多月来找一些数据在这里
好的 所以我们有数据在这里
因此云观察指标的酷事情是
你可以点击并选择你想要的时间段
在这里我们走
我们得到一些信息关于我们的指标
正如你所见 我们每五分钟得到一些指标
所以每个数据点每五分钟
因为详细监控没有启用这个实例
好的 但如果我启用详细监控
我将得到每分钟的数据
这就是云指标的基本知识
没有什么太疯狂
但我们可以肯定地按时间过滤
我们可以将其视为不同的线条
堆叠区域或线或数字或饼图
你可以将其添加到仪表板
你可以告诉它csv
你可以分享 好的
所以云指标非常方便
你可以查看所有指标
你知道 基于你想要的区域
基于你想要的维度
你想要的资源 所以你可以过滤一切
这就是关于clametrics的全部 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/038_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p38 04. CloudWatch Custom Metrics.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


到目前为止我们所看到的所有指标
在这个课程中，指标直接来自我们默认启用的数据服务
但是，你有一种方法可以获得云监控的定制指标
并且这就是为了让你能够定义自己的自定义指标
例如 你想要将内存使用率推高到lywatch的RAM上
或者磁盘空间 或者你应用程序的登录用户数量
对于这一点，你会使用一个名为的API调用
添加度量数据
你可以为你的段指标添加维度或属性
例如 实例ID，环境名称
你想要的任何内容 实际上完全取决于你如何命名
无论你想要如何 然后你可以使用存储分辨率的API参数来指定指标的分辨率
有两个可能的值
所以要么是一个标准自定义指标
你可以每分钟推送一个指标
所以六十秒
或者你可以启用非常高的分辨率
在这种情况下，你可以启用每推一次指标
五秒，十秒或三十秒
好的 值得知道的一点是，当你推送自定义指标时，当你推送一个过去的指标
或者未来的，这同样适用
所以这是一个非常重要的考试点
所以，如果你正在推送一个指标
在过去的两周或未来的两小时内
你不会从云观察中收到错误
好的 这将接受你的指标
这意味着你需要确保你的e
C两实例时间是正确配置的
如果你想让指标与aws的实际时间同步
所以让我们推送一个自定义指标
为此我去了云观察的文档
put metric data 这是cli文档
这是向你展示如何将指标推送到云观察的
所以我不打算阅读文档
你可以在这里查看所有成员
好的 但非常重要的是，可以指定时间戳
因此您可以指定时间戳
可以在过去两周和未来两小时内指定
所以非常重要
嗯 然后您可以指定数据
单位的值的名称
值和尺寸以及存储分辨率
如果你想获得一个高分辨率的指标或标准分辨率
好的 所以我要做的就是推一个非常自定义的例子
所以最后有例子
你可以使用一个metrics或js文件来推一个指标像这样
如果你想要 然后使用这个api调用
或者如果你想更快
你可以使用一个API命令来指定你的指标值
单位 字节以及实例ID
实例类型等等
那么让我来做这个
嗯 来到这里，我们将打开
嗯 云Shell实用程序来推送那个指标
好的 所以云轨迹已经启动
我将把评论粘贴进去，然后按回车
这将把集群指标推送到云观察中
现在你必须想象，如果这个是从一个e
C Two实例中运行的脚本
例如 你可以定期推送任何指标
我正在使用CLI将一个数据点推送到云观察中
这是uh
已经很实用了
好的 如果你知道云监控的统一代理
它会使用put metric data api调用定期将指标推送到云监控中
所以当它被推送时
我们已经推送了一个名为我命名空间的新命名空间 这意味着如果我回到云监控指标并刷新
这个
我需要清除我的图表
然后我只是退出服务，然后回到服务会更容易
然后转到所有指标会更容易
比去所有数据更容易
正如你所看到的，我们已经创建了一个自定义命名空间，就在这里
所以所有这些之前命名空间都是由aws创建的
但现在我们有我们自己创建的命名空间
所以在其中我们有两个维度
实例ID和实例类型
这些代表命令中指定的相同实例和实例类维度
所以这些维度显然由你定义
然后你点击它
你可以看到实例类型和指标名称的缓冲区
如果我现在点击它，我们几乎看不到什么
因为，嗯，我们没有多少
但这里有一个数据点已经被创建
好的 这是自定义指标的一部分
就是这样 这非常有用
你可以看到如何很容易地创建自定义指标
通过API调用 我希望你喜欢它 我会在下一堂课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/039_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p39 05. CloudWatch Logs.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈云观察日志
云日志是存储AWS中应用程序日志的完美场所
要做到这一点
您首先必须定义日志组
它们是你想要的任何名称
但通常它们代表您的应用程序之一
然后在日志组中，您将拥有多个日志流
它们代表应用程序中的应用实例或特定的日志文件
或您作为集群一部分的特定容器
然后定义您的日志过期策略
所以你可以选择让日志被永久保留永远不会过期
或者你可以选择让它们在一天到十年之间过期
同时将云观察日志发送到各种目的地也是可能的
例如 将日志批量导出到亚马逊S3
或者将其发送到Kinesis数据流
你可以看到火烈鸟
AWS Lambda Amazon Open Search
所有日志默认加密
你可以使用你自己的密钥设置自己的KMS基于加密
如果你想现在开始
云观察日志中的数据日志类型是什么
现在 可以放入云观察日志的日志类型有哪些
嗯 我们可以使用SDK或云观察日志代理
或Lywatch统一代理发送日志
现在云统一代理将日志发送到云观察
因此云观察现在基本上被废弃
您可以使用Elastic Beanstalk来收集日志
所以直接从应用程序进入云观察
Ecs将直接从容器将日志发送到云观察
Lambda将从函数本身发送日志
Vpc for logs将发送与您的vpc元数据特定的日志
网络流量 嗯
Api gateway会将所有发送到api gateway的请求发送到云观察日志
云跟踪您可以根据过滤器直接发送日志
Route fifty three将记录所有发送到其服务的DNS查询
所以如果您想查询云观察日志中的日志
对于这一点 你可以使用CloudWatch日志洞察
所以它是CloudWatch日志中的查询功能
允许你编写你的查询
你指定你想要应用的查询的时间范围
然后你将自动获得一个可视化结果
你也可以查看具体的日志行，这些行生成了这个可视化
这个版本也可以导出结果
或者添加到仪表板，以便随时重新运行
所以这非常有用
这将允许您在云日志中搜索和分析日志数据
云监控提供了许多简单的查询
对于云观察日志洞察
例如，您可以找到最近两个
五个 最近期事件
或者您可以查看日志中哪些事件有异常或错误
或者您可以查找特定IP等
它提供了一个专门设计的查询语言
所有允许您构建查询的字段都将自动从云观察日志中检测
然后你可以根据条件进行过滤
你可以计算聚合统计数据
你可以对事件进行排序
限制事件数量等等
正如我所说 你可以保存查询
还可以将它们添加到云观察仪表板中
你可以同时查询多个日志组
即使它们位于不同的账户中
所以记住云日志洞察是一个查询引擎
不是一个实时引擎
因此，正如所说 当你运行查询时，它只会查询历史数据
如前所述
云观察日志可以导出到多个目的地
第一个是亚马逊S3
这是为了批量导出，将所有日志发送到亚马逊免费
这次导出可能需要12小时才能完成
发起这次出口的API调用称为创建导出任务
由于这是一次批量导出
这不是实时或接近实时
相反，你必须使用云观察日志订阅
这些允许您获取这些日志事件的实时流
您可以进行处理和分析
您可以将此数据发送到多个地方
例如您可以看到数据流
您可以看到数据火炬或lambda
您可以指定订阅过滤器
以指定您希望发送到目的地的哪种类型的日志事件
因此，订阅过滤器可以将数据发送到kdata streams
如果你想要使用，这将是一个很好的选择
例如，它与Kinesis数据火烈鸟的集成
你能看到数据分析或亚马逊e
C Two或lambda
你也可以直接将其发送到Kinesis数据火烈鸟
从那里，您可以以接近实时的方式将其发送到亚马逊S3
或者例如开放式搜索服务
或者你有lambda
所以你可以编写你自己的自定义lambda函数
或者你可以使用一个管理的lambda函数
它将实时将数据发送到其上的open search服务
多亏了这些订阅过滤器
你可以从不同的云观察日志中聚合数据
从不同账户和地区到一个共同的目的地
例如，您可以查看特定账户中的数据流
然后您可以查看can you see fire hose
然后在接近实时中将其发送到亚马逊s3
这是完全可能的
这是您执行日志聚合的一种方式
那么，这就是这是如何工作的详细信息
您必须使用所谓的目的地
假设您有一个发送账户和接收账户
您创建一个云观察日志订阅过滤器
然后将其发送到订阅目的地
这是一个接收账户中can you see数据流的虚拟代表
然后您为第一个账户附一个目的地访问策略，允许其将数据发送到此目的地
然后在接收账户中创建一个iam角色
它具有将记录发送到您can you see数据流的权限
并确保此角色可以被第一个账户假设
当您将这些所有东西都设置好
然后您可以从一个账户中的云日志
将数据发送到另一个账户中的目的地
这就是本讲座的全部内容
我希望您喜欢它 我将在下次讲座中见到您 再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/040_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p40 06. CloudWatch Logs - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 所以我在云观察日志中
我们可以看到我们现在有的所有日志组
正如你所见，我们有八个，它们是由一些服务创建的
例如，这个由lambda创建
这个由数据同步创建
这个由glue创建
这个由我们在执行ssm运行命令时创建
我们希望输出被填充到这个日志组中
如果我们看看这个例子
例如 我们有六个日志流
每个代表我们运行的特定实例
所以我们有一个特定的运行ID
在这六个地方都是一样的
我们有每个这六个不同的实例ID
二加二
然后我们有std out和std air
如果我们看cd out
我们可以查看由此命令生成的所有日志
我们可以查看所有日志行等等
这非常有用
想法是，从日志中，例如，你可以查找http关键字
它会显示所有包含http字段的日志行
如果你只查找installing关键字
例如
它会显示大约两到三条包含installing字段的日志行 这相当方便
我们有日志流
嗯，std out和sd air
所以我们可以看到不同日志流的想法
现在我们可以在这里创建指标过滤器
这些指标过滤器是我们找到过滤模式的一种方式
例如，installing
然后我们需要选择
例如，自定义数据
例如，这个日志流
然后我们测试模式
这将给我们提供五条样本日志中的三个匹配
如果你继续使用这个过滤器名称
正如你所见
我可以称之为demo filter和demo metric filter 这是一个新的命名空间
好的，这是demo metric
嗯
这是demmetric filter 嗯，命名空间
这是demo metric filter
这是demmetric filter
这是demo metric filter
好的 当出现过滤模式匹配时
所以你可以说一个
例如 为了添加1到计算多少次安装行已经被找到
和默认值和单位
如果你想要
然后点击下一步创建
这将给您一个新的指标
如果你进入云
看指标在这里
我们将清除这个图表
我们将创建一个新的指标
让我们
刷新此页面
这可能会帮助我们
好的 如果我们去所有名称空间
嗯 一旦这个指标
指标过滤器会出现
它将在这里出现并且我们可以可视化它
但现在因为我们没有发送任何日志输出
那么我们看不到它
但想法是我们可以在这个指标过滤器上创建一个警报
我们可以点击创建警报
这将允许我们创建一个警报
例如 如果这个指标超过了一个特定的值
再次这个指标是基于日志流过滤器计算的
我们也可以创建订阅过滤器
正如你所看到的这里 我们可以为不同的结果创建过滤器
elasticsearch kinesis数据流
你可以sis火喉或lambda过滤器
如果你想将数据发送到自定义lambda函数
我们可以为每个日志组创建多达两个订阅过滤器
根据这个 好的
现在我们也可以编辑保留设置
我们可以看到日志永远不会过期
直到 一百二十个月
好的 十年
然后我们也可以将数据导出到亚马逊历史
你可以点击导出数据
你可以选择一个数据范围进行导出
然后流前缀
如果你想要特定的日志流
然后三个桶和桶前缀
你将可以正常工作
然后在这里你可以创建一个日志组
我将其命名为演示日志
好的 你可以设置保留设置
A是关键
如果你想要加密那个日志组
然后点击创建
因此加密设置将出现
然后如果在这里指定了 kms 密钥 g
好的 最后还有云监控日志洞察
好的允许您使用漂亮的查询语言来查询一些特定的日志组
例如我们可以查询这个并运行查询
然后这不会给我们任何数据
因为我们正在查找过去一小时的数据
但是如果我们查看过去
嗯 60 天的数据并运行此查询
也许我们会找到一些东西，这样你们就能看到
我们发现了 嗯 十二张唱片
十八张唱片从这个查询中
这给我们提供了一个很好的查询语言
以便我们能开始从日志中获得一些见解
然后你可以导出结果
如果你想要的话
在右边你可以看到你可以保存你的查询
好的 你可以在这里查询和保存它们
或者你可以查看一些示例查询并查看登录日志大小的使用案例
例如 查看Lambda五分钟间隔的延迟统计
或者获取前十个源和目的地的字节传输
PC日志的IP地址
所以它给你 例如
如果你点击这些，会有一些关于查询语言如何适用于云的好见解
查看日志 具体洞察
我看日志 希望你喜欢 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/041_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p41 07. CloudWatch Logs - Live Tail - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以我想让你看看一个非常酷的云观察日志功能，叫做实时尾随（Live Tail）
首先，我们创建一个日志组，我将其命名为demo日志组
然后创建它
我们点击它
然后我们创建一个名为demo日志流的日志流
让我们创建它并点击它
然后我们就在里面了
所以我们可以开始尾随
这里有一个按钮 开始尾随
这意味着
我会在背面页面中保持另一个打开
所以我们可以访问我们的日志流
在这里我们点击了实时尾随，我们就在实时尾随设置中
所以这里是一个日志流UI，我们已经过滤到了一个特定的demo日志组
然后过滤到了demo日志流作为一个日志流
这是可选的 你可以选择是否指定一个日志流
然后你应用了你的过滤器
这意味着它将等待匹配你的过滤器的日志事件
这意味着当事件被发布到云日志时
它们将出现在我们的实时尾随中
这可能对你的调试需求非常有帮助
所以让我们做一个例子
所以我们将回到我们的demo日志流在这里
在操作中我们将创建一个日志事件
我们有hello world
所以我们可以创建一个日志事件并发布它
所以现在hello world已经被发布
如果你去看实时尾随
正如你所见，它出现了
这是非常不错的方式
因为如果你有日志快速流过
它们将都会出现在这里
然后我们可以从这里获取更多信息，关于这发生的时间
日志组等等
然后我们可以点击这里获取到一个链接到它发生的直接日志流中
所以这是一个非常酷
非常容易的功能来调试你的云日志
从定价角度来看
你只能得到每天几小时的免费使用
所以可能每天一小时的免费实时尾随使用
所以请确保取消并关闭你的实时尾随会话
这样你不会有任何费用
但你有每天一小时的免费
所以这相当不错
好的 这就是本讲座的内容 我希望你喜欢它 我会在下一个讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/042_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p42 08. CloudWatch Agent & CloudWatch Logs Agent.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在 我们来谈谈如何使用称为CloudWatch代理的东西来收集日志
来自EC two实例的日志 以及指标，并将它们上传到CloudWatch
默认情况下
没有日志从你的EC two实例发送到CloudWatch
为了实现这一点，你需要在你的EC two实例上启动一个代理程序，这是一个小的程序
你需要创建一个并启动这个代理 这个代理是一个程序，运行在你的EC two实例上
它将收集日志和指标并将其发送到CloudWatch
C 两个实例会将你想要的日志文件推送出去
所以，想法是，你的e
C 两个实例将运行云观察日志代理
例如 运行并将日志发送到云观察
日志使其运行
你的e C 两个实例必须具有允许它们将日志发送到云观察的i am角色
有意义的日志
并且值得了解
值得注意的是，这个云观察日志代理也可以部署在预置服务器上
因此，您可以在预置服务器上设置您的服务
例如，预置虚拟机如vmware
您可以安装完全相同的代理，即一个小型linux程序
您的日志将最终出现在云观察日志中
在云观察中，有两个不同的代理
您有云观察日志代理，这是较旧的一个
并且云观察统一代理是最新的
所以它们都是为虚拟服务器设计的
E c 两台本地服务器
等等 云观察代理是旧版本
只能向云观察发送代理
而统一代理将收集额外的系统级指标
例如内存和进程
我将在下一张幻灯片中向你展示
也将将日志发送到云观察日志
现在统一了
这更好，因为它可以同时处理指标和日志
因此，它的名字叫做统一代理
但也可以使用ssm参数存储非常容易地配置该代理
这是前一个代理没有的功能
因此，您可以为所有统一代理进行集中式配置
因此，云观察统一代理可以发送日志和花絮日志
但让我们看看 让我们看看指标
如果你在你的e
C 两台linux服务器上安装它
你可以收集指标
我们可以收集cpu指标
但在一个更细粒度的层面上
例如 活跃的客人偶像系统
用户偷窃 你
完全不需要了解他们
我只是在给你提供所有这些指标的详细信息
磁盘使用情况，包括空闲磁盘和总磁盘
I/O，包括写入次数
读取次数 字节数 IOPS（输入/输出操作每秒）内存
空闲内存 不活跃内存
Ucache
网络统计 TCP和UDP连接的数量
网络数据包 字节
你可以得到一些关于进程的信息
所以总共进程的数量
我在你的死亡中 阻塞、空闲、运行
睡眠和回收站
这是一些内存溢出到磁盘的情况
所以可用的和使用百分比是多少
所以我记得只需拍一张啊
这些物品的心理截图
底线是云监控
统一代理允许您获得更多的指标
在比正常监控更多的粒度细节中获取EC two实例
两台实例 作为提醒
出厂配置为e
C two 您会得到一些磁盘上的信息
CPU和网络
没有内存没有交换
但所有这些都在高层次上
好的 如果您需要更详细的信息
考虑云观察统一代理
好的 那就是我的全部 我希望你喜欢 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/043_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p43 09. CloudWatch Logs - Metric Filters.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈云蜗牛指标过滤器
所以，想法是你可以在日志上使用过滤表达式
例如，为了在日志中找到特定的IP
或者计算日志中错误单词的出现次数
然后你可以将其转换为指标
这就是为什么它被称为指标过滤器
并且可以使用此指标过滤器触发警报
所以你应该知道的一件事是，当你创建一个过滤器时
它不会回溯性过滤数据
所以指标数据只会被推送
在过滤器创建在其之上的事件发生
您可以为指标过滤器指定多达三个维度来创建一个非常有趣的指标
让我们以为例
我们在一个EC two实例上安装了CloudWatch日志代理
C Two 它将日志流式传输到CloudWatch日志
然后从中创建一个实际的指标
这就是您的指标过滤器
所以我们将从那里选择一个过滤器表达式，得到一个真实的大学指标
我们可以 例如 将其与云监控警报集成以说，嘿
如果我们在您的日志中不到一分钟内计数五次错误
您可能想要知道并收到SS主题的警报
这就是指标过滤器 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/044_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p44 10. CloudWatch Logs - Metric Filters Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以我在我的云中
查看日志 我想启动引擎
X 访问日志
我想在这些日志流上创建一个指标过滤器
所以我要寻找的是看看是否有错误代码
四百 所以我在这里输入四百
我们可以看到有很多 http 404 错误代码
我想在这些上创建一个指标过滤器并接收警报
这只是一个假用例
所以我要创建一个指标过滤器
我可以从这里创建
或者我可以回到这里并在指标过滤器中创建一个
所以我要创建一个指标过滤器
然后你需要输入一个模式
模式可以非常复杂
这里有一整套关于过滤器和模式的文档
但现在我只是寻找四百并使其非常简单
然后可以发送自定义日志数据进行测试
或者我们直接从我的日志中获取数据进行测试
然后测试模式
结果是在样本日志中找到了14个匹配项，共50个事件
这意味着我的模式非常简单
正在正常工作
然后我滚动并点击下一步
然后我需要为这个指标过滤器起一个名字
我将其命名为指标过滤器400错误代码
好的 然后我们需要一个指标命名空间
我将其命名为指标过滤器
然后需要一个指标名称
我的演示过滤器
然后指标值
每次匹配发生时
我们可以说 例如
发布值1
好的 然后默认值
如果没有值发布
它将是0
我点击下一步
然后我创建了这个指标过滤器
所以现在这个指标过滤器已经创建
所以我在我的指标中
我能够看到目前没有发布任何东西
因为 正如我所说
指标过滤器不是回溯的
所以我们需要让这个指标过滤器工作
这非常简单
我将进入我的第一个beanstalk环境
然后我将执行环境操作
我将重启应用服务器
这将触发更多的日志被写入到云观察日志中
所以我会等 我只是回到这里，我等大约五分钟让我的环境重建
希望指标过滤器会在云观察指标中显示出来
所以我的环境现在已经被重启
我将去把它打开
我将测试它以触发某些事情
我们准备就绪
好的 现在让我们回到云观察并刷新它
希望很快我们就能开始看到一些指标
好的 我已经刷新了我的云观察指标页面
我们开始看到的是一个自定义纳空间叫做指标过滤器
这就是我们创建的指标
这是我的演示过滤器
作为指标，它并不有趣
因为现在的值是零
这意味着我们没有检测到任何400事件
但我想向你展示的是
它没有回填以前的事件数据
所以指标过滤器只添加它们创建的那一刻的数据
在这个图表中，它并不有趣
但这没关系 我们可以对这个指标过滤器进行操作
然后创建一个警报
通过创建云监控警报
我们可以进行一些自动化
所以我将要创建一个假云监控警报
我将使用我的演示过滤器，目前什么都没有，但我可以说
如果作为一个静态阈值你大于
我将说50
那么我的Web应用程序真的有大问题
因此我将点击下一步
我将说好的
警报应该处于警报状态
我将把我的警报发送到一个现有的ms主题
也许这个是另一个
然后我可以说下一个并说演示指标过滤器警报
就是这样
所以现在我们在我们的指标过滤器上创建了一个云监控警报，来自云监控日志
所以你可以看到在这个例子中有很多不同的云监控服务结合在一起
所以可以创建警报
现在我有我通知的基础
显然现在不会这样，我不会收到任何通知
但你明白了大致意思
这就是你如何继续创建自己的指标过滤器
所以我刷新这个
现在，这个页面
我应该在下面看到的是
是的 这个指标过滤器链接到一个名为 demmetric filter alarm 的警报
这太好了 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/045_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p45 11. CloudWatch Alarms.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来讨论云观察警报
所以，警报，正如我们所知，用于从任何指标触发通知
您可以定义复杂的警报
以及各种选项，例如抽样或百分比或最大最小
警报有三个状态
OK意味着它没有被触发
数据不足
意味着数据不足，警报无法确定状态
警报，这意味着您的阈值已被突破
因此将发送通知
周期是你希望警报在指标上评估多长时间
所以它可以是非常短的
非常短 非常长
它也可以应用于高分辨率的成本指标
例如 10秒 30秒
或者60秒的倍数
现在警报有三个主要目标
第一个是针对EC two实例的操作
C 两个实例 比如停止它
终止它
重启实例或恢复实例
第二个是触发一个自动扩展操作
例如扩容或缩减
最后一个是向NS服务发送通知
例如 我们可以将服务连接到一个lambda函数中，让lambda函数
根据警报被触发的情况，执行我们想要的任何操作
现在让我们来谈谈复合警报
因为我们知道云监控警报是基于单一指标的
但如果你想要监控多个指标
那么你就需要使用复合警报
因为复合警报实际上是在监控多个其他警报的状态
而这些警报可以基于不同的指标
复合警报是将所有这些其他警报组合起来的操作
你可以使用和或条件来非常灵活地操作
就您检查的条件而言
因此，减少警报噪音非常有帮助
因为您可以创建复杂的复合警报并说
例如 如果CPU高且网络高
那么不要给我报警
因为我只想知道CPU高而网络低
这类事情 所以让我们举一个例子
我们有一个e c two实例
我们将在它的基础上创建一个复合警报
因此我们创建一个第一层基础警报
称为警报a，它将监控EC two实例的cpu
C 2实例
然后您创建一个警报b，它将监控EC two实例的iops
然后复合警报定义为警报a和警报b的交集
因此如果警报a处于警报状态并且警报b处于警报状态
并且这是我们必须自己定义的
那么复合警报本身将处于警报状态并触发
例如s通知
正如您所看到的，您可以对复合警报非常创意
让我们谈谈e
C 2实例恢复
所以我们有状态检查
并且我们有实例检查
我们将检查e
C 2虚拟机
我们有系统状态检查
它将检查我们e
C 2实例的底层硬件 最后，附加的ea状态检查将检查任何附加的ebs卷的健康状况
您可以对这些检查定义冲突警报
好的 您将监控特定的e
C 2实例 如果警报被违反
然后您可以启动e c
2实例恢复以确保
例如 您将e
C 2实例从一台主机移动到另一台主机
在进行恢复时
您将获得相同的私有公用和弹性ip
相同的元数据和相同的放置组
并且您可以向主题发送警报和警报以获得通知
该EC two实例正在恢复
现在loch警报有一些好东西
您知道首先
我们可以在云watch日志上创建一个警报
度量过滤器 如我们所见，云watch日志具有度量过滤器
该过滤器连接到云警报
然后当我们接收到太多特定单词的实例时，例如单词错误
然后做一个警报并发送一条消息到亚马逊同意
所以如果你想测试警报通知
你可以使用一个叫设置警报状态的cli调用
这在你想要触发一个警报时很有帮助
即使它没有达到特定的阈值
因为你想看看警报是否触发
结果是否对你的基础设施产生了正确的行动
这就是我们的lai 希望你喜欢 我会在下一节课见你，做一些练习
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/046_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p46 12. CloudWatch Alarms Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的
所以我们在云警报中
让我们创建一个警报
首先我会快速创建一个EC two实例
我们将在CPU利用率上创建一个警报
我们将创建一个两微实例
我会快速输入并启动
然后我说好的 我有这个，我们不需要保留它或类似的东西
我们只是想启动实例
并且我们希望创建一个警报来终止实例
如果CPU达到百分之百
那么让我们创建这个警报
因此我们需要选择一个指标，而为了做到这一点我们需要选择一个指标
所以我们需要去找到我们的e c two实例
所以这是我们的实例ID，在这里搜索它
我可能有点太快了
好的 所以让我们等待实例被启动
我将进入每个实例的e c two指标
然后我会等待它开始填充
所以有些指标在我的云监控仪表板上出现大约花了五分钟
对于我的实例 所以现在我可能可以刷新这一页
然后我有机会找到所需的指标
我正在寻找的 所以让我选择指标
然后粘贴实例名称
我有它然后我去找我的实例的CPU利用率
所以这就是这个指标
好的 我们将选择这个指标
如你所见 我们在这里有它
然后我们可以选择一种方法来计算这个指标
所以平均一些最大等等
我们想要评估这个警报的时间段所以五分钟是好的
因为这个指标每五分钟更新一次
如果我们不启用详细监控
现在我们以阈值为条件设置一些条件
所以它是静态的吗
还是它是动画的
检测 它是大于等于这些的，等等
所以我会说 例如
如果你长时间大于百分之九十五
所以这里你可以说三中三
这意味着15分钟内你卡在百分之九十五
那么可能这台机器出了点问题
因此，在这种情况下，我可以选择一个通知
我可以选择一个无缩放操作
我可以选择一个e C
Two操作，或者在系统经理操作
但我将选择一个e
C Two操作 好的
我会说嘿
如果你在警报中
好的 然后只是终止这个实例
因为我可能知道我的应用程序有时有一个巨大的失败
并且CPU波动会在
嗯 百分之九十五或百分之百很长时间
并且唯一解决方法是只是终止实例
所以我会选择这个，然后点击下一步，并设置终止e
C Two在高CPU
点击下一步以验证一切
我们现在很好，所以现在这警报显然没有足够的数据
所以我们需要等待15分钟，以便它变得良好
并且它不会触发
除非我们让它如此
所以我们可以进入e
C Two实例并启动一种方式来获取CPU非常高15分钟
但这将非常，非常长
或者我们可以使用API调用名称设置警报状态来真正看看会发生什么
如果此警报进入桥接阶段
所以让我们看看
这是警报的历史
好的，我将要做的是
是我将设置警报
我开始类型 它将cliwatch设置警报状态
并且我们看API参考
并且我们需要做设置警报状态
警报名称和状态值
和状态原因
所以我们会这样做在这里
所以aws cloudwatch设置警报状态
然后我们需要设置多个参数
所以警报名称将是这个
然后警报
嗯 所以状态值
将处于警报
州政府的原因是测试
我们按回车
现在出现警报
如果我们刷新
这个页面现在处于警报状态
如你所见 它说处于警报中
因此，操作是
当警报终止实例
因此，如果你查看历史记录
它说警报已经从正常更新为警报状态
并且采取了行动
并且成功执行了行动来终止我的e
C 两个实例 所以如果我进入我的两个实例这里
我刷新 如你所见
正在关闭并被终止
因为当这个e上面触发了警报时
C 两个实例 我们设置了警报来做这个特定动作
就是这样 我希望你喜欢
我希望这对你有意义 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/047_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p47 13. CloudWatch Synthetics.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈云监控合成的哨兵功能
基本思路是你有一个可配置的脚本
这个脚本将从云监控运行
并能监控你的API
你的URL或你的网站
你定义一个脚本
这个脚本将程序化地重现你的客户所做的事情
基本思路是
例如 如果你的客户访问了产品网页然后点击并购买
加入购物车 去结账
输入信用卡信息并确保结账正常
你可以使用云观察合成可以测试这一切并重现
想法是如果脚本出现任何问题
这意味着你发现了一个问题
在你客户之前找到这个问题是好的
想法是您可以检查某些流程是否正常工作
您还可以检查某些端点的可用性和延迟
甚至可以存储加载时间数据甚至截图UI
那么我们来举个例子
我们有一个应用程序部署在美国东部一
然后我们将使用高监控合成的 Canary 来监控该应用程序
以防事情失败
然后 CloudWatch 警报将被触发
这将触发一个 Lambda 函数
Lambda 函数可能想要更新 root t three 的 DNS 记录
以指向美国西部二的另一个实例
这样我们就可以重定向到一个我们知道正在运行的应用程序版本
那就是做这些事情的一种方式
所以，这个合成的 canary 可以在 nodeJs 或 python 中运行
在上面，你可以使用无头谷歌浏览器
在 synthetics canary 中，你可以访问一个无头谷歌浏览器
你可以做任何你在谷歌浏览器中可以做的事情
你可以选择运行你的脚本一次，或者定期运行
例如，如果你想检查你端点的可用性
你也可以使用一些蓝图
如果你想检查你端点的可用性 你可以选择运行你的脚本一次，或者定期运行
你也可以使用一些蓝图
所以你有心跳监测器来加载URL存储
截图和HTTP存档文件，并确保一切正常工作
API金丝雀用于测试REST API的基本读写功能
API你有断链检查器来检查URL内的所有链接
你正在测试 确保它们中没有一个实际上链接到断链
视觉监控用于比较金丝雀运行期间捕获的截图
与您在金丝雀记录器之前捕获的基础截图
它用于与CloudWatch合成记录器一起使用
这是你在网站上记录您的操作的一种方式
然后自动从中出来
将生成脚本
然后你可以直接在合成的金莺上运行它
并且自动地，行动将被重复
最后，有一个图形用户界面工作流构建器
那就是例如 你可以验证在你网页上采取的行动
例如，登录表单正在正确工作
好的 这就是关于lywatch合成金莺的全部了
我希望你喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/048_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p48 14. Amazon EventBridge.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈亚马逊事件桥
亚马逊事件桥以前被称为云观察事件
所以你会在考试中看到事件桥
但只是你要知道 如果你来自旧的aws经验
那么它以前被称为云观察事件
所以有了桥你可以做很多事情
例如我们可以在云中安排cron作业
所以我们可以安排脚本
例如我们说
每小时
请触发一个lambda函数
并且该lambda函数将运行一个脚本
因此事件每小时生成
因此得名亚马逊事件桥
但不仅仅是安排
例如每小时
你也可以对事件模式做出反应
这些是事件规则可以对服务做某事做出反应
例如你可以对事件做出反应
我是一个root用户在控制台登录
所以当发生这种情况时 也许你想将消息发送到s主题并接收电子邮件通知
所以如果有人使用root账户
那么你会收到电子邮件
这可能是您账户的良好安全功能
例如你有不同的目的地
你可以触发和函数
发送和消息等等我会在几秒钟内向你展示这一切
所以桥在中间
我们有所有可能将事件发送到亚马逊事件桥的来源
例如 EC two实例启动
当他们停止 当他们被终止
等等可以构建
例如如果你有一个构建失败
或s3每当有事件
例如当一个对象被上传
或可信顾问
当你账户中有一个新的安全发现
或作为好搭档
你可以结合事件桥和clap轨迹
并且实际上可以拦截任何api调用
这在很大程度上
此外 如我所说
你可以有一个安排或cron
所以你可以说每四个小时或每个星期一的上午8点
每月的第一个星期一
这是你也可以做到的事情
然后这些事件将被发送到亚马逊事件
你可以设置一个过滤器
例如 嘿
我只想为特定的亚马逊s三八获取这些事件
例如
然后eventbridge将生成一个表示您事件详细信息的json文档
例如实例
例如从其id开始启动等等，有很多信息
时间，ip等等
一旦完成
然后这个json文档
这个事件可以被发送到许多不同类型的目的地
允许您做
实际上可以进行一些集成
例如 您可以安排并触发lambda函数
您可以安排一个批处理
您可以启动一个亚马逊ecs任务
您可以将消息发送到sqs或甚至数据流
您可以 例如启动一个stamp step function
您可以使用code pipeline启动一个ccd管道
或者使用code build启动一个构建
您不 您知道所有这些东西
当然这些都是不同的服务
但我只是给你一个概述
您可以做的事情 您也可以
例如启动一个ssm自动化
或一个特定的e
C 两个操作 例如启动或停止或重启一个e
C 两个实例 您可以看到可能性是无限的
这真地取决于您的使用案例
所以亚马逊事件桥是我们称之为默认事件总线
这就是我们刚刚看到的
它代表从aws发送到默认事件总线的服务
但亚马逊有更多的能力
有一个叫做合作伙伴事件总线
这是aws与合作伙伴集成
他们很可能是软件即服务合作伙伴
他们将直接将他们的事件发送到您的合作伙伴事件总线
如果您使用 例如zendesk
Datadog 或零或其它你需要检查合作伙伴列表
然后它们有机会直接将事件发送到指定的合作伙伴事件总线
因此您可以直接在账户中响应AWS外部发生的更改
好的 最后有一个自定义事件总线
您可以创建自己的事件总线
然后您自己的应用程序可以向自定义事件总线发送自己的事件
因此您具有相同的能力将这些事件发送到不同的目的地
多亏了EventBridge规则
您也可以访问事件总线
跨账户使用资源基于策略
正如我们将很快看到的
您也可以存档事件
所有它们或仅限子集
感谢您的过滤器
通过存档事件
您可以设置无限期保留或保留期
好的 您可以对这些事件进行重放
例如 假设您的Lambda函数存在错误
并且您想要修复它
您已经修复了它 然后您想要重新测试事件
重放 您可以重放这些存档事件
这对于调试非常有用
对于故障排除和生产修复也非常有用
现在EventBridge从多个地方接收大量事件
因此您需要了解事件将如何看起来
记住这些事件以JSON格式存在
我们刚刚看到了
因此有一个模式注册表
EventBridge的能力是分析您的队列中的事件
然后它会推断模式
模式将允许您为应用程序生成代码
这将让您提前了解事件总线中数据的结构
例如 这是一个特定于代码管道动作的例子
有一个模式并且您可以下载代码
他们使用橙色按钮
这将直接了解如何推断模式并从您的事件总线结构数据
模式可以版本化
因此您可以随着时间的推移迭代您的应用程序模式
当然现在我们有一个基于资源的策略EventBridge
这意味着什么 这意味着您可以管理
嗯 特定事件总线的权限
例如 你可以说这是一个特定的事件总线
可以允许或拒绝其他地区或账户的事件，并且用例
例如 它将是在你的aws组织内的一个中央事件总线
一组账户
然后所有这些事件都将被聚合
这是否工作良好
我们有一个特定的账户的中央事件总线
我们将添加一个特定的资源基策略
允许其他账户将其事件发送到它
因此，例如，这个其他账户
将能够执行put events并将事件直接发送到中央事件总线 所以让我们从左到右说桥梁
你知道关于它的一切
所以记住，你可以响应你账户内发生的事件 多亏了默认的事件总线
但也包括合作伙伴事件
以及你自己的事件与自定义总线
你有模式限制能力
然后你有资源基策略
允许你跨账户
例如，对事件总线的能力
事件总线
好的 就是这样 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/049_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p49 15. Amazon EventBridge - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 首先让我看看云监控事件
Ui 这就是事件和云监控事件
它最终会消失
所以不要感到惊讶
如果你找不到它 因为现在云监控事件是事件桥
这是云监控事件的增强版本
所以我可以进入亚马逊
查看事件桥的新界面
在这里我可以访问多个东西
在事件总线下
我们可以访问默认事件总线
这个事件总线是默认创建的
你可以开始定义规则
但你可以创建自己的事件总线
称为中央事件总线 v2 你可以启用事件存档
如果你想要存档这些事件并永久保留
以便进行调试以及进行自动化模式发现
如果你需要对此事件总线进行跨账户访问
那么你可以定义一个基于资源的策略
你需要编辑一切
如果你没有基于资源的策略
那么只有事件总线所有者可以发送事件到此总线
这对我们来说是可以的
让我们创建这个
你已经创建了一个自定义事件总线
现在我们可以谈论事件了
我们有事件源可以来自合作伙伴
例如我们可以说
我想捕获来自of zero的所有事件
所以我们会设置
这里有设置你事件总线for of zero的方法
这里有一些of zero网站上的指示
然后一旦设置完成
我就能在事件桥中直接捕获of zero的事件
所以现在所有事件都被捕获到事件桥中
你需要创建一个规则
你需要选择创建规则选项
我会称其为demo rule event bridge
然后你可以选择总线
总线可以是默认的
可以是中央总线
或者你可以创建任何你想要的
我会使用默认总线
因为它是默认创建的
你可以按计划运行
例如我说
我想让这个规则每小时运行一次
那么我们选择第一个
接下来，我们必须选择一个事件源
我们有几个选项
我们可以选择事件源来自AWS内部
我们选择AWS服务
或者它是一个自定义事件或合作伙伴事件
我们将选择其他，如果您想将所有事件集中到您账户中的账户中
那么您将选择所有事件
然后将其发送到中央事件总线
感谢您的资源基策略
但现在我们将选择AWS服务
接下来，我们可以过滤样本事件
所以这是一个新功能，被称为沙盒
所以如果您回到Amazon Bridge并转到沙盒
您可以使用样本事件进行测试
然后无需创建规则即可测试事件模式，UI也是可访问的
当您创建角色时
对于样本事件
我将选择e
C Two，不要选择全部
这里有自动缩放 但您向下滚动，现在有e
C Two，您将选择e c two状态更改通知
这是将被发送到EventBridge的事件类型
每当有状态更改通知时
我们可以选择不同的样本事件
如您所见 这个瞬间状态是即将发生
而这个是正在运行
好的 让我们假设我们希望在实例进入停止状态时生成事件
让我们选择停止状态
因为我们想知道它们是否已被停止
好的 停止，好的
所以我将滚动并创建一个事件模式
我将选择一个服务提供商
这是e C Two，选择一个事件类型
这是即时实例状态更改通知
我们可以选择所有状态
如果我现在测试模式
它将匹配样本事件
但我可以指定一个特定的类型
例如 只有停止或终止的实例
谢谢
正如你所看到的，我的事件模式变得更加精细
所以如果我们现在测试这个，将与上面的匹配
这很好 但如果我选择
例如，处于待命或运行状态，然后测试模式
将不会截断
所以我们可以肯定我们现在捕捉到的事件是每当一个e
C 两个实例停止或终止时
我们做这个的原因是什么
也许因为每当这种情况发生
我们希望被通知
所以目标可以是一个事件桥
事件总线 当你想集中目的地时，或者一个API目的地
或者你可以选择一个以下AWS服务
你可以看到有很多可能的目标或操作
但是对我而言，最有趣的是主题
因为我想将我的演示主题发送到一个消息，每当一个e
C两个实例停止或终止时
我会点击下一步，下一步
然后审查和创建是
我的规则看起来很好
让我们创建这个规则
所以现在你可以尝试并开始启动这两个实例
然后终止或停止它
然后确保你订阅到你的主题的电子邮件中
然后你将收到一封电子邮件，每当一个实例停止或终止时
我认为这相当不错
所以总结一下
我们还有归档来查找所有您的事件归档
如果您需要的话
以及重放以重新播放事件
并将它们放回事件总线以正确修复您的集成
最后，您有这个模式注册表
这是您查看这些事件模式的一种方式
例如，我们可以查看AWS事件模式注册表
并输入aws点
说e C two并查看这里您可以查看e
C two e c two实例状态更改通知
这是版本1
模式类型为open api 3.0
这就是模式本身
这意味着它定义了可以放入此事件的可能性
我们可以看到
id是字符串
源是字符串
时间是字符串
以日期时间格式
这就是定义你的事件本身中事物如何看起来的方式
在你的事件本身中
多亏了这个相当复杂的模式
你可以实际下载代码绑定
它会为你生成代码
例如，Java
Python TypeScript
或Go 这样你就可以用更简单的方式在你的代码中操纵这些对象
而不必为你写一些手动代码
好的 这就是桥梁
正如你所看到的，这是一个非常完整的服务，具有许多不同的功能
但最重要的将是设置规则和设置事件总线
与资源策略
好的 就是这样 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/050_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p50 16. Amazon EventBridge - Multi-Account Aggregation.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以，仅作为一次简短的讲座，解释如何使用enbridge进行多账户事件聚合
所以假设 例如
你有多个aws账户
但你希望集中管理这些账户中的一些事件到一个中央账户的事件总线
假设你在所有账户中启动e
C 两台实例
并且你想要在中央账户中捕获这些事件
那么，你将如何做到呢
你将在一个账户中定义一个事件模式
然后在其中创建一个事件规则
这样账户a的所有状态更改都将发送到事件规则
并且事件规则在一个账户的目标
可以是另一个账户的事件总线
为了使其工作
以便账户a可以将事件发送到中央账户
我们需要在中央账户的事件总线上创建一个资源策略
以接受来自其他账户的事件
这是有道理的
然后我们可以在账户b，d和c中做同样的模式
这样我们就可以收集到我们的e
C 两台实例的所有状态更改，这些事件将发送到中央账户的事件总线
从那里，我们可以在中央账户的事件总线上创建自己的事件规则
例如，触发通知或lambda函数
或者你想要的任何事情
这就是全部，仅在架构方面需要了解的一件事
希望你喜欢它 下次讲座再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/051_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p51 17. X-Ray Overview.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


对我来说，这是伊比斯提供的最具革命性的服务之一
我认为它目前被低估了
它被称为伊比斯X射线
考试实际上是想让你了解X射线
我认为他们问两个问题是因为这个原因
因为他们想让人们使用它
我诚实地认为人们应该使用X射线
当你在生产环境中调试时
我以前在生产区域调试过应用程序
传统的方法
我所谓的老方法就是本地测试
到处添加日志语句并重新部署生产环境
然后从日志中尝试找出哪里出了问题
发生了什么 这真的很痛苦
这不是最佳实践
显然有更好的做法
我只是在简化事情
但我在这里简化了事情
但你明白调试生产环境并不有趣
然后你如果记录东西
如果你有不同的应用程序
如果你从不同的应用程序将日志记录到云观察
那么你知道它们所有的格式都不同
并且很难集中洞察和导航
云观察日志将会很难
并且上面的链接将会很难
所以如果你有一个单体
只有一个巨大的应用程序做所有事情
调试起来还是比较容易的
但如果你有分布式服务
你在os账户中运行数百个微服务
这将成为一个噩梦
调试真的很难
发生了什么 因为它们都相互交谈
是的 因此你对整个架构没有共同的看法
你整个服务图
等 所以这里来了一波x射线
所以x射线将给你提供一个视觉分析你的应用
这就是我们在实践操作中要做的
我们将看到基本上作为一个客户端对我们的应用发起请求
我们将看到有多少这些请求失败或不失败
然后从应用中我们将看到它做了什么所以它会调用其他ip
它会调用ns
它会调用一个dynamo db表
所以你可以看到
我们将能够精确地视觉上追踪到我们的e
C 两个实例
从这张图中你可以看出
如果我问你 你认为这个小小的橙色或黄色的错误来自哪里
嗯 它是来自这里吗
还是来自 S 不
它是来自我们的 DynamoDB 表
你可以直观地看到
这就是追踪的全部力量
当然你可以做更多
但你可以开始理解 X-Ray 的优势
你可以调试你应用程序的性能并识别瓶颈
你可以理解你微服务架构中的依赖关系
因为你可以直观地看到所有
所有微服务如何相互交互
我们可以定位到哪个服务出了问题
我们可以理解每个请求的行为
然后根据请求找到错误和异常
我们可以回答问题
比如我们是否满足了时间 SLA，关于请求的延迟或处理时间
我们可以理解哪个服务真正拖慢了我们
最终我们可以知道哪些用户受到了我们的错误影响
所以 X-Ray 有很多兼容性
它与 Lambda Beanstalk 兼容
你 cs elbapi Gateway 和 E
C 两个实例或任何应用服务器
甚至你本地的服务
他们真的让 X-Ray
尽可能地广泛兼容
尽可能地适用于任何应用
X-Ray 是如何工作的呢 它利用了一种技术
叫做追踪
追踪是一种从开始到结束的方式，来追踪一个请求
比如 当我向
我的应用服务器发送请求时
处理请求的每个组件
可能是我的数据库
可能是我的门户 我的负载均衡器
我的应用服务器
每个处理请求的组件都会增加自己的追踪
所以追踪是由段组成的，段又可以由子段组成
我们可以在追踪中添加注释来提供额外的信息
这样你就可以追踪每个请求或一个样本请求
你可以说你只想获取请求的百分比
或者每秒5次请求以满足安全需求
授权需要几分钟
您可以使用KMS对静态数据进行加密
一旦您获得了所有这些追踪
基本上，X-Ray
嗯，它提供了它的魔力，并提供了之前我给你看的那个漂亮的小图表
那么您如何启用X-Ray
嗯 您有两种方式
我认为这将是考试会问你的问题
所以你在这里需要非常小心
你的代码可以是java
Python Go node js和dot net
并且必须导入absdk
你需要很少的代码修改
但你仍然需要做一些代码修改
然后应用sdk
X射线 Xdk将捕获对服务的调用
HTTP 请求和 HTTP 请求
并且数据库需要使用mysql
Postgres 和 dynamo db
它也可以捕获q调用等
现在我们必须做的第二件事一旦
我们已经修改了我们的代码以安装x射线恶魔
或者启用X射线AOS集成
所以如果我们在一个本地服务器或EC two实例上运行
我们需要安装这个程序
并且恶魔基本上是一个工作在低层udp程序
数据包拦截器
它可以在Linux、Windows和Mac上运行
因此您需要在自己的机器上安装它
如果您使用Lambda或其他已经与X-Ray集成的服务
那么它们将为您运行守护进程
您就不必担心了
现在每款应用程序也必须具有将数据写入X-Ray的IAM权限
因此一个常见的问题是
我的X-Ray应用程序在我本地测试时能正常工作
但在EC two机上却无法运行
为什么答案是肯定的，可能是因为在你的机器上你正在运行x射线恶魔
但是当你部署到你的e c时
两个实例 它没有运行在X射线恶魔上
因此，X光现在看不到你的电话
为了使它真正清晰明了
这里有一个e c 两个实例
你需要将你的应用程序代码放在上面
因此，您的代码需要再次修改以导入is x ray sdk
然后它会将其轨迹发送到机器上运行的X射线恶魔
正如你所看到的 您还需要运行X射线恶魔
那个X射线恶魔会每1秒向EDX射线发送一批
X射线会做一些魔法
因此，为了得到这个图表
它是如何工作的 X射线会收集来自所有不同服务的所有数据并发送轨迹
然后，服务图将从所有段和轨迹中魔法般地计算出来
因此，这真的很酷
X射线是图形化的
因此，即使非技术人员也能帮助旅行拍摄
谈到故障排除
如果X射线在两个地方不工作怎么办
如我所说 您需要确保IAM角色具有适当的权限
您需要确保EC two实例确实正在运行X射线恶魔
如果您想在Lambda上运行它
那有点不同
您需要确保Lambda具有具有适当政策的IAM执行角色
虽然我们还没有看到Lambda是什么
但这可能是一个问题
因此，您需要确保Lambda具有预期的IAM角色
然后您需要确保已导入X射线代码
最后，您需要确保已激活X射线Lambda上的活跃跟踪选项
但我们也会在Lambda部分看到
这就是X射线概述的全部内容，接下来我们将在X射线上运行示例应用程序，以便更好地了解其工作原理
在下一讲中见
因此，在下一讲中见 所以，下一讲见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/052_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p52 18. X-Ray Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么我们来练习使用X射线
为此我将进入CloudWatch控制台
结果发现X射线控制台现在处于云控制台中
你可以在左侧的服务地图中看到它
目前我们什么也看不到但我们很快就会看到
这是因为X射线最好与指标、日志和警报一起使用
所有内容都放在一个地方
好的
所以如果我们想在X射线中有些数据 我们需要设置一个演示应用程序
但事实证明
根据我的经验和错误
在AWS中演示应用程序不起作用
因此我自己创建了一个演示应用程序
这是对已有应用程序的修改
我们将在CloudFormation中部署它
所以你去CloudFormation
并创建一个堆栈
我们将在这里使用的堆栈
是在X射线文件夹下的eb_javascore堆栈
保持X射线简单
这是一个来自AWS的简化模板
所以我们上传一个模板文件
并选择eb_javascrikeep_x_ray简化模板
这个名称将被称为score
保持X射线简单
然后滚动到底部
你将所有默认设置保留
除了在最底部的三件事
对于子网1
你将选择第一个子网
对于子网2
你将选择第二个子网
最后对于VPC ID
你将选择这里显示的VPC
这样做的原因是我们向模板指示我们希望部署资源的位置
然后点击下一步
然后确认并提交
这将为我们创建一个CloudFormation模板
如果你查看它
这个CloudFormation模板实际上部署了一个ECS集群
然后我们会有一个前端API
一个前端图像
抱歉 一个后端API
所有使用X射线
这样我们在X射线文件夹中可以看到数据
并且它将在t2或t3微机上运行
好的 现在一切都好
让我们在这里等待这一切完成
好的 所以我的堆栈已经完全部署
如果我进入资源
我可以看到所有作为部分这个云形成模板创建的东西
所以我们可以看到 例如一个ecs执行角色
Asg一个游戏表
这是一个mob等等
那么我们如何使用这个
这个网络应用程序
嗯 你去到输出
刷新这个
然后我们有一个负载均衡器
你在这里 你只需在新页面上打开它
然后你应该有这种ui
所以我将会留下会话作为游戏
我将会留下这个为随机并点击创建这里
我们必须创建一个游戏名称
所以我将创建一个样本游戏
然后规则将是tic tac toe
然后点击创建
现在我们可以查看会话的轨迹
但是如果你点击这个
这将带你到旧的x ray控制台
就在这里 正如你所见，有一个新的x ray控制台体验
那就是我正在向你展示的这里
所以到目前为止
让我们继续玩
所以点击这个游戏并点击播放
这里有一个经典的tic tac toe游戏
所以你只需点击
嗯 你想要的任何地方
所以这里这里这里然后
哦你看 有一条线
所以你会看到一秒钟
x有一个
所以x赢了
是的 我们做了所有的
嗯游戏
我们可以回去并玩更多的游戏
会发生什么当我们玩游戏
这将会发送痕迹进入X射线
那么如果我在这里进入X射线并查看我的服务地图
哪一个是第一部分
所以我要稍微拉远一点镜头，只为了这一个
所以这就是我的服务地图
这显示了我所有在aws组件的依赖关系
并且它们如何与已经进行的API调用相关联
正如你所看到的，我们这里有一个ecs容器
这就是代表它的东西
然后我们还有一个 dynamo db 表
我们有另一个 dynamo db 表
所以我们有两个 s
你现在可以看到 有点橙色
因为有剪刀 这是一个错误
我们会看一下
我们也有一个会话表
我们有一个状态表
一个 ns 主题和另一个表
所以我们有这么多 dynamodb 表等
这是服务图
你可以想象 当你有许多微服务和它们彼此之间都通过 api 进行调用
如果它们全都用 x ray 进行仪器
那么你将开始看到所有这些服务之间的依赖关系，在此基础上
如果出现错误
这里会突出显示
所以如果你点击这个
例如 我们可以看一下延迟
我们看到平均延迟等等
随着时间的推移，请求的数量
随着时间的推移，故障的数量
如果我们想看的话，响应时间分布
如果我们想要的话
当我们看到这一点时
如果我点击这里
正如你看到的，这里显示错误100%
看起来有一些错误
我可以分析这些跟踪
点击查看跟踪
现在我们有了这些
嗯 这是跟踪控制台
我们可以开始查询一些跟踪
我们可以运行一个查询并查看发生了什么
但现在我们没有任何数据
所以我要做的就是运行一个没有查询
正如你所看到的，我们有两条不同的轨迹
所以看起来一切正常，接下来你可以根据音符过滤它们
所以找出哪些对你来说是重要的
也许你只想查看与ecs容器相关的轨迹
或者与这个分数相关的
查看游戏表等 你可以开始构建你的查询
如你所见，如果我只想查看scokeep游戏
我可以添加到查询中
这将填充我的轨迹查询在这里
我可以运行我的查询
而不是两个，我有一个半到十个轨迹
然后我现在有这个
我可以看响应图在延迟方面
看起来我的大多数请求都在200毫秒以下
但有一个请求超过500毫秒
所以这真的取决于你想要从中得到什么
但这可能是一些好的建议帮助你看看
例如 这个慢的请求我们可以看看并理解
如果我们看持续时间
这可能是这一个
所以如果你点击它
现在你有关于特定轨迹的详细信息
所以这条轨迹将显示轨迹图
仅此一次
所以你可以看到我们在这里有少一些信息
因为这条轨迹只使用了ecs容器和四个
嗯 Dynamodb表
如果你向下滚动，你会看到请求的具体分解，基于不同发生的事件
你可以看到这条帖子实际上触发了对DynamoDB的大量API调用
所以，你可以看到这条帖子实际上触发了对DynamoDB的大量API调用
首先获取分数
然后获取游戏 然后获取分数状态等等
你可以看到延迟
每个需要多长时间等等
所以这给你提供了一些关于你数据的信息
当然，如果你点击它
那么你将获得一些分段详情
可以查看的信息
查看是否有错误
查看资源
查看注释 如果有任何问题
查看元数据 所以你可以了解哪些失败了哪些没有失败
当然，只有在有失败的情况下分析失败才有意义
但这给你提供了非常好的延迟信息
如果你启用了云观察日志
那么你还可以看到这条特定追踪对应的日志
这使得X射线非常强大
就是这样
这就是我想让你记住的X射线现在的状态
X射线目前没有之前的控制台所有的功能
所以我们只有服务映射和追踪
但是如果你在这里进入X射线控制台
正如你所见
我们有抽样、加密和分组等配置，这些都可以在这个控制台中进行设置
所以目前
我可能也会使用这个控制台
在以后的视频中
只需知道你输入x ray 就可以正常使用
最后，为了确保清晰
你需要删除这个堆栈
这样它就不会留下
痕迹
它在运行 所以你可以直接删除它
称为得分 保持x射线
删除堆栈 然后你就可以走了
这就是这节课的全部内容 我希望你喜欢它 我会在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/053_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p53 19. X-Ray Instrumentation and Concepts.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们来谈谈X射线的一些高级概念
我想首先向你展示如何对你的代码进行仪器化
这个词可能新
它对我也是新的 所以仪器化意味着衡量产品的性能
诊断错误和记录跟踪信息
所以它是软件工程中的一个领域来做这些事情
现在我们想要使用X射线对我们的应用程序进行仪器化，这就说得通了
当我们想要使用X射线对我们的应用程序进行仪器化时
我们需要更改我们的代码并使用X射线SDK
所以这里是我们如何使用X SDK来对我们的Node.js代码进行监控的一个示例
一旦我们添加一些代码，例如这里引入X SDK并在我们的Express应用中使用它
那么我们的代码就会被监控
这意味着我们将从我们的代码中获得跟踪信息并将其发送到X射线服务中
使用X射线SDK非常容易，有时只需要进行一些配置更改
你也可以修改你的应用程序代码
使用X射线SDK非常容易，有时只需要进行一些配置更改
你也可以修改你的应用程序代码
如果你想自定义你的路径并标注数据
或者改变x射线向x射线服务发送数据的方式
为此我们可以创建接收器、工具、过滤器、处理器和中间件
过滤器 处理器和中间件
这相当高级 但我的意思是你可以自定义x射线在你的代码中的工作方式
所以现在是一些高级的x射线概念
所以定义是段是如何我们在us看东西的
所以我们到目前为止一直在看段
因此，每个在运行中的应用程序都会发送它们
但如果你想要更精细
你可以定义子段
当你需要对段有更多细节时
然后跟踪是当你收集所有段在一起时
这将形成一个端到端的视图，对你的API调用或调用
因此这将是一个端到端的跟踪采样
我们会很快看到
这将减少发送到X Ray的请求数量，以减少成本
因为我们可能不需要所有的请求
非常重要的注释是当我们向索引添加轨迹时，添加一些键值对数据，以便使用筛选器
并且与筛选器一起使用
因此，在x ray中，注释非常重要
如果您想能够使用新索引搜索您的轨迹，而不是元数据
元数据也是键值对
但这一次，它们没有被索引
好的 因此，您的注释被索引，并且可以使用它们进行筛选搜索
而元数据没有被索引，因此不能使用它们进行搜索
现在，x ray 代理和 demon 也有一个配置，用于跨账户发送轨迹
为了做到这一点，我们需要确保i权限是正确的
代理将自动假设正确的角色
这将使我们拥有一个中央账户用于所有日志和应用程序跟踪
现在让我们详细谈谈抽样
因此，通过抽样角色
我们可以控制您发送到X-Ray服务和记录的数据量
您发送到X-Ray的数据越多
您支付的就越多
您可以在不更改代码的情况下修改您的抽样规则
默认情况下
有一个抽样规则
这意味着额外的额外sdk将记录每个秒的第一次请求
然后任何额外的请求中有五个
因此，蓝色的部分
每一秒的第一个请求被称为蓄水池
确保至少有一条轨迹每秒被记录
只要服务还在处理请求
然后那百分之五被称为超出储备侧的额外请求的速率
我们的样本尺寸
那么让我们谈谈自定义抽样规则
你可以制定自己的规定
你可以定义什么是蓄水池，什么是权利
这里是一个例子
在这个例子中，帖子的最低速率更高
所以我们说蓄水池是十
这意味着每秒会向x ray发送十次请求
然后其余的百分之十会被发送
在这里我们有更高的最低权利，并向x ray发送更多请求
而在这里我们希望进行调试
所以我们说我们想要所有的请求
所以有一个水库和一个正确的
这意味着所有请求都将发送到x射线
所以我们不想失去任何踪迹
这在我们需要调试以找到发生了什么时非常有帮助
对于每个单个踪迹
显然在生产中
这会非常昂贵因为我们现在将大量数据发送到x射线
但这非常有帮助
暂时更改这些自定义抽样规则以查看发生了什么
酷的地方是如果您在x射线控制台更改抽样规则
你不需要重启你的应用程序
你不需要对SDK中的任何X射线做任何事情，自动地，守护进程
额外的守护进程知道如何获取这些采样规则
并且正确地将正确的数据发送到X射线服务 所以，让我们进入下一节课，看看我们如何定义采样规则
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/054_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p54 20. X-Ray Sampling Rules.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以让我来告诉你在云观察中
你可以设置抽样规则
所以对于额外的追踪
您在左侧设置
然后在云设置下有追踪
你可以例如有加密规则
分组规则和抽样规则
所以我们将查看抽样规则
我们将查看设置
所以你可以看到现在有默认设置
这有十万优先级，说你有每秒一个请求
然后5%固定利率和匹配标准是所有
所以你可以编辑它
例如改变水库边和固定利率
如果你想要它会所有请求
因为这不能编辑
这是一个默认规则 好的
你唯一可以改变的是限制
但你实际上可以创建自己的采样规则
如果我点击创建采样角色
我可以将其命名为demo采样
在这里我们可以设置优先级
所以是1到9999之间，最低的优先级最高
如果我设置成5000
这将比默认规则具有更高的优先级
这是有道理的 在这里我们可以设置蓄水池大小
即每秒最多采样请求的数量
例如最大
嗯，一和固定利率为百分之一百
例如，如果你想要，这完全取决于你设置这些限制的方式
你想要如何进行
但更有趣的是，如果你想要只针对特定的服务
你可以输入服务名称
例如我的服务
如果你想要只获取例如POST请求
你也可以指定URL路径
所以你真的可以 例如
对向这个服务发出的所有请求进行抽样，并获取该请求的追踪信息
而且，一旦你创建了这个抽样规则
那么，你不需要重启x ray的守护进程
它们会自动考虑这些规则
然后你会在x ray控制台直接看到抽样效果的影响
这就是本节课的内容 希望你喜欢 我们下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/055_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p55 21. X-Ray APIs.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 让我们来谈谈X射线API
你需要在高层次上了解它们并理解它们做什么
因为考试可能会要求你选择
这是否是X射线用于某事的正确API
所以让我们看看正确的API
这是X射线鬼用来将数据写入X射线服务的API
所以这是一个管理策略称为X射线权限
仅限访问 你可以看到它有五个项目
我将尝试向你描述它们
第一个是插入轨迹段
正如名称所示，它上传一个段文档到AWS
X射线这是需要的
如果你想要写入X射线
然后我们有插入遥测记录
这是用于上传有关接收的段数量
拒绝和后端连接错误的信息
这有助于度量
我们有获取采样规则
通常当我们写入时
我们有很多插入
因为这就是AWS中API的名称
每当你写入时都说插入
但对于这个权限API
有一个获取 这被称为获取采样规则
你知道为什么吗
我们曾看到每当我们在X射线控制台更改采样规则时
所有X射线鬼都会自动更新以知道何时将数据发送到X射线
因此，为了使您的X射线鬼能够知道采样规则是如何变化的
那么获取采样规则的授权和权限是必要的
这也适用于获取采样目标和获取采样统计摘要
这些都是高级API
但也与采样规则相关
因此，总结您的X射线鬼以写入X射线
需要写入权限
所以插入轨迹段和插入遥测记录
然后你应该能够获取采样规则
所以获取采样规则非常简单
现在，为了使这些API调用工作
显然，您需要确保您的X射线鬼具有正确的
我是政策授权这些API调用
这是权限方面
那么，读取方面呢 这更复杂
但这是一个管理策略用于读取
正如你所看到的，所有这些都是获取
获取获取获取获取获取 我们有一个批处理
获取跟踪 这也意味着获取服务图是为了获取我们在控制台看到的主要图
批量获取跟踪是为了检索由ID指定的跟踪列表
每个跟踪 正如我们所知
是来自单个请求的一组段文档
然后我们有获取跟踪摘要来获取可用的指定时间的跟踪ID和注释
如果你想获取完整的跟踪
那么你将这些ID传递到批量
获取跟踪API
最后获取跟踪图来检索一个或多个特定跟踪ID的特定服务图
这就是全部
这些都是读取API
当我去控制台时这是必要的 如果你在考试中看到这些API
你应该准备好知道何时使用哪个以及为什么
好的
希望这有所帮助
我会在下次讲座见到你 希望这有所帮助 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/056_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p56 22. X-Ray with Beanstalk.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以这里有一个快速讲座，讲解如何将x射线与beanstal集成
所以beanstal平台包括额外的恶魔
所以我们不需要包含它
你可以通过在beanstalk控制台设置一个选项来运行恶魔
正如我们在实践操作中看到的
或者你可以创建一个名为x ray - demon. config的eb扩展文件
所以再次在d. eb扩展文件夹中，有一个点配置扩展
它看起来像这样
它只有一条线
它只是启用了x射线恶魔，所以简单
然后你这样做之后
显然你需要确保你的e c
两个实例需要有正确的实例配置文件
这样extra demon可以正确运行并写入x ray服务
并且 当然 你需要确保你的应用代码已经进行了instrumentation
使用extra sdk发送这些trace
如果你运行多容器docker
你需要自己管理extra demon
正如我们在下一节课中会看到的，ecs
好的 所以只需前往亚马逊弹性beanstalk控制台
然后创建一个应用程序
这个叫做demo x ray
我只想向你展示哪些选项对于设置x ray很重要
对于平台 只需选择node js，然后选择推荐的设置
我们将使用示例应用程序
然后我们点击
配置更多选项
所以我们配置更多选项时
重要的是围绕软件
所以你点击软件并编辑
如你所见 只需点击一次
即可启用射线gm在你的beanstalk环境中运行
所以这是你需要做的第一步
所以 这样做
然后你确实可以保存
第二部分是确保e c two实例有一个
允许它们连接到x ray的角色
为了做到这一点 我们将进入安全并编辑这个
正如你所看到的 我们需要有一个名为iam instance profile的虚拟机权限，并从这个列表中选择
所以现在对我来说选择的是aws elastic beanstalk
e c two角色 让我们进去
我只是来看看这个角色是关于什么的
在角色下
我们输入beanstalk，我们有Elastic Beanstalk
E c two角色
如果我们看一下现在的权限
我有三个权限策略
这里就是beanstalk
多容器
Docker和工人层
如果我点击第一个
这是beanstalk网络层
我可以看一下策略概述
下面我们看到我们有X-Ray的权限在这里
如果我点击它们
我们有读取权限来获取采样规则
统计摘要和采样的目标
然后对于权利我们有记录遥测和跟踪片段
这允许我们将数据发送到X-Ray
所以如果你要为你的E C
Two实例分配一个角色或IAM实例配置文件
请确保您仍然具有必要的额外权限
即使您启用了Beanstalk的代理
您仍然需要确保IAM角色是正确的
这就是本讲座的全部内容
完成时，请确保删除此应用程序
但现在你知道如何使Beanstalk与X-Ray一起工作
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/057_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p57 23. X-Ray & ECS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 所以，关于如何将ecs与x射线集成的理论讲座
以及您将拥有的三种选项
首先，您有一个ecs集群
运行x射线守护程序的一种方式
是使用容器作为守护程序本身
这意味着我们有两个ecs
两个实例 例如，在我们的ecs集群中
记住，我们管理这些ecs
两个实例
因此，我们将运行一个守护程序任务
x射线守护程序的守护程序容器
这里有两个eyes到单词守护程序
这意味着x射线dm容器将运行在每个ecs
两个实例上 如果您有十个ecs
两个实例在你的ecs集群中
那么你将有十个容器
一个在ecs 两个实例上运行作为守护程序容器
好的 这意味着x射线代理现在运行在所有ecs
两个实例上 因此，您可以在ecs
两个实例上启动您的应用程序容器
并在从网络角度来看正确地连接它们
以通过udp端口与x射线守护程序通信
然后您可以运行所有应用程序
在这种情况下，您将每个ecs 两个实例上有一个x射线守护程序容器
现在，运行x射线在您的ecs集群中的第二种模式称为侧车模式
这意味着您仍然有ecs 两个实例，但现在您将运行一个x射线守护程序容器
与每个应用程序容器一起运行
并将它们从网络角度来看连接
这就是为什么它被称为侧车模式
因为它意味着x射线守护程序现在作为应用程序容器的侧车运行
这就是为什么它被称为侧车
如果我们看看这个
现在我们每个应用程序容器都有一个侧车
如果您在ecs
两个实例上有20个应用程序容器
那么我们将有20个x射线侧车
这就是侧车模式的工作方式
现在，fargate集群我们没有对ecs 两个实例的控制权
它就是一个ecs集群
但我们没有对底层实例的控制权
因此，我们不能使用x射线守护程序容器，我们必须使用x射线容器作为侧车模式
所以，如果你想启动一个fargate任务
它将是应用程序容器和x ray侧车在这里和那里
所以这给你提供了三种运行ecs和x ray的选项
我希望这能使它稍微更清晰
至于你怎么做
现在我仍然要向你展示一个示例任务定义
我们不会运行它
因为我们需要构建所有图像
这将非常复杂
但这里是来自文档的内容
我们首先应该看的是x ray demon将运行
这是任务定义的第一部分
在端口映射方面
容器端口2000映射到实例
协议是udp
所以记住这个容器端口2000和协议是udp
一旦x regiment运行
这是一个侧车模式
这里有我们的应用程序
这个案例称为记分板api
我们需要查看的第二件事是此环境变量aws
X ray demon地址
您需要设置此环境变量
因为那是x ray demon如何找到x的方式
他们说那是x ray sdk
抱歉将知道如何找到x ray demon的方式
这个的值是x ray demon端口
2000和2000来自上面的2000
最后你需要做的是将这两个容器链接在一起
从网络角度来看
这就是为什么说链接x ray demon
这就是我能够解析这个主机名x ray demon到此处容器的方式
所以这可能有点复杂
尤其是如果你是新的ecs用户
但请记住这个幻灯片的要点
是你需要将容器端口的x regiment映射到2000 udp
然后您需要设置一个名为x dm地址的环境变量
最后需要从网络角度来看链接这两个容器
我希望这能帮助你理解如何精确地与ecs一起运行x ray
我知道这个问题已经多次出现在学生的考试中
所以我认为你应该对它有更深入的了解
更深入的了解这些是如何工作的
我希望这是有帮助的 我将在下一节课见到你 我希望这是有帮助的
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/058_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p58 24. AWS Distro for OpenTelemetry.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在我们来谈谈AWS Distro for Open Telemetry
那么Open Telemetry是一个项目
AWS创建了这个项目的一个分发版，并且它是AWS支持的
他们称之为安全且生产就绪
那么Open Telemetry是什么
嗯，Open Telemetry是一种获取一套API的方法
库、代理和收集服务来收集您应用程序的分布式追踪和指标
它也可以帮助您收集来自AWS资源和服务的元数据
想法是它与X-Ray非常相似
但它是开源的
因此你有代理，这些代理可以自动进行仪器化，收集跟踪信息，无需你
甚至无需更改你的代码
这与x射线非常相似，在此基础上
多亏了这种可以发生在你账户和应用中的大规模收集
所有这些跟踪和这些指标可以发送到多个ab服务，也可以发送到合作伙伴解决方案
例如
我们可以将跟踪发送到x射线服务
我们可以将指标发送到云观察
或者将跟踪和指标发送到prometheus
想法是你将对你的在aws上运行的应用进行仪器化
例如e C Two
在ecs 在eks
屁或lambda
或者它可能是在预置环境中运行的应用程序你将
然后使用开放式遥测标准将这些跟踪和指标发送到最佳
例如x ray或合作伙伴服务例如datadog等
因此 开放遥测与X射线的区别在于，您可能希望从X射线迁移到使用AWS分布式开放遥测
如果您希望与开源API标准化
因为希望所有数据使用遥测
或者您可能希望同时将追踪数据发送到多个目的地
这是开放遥测支持的功能
所以总结一下
我们有开放遥测的分布式
我们收集追踪数据
然后每个应用的请求都会通过
然后我们可以再次收集每个有它的地图的指标
然后我们还可以收集
多亏了aws
这个发行版 我们可以收集关于您aws资源的上下文数据
这可以发送到x ray cloud
观看亚马逊管理的prometheus服务
以及任何由open telemetry支持的合作伙伴监控解决方案
这就是全部，只是一个高层次的概述
但你知道它是什么
如果您在考试中看到这一点
通常只有 它只能是一个非常高级的问题
所以我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/059_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p59 25. CloudTrail.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈云追踪
云追踪是一种获取治理信息的方式
用于您的AWS账户的合规性和审计
云追踪默认启用
这将允许您获取在您的AWS账户内所有事件和API调用的历史记录
通过控制台
通过SDK
通过CLI 其他AWS服务
所有这些日志都将出现在云追踪中
你现在可以做的是，你也可以将这些来自crp trail的日志上传到云中
查看日志或亚马逊是直接的
你可以创建一个跟踪，应用于所有地区或单个地区
如果你想积累所有这些地区的事件历史
到一个特定的
例如 S三个桶
当我们使用cloudtrail时
例如 如果有人去删除一些在aws中的东西
例如 假设一个e
C 两个实例正在被终止，你想找出是谁干的，嗯
答案就是查看云追踪
因为云追踪里会有那个api调用
我们将能够找到答案，理解谁做了什么
以及何时，所以总结一下
云追踪在中间
和SDK的动作
命令行或控制台
或者对于用户和角色的操作，以及其他云服务，都会在云控制台中显示
我们可以在其中查看和审计发生了什么
如果你想要保留事件超过90天
那么我们可以将它们发送到云监控日志
或者我们可以将它们发送到三个存储桶中
所以让我对云追踪深入探讨一下
所以在云追踪中，你可以看到三种类型的事件
第一种叫做管理事件
这些代表在你AWS账户中的资源上执行的操作
例如 每当有人配置安全时
他们会使用名为我是附加角色策略的api调用
这会出现在云追踪中
如果你创建一个子网
这也会出现
如果你设置插头
它会默认出现
任何修改你的资源
或你账户的东西都会出现在云追踪中
默认情况下，轨迹被配置为记录管理事件
无论什么，你都可以把管理事件分为两种类型
你有读取事件，这些事件不会修改资源
例如，有人正在列出我在i am中的所有用户或列出所有e
C 两个实例在e中 C两个
这类事情你可以将它们与可能改变资源的正确事件分开
例如，有人删除或试图删除一个LGB表格
显然，正确的事件可能具有更多重要性
因为它们可能破坏你的阿里云基础设施
而读取事件只是为了获取信息
这仍然非常重要，但可能破坏性较小
然后你有数据事件，它们分开
默认情况下，数据事件不会被记录，因为它们是高并发操作
那么事件是什么
你有亚马逊S3对象的活动级别
例如获取对象
删除 对象
放置对象 正如你所看到的
这些可以在s3桶中发生很多
这就是为什么它们默认不被记录的原因
你可以再次选择分开
读取和写入事件
读取事件将是获取对象
而写入事件将是删除对象或放置对象
云追踪中的另一种事件是aws lambda函数执行活动
所以每当有人使用invoke api
所以你可以了解你学习了多少次
函数的调用次数 这可能是巨大的数量
如果你的lambda函数被执行很多
第三种类型的事件在cloutrell被称为cloud trell insights
事件 所以我会详细地谈论cloud insights
在下一页我会详细地谈论cloud insights
现在让我们谈谈lateral insights
当我们有这么多管理事件跨越所有类型的服务
因此，在你的账户中发生了很多很多API，非常迅速地发生着。
理解看起来奇怪的东西可能会相当困难
什么看起来不寻常，什么看起来不寻常
这就是文化洞察力发挥作用的地方。
所以，有了文化洞察，你必须启用它，你必须为此付费
它将分析您的活动，并尝试检测您账户中的不寻常活动。
例如 不准确的资源分配
达到服务限制
一系列行动爆发
定期维护活动的空缺
它的工作方式是，clu会分析正常管理活动应该什么样子，来创建一个基准线
这个基准线
然后它会持续分析任何符合这类事件的东西
所以每当有东西被改变或者试图被改变以检测异常模式
所以非常简单，管理事件将被clu持续分析
这将生成洞察事件，如果检测到异常
所以这些异常
这些洞察事件将出现在云轨迹控制台
它们将被发送到亚马逊S3
如果你想要 以及一个事件桥事件，所以在云中
哪类事件将被生成
如果你需要在这些云轨迹洞察的基础上进行自动化
例如发送电子邮件
这就是文化洞察背后的想法，最后
让我们谈谈云轨迹的保留
所以事件默认情况下在云轨迹中存储90天
然后它们将被删除
但有时你可能想让事件持续更长时间
如果你需要回溯一年前发生的某件事情，以便于审计目的
为了保持这些事件超过这个期限
你需要做的是将它们转移到s3
所以将它们发送到s3
然后你会使用athena来分析它们
所以非常简单，你所有的管理事件
你的数据事件和你的洞察事件将进入文化进行90天的保留期
然后你会将这些事件记录到你的s3桶中进行长期保留
当你准备好分析它们时
你将使用雅典娜服务
这是一个无服务器服务，用于查询S3中的数据
以找到您感兴趣的事件并了解更多关于它们的信息
好的 我希望你喜欢这节课 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/060_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p60 26. CloudTrail Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来看看cloudtrail和相关内容
这是一个服务，可以拦截您账户内的任何API调用或用户活动
在这里，左边的面板上
我们可以查看事件历史
这是过去90天的管理事件
您可以看到随着时间的推移，账户内所有API调用
所以它不必
它不必非常有趣
好的 但所有内容都会在这里
所以我想做的是
例如，我想查看我的e
C 两个控制台 我创建了一个演示实例
我将要做的是我将要终止这个实例
所以我做对了
点击终止
现在实例正在终止
我将要做的是
我将检查这个事件是否发生在云轨迹中
我将等待大约五分钟后再回来
我刚刚刷新了我的页面
如您所见 我运行了终止实例的API调用
我们可以看到事件源是什么
它是E C 二从哪做的
访问密钥 那是用过的
用过的区域等等
我们可以在这里得到整个事件
这就是云轨迹的全部力量
我们可以看到真正发生的所有事件
云轨迹我清理了这个UI
这是一个实践层面的简短介绍
但这足以让你开始并回答考试中的问题
就是这样 希望你喜欢 我会在下一堂课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/061_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p61 27. CloudTrail - EventBridge Integration.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


你需要知道的一个非常重要的文化融合是
与亚马逊事件桥拦截任何API调用
例如，如果你想接收短信通知
每当用户删除Dynamo DB中的表
通过使用删除表API调用
每当我们在AWS进行API调用时
正如你所知，API调用本身将在云跟踪中记录
对于任何API调用
所有这些API调用最终也会作为事件出现在亚马逊事件桥中
因此，我们可以查找那个非常具体的删除表API调用
从中创建一个规则
在这个规则中会有一个目的地
目的地是亚马逊s
因此我们可以创建警报
让我给你举几个例子，说明如何将亚马逊
Eventbridge和cloutre集成
例如 假设你想被通知
每当用户在你的账户中假设一个角色
所以假设角色是i am服务中的一个api
因此将被云追踪记录
然后使用事件桥接集成
我们可以触发一条消息发送到S主题
同样我们也可以拦截API调用
例如 更改安全组的入站规则
所以安全组调用被称为授权安全组入站
这是一个E C
二API调用
所以这些将被云追踪记录
然后他们将出现在事件桥中
然后我们可以在s和s中触发通知
所以你可以看到可能性是无限的
但现在你已经有一些关于如何集成可以利用的想法
我希望你喜欢它 我会在下次讲座中见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/062_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p62 28. CloudTrail vs CloudWatch vs X-Ray.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以这是你可能觉得显而易见的事情
但你们知道云追踪，云监控和X光有什么区别吗
我会试着记住它，总结在一张幻灯片上 所以云追踪是用于审计在你账户中由用户服务或甚至从AWS控制台发出的API调用
这非常有用当你想要检测未授权的调用，或者你想找到由于API调用导致的根本原因时
现在云监控是用于使用指标进行监控
云追踪是审计API调用
云监控是使用指标进行监控
X光是使用日志进行监控
云追踪是审计API调用，云监控是使用指标进行监控，X光是使用日志进行监控
所以云指标用于监控
云监控日志用于存储应用程序日志
云监控警报在出现意外指标时发送通知
例如 所有这些都与监控有关
好的 所以云API调用
云监控用于监控，X-Ray用于中央服务的自动化跟踪分析
地图可视化 所以如果您有分布式服务
这是一个看待事物的好方法
这对于调试非常有帮助
还可以在x射线控制台中查看延迟错误和故障分析
你也可以得到
如我所说 请求跟踪跨分布式系统
希望 这使您很清楚哪个服务用于什么，云观察主要是用于总体指标
x射线更具颗粒性
以追踪为导向的服务
云追踪将被用于审计API调用
好的 我希望这对你有帮助 下次课程再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/063_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p63 29. AWS Quick Clean-Up.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以现在只需要快速清理一下
我们不再使用beanstalk
如果你去beanstalk
你可以删除所有这些环境
你可以直接删除应用程序
然后点击删除
这将删除你里面的所有内容
同样你可以去code deploy和code pipeline
如果你想要 你也可以删除它们
这个过程非常简单
你去code pipeline
点击你的管道
然后你可以编辑和删除
如果你想看一些成本
你也可以删除我们在这门课程中创建的任何东西
这允许你控制你的成本
但是
现在最昂贵的资源是elastic beanstalk
所以确保你删除elastic beanstalk 如果你跟着我在这门课程中
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/064_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p64 01. AWS Lambda - Section Introduction.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们开始进入正题
新的开发者考试将询问您许多关于无服务器计算的问题
无服务器 你可能听说过
这不是一个流行词
这是一个新的趋势，一个新的范式
我们将从aws lambda开始无服务器的旅程
aws lambda正成为最广泛使用和受欢迎的服务之一，它在多个领域进行了革命
人们如何做应用程序
部署它们并扩展它们
对你来说，知道如何正确地使用lambda函数非常重要
所以我专门安排了这一节来理解lambda的工作原理
不仅仅是在高层次上
而是以现实世界的方式
那么我们开始吧 编码我们的第一个函数
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/065_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p65 02. Serverless Introduction.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们来讨论
什么是无服务器
无服务器是新事物
当你使用无服务器服务时，开发者
你不再需要管理服务器了
不是说你没有服务器了
只是说你不再管理它们
你只需要部署代码
最初你只部署函数
所以最初无服务器意味着无服务器计算或FaaS
但现在无服务器意味着更多，所以最初
无服务器由AWS Lambda开创，我们将在本节中看到
但现在也包括任何远程管理的东西
所以数据库，消息传递，存储
只要你不设置服务器
所以无服务器并不意味着没有服务器
它只意味着你看不到它们
或者你不设置它们
所以如果我们深入研究AWS中无服务器的含义
我们有我们的用户
他们会收到
例如 静态内容从我们的S3桶交付作为网站或云加S3
然后我们将使用Cognito登录
这是我们的用户身份存储的地方
他们会通过API网关调用您的REST API
API网关将调用Lambda函数
Lambda函数将存储和从DynamoDB中检索数据
这只是一个例子
本节将致力于学习与lambda dynamodb相关的许多事情
API网关 认知和等等
但是，这只是为了给您提供一个无服务器应用的参考架构
是的，没错
它是lambda动力
Cognito身份和访问管理
亚马逊API网关是三个
但是也有事情我们已经见过了
例如s和s和sq
是的 确实 我们没有管理任何sqs和s的服务器
它们自己就在扩展
这符合无服务器使用场景
你能看到数据流吗
因为再次 它会根据你的数据吞吐量进行扩展
你只支付你所使用的费用 你不需要预置服务器
极光无服务器，当您的光环
数据库按需扩展
无需您管理服务器
步骤功能和farforget
因为farwas一个无服务器函数ecs
在那里我们没有为运行我们的Docker容器提供基础设施
希望这是一个简短而甜美的无服务器介绍
在下一讲中，我们将开始使用lambda
这将是许多内容要学习
但考试将严重测试您的无服务器知识 所以让我们开始
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/066_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p66 03. AWS Lambda Overview.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以什么是aws lambda
并且为什么这对我们有帮助
那么让我们举一个例子
我们将从亚马逊开始
E和C两以及亚马逊两
正如我们所知，云中有虚拟服务器
我们必须为他们准备物资
因此我们的资源分配受到内存和CPU数量的限制
他们必须持续运行
我的意思是我们可以通过高效地启动和停止它们来优化它们
但是除此之外，它们会持续运行
无论你实例上是否发生任何事情
如果你想要扩展
你可以使用自动扩展组
但这意味着你需要做一些事情来自动添加和删除服务器
这是做事的一种方式
而且它做得很好
然后有aws lambda
所以使用lambda 这些是视觉函数
无需管理服务器
这意味着我们只需准备代码，函数就会运行
它受到时间限制
所以我们谈论的是不超过15分钟的短执行时间
在我看来这并不是很短的时间
最后它们按需运行
这意味着当你不使用lambda时
你的lambda函数不会运行
你只会在建立你的函数时运行
并且在被调用时会按需运行
这是从亚马逊的巨大转变
E C Two 最后，这个杀戮是自动化的
如果你需要更多的lambda函数
嗯，并发事件
然后自动
它将为你提供更多的lambda函数
神奇的 我们会在实践中看到这一点
Lambda的优点
我相信你已经看到了很多 首先，定价非常容易
你将为请求的数量付费
Lambda接收 所以调用的数量和你的计算时间
所以Lambda运行的时间
Lambda有一个非常慷慨的免费层
这是一百万次Lambda请求和四十万吉字节秒的计算时间
它也集成了众多其他服务
正如我们将看到的 我们可以在lambda中使用许多不同的编程语言
所以我们相当自由
最后，监控集成到云观察中非常容易
如果你想为函数提供更多资源
你可以为每个函数提供高达10GB的RAM
这很多
顺便说一下，如果你增加函数的RAM
这将也会提高你的CPU和网络的性能和质量
所以，lambda可以运行多种语言
例如，node js用于javascript
Python Java C#
所以，无论是.NET Core 还是 PowerShell Ruby
它还通过称为自定义运行时API的东西支持多种其他语言
例如 它支持Rust或Go语言
通过这种方式，您还可以在lambda中使用容器
这就是容器映像
你必须实现被称为lambda运行时API的东西
从考试的角度来看，这可能有点超前
但我们应该记住有一个名为ecs或far的服务
为了运行容器映像
尤其是Docker映像
从考试的角度来看，总是倾向于在ecs或gets上运行它们，而不是lambda
即使lambda支持运行一些级别的自定义Docker映像
所以你不需要记住所有的语言
当然，从lambda的角度来看
但是请记住它具有一定的支持水平
最重要的肯定是无疑的
Node.js 和 Python
现在我说了，lambda已经与许多服务集成了
那么我会给你一些例子和一些关于它们如何整合的想法
在这个课程中，我们将会看到一些这些集成。
所以API网关是用来创建一个REST API
他们将调用我们的lambda函数
Kinesis将使用lambda在实时进行一些数据转换
然后使用群组来创建一些触发器
所以每当我们的数据库发生任何事情
都会触发一个lambda函数
亚马逊s3 我们已经见过了
一个lambda函数会在任何时候被触发
例如 在s3中创建了一个文件
这将是lambda边缘
我有一节专门讲这个在章节中
云观察事件或事件桥
这是我们在aws基础设施中发生的事情
我们希望能够对这些事情做出反应
例如 假设我们有一个代码管道的状态变化
我们希望根据它进行一些自动化操作
我们可以使用lambda函数，云观察日志流这些日志
无论何时何地，我们都可以在ns主题中接收通知
在sqs中处理来自sqs的消息
最后，cognito用于在用户登录到数据库时做出反应
例如
所以这些都是主要的
有很多lambda集成
所以我想给你展示一个很好的例子
这是一个无服务器缩略图创建
假设我们有一个s3桶
我们希望在飞行中创建缩略图
所以会有一个事件
那就是新图像被上传到亚马逊s3
这将通过s3事件通知触发
一个lambda函数在那个lambda函数中会有生成缩略图的代码
那个缩略图可能会被推送并上传到另一个三个桶中
或者相同的三个桶中
这将是那张图片的一个小版本
而且我们的lambda函数可能会想要在元数据周围插入一些数据
对于图片 例如 图片的名称和大小
创建日期 等等
因此，多亏了lambda
我们已经自动化并采用了对新应用程序事件的响应架构
新图像正在被正确地创建
另一个非常流行的例子是无服务器定时任务
所以cron是你在服务器上的一种方式
C 两个实例 例如，每5分钟或每周一上午10点生成任务等等
但你需要在虚拟服务器上运行cron
所以e C 两个实例等等
如果你的实例没有运行
或者至少你的实例没有做任何事情
那么你的实例时间就会被计为浪费
因此
你可以创建一个云观察事件规则
或者一个事件桥规则，它会每小时触发一次，并且每小时
它会与一个lambda函数集成，该函数会执行你的任务
所以这是一个创建无服务器Chrome的方法
因为在这个例子中
Cloud Watch事件是无服务器的，Lambda函数也是无服务器的
现在让我们以Lambda定价为例
你可以在这个网站上找到所有必要的信息，如果这个信息在这里过时了
但它会给你一个例子，告诉你这是如何工作的
所以你支付调用
前100万次请求是免费的
然后你将支付每额外20美分
100万次请求
这使得请求非常便宜
然后你将按毫秒增量支付持续时间
所以你将获得第一个400,000GB秒的计算时间
每月免费 然后这意味着Gigabyte Seconds
意味着
这意味着你获得400,000秒的执行时间 如果函数有1GB的RAM
这意味着你有8倍的更多秒
如果函数有8倍的更少RAM
即128MB的RAM
然后您将支付6美元600,000GB秒
所以老实说
你可以做数学 运行代码在Lambda上通常非常便宜
所以这是一个创建应用程序的流行选项
这就是全部了 现在让我们进入实践环节，了解Lambda是如何工作的 让我们开始吧
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/067_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p67 04. AWS Lambda - First Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 我们将练习使用lambda服务
当你进入lambda时
你可能会在屏幕上看到
但我真的很喜欢另一个屏幕
如果你在你的url中
你将替换斜杠
发现由斜杠开始
你可能会在这个屏幕上
这是我真的很喜欢的屏幕 因为它具有教育价值
我想向你展示，所以lambda在这里帮助你运行代码而不用考虑服务器
这使得它成为一个真正的无服务器服务
所以，我们可以使用任何类型的编程语言
例如 .NET Core
Go java Node.js
Python Ruby 或者任何自定义运行时
如果你需要一个由运营商提供的运行时
例如，使用lambda运行时是可能的
因此，从这个代码中，你将看到它被上传到lambda控制台
然后，lambda将运行代码为你
让我们看一个非常简单的代码
例如，Python 我们有一个lambda处理程序
它将打印事件
然后说返回来自lambda的问候
那么我们点击运行
我们得到来自lambda的问候
这意味着lambda函数运行了我们提供的代码，就在这里
非常简单 接下来
lambda函数是如何被调用的
我们可以点击运行按钮
当然 但我们也可以让lambda对事件做出响应
这就是我想向你展示的
我认为这真的很酷 正如我们所见，事件可以来自各种来源
例如 在这个例子中，这是修剪分析
因此，流分析将事件发送到Lambda函数
Lambda函数返回
你好费尔南达 来自Lambda的问候
来自那的问候，等等
但这不仅仅是流分析
如果你点击电话
这里会向移动物联网后端发送一条消息
而这个物联网后端也会调用我们的lambda函数
同样，如果上传照片到S3存储桶进行数据处理
那么lambda函数也会被调用
但酷的是，如果你在这些来源中点击很多
你可以看到右边
我们有更多的齿轮
随着左侧的流量和lambda调用增加
那么lambda调用和并发运行的lambda函数也会增加
所以这真的很酷，因为这意味着随着我们有更多的负载，会自动
Lambda会根据我们的负载进行扩展
那就是使用lambda作为计算平台的全部力量
这就是为什么lambda是无服务器的
这相当有效
所以如果我们在这里进去
正如我们所见，当Lambda函数被调用时
随着时间的推移，我们接收的调用越来越多，但成本仍然为零。
因为提供了免费试用
一旦我们达到一百万次调用
然后Lambda函数将开始产生一些费用
所以我们进去并开始有超过一百万的调用，这就开始了
我们可以看到
正如你所见 我们已经接近200万次调用
而我们的成本只有14美分
所以它非常、非常、非常
嗯
在规模上运行Lambda函数并执行一些工作是非常经济实惠的
所以你可以看到你可以玩一玩，看看你调用越多，费用就越高
成本越高
但控制得很好
Lambda可以是一种成本节约机制
如果你规模使用
这就是对lambda的介绍
所以我点击创建函数
我可以选择三种选项
我将选择使用一个蓝图
这将是hello world函数
所以我只是搜索hello world
然后我会选择Python版本
所以使用Python3进行示例
但这可能与你的不同
只要它是用于函数名的Python next
我们将进入demo - lambda
然后我们将创建一个具有基本lambda权限的新角色
这将是我们的lambda函数的 我是角色
然后我们可以查看函数代码
所以这就是lambda函数的样子
所以我们有一个lambda处理程序
这是处理调用我们lambda函数事件的函数
目前它只是打印一些值并返回键值1
所以我们在测试我们的函数时会详细查看这一点
当你准备好时 只需点击创建函数
好的 所以我的功能已经创建
正如我们所见，代码源在这里
实际上点击lambda函数
打开并打开它
我们可以看到之前加载的函数代码现在加载到这个代码编辑器中
那么我们为什么不去测试这个函数呢
所以我要点击测试
我们需要创建一个新的测试事件
这是一个hello world事件
包含key one value one
Key two value two key three value three作为相邻的文档
我将其命名为demo events并点击创建
所以现在demo事件已成功保存
如果我点击测试
现在将运行演示事件，结果是值一
函数日志是值一等于值一
值二等于值二
值三等于值三
这只是
嗯 这三个打印语句的结果
最后，响应值又是值一
由于这行代码
所以这可能看起来并不起眼
但从程序员的角度来看
如你所见
你只有一些代码，它就被上传到了lambda
然后它很快地被lambda运行
如果你的开发者，这是一个巨大的改进
如你所见，部署代码并运行它
除此之外，它无缝运行，并且会自动扩展
并且它是完全无服务器的
好的 我们现在没有部署任何服务器，在建设期间
如果你在这里向下滚动
对不起 然后 如你所见
持续时间为2.3秒
2毫秒 我们被收取了3毫秒的执行费用
这里是我们分配的内存大小
以及实际使用的内存
并且初始化花了多少时间，因为这是我们第一次使用我们的lambda函数
如果我再次运行它 哦，如果我回到函数
对不起，再运行这个
正如你所看到的，现在函数的持续时间为1.33毫秒
在右边没有初始化
因为我的lambda函数已经准备好被使用
好的 所以这是处理问题的一种方式
我会向你展示的另一件事是从这个lambda函数
我们能够配置它
那么如果我进入一般配置
我们得到了一些最重要的设置
第一个是关于内存的
因此我们可以拥有来自128兆字节到任何地方的内存
高达一万两千四百兆字节的内存
显然如果你有更多的内存
你将会在超时方面有更多的构建
我们可以在三秒到五秒之间去任何地方
一路到 正如你所看到的，十五分钟后
所以最大超时是十五分钟
但你需要确保你只使用
适合你预计使用的功能的时间
然后执行角色是lambda在开始时创建的
好的 所以这些都是最重要的设置
好的
我们可以查看的另一件事是监控
所以在监控
我们能够看到lambda函数的运行情况
它被调用了多少次
在这里 一次持续了多久
是否有错误或成功
等等 这可能非常有帮助
但我们有像 uh
与云监控指标的集成
还有云监控日志
所以现在我们什么都没有 但我们现在可以查看云监控日志
当函数运行时
要做到这一点 只需在右侧刷新
最近的调用 我们可以看到这里有一个流锁定
如果我点击它
我将直接进入云监控日志
我们可以看到云日志
我们都有 uh
调用该lambda函数的日志记录
Lambda 和 lambda 是我的region中的lambda函数的名称
显然 我们这里有一个日志流
所以我们将所有日志记录发送到 lambdas
你可以尝试修改代码
例如 如果我们取这个代码
我们去 lambda 函数
我将在这行代码上添加注释，使用#，取消注释这一行
这将引发一个异常
所以要做到这一点 我需要首先部署更改，点击部署
现在更改已部署
现在我可以测试我的功能
在这里我们可以看到执行结果
这是一个错误，某事出错了
类型是异常
正如我们所见，某事出错了
这是由于这里的这行代码触发的
任何类型的错误也会被lambda报告
你可以在云观察日志中查看
以便理解
错误日志的发生位置
如果我回到云日志
这里有第二个日志流
我打算打开它
然后我们在这里得到了这个异常
所以我们也可以回溯到异常的日志
在低日志中 理解问题的根本原因
现在相当容易
如果你想让函数再次运行，没问题
你只需要
反向操作 然后点击测试，再次
这次，Lambda执行函数将正常工作
我们可能最后想要检查的一些事情
是在这里，我们运行Python 3.7的运行时设置
在这个例子中 但你可能会收到一个更新的版本
可能在你的那边，处理程序是lambda_function点lambda_handler
这意味着要查看lambda_function点py文件和函数名称lambda_handler
如果你往上看
我们可以看到函数名称是lambda，只有这一个函数
p中我们有lambda_handler函数
这就是为什么需要调用这个函数
特别是我们也写了到云观察日志
我们能够这样做的原因是
如果我们进入我们的lambda配置并转到权限部分
我们有一个名为demo lambda roll的真实名称，它是由lambda控制台为我们创建的
如果你查看策略本身
我们可以在策略概述中看到我们有权将日志写入云观察日志
这在资源概述中也可以看到
云观察动作在资源上
允许我们创建直播流分析组
同时也将日志发送到云观察日志
这就是整个策略背后的想法
嗯 就在这里权限部分
这就是讲座的全部内容
我希望你喜欢它 如果你是aws认证开发者课程的一部分
那么准备好接受关于lambda的额外几个小时的内容
如果你不是，这也足够你考试了
我希望你喜欢它 我会在下次讲座见到你 我希望你喜欢它
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/068_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p68 05. Lambda Synchronous Invocations.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在
让我们详细看一下我们已经在使用的lambda函数的第一种调用类型
称为同步调用
当你使用CLI和SDK
API网关
甚至应用程序负载均衡器时
什么是同步
这意味着你正在等待结果
然后结果将返回给你
并且任何返回给你的错误都必须在客户端处理
这意味着如果我的lambda函数失败而我是从控制台调用它的
我想点击重试按钮来重试它
这意味着任何时候在lambda中发生错误
客户端必须决定如何处理
你是想重试
你是想进行指数后退
等等 所以同步意味着直接的调用你正在等待结果
所以CLI和SDK将调用我们的lambda函数
lambda函数会做一些事情并给我们响应
这在我们未来章节中使用API网关时也是一样的
客户端将调用API网关
API网关将代理请求到lambda函数
它将为你调用lambda函数
lambda函数将给您的API网关响应
然后给您响应
所以在这个方案中
我们只是等待响应
这使得它是一种同步类型的调用
所以什么服务与我们的lambda同步
首先
任何用户调用时
那么它将是同步的 所以通过应用程序负载均衡的弹性负载均衡
API网关
云前与lambda at edge
我们在这个课程中看到的任何粗体内容
然后我们在这个课程中不会看到的任何非粗体内容
所以S3批处理
所有像Cognito这样的服务
步骤功能和其他服务
Lex就像Alexa
你可以看到数据火线
所以在这个部分我们将看到应用程序balancer
API网关
云前
我们将在各自的部分看到Cognito和函数
好的 现在我们知道哪些服务同步调用函数 让我们动手玩
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/069_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p69 06. Lambda Synchronous Invocations Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么我们来看看同步调用
实际上当我们有代码和函数时，我们只是进行测试
那时这是一个同步调用
因为我们正在等待调用的结果
我们在这个窗口中得到了结果
如果调用需要两分钟才能完成
我们将等待两分钟才能得到执行结果非常简单
这就是在UI中发生的事情
我们可以使用CLI来测试同步调用的另一件事
所以我要开启一个风险云终端，这个在我的区域是可用的
否则你可以用你的命令行终端进行这个操作
在这里，正如你所看到的，命令行对我们是可用的
所以我输入投资管理版本
我们可以看到版本号是2.1
所以这完美 好的
让我们用命令行进行函数列表
它是lambda列出函数
这将列出我区域中的函数
确保添加区域标志
如果你使用命令行界面（CLI）
对我来说 是eu s one
如果你在终端中使用CLI
并且没有使用云服务
输出结果 但这就是我们要做的
我们发现我们有我们的函数名称
我们的函数和运行时等
所以我们接下来想要执行一个同步调用
从我们的lambda函数的cli
为此，我们将前往我们的代码
在同步h下
我们有不同的指令
我在Linux或mac上
因为这是云外壳
并且这使用的是cli v2版本
所以如果你有c liver1
版本 一个版本将针对命令行略有不同
但你现在应该已经有了版本二
所以使用这个命令
然后你粘贴它
这将会调用我的功能名称
Hello world将会传递这个payload
然后它将会以json格式作为结果写出响应
我可以删除这里的region参数
否则它将不会工作
所以我按回车键，但它说我没有找到函数
是的 名字不是hello world
这是一个示例lambda
所以我要在这里将函数名改为demo lambda
我们可以看到它正在运行
我们收到了200的结果
然后我进入响应
JSON 我们得到了一个值为一的响应
这意味着我 我的同步调用成功了
这就是本节课的内容 我希望你喜欢它 我会在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/070_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈我们的lambda函数如何与应用负载均衡器集成
所以目前
Lambda函数可以通过CLI或SDK进行调用
但有时如果你想将它们暴露在互联网上
你想让人通过HTTP或HTTPS端点使用它们
因此 你可以有两种方式去做
第一种方式是使用应用负载均衡器或API网关
正如我们在下一讲中所看到的
在下一节中
所以，在本次讲座中，我们将专注于应用负载均衡器（ALB）
然后，要让它工作
您需要在目标组中注册Lambda函数
因此，您的客户将通过HTTP或HTTPS的形式发起请求
发送给您的ALB
ALB将同步调用目标组中的Lambda函数
因为同步调用
因为我们正在等待Lambda函数返回应用到负载均衡器
然后，负载均衡器将向客户端返回响应
问题是，负载均衡器如何将HTTP请求转换为Lambda调用
所以从alb到lambda
http被转换为json文档
这是您的lambda函数的请求负载示例
正如我们在文档的顶部所看到的
这里有alb信息，这将被调用
目标是什么目标组
然后我们得到一些关于http方法的信息
这是一个get
路径是lambda
我们得到查询字符串参数作为键值对
所以每个查询字符串都会在相邻的文档中出现
我们会得到以键值对形式出现的头信息
并且我们会得到post post put的body
值是64位基
64位编码 所以你需不需要解码
因此通过这些信息，整个http请求被转换为json
所以我们应该记住的是查询字符串参数
头信息和body都被转换
对于查询参数和头信息
它们是键值对
因此，我们的lambda函数应该返回与文档相邻的东西
而ALB会将其转换回http
如果我们看一下来自lambda函数的响应
它非常简单
它需要包括状态码和描述
以及响应头作为键值对
最后，响应正文和标志
是否为64位
64位编码
好的 所以我们知道lambda和alb如何将http转换为json并转换回来
但是现在让我们谈谈alb集成的最后一个特性
这可能会在考试中出现
那就是多值标头
所以如果我们的客户与alb进行通信
我们可以启用一个alb设置，即允许多值标头
这意味着如果我们以相同值传递多个标头或查询字符串
所以我可以轻松地表示查询字符串
例如
在这个例子中
名称等于u和名称等于bar具有相同的名称
但具有不同的值
我们可以启用此设置
然后标头和查询字符串参数都将被转换为数组的lambda函数
这意味着当我的alb调用我的lambda函数时
查询字符串参数
json 我将看到的是名称
而不是一个值
我将看到一个值数组
所以fu和bar
所以所有值都被转换为
这是考试会测试你的内容
它会问你
我们如何支持多值标头
这是alb的一个设置
这就是它做的事情，所以下一讲 我们将去练习alb和lambda
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/071_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p71 08. Lambda & Application Load Balancer Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 让我们创建一个Lambda函数，它将与我们的负载均衡器集成
为此，我将创建一个Lambda函数
将其命名为lambda_a_b，运行时我将选择Python版本3
然后点击创建函数
与此同时，我还必须为我的Lambda函数创建一个负载均衡器
因此，让我们创建一个负载均衡器
我们将选择一个应用负载均衡器
让我们完成创建过程
我将其命名为demo_lambda_alb
它是面向互联网的
我将部署到三个可用区
对于安全组
我将为我的alb创建一个新的安全组
以确保我有一个demo_lambda_albsg
对于入站规则
我将允许任何地方的HTTP访问
我将创建安全组，完美
并让我们的负载均衡器分配这个安全组
接下来，我们允许在端口80上监听HTTP协议
默认操作是将流量发送到目标组
因此，我们需要创建一个目标组来包含我们的Lambda函数
所以我们在创建这个目标组时
我们将选择Lambda函数
这将是demo_tg_lambda
这个目标组只对应用负载均衡器可用
所以我们点击下一步，选择我们的Lambda函数
我们将选择我们刚刚创建的Lambda函数，点击创建目标组
这个目标组还没有创建
如果我刷新这个，我可以选择demo_tg_lambda作为我的目标
现在我们可以创建我们的负载均衡器并查看它
在我们创建负载均衡器时，我们需要选择一个Lambda函数
我们将选择我们刚刚创建的Lambda函数，点击创建目标组
这个目标组还没有创建
如果我刷新这个，我可以选择demo_tg_lambda作为我的目标
现在我们可以创建我们的负载均衡器并查看它
在我们创建负载均衡器时，我们需要选择一个Lambda函数
我们将选择我们刚刚创建的Lambda函数，点击创建目标组
这个目标组还没有创建
如果我刷新这个，我可以选择demo_tg_lambda作为我的目标
现在我们可以创建我们的负载均衡器并查看它
所以这里我将在控制台中输出
然后事件，这将查看这里将传递什么事件
所以如果我首先部署更改
然后像往常一样测试我的功能，正如我们所见
哦，它没有输出到控制台
当然，它将是打印，所以打印
然后事件，让我们部署并测试此功能
现在我们从lambda收到了一个问候
在这里我们可以看到传递给控制台的事件
当我们想要查看传递给线性函数的事件时，这将很有帮助
来自负载均衡器
所以回到负载均衡器
让我们刷新这个
在这里是dns名称，状态是活动
如果我去并打开一个新标签并按回车
正如你所看到的，这给了我一个响应类型为dms
如果我只是去打开此文件在文本编辑器中
我得到的是
这是来自lambda的问候
所以如果我们回到负载均衡器
这是因为，嗯
我们响应来自lambda的问候
但我们不希望此响应被下载
而是希望它在我的Web浏览器中显示
为了做到这一点
让我们做示例lambda负载均衡器
aws
我们有一份名为使用lambda与应用程序的答案的文档
这将请求看起来像这样
我们将在几秒钟内看一下
但这是文档对于响应应如何看起来
我们需要响应像这样
这将被我的负载均衡器正确解释
这将确保我们收到一个正确的http响应
所以回到那里
我将 而不是返回这个
我将返回我刚在网上找到的文档
所以我们部署这些更改并测试我们的函数，通过直接进入负载均衡器
刷新此页面
正如你所看到的
我得到了来自lambda的问候
这来自我的身体文本在这里
所以第一部分正在运行
如果你想做一些示例，你可以
例如
更改文本并施魔法 因为在头部我们设置了内容类型为text html 所以魔法发生了
因为内容类型设置为text html
因此，这是我们在网页浏览器中部署的方式
我们可以在这里更改状态代码为200等
这就是lambda函数如何将我们的alb数据正确发送到我们的alb，然后是我们的lb
直接从网页浏览器中显示数据
我们还可以做的另一件事是直接进入我们的log监控选项卡，查看关于我们lambda函数的
日志
我们可以查看最近的请求
我们可以查看 lambda函数从alb接收到的数据类型
让我点击这里
这个日志流，正如我们所见，在这个日志流中
我们有这里的查询
这个json文档
它代表了alb将如何调用我们的lambda函数的信息
这与您在这里找到的文档相同
这是alb到lambda函数的请求事件
这就是你可以
例如 查看路径
http方法
查询字符串参数等
以及头部
关于头部
正如你所见
我有一个头部，每个头部都有一个唯一的值
但如果您在这里进入目标组并转到属性
您可以配置多值头部
如果您允许多值头部
这将允许负载均衡器在此处有多个头部
例如 您可以为accept或host或user agent有多个值
等等 这是一个您需要了解的负载均衡器功能
您还需要稍微修改lambda代码才能使其正常工作
因为这里头部被发送到作为键值
但如果您启用多值头部
您需要稍微更改响应
但我只想向您展示这个选项
嗯 您知道这是一个目标组类型的选项
所以让我现在不启用它
尽管，我也想向您展示这个lambda函数是如何被调用的
正如您所看到的，如果转到配置
您会看到我们的应用负载均衡器是我们的触发器
当然 但如果我们看看函数的权限
正如您所看到的这里
我们有一个基于资源的策略声明
而这个策略就是这里
如果你点击声明
它将允许我的负载均衡器调用我的lambda函数
这很好，这正是我们所需要的
这是浓缩的形式
但你可以查看策略并查看整个json文档
正如我们所见 多亏了lambda函数的资源基策略
这允许我们的alb调用lambda函数
这就是本讲座的全部内容
现在 为了清理，你需要做的就是删除负载均衡器
然后你就可以继续了
好的 就是这样 希望你喜欢 下次见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/072_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p72 09. Lambda Asynchronous Invocations & DLQ.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们已经看到了同步调用，让我们进入异步调用。
所以这是零服务，它将在后台调用我们的函数。
所以亚马逊有三种主题，云观察事件等等。
让我们通过一个具体的例子来了解一下。
假设我们有一个S3桶和一个S3事件通知，用于新文件。
这将进入Lambda服务。
因为这种异步调用。
所以让我们通过一个具体的例子来了解一下。
假设我们有一个S3桶和一个S3事件通知，用于新文件。
这将进入Lambda服务。
会发生一些事情 事件将被放置在内部事件队列中
所以我们这里有一个事件队列
而你的lambda函数将读取那个事件队列
然后lambda函数将尝试处理这些事件
但如果某些事情出错了
lambda函数将自动尝试重试
这意味着总共会有三次尝试
第一次尝试会立即发生
第二次尝试会在一分钟后发生
第三个将在第二个发生后两分钟后发生
所以，我们的线性函数总共将尝试三次
然后一旦重试发生
这意味着我们的lambda函数可能多次处理相同的事件
这可能是个问题
因此，如果你的lambda函数不是线程安全的
这可能是个大问题 这意味着你的lambda函数应该线程安全
我 C 这意味着在重试的情况下
结果将是相同的
那么，如果你有一个重试发生
会发生的情况是，你会在云观察日志中看到重复的日志条目
因为你的lambda函数会一遍又一遍地尝试
我们可以为重试完成后定义一个DQ或死信队列
这意味着如果在处理过程中出现失败
并且由于重试我们从未成功
那么，Lambda函数可以向SQS发送一些事件以供后期处理
这就是异步调用背后的整个想法
你可能会问我 为什么我们要使用异步而不是同步
嗯 首先，一些服务必须使用异步
所以你没有其他选择 第二个原因是
例如 假设你需要加速处理
你不需要等待结果
那么你可以同时处理一千个文件
你只需等待所有文件在并行处理完成后
但你不必等待每个单独的结果
因此这将加快你的处理时间
所以哪些服务是异步完成的
第一个是亚马逊
S3 当我们有 S3 事件通知调用 Lambda 函数时
我们有 S3 当我们收到通知时
并且触发一个 Lambda 函数
Cloudwatch 事件或 Cloudwatch 事件或事件桥
这将基本上使我们的 Lambda 函数对我们的基础设施中发生的事件做出反应
其他我们不会在动手实验中看到的服务
将是代码提交触发 Lambda 函数
每当有新的分支
一个新的标签 并且你推送代码管道以在管道中调用 Lambda 函数
并且 Lambda 必须回调代码管道或其他服务
Cloudwatch 日志处理一个简单的电子邮件服务用于发送电子邮件
CloudFormation
Config IoT 和 IoT 事件
所以从我们的角度来看对于这个认证
我们需要了解 Lambda 如何与 Amazon S3 和 Cloudwatch 事件或事件桥一起工作
所以让我们去学习异步调用 在动手实验中 我将在下一节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/073_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p73 10. Lambda Asynchronous Invocations Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 所以我有一个演示lambda函数
这次我想异步调用
如果你再看代码
它会打印一些值
然后它会返回事件键一
但如果我们异步调用
我们不能从控制台做
我们必须从cli做
让我们打开云shell
和 所以 异步调用的整个目的是
我们不会得到结果
所以让我们复制整个命令
所以我粘贴命令并按
Enter
我的lambda函数现在已经被调用
并且我们得到一个状态码202
这意味着函数已成功调用
但我们不知道结果
所以要看结果
我们可以看云锁
如果你去监控并看云watch日志
我们可以看最近的调用
然后如果我们看一个
应该会很快出现
所以让我们在这里看日志组
然后我们看这里
那是我最近的调用
我们可以看到函数被调用请求成功
但我们不知道
这是否成功
感谢这个注释 因为这是异步调用
我们可以确定
因为我们去我们的lambda函数
我们会改变代码使其失败
我会注释返回
我会取消注释抛出异常
我会部署保存更改
如果我们测试这个函数
我们知道它失败了
它刚刚失败
但如果我们用云shell
我们的cli调用函数
我们又得到一个202状态码的错误
我可以确定它失败了
因为我去看我的日志流并打开这个日志流
我们在这里得到一个错误
正如我们所见，异步调用函数
返回相同的状态码202
无论函数是否成功或失败
因为我们不需要知道结果，由于异步性
所以我们可以做的是，可能设置一个死信队列
如果我们进入我们的lambda函数
并在配置下异步调用
我们有一些信息
我们可以编辑一些关于死信队列的配置
所以零
一次或两次重试尝试在异步事件的失败
所以我们保持为2
然后我们可以将未处理的事件
嗯 从异步调用发送到数据队列
所以我们可以选择sqs并且我们需要为这创建一个sqs队列
所以我们进入sqs服务
我将创建一个队列
它将是一个名为lambda dlq的中心队列
我将点击创建队列
现在我的lambda dlq已经创建
所以我们回到这里并刷新
我需要刷新此页面
可能所以让我们刷新
编辑队列服务
sqs和q
lambda q在这里
它出现了保存
正如我们所见我们不能保存
因为函数没有足够的权限来调用
在sqs上发送消息
因此要修复这一点我们需要修复lambda函数的i am角色
如果你进入我们的lambda函数
我们在配置和通用配置权限下
抱歉 这里是执行角色
我们点击它
我们进入i am控制台
我将为它附加一个策略
我将查找sqs类型的策略
我将给它亚马逊sqs全权访问至少
这样我们确定我们的lambda函数可以写入我们的sqs队列
所以我们回到lambda控制台在配置下异步
我们滚动 我们保存
这次是的
它完成 现在我的lambda函数可以写入sqs
如果我们现在尝试进入我们的cluckshell
并再次调用此函数
我们知道调用本身会失败
因为 Lambda 函数被编程为失败
但现在会发生什么就是 DLQ 会将其踢入生效
所以我们将有两个重试尝试
并且在重试尝试失败后
消息应该进入 Amazon SQS
所以现在如果你去 Amazon SQS
并且我们发送和接收消息并查看可用消息
我们可以拉取消息
我们有一条消息可用
这仅仅是一个测试
用于 Lambda 函数
只是为了测试它是否能够将数据发送到 SQS 所以我可以做的是
我可以直接删除这里那条消息
然后我会等待四分钟看看
我的 Lambda 函数是否由于重试将消息发送到 SQS
所以让我暂停视频并回来
好的
所以现在如果我去我的 CloudWatch 日志并查看此日志流
我们可以看到一些有趣的事情
所以我们可以看到一个请求 id 表面到 a b 并且失败了 然后如果我们滚动
这里有另一个请求带有 two ab
所以同一个请求 id
然后它失败了
那是第一次重试
然后有另一个请求带有 two a b
然后它失败了
那是第二次重试
然后有另一个请求带有 two a b
然后它失败了 然后有另一个请求带有 two a b
然后消息进入了 DLQ
然后如果我们去 SQS 并拉取消息
我们可以看到这条消息在这里失败了
我们可以看到这条消息的键和值
并且这是关于消息的所有信息
如果我们查看消息的属性
我们可以看到错误
因为 two hundred 发生了一些错误
并且请求 id 是 to a b n
所以这与 Lambda 中的调用 id 对应
我们可以直接从 SQS 的消息属性中获取
这真地显示了
嗯 异步调用和 DLQ 工作的很好
这就是本次动手操作的全部内容 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/074_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p74 11. Lambda & CloudWatch Events  EventBridge.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在我们来谈谈我们如何将云集成到事件中
监控事件 甚至与lambda桥接
有两种方法 第一种是使用无服务器的cron或正确
我们将创建一个事件桥接规则
然后每隔 例如
每小时将触发我们的lambda函数来执行任务
我们可以创建一个代码管道
甚至桥接 例如
检测每次代码管道状态更改时
状态更改将调用我们的lambda函数来执行任务
这是一个非常简单的想法 但让我们看看如何在实践中实现
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/075_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p75 12. Lambda & CloudWatch Events  EventBridge Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们开始练习将lambda与事件桥集成
所以我要创建一个名为lambda demo events的功能
桥向下滚动
对于运行时
我将选择python 3.9
然后我将创建这个功能
我们将确保这个功能被桥调用
为了做到这一点
让我们也探索事件桥控制台
嗯 这个功能正在被创建
所以我会去规则那里我需要创建一个新的规则
我将其命名为invoke lambda every minutes 我们需要选择一个事件总线
我们将使用默认事件总线
这里有两个选项
第一个是使用带有事件模式的规则
这是在您想要匹配aws中发生的事件时使用
例如代码提交到代码提交或EC two实例被终止
我们不会深入探讨这个
我们将保持简单
我们将使用调度
正如你所看到的如果你使用调度
它会提示你去事件桥调度
你可以在空闲时间玩这个
这是一个有趣的练习
但我现在点击底部左边继续创建角色
因为这将创建一个事件桥规则
而不是事件桥调度
但就能力而言
我们做的完全相同
但我们点击
继续创建角色
因为我想向你展示一些特定的资源策略
在这里我们定义调度模式
我们是否想要cron表达式
或者是否想要定期运行调度
我想要我的调度每分钟运行一次然后点击下一步和下一步
我们必须选择一个角色的目标
我们的规则的目标是lambda
当然所以我会选择一个lambda函数
这里我会选择我的lambda demo event bridge
我们可以配置特定的版本在别名
如果你也想要以及额外的设置围绕那个队列和最大尝试等等
这将调用我的lambda函数
正如你所见这里
桥将自动为选定的目标配置适当的权限
我们将在下一刻也看到这一点
所以让我们点击下一步下一步
我们准备好了
所以让我们创建这个角色
现在，我调用Lambda
每分钟规则已创建
如果我回到Lambda
如你所见，现在 左边没有触发器
但如果我决定刷新此页面
现在我们的事件桥作为我Lambda函数的来源
如果我点击它
如你所见 这里有触发器
这与我创建的规则相对应
这是一分钟的规则
那么，这个规则如何调用函数呢？
如果你去看权限，现在
我们看资源基策略声明
有一个声明被添加
我点击查看策略
如果你看看这个声明，它说
允许事件桥服务原则调用我们的Lambda函数
资源ARN必须是我们的Lambda演示版本
这正是我们想要的函数
然后条件是n必须像
这是为了源ARN像
这是事件桥ARN
这意味着只有我们的事件桥规则有权调用我们的Lambda函数
这正是我们所希望的
所以这完美
因为我们有一个一分钟的速率
我可能已经讲了一分钟
我们可以在监控中查看日志和调用
现在，我们有可能这里看不到任何东西
因为这还太早 如果我点击查看云观察日志
我将直接进入云观察控制台
从那里我应该能看到一些调用
是的，我们在日志组lambda events demo demo event bridge
我滚动
我有一个实时流
现在，我看到我的Lambda函数正在被调用
我想让它更有趣
在这里，我将打印事件，这将打印
将发送到我们的Lambda函数的内容
所以我部署了这个
这将更新我的函数
现在我只需要再等一分钟，看看日志中有些事件
现在，已经超过一分钟了
如果我在这里刷新我的日志
实际上我们需要一个新的日志流
因为我们确实更新了函数 所以我上一层，选择最新的日志流
现在我看到我的日志中输出，事件被打印到控制台
所以我们看到版本零
这是事件的想法
详细类型是它是一个调度事件
来源是aws. events
这是我的账户
这里是时间
这里是这个事件被调用在的区域
这里是调用了我们的lambda函数的资源
在详细信息中我们什么都没有
因为我们没有提供任何特定的json
但正如你所见
我们现在有一些关于这个调用的信息，并且一切正常
所以为了停止这个练习
确保禁用你的规定
这样你就可以继续前进
好的 就是这样
我们已经看到了如何将lambda与事件桥集成
我希望你喜欢它 我会在下一节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/076_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p76 13. Lambda & S3 Event Notifications.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来看看我们如何将S3事件通知与Lambda集成
所以，关于S3事件通知的提醒
这是你在对象创建时接收通知的一种方式
删除 恢复
在复制过程中
您可以根据前缀和后缀进行过滤
用例是生成
例如 上传至Amazon S3的每张图像的缩略图
您将在Amazon S3中收到事件
S3可以将事件发送给三件事
发送到S和S
从S主题中我们可以进行广播模式将其发送到多个SQSQ
我们可以将其发送到SQSQ
我们可以让Lambda函数直接读取该SQSQ
或者我们可以直接将Amazon S3事件通知调用我们的Lambda函数
这是非阻塞调用
函数可以随心所欲地处理数据
如果出现任何问题
我们可以设置死信队列
例如SQS
如前所述
S3事件通知通常在秒内传递事件
但有时可能需要一分钟或更长时间
如果您想确保不会丢失任何事件通知
确保在桶中启用版本控制
否则，如果对同一对象同时进行两次写入
您可能只会收到一次通知而不是两次
这是文档中的一些小印刷
但值得注意
好的 所以这是一个简单的模式
S3桶将有一个新的文件事件到Lambda，Lambda函数将处理该文件
也许将该文件的元数据插入DynamoDB表
甚至您的RDS数据库 非常简单 让我们在动手实践中看看如何做到这一点
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/077_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p77 14. Lambda & S3 Event Notifications - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么让我们创建一个新函数
并且这个函数将被称为lambda s three
每当一个对象被调用的时，它会被调用
将其插入到s三个桶中
所以对于这一点 我将选择python three eight作为我的运行时
我将会在旁边创建这个函数
我正要进入S3服务
我将创建一个桶，它会触发madame da函数
所以为了做到这一点 我将进入s三
我将创建一个桶并命名为demo s three event
斯蒂芬
并确保我的桶和我的lambda函数在同一地区
所以爱尔兰两者都是
然后我只是滚动并点击创建桶
好的 所以我将进入我创建的桶
然后在属性中我将滚动并下去
我想找到事件通知的属性
因为我们想让这三个桶触发我的lambda函数
为此，我将创建一个事件通知
它被称为调用lambda
然后对于前缀，我们将使用所有
我们有所有 然后对于事件类型，我们将选择所有对象
创建事件，滚动下来
至于目的地，我们有lambda和sqs的选择
但我们将选择lambda
我们将从可用的lambda函数中选择它
所以lambda是射线
我会保存更改
所以现在这已成功完成
所以这次事件通知已启用，将数据发送到我们的lambda函数
因此，我们可以在这里刷新这个lambda函数页面
现在我们可以在左侧看到s3正在调用我们的lambda函数
所以让我们修改函数做更多的事情
所以而不是这个
我只是打印事件以查看正在将什么发送到lambda函数
并部署它，好的，完美
那么最后一件事
这个S3桶如何与lambda函数集成
嗯 你应该已经知道了
但如果我们进入配置
然后查看权限，就在这里
我们向下滚动并查看资源基策略
我们可以看到这里有一个策略声明
它说lambda可以调用我们的函数
如果我点击声明想法
在这里我们有策略
或者我可以点击查看策略文档以查看整个JSON
这允许我们的S3桶演示S for事件扇出调用我们的Lambda
Lambda S3，完美
所以最后一件事是我们需要测试这个集成是否正常工作
所以让我们进入我们的S3管理控制台
我们将上传一个文件到我们的桶
所以我会添加一个文件
我会选择之前从代码中的咖啡JPEG文件，来自S3文件夹
我将上传此文件，输出已成功
所以现在应该发生这种情况，即此文件将触发我Lambda函数的事件
要查看这是否起作用
然后我们将进入监控
我将点击查看ClayWatch日志
这将我们直接指向LyWatch日志
我们可以看到在这里有一个日志流
这与由S3触发的此调用相对应
如果我们看一下这里
我们可以看到事件源是AWS
S3
我们可以查看区域 我们可以查看对象创建PUT事件和谁创建了它
以及我们可以获取有关桶名信息
这是demo S3 events fan
以及另一个桶
以及对于对象，我们有key
我们有coffee点
Jpeg
我们有大小和e tag 所以这里所有的信息
足够我们的Lambda函数在代码中进行S3点获取对象API调用
多亏了事件
然后获取实际上传到S3桶的对象
因此可以对其进行一些处理
好的
这是另一种异步调用类型
到现在你已经看到了很多Lambda的异步调用
但希望这现在说得通
你也看到了资源策略是如何工作的
这就是本讲座的内容
我希望你喜欢它 我将在下一个讲座见到你 结束
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/078_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p78 15. Lambda Event Source Mapping.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们已经看到了异步处理
我们已经看到了同步处理
现在我们将看到事件源映射
所以这是lambda在aws中处理事件的最后一类
所以适用于
你能看到数据流
SQS和SQS
V4Q和DynamoDB流
所以所有这些东西的共同点是记录需要从源头拉取
所以lambda需要从服务获取一些记录
然后记录将被返回
这意味着lambda需要从这些服务拉取
所以这种情况下，lambda函数以同步方式被调用
让我们看看这个，我们有kinesis和lambda服务
如果我们配置lambda从kinesis读取
那么内部会创建一个高级源映射
它将负责从kinesis拉取数据并返回结果
所以kinesis将返回一批数据给我们
一旦事件源映射中有数据供lambda处理
它将以事件批同步调用我们的lambda函数
所以核心
这就是它工作的方式
所以事件源映射有两种类别
第一种是流，第二种是队列
让我们处理流和流
适用于ky's数据流和DynamoDB流
我们将很快看到DynamoDB流
对于流来说
会有一个事件源映射为每个分区创建一个迭代器
每个kinesis分区或DynamoDB流
分区将按顺序处理
你可以配置从何处开始读取
你可以只读取新项
或者从分区的开头
或者从特定时间戳
每当从分区处理一个项
它是从创世还是主链提取的
项不会被从流中移除
这意味着其他消费者可以读取kinesis或主链的数据
这是他们最初工作的方式
但我只是想强调这一点
所以这种情况适用于低流量或高流量
如果你有一个低流量的流
你可以使用批处理窗口在处理前积累记录
以确保你高效地调用lambda函数
如果你有一个非常高吞吐量的流并且你想加快处理速度
你可以设置lambda以在分区级别并行处理多个批处理
这是从aws博客的图表
我们有一个分区
这里有一个记录处理器
并且有一种方法可以实现并行处理，以便有多个lambda函数
在同一个分区内处理批次
所以你可以在每个分区内有多达十个批次处理器
并且对于每个批次，它们在分区键级别会以顺序进行处理
如果你指定了一个分区键
它将不会完全按顺序在整个分区中读取
但在分区内每个键将按顺序读取
这就是我们如何并行处理lambda函数和您的流
关于错误，默认情况下
如果你的函数返回错误
整个批次都将被重新处理，直到函数成功
或者批次中的项目过期
这非常重要
批次中出现错误可能会阻止处理
为了确保有序处理，受影响的图表的处理将被暂停，直到错误解决
你可以用几种方式来管理这一点
你可以配置事件源映射到1
丢弃旧事件
或者限制重试次数
或者在错误时分批
在这种情况下，这是关于lambda时间的问题
所以如果你的lambda函数没有足够的时间来处理整个批次
也许它有足够的时间来处理一半的批次
然后在你希望丢弃事件时
所有事件都可以发送到一个目的地
我们将在下一堂课中讨论目的地
这就是关于流的所有内容
现在你需要了解关于队列的内容
所以对于队列
这是关于sqs和sqsvo
所以你有同样的想法
SQS将被Lambda事件源映射拉取
然后每当一批数据返回
您的Lambda函数将与事件批次同步调用
在SQS的情况下
事件源映射将使用长轮询拉取SQS
所以它会很高效
我们可以从1到10条消息指定批处理大小
这里是配置
所以只有批处理大小和SQS队列
然后有一些来自网站的建议，建议将队列的可见性超时设置为
六倍于你的lambda函数的超时时间
这是可以配置的
然后如果你想使用dlq
所以 如果你想确保在sqs中读取或处理消息时出现问题
它会转到那个信件队列
那么你需要在sqs上设置dlq
而不是在lambda上 所以我们在sqs上设置了dlq，而不是在lambda上
为什么因为lambda的dlq只适用于异步调用
这是异步调用
或者正如我们所见
我们也可以使用lambda失败目的地
这将在下一讲中看到
现在关于队列和lambda的一些信息
我很抱歉 这相当无聊
但我必须说
所以lambda支持按顺序处理
如果你有一个fifo队列
所以先进先出
处理你的队列的lambda函数的数量
将与活跃的消息组数量相等
这是组ID设置
如果你使用标准队列
那么项将不会按顺序处理
对于标准
lambda将尽可能快地扩展以读取所有标准队列中的消息
如果在你的队列中发生了错误
那么批次将作为单个项返回到队列
并且可能在原始批次的不同分组中处理
偶尔事件源映射可能会从队列中接收到相同的项两次
即使没有函数错误复发
因此你需要确保对你的lambda函数进行幂等处理
以防发生这种情况
最后 当他们被lambda处理时
lambda将从队列中删除项
然后他们将永远不会再次出现
最后 如我所说
你可以配置源队列将项发送到死信队列
如果他们无法处理
我希望这一切都讲得通
我们将在动手实践中看到
我们可以设置它 那么关于扩展
我已经说过了 但我们可以再次总结事件映射的扩展
所以danny
你能看到数据流吗 然后我将被流
你将获得一个lambda调用每个流分区
或者如果你使用并行化
你可以同时处理每个分区多达十个批次
对于sqs标准
我说lambda会快速扩展 是的 它会在60分钟内增加60个实例
所以这相当快
然后同时处理的最大批次数每秒是一千个，适用于sqsvo
这有点不同 所以具有相同组ID的消息将按顺序处理
无论什么情况 Lambda函数将根据活跃消息组的数量进行扩展
再次 它们是由组ID定义的
这就是关于Lambda事件映射的所有内容
数据源 我知道这是一节相当长且无聊的理论课
在下一节课中，这将变得非常有意义
当我们进行实践操作时 但我们必须复习一下
我建议你在考试前再看一遍这节课
因为可能 考试可能会问你一些关于事件成员的详细信息
好的 就是这样 下次课见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/079_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p79 16. Lambda Event Source Mapping Hands On (SQS).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们来练习事件映射器
为此我们将从头开始提供一个新功能
使用的映射器是SQS
我将把我的函数命名为lambda SQS
Python 3.8
我将创建一个我的功能
我们也需要创建一个SQS队列
为此，我的lambda函数能够从SQS队列中检索消息
所以我只是创建一个队列
我将在我的队列lambda演示SQS中
好的 这是一个标准队列
我将向下滚动并创建此队列
好的 所以我的队列已创建以及我的lambda函数也已创建
所以现在我的lambda函数要从我的SQS中检索消息
我需要做的是点击
添加触发器
我们将添加一个触发器
在这里，我们有所有触发选项，用于Lambda函数
如您所见，这里有很多AWS集成类型
但也包括一些合作伙伴的事件源，可以直接连接到您的Lambda函数
但对于这个例子，我将进入SQS
它正好在这里
好的
我们需要选择一个SQS
好的
所以我们需要选择一个SQS
所以我会选择使用Lambda和SQS的示例
接下来我们需要指定批处理大小
所以我们希望一次性接收多少条消息
你可以从
嗯 一条消息到更大的批处理大小
好的 你需要查看一下文档
嗯 最大的批处理大小是多少
我以为是10
但现在我猜它更长了
所以批处理窗口
所以收集记录前调用函数需要多少秒
这样会更高效，调用函数更少
同时让你的lambda函数处理更大的批处理
最后你需要确保启用触发器
所以我会启用这个触发器并点击添加
现在我们会得到一个错误
说执行角色没有权限调用sqs的接收消息
是的 因为我们的lambda函数正在从sq sq读取
并且有一个i am角色附加到lambda函数
那么我们需要确保它被正确配置
并且具有从sqs读取的权限，这相当简单
让我们回到我们的lambda qs函数
我们将进入配置权限
这里是真正的名称
所以我们将点击这个角色
这将带我们进入控制台
我可以将我的角色附加一个策略
我将输入lambda sqs
应该有一个角色
所以嗯
我们输入sqs十，我们有一个aws lambda sqsq执行角色
这个角色足够让它从sqsq读取
我们将附加这个策略
这个lambda sqs q执行角色
如果我回到lambda触发器并再次添加，这次它将工作
因为我们有权限
所以你现在看到 lambda函数的sqs链接到我的sqs队列
好的 所以现在我的lambda函数的代码会做什么
让我们去lambda函数
我们只是再次打印事件以获取一些信息
而不是返回这个
让我们只是返回 嗯
成功
好的 让我们部署我们的更改，完美
这很好 现在让我们通过简单地进入SQS并发送一条消息来测试我们的lambda函数
所以在我的SQSQ
我将发送一条消息
消息将设置为你好，世界
然后我们可以添加一些消息属性
例如 foo的值将是bar
试试看
然后我们发送这条消息
所以现在消息已经发送并且准备好接收
因为我的lambda函数持续从sqs拉取
那么它应该处理这条消息
那么我们怎么确保呢
我们在这里通过进入控制台日志记录事件
所以我们进入监控并再次
我们打开日志 Inkly watch
现在我们可以看到一个日志流
这完美 点击它
我们这里确实有一个请求
所以我们可以看看一切
我们可以看到，正文是hello weld
以及消息属性包含foo bar，关于属性
我们可以得到关于它何时发送的一些信息
事件源为sqs等
这意味着调用是正常的
以及，如果我们回到sqs到我们的队列
进入发送和接收消息
我们可以看到队列中可用的消息为零
嗯 那是因为消息已经被我们的lambda函数处理了
最后，您需要确保禁用这个事件映射
如您所见，目前它应该在启用状态
但您需要禁用它
如果您不这样做
那么lambda将持续从您的sqq拉取
这在长期内可能会产生一些费用
或者在sqs脉冲中消耗您的免费配额
所以让我们禁用sqs q
但我们继续添加一个触发器
我只是想向您展示kinesis触发器
因为它是另一个事件映射
我想向您展示当使用kinesis调用lambda时可用的不同选项
您可以看到流
您需要选择 当然，您可以看到流以获取consumer的更新
如果您有一个增强的
找到consumer 那么您可以创建一个consumer应用程序并启用增强的consumer模式在这里
但现在我们没有
所以 我们将退回到kinesis的标准消费方式，批处理大小
一次读取多少记录
一百批窗口
如果我们想要一些等待时间来创建更大的批处理
在调用我们的lambda函数之前
我们是否想要读取最新数据
我们是否想要读取最早数据
或者是否想要读取一个特定的时间戳来读取我们的lambda函数
然后您可以看到一些额外的设置
例如丢弃一些数据的不熟悉目的地，如果在无法读取时
最大重试记录的年龄
如果您想按错误拆分批
每个分区并发批处理的最大数量
如果您想并发处理相同的分区
以及如果您这样做
然后你有更多的记录处理器
但是琳达会确保它们仍然按顺序阅读
一个分区键级别
滚动窗口
如果你想进行聚合和报告补丁项，持续时间为
因此，Kinesis有很多选择
你不需要全都知道
为了考试 只需要知道kinesis是你的lambda函数的事件源映射器
如果你想了解更多关于这些选项的详细信息
然后文档将成为你最好的朋友
然后启用触发器
如果你做得好 但我们只是取消这个
因为我们只想看选项
这就是这节课的内容
我们已经看到了事件映射是如何工作的
我们已经看到了如何为lambda函数添加缺失的i权限
以便能够从我们的事件映射中读取
这就是全部 我希望你喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/080_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p80 17. Lambda Event & Context Objects.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来理解一个非常重要的概念，即事件和上下文对象在你的lambda函数中
让我们以一个例子来说明，lambda函数被调用
例如，由事件桥规则调用
所以将要发生的事情是，事件桥将创建一个事件
并且该事件将传递给你的lambda函数，而你的lambda函数
将接收该事件
被称为事件对象
事件对象包括很多关于细节，例如
事件本身来自哪里
服务本身将包括与该事件相关的大量数据在事件中
但我们也有一个上下文对象
所以这是lambda函数的第二部分
这是关于你函数的一些元数据
例如aws的请求id
你函数的名称
与lambda函数相关联的日志组
内存限制
等等 所以事件对象和上下文对象非常不同
但它们是互补的
所以事件对象与包含函数将要处理的数据的文档相邻
所以调用服务
例如 Eventbridge
或 sqs 或 s
或你想要的任何内容都将包含你 lambda 函数处理事件所需的所有信息
然后根据你使用的运行时
这个事件对象将被转换为一个对象
例如 如果你使用 python 将被转换为一个字典
所以任何类型的输入参数
或者在调用服务时，参数将被包含在事件对象中
上下文对象
另一方面
提供了关于调用本身和运行时环境的数据的方法
因此，这是在运行时传递给线性函数的。
从上下文对象中，我们可以获取aws请求ID
函数名称
内存限制以兆字节表示
依此类推 我们可以使用那个概念信息在我们的lambda函数中
在你的代码中你会看到
例如 我使用python
所以处理程序有一个事件和一个上下文
事件会有信息
例如事件的来源或事件的区域
等等我们可以打印到控制台
或者上下文会有信息
例如请求ID
函数ARN
函数名称
内存限制，单位为兆字节
然后 例如
关于如何打滑的一些信息
例如流名称或组名称
这样你就可以选择正确的事件或上下文
以便在考试中获取您请求的特定信息
好的 这就是本讲座的全部内容 希望你喜欢 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/081_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p81 18. Lambda Destinations.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以这里是一个非常酷的新功能，来自2019年11月，叫做lambda目的地
所以问题是
当我们在做异步调用或事件映射时
很难知道它是否失败了还是成功了
以及如果成功了如何获取数据
所以 目的地的想法是将异步调用的结果
或事件映射的失败发送到某个地方
所以它会做 我们很快就会看到
所以对于异步调用
我们可以定义成功和失败的事件目的地
我们说的成功和失败
指的是那个事件的处理
对于异步调用
我们有sqs和s lambda以及亚马逊桥bus的目的地
所以云watch事件
想法是我们的lambda函数异步调用
例如 通过s三事件
如果我们成功
我们可以将消息发送到成功的事件目的地
如果我们失败 我们可以将消息发送到失败的事件目的地
你可能已经注意到，这与DLQ设置在异步调用中非常相似
这就是为什么建议您使用目的地而不是DLQ的原因
即使您可以同时使用两者
为什么，因为目的地是新的，它们允许更多的目标
因为 目的地
Dq刚刚允许将失败发送到sqs
嗯 将失败发送到sqs
但目的地允许将成功和失败都发送到sqs
S lambda和ibridge
好的 这是用于异步调用
现在 那么事件源映射呢
这仅用于您有一个被丢弃的事件批处理
因为我们无法处理它
所以我们可以将事件批次发送到amazonsqs或amazon is
这在这里由这个图表表示
所以我们从kinesis读取
会有一个事件源映射
我们会尽力处理数据
但我们没有成功
而不是阻止我们整个数据流的处理
我们可以将丢弃的事件批次发送到您的失败事件目的地
请注意，如果您的事件源映射从sqs读取
你可以设置一个失败的目的地
或者你可以直接在你的sqsq上设置一个dl q
这取决于你想要如何操作
所以在接下来的讲座中，我们将探讨目的地
做一些实际操作 并做一些练习，以更好地理解这个功能 所以下次讲座再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/082_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p82 19. Lambda Destinations Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来练习目的地功能
为此，我们将进入lambda s三函数
我们将直接在我的lambda s三函数中添加目的地
我们将为成功和失败添加目的地
首先，我们需要这样做
我们需要进入sqs
我们将创建两个队列
这些将是我们的目的地
让我们创建一个队列
我将其命名为s三成功
这将是我们s三函数的处理成功的目的地
然后点击创建队列
我将创建一个第二个队列
将其命名为s三失败
然后创建这个队列
好的
现在我们有了成功和失败的队列
让我们进入我们的lambda函数并配置
让我们添加一个目的地
来源类型将是异步调用
但你也需要一个流类型的目的地调用
例如 如果是kinesis或流映射到该函数
但我们将处理异步调用
条件将是失败
目的地类型将是sqsq
目的地将是s三失败
现在 它说函数执行规则没有发送结果到目的地的权限
是的，这是预期的
但此控制台很好，点击保存
权限将自动添加
让我们点击保存，权限也应该被添加
我们可以通过进入我们的lambda函数的iam角色来确认这一点
为此
让我们在新标签中打开我们的函数并转到配置权限
找到角色名称
如您所见
我们确实有
嗯一个目的地亚马逊lambda sqsq执行角色
这允许我们对sqsq进行权限操作
如果q名称为s三失败
这已被正确添加
我可以为异步调用的成功添加第二个目的地
这次为sqsq，目的地仍然是
我的s三成功q，就像之前一样
权限将被添加
我们准备好了
好的 太好了
现在我们需要测试这两个目的地是否正常工作
为了做到这一点
我们将测试一个成功事件和一个失败类型的事件
首先让我们测试成功
我们将进入
顺便说一句，您可以在这里看到两个目的地已配置在目的地样式下
但也可以看到它们在lambda控制台中
好的 让我们测试成功用例
让我们进入亚马逊S3
我们的存储桶 让我们打开我们的存储桶
让我们看看这个
是的 我们可以进入我们的存储桶，我将上传一个新文件
我添加一个文件
这将是海滩.jpg并上传
上传已成功
因此，线性函数应该运行
并应该返回这个
这是一个成功
这不是一个失败 这是一个成功
因此，日志应该在云监控日志中
然后目的地将其发送到我的SQS名为S3成功
如果我进入SQS并刷新此页面
我看到我的S3成功队列在这里
我们看到有一个消息可用
这意味着是的
确实，消息已发送到我的SQS名为S3成功
我们可以发送和接收消息
我们可以接收消息
有一个可用 让我们拉取消息
这里是消息
就消息体而言
我们得到很多关于请求上下文的信息
这是一次成功
并且它被调用一次，以及记录代码本身
这是一个S3事件源对象创建
放置 等等，我们得到很多关于事件源本身的信息
我们还得到关于响应负载的信息
其中包括状态码和正文
所以我们得到了事件源和事件响应
以及一些额外信息在我的SQQ消息中
这太棒了 因此，目的地包含大量信息
如果你想测试失败情况
那么我们需要进入代码
我们需要抛出异常而不是返回这个结果
抛出异常
我们将使用boom作为异常信息
让我们部署这个
所以现在我的函数应该抛出异常
所以如果我们再次进入我们的s3控制台
我们将回到这里并上传一个新的文件
这次我们将上传一个可能名为index.html的文件并上传
上传已成功
我的lambda函数将被异步调用并抛出异常
如果你记得
如果我现在去讨论
我不应该立即看到任何消息
让我们看看
让我们刷新一下
是的
我的s3失败 还没有任何消息
你知道为什么吗？你应该知道
但是因为s3在
嗯
调用melinda函数是非阻塞类型的调用 然后我们去配置
记住并去非阻塞调用
嗯
我们有两个重试尝试我们将运行 这些重试尝试将被运行
然后一旦重试尝试被运行
然后目标将被作为失败调用
并且消息应该进入我的sgs sq
所以让我们等一会儿
我将暂停视频并在两三分钟后回来
好的
我刚刷新 确实在我的s3失败中看到了一条消息
Sqsq
所以让我们去发送和接收消息
滚动下来
拉取消息
这是我的消息 如果你看一下正文
嗯
这是表示这个消息之所以在这里 是因为重试已经耗尽
然后近似调用次数是三
然后它被发送到我的失败目标
我们可以看一下导致我们的lambda函数失败的记录
我们可以调试在这里发生的情况
以确保下次我们的lambda函数不会失败
并且我们的lambda函数确保下次不会失败
我们可以更优雅地处理这个错误情况
然后我们也可以获取关于响应负载的信息
这表明错误消息是boom
类型是一个异常
堆栈跟踪就在这里
这也帮助我们调试函数
这太好了 我们已经看到了目的地是如何工作的
它们真的很棒
因为你可以在两个不同的目的地同时处理成功和失败
我希望你喜欢这个 我将在下一节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/083_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p83 20. Lambda Permissions - IAM Roles & Resource Policies.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈lambda执行角色和权限
我们已经通过实践操作做了很多这方面的事情
我相信你对此完全理解
但回顾理论课程总是好的，以便尝试一下
因此，I角色必须与您的lambda函数相关联
这将授予lambda函数访问aws服务和资源的权限
我们有一些lambda管理的策略示例，我们可以重用
例如 基本的执行角色允许我们将日志上传到云观察
但是有kinesis执行角色用于从kinesis读取
SQSQ执行读取从SQS中
Lambda VPC访问执行角色
允许我们在VPC中部署Lambda函数
如本节所见
X射线恶魔访问将跟踪数据上传到X射线
如本节所见
这些是管理策略
但我们可以为Lambda创建我们自己的策略
因此每当我们使用事件源映射来调用我们的函数
Lambda 是我们读取数据的唯一方式
因此我们必须使用一个执行角色来读取事件数据。
在另一种方式下，该函数由其他服务调用
所以我们不需要特定的i，只需带着一些特定的权限
顺便说一句，最佳实践是每函数创建一个Lambda执行角色
正如我们在实操中一直做的那样
所以这是为事件源映射的
或者如果我们的Lambda函数实际上需要调用其他服务
但是，关于 如果我们的lambda函数被其他服务调用
然后我们使用资源基策略
这是为了让其他账户或服务有权使用你的lambda资源
所以可以调用你的lambda函数
这与亚马逊s3桶策略非常相似
所以原则上，i可以访问你的lambda函数
如果这两件事中的任何一件事首先发生
IAM策略附加到主体授权它
所以 例如 我们有我们的用户，我们有全权，所以可以访问我们的线性函数
这就是我们到目前为止所做的
多亏了我们的管理员访问策略
或者如果我们有一个基于资源的策略来授权对线性函数的访问
这在你有一个服务到服务的访问时更有帮助
所以我们以前见过
但我们还会再见
当另一个aws服务
比如亚马逊s3想要调用函数时
那么我们需要确保基于资源的策略给它访问权限
而这是控制台在我们幕后为我们完成的
但如果你要自己做集成
这就是你要自己做的地方 所以让我们去控制台看看这是如何工作的
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/084_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p84 21. Lambda Permissions - IAM Roles & Resource Policies - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的
那么我们来看看lambda的不同权限
如果你进入IAM控制台
记住，每单个lambda函数都必须有一个IAM角色
如果我在我的角色中查找lambda
我们可以看到我们这里有很多可用的lambda角色
这里有demo lambda角色
lambda ald
lambda s three
我们还有sqs
所以我们看看
例如 演示和行是第一个创建月桂的行
有一个lambda基本执行角色附件
所以这将附接到你创建的每个lambda角色通过控制台
如果你看那个角色的策略本身
我们可以看到它允许你创建日志组
然后将lug事件发送到您的cloudwatch日志
所以这里的想法是真的要有这个lambda函数
能够将日志发送到cloud watch日志
这就是为什么它被称为基本执行角色
好的 接下来我们看到的是资源策略
例如
你可以打开你的lambda s三
Lambda ibridge和lambda sqs
所以我可以向你展示这是如何工作的
如果我们看看lambda s三
你滚动向上
嗯 我们看到s three正在调用我们的lambda函数
所以我们有一个来自s three存储桶的触发器，你去配置中
然后权限并滚动
我们可以看到我们的lambda函数有一个资源基策略声明
我们可以点击查看策略
并且点击查看策略
我们有这个整个声明
显示我们允许亚马逊s three服务调用我们的lambda函数
一个条件是我们正在调用此lambda函数
然后源帐户是这个
并且源区域
因此，我们的S3桶的ARN会调用lambda函数
就是这个
这就是亚马逊S3桶调用lambda函数的魔法
所以bridge会再次调用我们的lambda函数
所以我们需要再次查看资源基策略声明
我们点击查看策略
在这里，我们看到我们允许亚马逊的事件
嗯 这是com，用于再次调用我们的lambda函数
因为源arn必须是这里桥上的这个规则
如果我们查看lambda sqs，现在并在配置下
我们滚动下来并看到没有资源基于策略声明
所以这里有些不同
因为sqs没有调用我们的lambda函数相反
我们的lambda函数将查询
嗯，并在sqs中查看是否有数据
因此，我们这里看的是执行角色
这是我的lambda函数的执行角色
如果我们查看它
我们可以看到我们有sqs lambda执行角色
这允许我们的lambda函数接收删除和获取消息
嗯 如果我们查看linda chris这里
你也可以通过点击这个下拉菜单看到
并点击亚马逊is qs，我们看到是的
我们可以接收删除和获取q属性
所以这非常重要
因为在sqs中
嗯，案例
然后lambda不是sqs调用
相反，lambda从sqs获取数据
所以你需要了解这一点
这就是这节课的内容
我希望这使资源与策略与执行角色之间的区别变得清晰 我希望你喜欢它 我会在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/085_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p85 22. Lambda Environment Variables.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们已经完成了所有的lambda调用
让我们进入更多的lambda配置和部署
所以lambda有环境变量的概念
它是什么
它是一个键值对，并以字符串形式存在
它们可以帮助您在不更新代码的情况下调整函数行为
环境变量将可供您代码使用
并且Lambda服务将自动处理这些事情
除了添加自己的系统环境变量
这在编程中很常见
所以它们支持lambda
酷的事情是我们可以加密这些环境变量
例如，通过KMS存储秘密值
秘密值可以是由Lambda服务密钥加密
或者您自己的客户端主密钥加密 所以让我们继续进行环境变量的实践
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/086_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p86 23. Lambda Environment Variables - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么我们来练习环境变量
为此我将从头开始编写一个函数
我将其命名为lambda lambda config demo
我将使用python三件套创建我的函数
这里的想法是我们想要与环境变量打交道
我们将以加密或未加密的形式将环境变量传递给lambda
在另一个函数中进行处理
加密部分将在本课程的安全部分进行处理
我们希望将此环境变量传递给lambda并让lambda将其打印到控制台
好的
首先让我们修改我们的lambda函数的代码
让我们进入代码源 我们需要稍微修改一下代码以便其正常工作
首先我们需要导入os包以便我们可以访问环境变量
然后在返回语句中你将返回os.getenv(environment_name)
我们将创建一个名为environment_name的环境变量
并将其赋值为dev
我们将创建一个名为environment_name的环境变量
并将其赋值为dev
我们将创建一个名为environment_name的环境变量
并将其赋值为dev
我们将创建一个名为environment_name的环境变量
并将其赋值为dev
我们将创建一个名为environment_name的环境变量
并将其赋值为dev
让我们部署此函数以保存我们的更改
接下来我们需要进入lambda函数的配置
我错过了
让我们在这里进入配置
我们有环境变量
在这里我可以编辑并添加一个环境变量
键将是environment_name，值将是dev
但你可以添加多个环境变量 正如我们所见
我们可以有一个加密配置
但我将在本课程的安全部分进行处理
因此，目前此环境变量未加密
现在我们已经将键和值设置为dev
现在让我们测试我们的函数
如果我们在这里测试我们的函数
我们将创建一个样本事件并创建
现在测试我们的函数，正如我们所见，响应是dev
这与环境变量environment_name的值相对应
但现在如果我去编辑并更改此为prod
并保存我的功能
正如我们所见，函数的代码没有改变
因此，代码没有改变
但现在如果我再次测试我的功能
然而，代码没有改变
回应将被发布
因此，在这里我们看到环境变量的影响，可以影响返回值和我们代码的行为
这就是环境变量的全部力量
就是这样 我希望你喜欢这个讲座 我将在下一个讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/087_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p87 24. Lambda Monitoring & X-Ray Tracing.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈琳达如何进行日志记录
监控和跟踪
首先我们知道lambda与云监控日志有集成
因为所有lambda执行日志都会自动存储在云监控日志中
如果你的lambda函数有一个执行角色
并且有正确的i策略授权你的lambda函数将日志写入云监控日志
并且这在lambda的基本执行角色中已经包含
正如我们所见
但我们还没有看到
但是有云监控指标
因此它们被部署在云监控指标中
UI或lambda UI中
它们将代表有关您的调用的信息
持续时间 并发执行
错误数量 成功率
限流 异步交付失败
如果您从kinesis或dynamodb流中读取，则会显示这些信息
您的迭代年龄
这意味着您在这些流中阅读的进度
您在阅读这些流中的滞后程度
那么我们很快就会看看这些
最后，您可以使用X射线在Lambda函数中进行跟踪
这非常简单
您只需在Lambda配置中启用它
它被称为活动跟踪
它将为您运行X射线守护程序
您唯一需要做的就是在代码中使用X射线SDK
你需要确保你的lambda函数具有正确的执行角色，以便能够写入x-ray数据
因此有一个管理策略叫做aws x ray demon right access
以及环境变量用于与x-ray通信
如果你需要它们
这些三个在这里，你需要看一次
我不会读它们给你
但看一次
它们可能会出现在考试中
我认为最重要的一个是最新的
AWS X-Ray 演示地址是哪个
代表X-Ray 守护进程的IP和端口
关于你的Lambda函数
这些环境变量可以像以前一样通过其他环境变量访问 就是这样了 让我们进入实践环节，看看这是如何工作的
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/088_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p88 25. Lambda Monitoring & X-Ray Tracing - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么让我们看看监控和追踪
所以对于这一点 让我们打开lambda s免费函数
我们将前往它的监控选项卡
在指标下
我们可以了解到我们的lambda函数被调用了多少次的信息
召唤持续了多久
错误数量和成功率
正如我们所见，有些是绿色的
这意味着在某个时刻，它正在成功
然后它变成了红色
所以它变成了错误 这是因为我们在测试两个目的地的成功和错误
所以这真的很好地监控这个图表随着时间的推移，当你有一个lambda函数在生产中
节流 所以如果我们超过了我们的lambda限制
异步交付失败
我猜函数
嗯，不行 嗯
没有机会处理永恒的
嗯 事件
迭代器 H
如果我们从流中读取并且并发执行
以获取我们的lambda函数的并发级别
目前我们只有一个因为我们不会调用太多
但是如果你有一个高并发的lambda函数
然后并发
嗯 并发执行的数量将会大幅增加
好的 云指标对于我们看到的函数非常有用
云监控对于Lambda函数的指标
所以我们知道每当我们的Lambda函数被调用时
我们将会得到一个日志流
并且在这个流中
我们将能够获取到Lambda函数的所有日志包括
例如 请求ID
我们记录到控制台的任何内容
以及请求ID的末尾
无论何时发生
以及一个报告以获取一些关于函数持续时间的信息
以及为它构建了多少
内存大小 最大内存使用情况
以及迭代，如果是相关的lambda函数
好的 你可能想看的最后一件事是在x射线周围
所以如果我们进入配置
然后进入监控和操作工具并点击编辑
然后我们可以选择显然的云slug
这是以默认方式启用的
现在我们也得到x射线
通过启用此
Lambda函数会将其跟踪记录到aws x射线
再次 没有找到Lambda的权限来写入x射线
但控制台将尝试通过添加执行角色来修复此问题
所以点击 保存
现在已启用
因此要确保这正在运行
如果我们进入权限
打开lambda角色
实际上就在这里
在资源摘要中
我们可以看到我们有权访问云watch日志
SQS 我不确定
哦，是的 因为目的地和x射线
因为我们需要能够将跟踪段放入并将遥测记录放入
所以现在这个lambda函数将写入x射线
因此如果我们进入s3桶在这里
我将上传一个对象
例如 我将上传我的错误html文件并点击上传
实际上Lambda函数失败了
所以让我们只是uh
返回成功
让我们让它返回成功并部署
我们将上传一个新的文件到我们的rebucket
所以让我们关闭此上传一个新的文件
添加文件 我将添加一个不同的fetch文件
每次我也可以重新加载相同的文件实际上
但这是可以的 好的
所以我上传了所有这些文件
所以我的lambda函数将处理这些文件
我们希望在稍后的时间内在x射线中看到跟踪
所以让我们打开x射线控制台
获取我们的服务图
所以这花了大约五分钟
但我们可以看到客户端
嗯 调用我们的lambda函数
然后服务器做的不是很好
然后lambda函数本身被调用
我们得到了一些关于有时有错误的信息
有时它是绿色的
所以绿色和橙色
因为有时它有错误
有时它正常工作 但我们了解到我们的lambda函数现在出现在我们的x ray控制台中
这就是lambda和x ray集成的全部力量
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/089_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p89 26. Lambda@Edge & CloudFront Functions.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来谈谈边缘的定制化
那么这意味着什么
我们了解 我们知道我们将我们的功能和应用程序部署到特定的区域
但有时使用
例如云前端
我们有边缘位置，这些位置分发我们的内容
有时现代应用程序需要执行某种形式的逻辑在边缘
在到达应用程序本身之前
这些被称为边缘函数
这是你写的一段代码
你可以将其附加到你的前端分布
想法是你希望这些函数靠近用户运行
以便最小化延迟
在某些情况下
所以云前端有两种函数
你有云函数和边缘lambda
目的是理解何时需要它们以及它们的差异
我们将在本课中这样做
但使用边缘函数你不需要管理任何服务器
这些边缘函数在全球范围内部署
它们的用例
例如 可能是自定义来自平台的cdn内容
你也只需为你使用的付费
并且它是完全无服务器
所以现在让我们更深入地看看这些事情
用例 第一个是围绕网站的安全和隐私
然后我们有边缘动态web应用程序
我们可以做搜索引擎优化seo我们可以做智能路由跨起源和数据中心
但在边缘缓解
实时图像转换在边缘
A/B测试
用户身份验证和授权
用户定价
用户跟踪和分析等等
所以这是用云函数和边缘lambda可以做的大量定制
所以现在让我们讨论一下云函数用于什么以及它们是如何工作的
所以这是一次典型的请求到云的样子
所以客户端会向云前端发出请求
这叫做观众请求
因为客户端查看它
然后云前端会向源服务器发出请求
服务器会回复平台
所以我们有一个源响应
最后云将该响应发送给客户端
所以我们有一个观众响应
现在云函数是轻量级的javascript编写函数
它们是你写的
他们修改观众的请求和响应
它们用于高规模低延迟敏感的cdn定制
这给你带来毫秒级的启动时间
以及每秒百万级的请求规模
如我所说，它们用于改变观众的请求和响应
所以观众的请求是在云前收到观众请求后
你可以修改这一点
或者观众的响应是在向前方将响应返回给观众之前
这是云中的一项便利功能
整个代码都是在云前管理的
直接 记住云函数
高性能 仅对请求和响应进行高扩展，现在边缘Lambda稍微多一点
所以你可以修改所有这些
所以这些是用Node.js或Python编写的功能
你可以扩展到每秒数千个请求
它用于改变云请求和响应的多个实例
所以所有这些实际上都是请求者和原点请求
这是在云前将请求转发给原点之前
你也有原始响应
这是云前在接收来自原始源的响应后
以及用户响应，这是云前在将响应转发回用户之前
你也在一个区域工作
这是us east 1，这与你管理你的平台分布的同一区域
然后云前将在其所有地点复制此功能
这里有一张表格，用于区分云函数和Lambda at Edge
所以有一个显著的区别是运行时支持
当然 仅限JavaScript的云函数
然后使用node js和python进行lambda边缘处理
规模真的很大
平台函数的规模
我们谈论的是每秒百万次请求与lambda边缘处理的数千次请求
现在 触发发生的地方是一大区别
所以lambda对观众请求和源都有影响
而 uh
云函数仅在观众上
并且非常重要
最大执行时间在云函数中少于一毫秒
所以它们是非常快速和简单的函数
而对于lambda edge
你可以得到五到十秒
所以你可以在这些函数中执行大量的逻辑
剩下的你可以看一下
在用例方面
云函数将用于缓存键归一化
所以进行转换 例如
请求属性创建最优缓存键头操作以插入
在请求或响应中修改或删除http头
或者进行url重写或重定向
或者请求授权创建和验证jw
两个令牌允许或拒绝请求
所有这些都可以在少于一毫秒的时间内执行
而边缘lambda的执行时间更长
可能高达十秒
例如 您可以调整CPU和内存
因此您可以加载大量库
并且您代码可以依赖于
因此第三方库如SDK
如果您想要访问其他aws服务
您还具有网络访问外部服务以处理数据
我们可以真正进行一些大型集成
边缘lambda为您提供文件系统访问或对http请求的请求本体访问
因此您可以进行一些更自定义的操作
希望这能帮助您
我希望您喜欢这门课程 我将在下次课程见到您
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/090_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p90 27. Lambda in VPC.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们来谈谈网络和lambda函数
默认情况下，你的lambda函数在外部VPC之外启动
所以它是AWS拥有的另一个VPC
好的 因此，它无法访问属于您VPC的资源
因此，部署在您的VPC中的资源
可能是您的EC two实例 或RDS数据库
或ElastiCache
或者一个内部的弹性负载均衡器
这些种类的东西，所以默认情况下，在你那个lambda部署中
看看这个 你有云
你的lambda函数
它可以访问任何公共网站
我们可以访问外部API
我们也可以访问其他服务
例如dynamo db
但是如果我们有我们自己的VPC和我们自己私有的子网
我们有一个私有的rds
然后lambda无法访问rds
你可能会问我一个问题
我该怎么解决
我可以在vpc中部署melinda吗 当然可以，所以为此
你必须定义你的vpc id
子网
id 子网
你需要为你的lambda函数分配一个安全组
在幕后，lambda函数会在你选择的子网中创建一个
E i 所以弹性网络接口在您选择的子网中创建
您的lambda函数需要一个lambda vpc访问执行角色
所以回到我们的私有子网
我们在亚马逊RDS数据库在我们的VPC中有我们的RDS安全组
我们希望这个lambda函数具有VPC访问权限
因此一旦我们正确设置
它将在lambda安全组旁边创建一个e和i在信号或接口
要访问您的rds数据库
你的lambda将通过你的网络接口（eni）
你知道它是看不见的
我们不看它 但这就是幕后发生的事情的方式
所以它将通过eni进入你的亚马逊RDS数据库
因此，为了这能起作用
我们需要确保RDS的安全组允许来自Lambda的安全组的网络访问
就像对这两个实例和负载均衡器一样
例如
好的 所以这里有一个警告
如果我们在一个VPC中部署一个lambda函数
我们能否访问公共互联网
默认情况下，VPC内的函数无法访问互联网
所以您可能会问我
好的 我不想在我的VPC中部署我的lambda函数
我不想在我的私有子网中部署我的lambda函数
我想在一个公共子网中部署它
你告诉我要管理那些可以访问互联网的公共子网
因此对于e来说是真的
C 两个实例 但对于lambda函数来说，这并不是真的
所以在公共子网中部署一个lambda函数
不要给它互联网访问权限或公共IP
知道这一点是好的
所以考试肯定会在这上面考验你
那么我们能做什么
您可以在私有子网中部署您的Lambda函数
为了使其具有互联网访问权限
您可以使用NAT网关或NAT实例
就像我们在VPC基础教程中看到的那样
我们的Lambda函数在VPC中
我们在云端，它在私有子网中部署
不在公共子网中 所以它在私有子网中
我们有RDS的访问权限
但是要访问外部API
我们需要通过一个带有NAT设备的公共子网
所以是一个NAT网关或NAT实例
NAT网关或实例 会连接到我们VPC的互联网网关
而互联网网关会给我们访问外部API的权限
所有这些都是通过你的路由表和VPC配置来设置的
好的 下一个
如果你要访问DynamoDB怎么办
我们可以通过公共路由或你的网络网关访问mdb
一旦设置完成，这个就会起作用
如果你想私有访问dynamodb
你可以使用vpc端点和dpc端点
如果你记得，它们用于私有访问你的别名服务，在你的云中
没有访问设备或网关的需求
所以我们为mdb创建一个vpc端点
这是一个vpc端点
网关和lambda函数会与端点进行私有通信
你的数据库服务
这很好 所以所有这一切都能正常工作
因此，如果您在私有子网中部署线性函数
请注意，您的云监控日志正常工作
即使您没有端点或裸体方式
有多少爱是某事能够正常工作
无论发生什么 好的
这就是理论的全部内容了 让我们进入实践环节
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/091_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p91 28. Lambda in VPC - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 所以让我们练习在VPC中的lambda
所以我们将从头开始修改一个lambda函数
将其称为 lambda vpc runtime 是 Python 三，正确地创建这个函数
让我们也进入e
我们将创建一个安全组，用于Lambda函数
所以我会进入安全组
我创建了一个新的安全组
我将其命名为lambda sg
我们将其附加到vpc
我们有 我们不需要任何入站规则和出站规则
想法就是向你展示一个用于lambda的sg
想法就是拥有一个安全组来附加你的lambda函数
一旦它在我们的vpc中部署
好的，现在我们回到lambda函数
让我们进入配置
并确保我们可以在我们的vpc中部署这个
因为现在lambda函数在ais云中，它有互联网访问权限
但它没有vpc访问权限
所以在配置的左边
有vpc 我们可以编辑这个并选择一个vpc来将我们的lambda函数附加到它
这里有一个警告标志
它说当你将函数连接到账户中的vpc时
我们现在正在做
它没有访问互联网的权限
除非你提供vpc
嗯 你的vpc访问
这意味着它必须在私有子网中
我需要将出站流量路由到一个位于公共子网中的NAT网关
这是唯一能做的方法
即使我们现在将我们的lambda函数发布到三个子网中
好的 这些是公共子网，因为它们可以访问互联网
正如我们所知，lambda函数仍然无法访问互联网
相反，它需要在私有子网中发布
嗯 将lambda函数部署到一个私有子网中，并使用NAT网关或实例
在一个公共子网中，用于运行流量
所以现在没问题
因为我们不会通过lambda函数访问互联网
当你在一个vpc中部署一个lambda函数时
通常是为了进行一些本地操作
例如，对你的rds数据库或你的elasticcache集群进行操作
好的 在安全组方面
让我们添加上之前创建的lambda sg安全组
以及其入站规则
并且外联规则将有助于定义对其他服务的访问
实际上，入站规则将无能为力
但规则可能会有所帮助
好的 所以我们点击保存
现在我们可以看到这是一个工作
因为lambda函数没有调用EC two创建网络接口的权限
EC two 是的
因为你在VPC中创建了一个lambda函数
要运行它，需要拥有网络接口
现在它们属于你和你的VPC
所以我们需要为lambda函数提供足够的权限来执行
让我们打开一个新的标签配置权限并点击角色
然后我们会编辑权限角色
让我们给我们的角色添加一个策略
我在这里只输入lambda，然后在这里有一个lambda ENI管理访问
这个，然后我们会添加一个策略
所以我们看看lambda
E i管理访问
这具有所有必需的权限
例如创建网络接口
删除网络接口
描述等等，以便能够给予功能
在我们的vpc中拥有权利存在
所以现在可以了
点击保存
我们的lambda函数现在部署在我们的vpc中
所以我们只需要运行lambda函数并测试它
顺便说一句 当你在一个VPC中创建一个lambda函数时
刚开始更新和启动可能需要一些时间
这是因为AWS需要设置几件事
但之后，你的lambda函数的性能应该没问题
所以我们只需等待它完成
这花了大约三分钟
但我的lambda函数现在已经更新了
所以我可以测试它
所以让我们去这个函数的测试页面
我们将创建一个示例事件
然后点击创建现在测试我们的函数
所以函数已成功
但更有趣的部分是，如果我们进入e的管理工具C two并且我们转到网络接口
如您所见
已经创建了三个网络接口
这与我lambda函数在我vpc中的网络接口相对应
所以这些网络接口每个都在一个不同的az
所以每个都在一个不同的子网
这就是允许我的lambda函数与我们的vpc通信的方式
你可以想象这些ennis
安全组需要有必要的规则来访问rds数据库或弹性缓存集群
例如 所以相当简单
但这就是本次演示的全部内容 希望你喜欢 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/092_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p92 29. Lambda Function Performance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们来谈谈我们的lambda函数配置和性能
我想首先解决的问题是内存
目前我们使用了128兆的内存
但我们可以增加到10GB的内存
以1MB为单位增加
添加到lambda函数的内存越多
你获得的vcpu信用就越多
你不能
嗯 设置vcpus的数量
你需要增加ram以隐式获得更多的vcpu
当你达到101千
792兆字节的ram时
你的功能将拥有相当于一个完整的vcpu
之后你将获得多于一个vcpu
因此你需要使用多线程来利用增加的vcpu
所以如果你的应用程序是cpu绑定的
这意味着它有大量的计算
并且你想要改善你应用程序的性能
这意味着减少你函数运行的时间量
那么你需要增加你的应用程序
你的lambda函数ram
这也是一个非常常见的考试问题
然后我们来谈谈超时
所以你默认的学习函数有三秒的超时
这意味着如果你的lambda函数运行时间超过三秒
它会以超时结束
但你可以设置超时时间至最大九百秒
即15分钟所以任何时间
任何从零秒到15分钟的执行间隔都是使用lambda的好用例
任何超过15分钟的间隔都不是使用lambda的好用例
这可能是更适合fargets的事情
或者ecs 或者e
c 二 这又是考试可能会测试你的东西
我们将讨论性能
所以lambda有一个执行上下文
这是一个临时的运行时环境，它会初始化你lambda代码中的任何外部依赖项
所以你会使用这个上下文来建立数据库连接
创建你的http客户端或你的服务器端客户端
执行上下文的酷之处在于它会在一段时间内保持不变
以期另一个lambda函数调用
这意味着如果你连续多次调用该函数
那么该调用上下文可以被重用并重用所有现有的数据库连接
http客户端等等
这对你lambda函数的性能有很大的帮助，因为它可以加速并提高性能
我会在下一秒给你展示一些伪代码
现在执行上下文中包括我将要讨论的tp目录，这在本讲座中也是如此。
这是一个你可以写入文件的空间，文件将在执行中跨执行可用。
所以我想向你展示一些利用执行上下文的代码。
所以这段代码是有问题的。
为什么，我们看看这个函数get_user_handler，
这是linda将要调用的函数。
如果你仔细阅读这段代码，
我们获取db url，os.getenv()。
我们获取了一个环境变量，
这很好，
但是接下来的一行是db_client = db.connect(db_url)。
虽然这看起来是正确的，
因为我们首先需要连接到数据库才能获取用户，
每次我们的lambda函数被运行时，
这个数据库连接每次都要运行，
所以每当有人调用lambda函数时，
它首先必须连接到数据库，然后获取用户，
这是非常低效的，
因为函数可能会被多次调用。
相反，
数据库希望你这样做，
最好的做法是在你的handler之外初始化数据库连接， 为什么，
因为只初始化一次，
然后在函数调用中重用它，
这将大大提高你函数的性能，
所以这种用例是考试中可能会出现的，
它会给你一些伪代码，
试图让你理解什么是好的，什么是坏的，
基于你在哪里打开你的数据库连接客户端，http客户端或sdk客户端，
最佳实践是任何需要很长时间初始化的东西，
放在你的函数handler之外并重用它，
最后，
如果你需要写一些临时文件并重用它们，
你可以使用tp空间，
例如，
如果你需要下载一个大文件来处理，
或者如果你需要为操作提供磁盘空间，
在这种情况下，
将这些文件存储在tp中，意味着临时的，
你获得10GB的磁盘空间，
你可以使用它的lambda函数，
这个目录在你lambda函数的执行时间内存在，
即使你的lambda函数停止并重新启动，
你可能需要重新调用它，
你可以在这个tp空间中重用相同的文件，
这将节省你很多时间，
这就是执行上下文的想法，
你可以在tp空间中写入非常大的文件，
所以如果你需要
尽管你的对象如此非临时，需要一个永久的持久性
那么你需要将其存储在一个你知道它将会在调用之间持续存在的空间中
并且这个空间将是亚马逊的s3
例如 如果你希望在tmc空间中加密内容
在lambda中没有设置来做到这一点
你必须使用kms功能来生成数据密钥
实际上使用这些数据密钥对你的临时空间中的数据进行加密
我们已经看到了我们可以如何提高我们的lambda函数的性能 现在让我们进入控制台来玩那些
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/093_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p93 30. Lambda Function Performance - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以对于这项实践
让我们进入lambda配置演示
我们将查看影响我们的lambda函数的不同选项
如果我们进入lambda函数的配置
我们看到的第一件事是在通用配置下
我们可以编辑基本设置
我们已经见过它们
但现在我们再看一下
所以内存可以在128兆字节到10000之间
总共240兆字节
我们添加的内存越多
我们就会有越多的CPU
正如你所看到的
我们可以要尽可能多的内存
好的，CPU与内存成比例分配
如果您有10,000和240
那么您将支付更多的钱
为您的lambda函数
如果您有最小值
所以您的想法是确实监控lambda函数的内存使用
并确保您设置内存
以便您有足够的内存来执行您需要的
但不要太多以至于您没有超载
一个非常流行的考试问题是
如果您需要更快的CPU或更多的CPU核
设置方法是通过修改内存
在今天的lambda函数中，无法独立更改CPU
好的 在超时时间方面
这是你lambda函数运行前抛出错误的时间
现在设置为3秒
我们很快就会玩它
让我们将超时保持在3秒
让我们有一个lambda函数
嗯
来做一些工作
让我们保持在功能中
我将在顶部导入时间库
然后我们将执行时间点
睡眠到
这是模拟一些工作
通过让lambda函数睡眠2秒
我们说lambda函数做了一些工作
在两秒后它将返回结果
让我们部署并测试这个
我们看到在2秒后我们得到了响应产品
持续时间约为2000毫秒
如果我们让lambda函数睡眠5秒会发生什么
现在lambda函数正在做很多工作
可能比我们之前预期的要多
那么我们部署更改并点击测试
现在会发生什么，Lambda函数将失败
为什么，因为它会超时
我们会在这里得到一个错误消息
说嘿 任务在三秒后超时
这是因为在Lambda函数的配置选项卡中
我们决定将超时时间设置为3秒
但现在如果我们将超时时间更改为6秒
好的，因为我们知道我们的Lambda函数预期要做更多的工作
然后我们再次测试Lambda函数
这次执行结果应该在5秒后成功
因为我们没有达到超时
确实，是的 我们正确地收到了响应
持续时间为5000毫秒
所以我们真正看到了超时对函数本身的影响
所以可能有人会问我，嘿，斯特凡
为什么我们不总是将超时时间设置为一个非常大的数字
比如15分钟或10分钟
嗯 如果你这样做
想象一下，你的函数卡住了
假设平均情况下Lambda函数执行时间不超过10秒
你可能无法及时处理错误情况
因此你可能需要重试或解冻你的函数
所以你需要根据你的功能设置超时
到一个你认为合理的数字
因为你希望当函数内部出现错误时函数失败
而不是等待15分钟直到函数超时，然后可能得到一个错误
所以这取决于你
这取决于你的使用案例和你的功能做了什么
但请根据你的功能设置超时
最后，优化你的Lambda函数
性能主要集中在你设置函数的初始化位置
如果你连接到数据库
如果你有一个连接到数据库的功能
你想要它在你的功能处理器之外初始化
例如
假设你将其放在这里 那就是你的功能连接到数据库
现在正在运行 这是睡眠3
好的 所以连接到数据库大约需要3秒
如果我们在这里有这个函数
正确
所以连接到数据库大约需要3秒 如果我们在这里有这个函数
正确
在我们在lambda处理程序中连接到数据库的地方
这意味着每次我们调用我们的函数时
这个连接到数据库的功能将被运行
它将需要3秒
因为它需要很长时间才能与您的数据库连接
然后它将返回您拥有的结果
如果我们测试它 这将需要3秒
所以我们等待1,2和3
好的 我们再次运行它
所以1,2和3
正如你所看到的，每次我们运行我们的函数
它需要3秒
因为我们每次连接到数据库
好的 但我们在考试中看到的优化是，而不是在lambda处理程序中连接到数据库
您将在其外部进行连接
所以让我们部署它并看看差异
现在我们在调用lambda处理程序之前连接到数据库
所以我们测试一下1,2,3
这花了很长时间
但这没有起作用，因为我们需要
所以如果你去看结果
它说连接到db未定义 所以我需要先定义我的功能
在调用它之前连接到db
这很有道理
所以让我们只把这个函数定义移上去
所以我们部署更改并再次测试
所以1,2,3
这花了我的功能初始化很长时间
正如我们所见
函数的持续时间为1毫秒
但初始化持续时间为3000毫秒
所以这是第一次运行我的功能所需的时间
但现在如果我再次测试我的功能
它不到1毫秒
因为我们不再运行这部分代码
所以我们可以测试测试测试
现在我的功能更快了
因为我们在外部初始化了数据库
不在函数处理程序中
希望这是一个很好的演示
想象而不是这里
而不是睡眠
而是连接到数据库 并从中获得一个数据库对象，您可以在lambda处理程序中使用它
这就是这节课的内容 我希望你喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/094_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p94 31. Lambda Layers.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们来谈谈lambda层
这是lambda的新功能
它们可以做两件事
第一，可以为lambda创建自定义运行时
这意味着那些最初不被lambda支持的语言
但是通过lambda层，社区决定支持它们
我们有C++和Arest
例如 所以这些都是允许你使用C++语言的例子
或者使用Rust语言在两个Lambda函数中
Lambda层的另一个更常见的用例是将依赖外部化
以便重复使用它们
如果我们看一下压缩的应用程序包
它可能会很大我们有一个学习函数
以及可能一些庞大的库和依赖项
因此这可能是30兆字节
并且我们看到为了更新我们的线性函数
我们需要重新上传那个zip文件一遍又一遍
所以我的意思是每次我们重新打包您的应用程序并重新上传一切
但有时我们使用的依赖项没有变化或者变化非常缓慢
因此将它们外部化为所谓的层会更好
目标是让你的应用程序包
你可以更改得非常频繁
将代码外部化
这可能是20KB
非常小
然后你为你的重量级库创建了层
所以你创建了第一个10兆字节的lambda层
第二个30兆字节的lambda层
这些层可以一起引用你的功能
对不起 你的功能当然可以引用你的层
因此我们有了一种更快的部署功能的方式
我们不需要每次重新打包我们的依赖项
因为我们的层是外部化的，另一个功能
另一个应用程序包可以创建另一个功能
也许60KB
并且引用这些相同的层
这就是整个目的
我们将我们的应用程序依赖项打包成层
我们可以在lambda函数之间重复使用 现在 让我们动手看看这是如何工作的
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/095_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p95 32. Lambda Layers - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么我们来练习lambda层
我们将遵循八的教程
让我们调用一个函数
Lambda层演示
运行时将是python3轻量级
我们将创建这个函数
我们将使用aws提供的层
因为我们很难自己创建一个层
我只是想向你展示层是如何工作的
所以对于这一点，让我们去谷歌搜索a is blog
Lambda 层边由 sci p y 侧
所以我们得到一个新的 lambda
任何编程语言
嗯，它共享通用组件
这就是我们正在寻找的博客
你会往下滚动
我们希望在这里找到代码
我们需要的 python 代码
好的 那么我们进入我们的lambda函数
在这里我们可以看到
当前的lambda层演示目前没有层
如果你点击层
它会带你到页面底部
在这里我们可以添加一个层
我们可以获得不同类型的层
我们可以获得aws层或自定义层
或者指定一个
所以我们会选择8个aws层
因为我们还没有创建一层
在这里你选择一个lambda python三八边之一x
然后，在版本方面，选择我们可用的最新版本
所以这意味着这是一个层，该层已经为python编译了scipi库
三个日期可供 Lambda 函数使用
所以我们会点击 加上并感谢这一点
然后我们可以使用引用站点i库的代码，而不需要我们。
打包那个函数的依赖项
那么让我们把我们的Python代码放在这里并完全复制它
然后粘贴到这个窗口中
这个窗口
我们可以看到前两行是导入numpy as np和导入a sci fi spatial
这个函数在这里
这意味着这些东西正在被导入
当你有导入的东西时，lambda函数不知道
通常你需要打包依赖项
就像我们为node js和npm做的那样
好的 但事实证明，多亏了层
实际上，我们的lambda函数可以使用这些依赖项
但我们不需要将它们作为依赖项打包到我们的代码中
这相当酷 所以这就是层的全部力量
所以让我们部署这个函数
并确保它确实在运行
并且我们可以利用这些库
所以让我们进入测试选项卡
我们将其命名为简单事件
然后点击测试
现在函数正在执行
我们得到一些关于日志输出的信息
它使用了numpy
它创建了一些矩阵和其他矩阵
进行一些计算
然后计算一些随机点并找到包含所有点的最小集合
关于这个函数的功能并不重要
但重要的是，函数代码本身使用了一个库
而这个库来自我们之前添加的lambda层
所以层具有巨大的力量
快速演示
但希望这展示了你可以构建的想法
并且使用层在lambda函数中可以进行优化
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/096_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p96 33. Lambda File Systems Mounting.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈文件系统挂载
这样你的lambda函数就可以访问你的efs文件系统
如果他们在vpc中运行，这样做
我们刚刚配置了lambda将fs文件系统挂载到本地目录
为了使其工作，请在初始化期间这样做
你必须利用s的efs访问点功能
假设你有一个s文件系统并创建了一个efs访问点
然后 如果你的lambda函数部署在私有子网中
该子网具有对vpc的私有连接
然后你就可以开始了
这个的限制是，对于每个即将启动的lambda实例，
你将多出一个连接到你的文件系统fs的连接
所以你需要确保你不会达到es连接的限制
并且如果你有很多
很多不同的同一时间突然启动的lambda函数
那么你也可能会达到连接爆发的限制
所以我想花点时间来比较lambda的存储选项
这样你就可以根据情况了解哪个是最好的
所以 斜杠tp的临时存储最大容量为十千兆字节
这是很大的，持久性是临时的
这意味着一旦你的lambda函数实例被销毁
你将失去存储
这就是为什么它被称为斜杠temp，临时的
内容动态
你可以随意修改它，它是一个文件系统
它支持任何文件系统操作
它包括在你的lambda函数中，高达512兆字节
然后你会为额外的存储付费，如果你的数据量超过512MB
并且只有你的函数可以访问这些数据
因为这种存储是基于你的lambda函数的
这是最快的数据检索级别
并且不会与你所有的lambda函数调用共享
所以现在你对lambda层的理解应该更清晰了
每个函数的最大层数是5层
总大小不超过250MB
以确保不超过最大lambda包大小
并且这种存储是持久的
因为它是不可变的
你不能改变传入lambda层的内容
所以它的类型是归档
它是静态的 它包含在你的lambda函数定价中
要获取层的访问权限
你需要确保你有适当的权限
它也提供了访问层数据的最快速度
因为它作为存储附加到你的lambda函数
并且它共享你所有lambda调用的实例
所以他们共享它 记住你不能修改lambda层的数据
如果你使用亚马逊s3
那么你可以无限制地扩展大小
它是持久的 它是动态的
源类型是对象
所以你需要使用s3 api来访问s3对象
然后你有原子操作
所以你可以得到put post等等
对于定价你有版本控制
当然对于亚马逊是免费定价
所以存储加请求加数据传输
要获取访问s3的权限
你需要确保你有适当的权限
这是一个基于网络的存储
所以我们有快速的访问
因为我们有专用的aws带宽
但它不是最快的
当然亚马逊是免费的 它是共享所有lambda调用
因为它是一个外部的数据存储
最后对于amazon es
我们有弹性 它是持久的
它是动态的 存储类型是文件系统
所以我们使用任何文件系统操作来访问它
我们将为存储付费
数据传输和吞吐量
因为它被挂载为你的lambda函数的网络系统
你将有快速访问你的数据
最后因为它是一个网络类
这将被共享所有lambda调用
希望这使lambda的存储选项有意义
我希望你喜欢它 我将在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/097_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p97 34. Lambda Concurrency.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈lambda并发和限速
我们调用lambda函数越多
我们就会有越多的并发执行或lambda函数
我们知道这是因为lambda可以非常
非常容易和快速地扩展
这意味着如果我们以较低的规模调用函数
我们可能有两个并发执行我们的lambda函数
但如果我们有非常高的事件发生规模
我们可能会有多达1000个并发的lambda函数一起工作来处理
任何传入的内容
你可以做 虽然限制lambda函数的并发执行数量
这是推荐的
我们可以设置一个叫做预留并发的东西
这是在函数级别设置的
这是一个限制
我们说，好的
这个lambda函数最多只能进行50个并发执行
超过并发限制的每次调用
都会导致所谓的限速
限速有不同的行为
如果是同步调用
我们直接调用lambda函数并被限速
它会返回限速错误4到9
如果是异步调用
它会自动重试并转到DLQ
如果你需要同时超过1000个并发执行
你可以提交支持请求请求更高的限制
现在我们了解了并发的概念
这里有一个如果我们不仔细设置并发可能会发生的情况
如果你没有设置任何预留并发
也就是说没有对你的函数并发设置任何限制
这可能会发生
例如，我们有一个应用程序平衡器 连接到lambda函数
我们有另一个应用程序有几个用户连接到API网关
连接到另一个lambda函数
还有一个应用程序可能使用SDK和CLI
来调用函数
当一切都处于较低水平
比如调用吞吐量较低
一切都很好
但假设我们正在进行一个大型促销
我们无意中得到了很多用户对我们的应用程序进行大量调用
负载均衡器非常成功
所以会发生什么，我们的负载均衡器会调用很多lambda函数
lambda函数可以自动扩展
所以我们会有多达1000个并发执行
这看起来不错 对吧
Lambda 已经扩展 但这里有一个问题
所有并发执行都流向了第一个应用程序
这意味着我们的 API 网关应用程序用户将被限速
这意味着 CLI 和 SDK 也将被限速
你需要记住这个幻灯片的内容
并发限制适用于您账户中的所有函数
因此您必须小心
因为如果一个函数超过了限制
可能您的其它函数也会被限速
所以这非常重要
接下来，让我们谈谈并发和您的非阻塞调用
让我们以 S3 事件通知为例
我们正在将文件上传到 S3 存储桶
这会创建一个新的文件事件，从而触发我们的 Lambda 函数
假设我们同时上传了很多文件
因此我们得到了很多
并发执行的 Lambda 请求
如果函数没有足够的并发
也就是说，如果它无法扩展
因为我们已经达到了限制
那么额外的请求将被限速
但这是一个非阻塞请求
对于任何限速错误和系统错误
对于 29 和 500 系列
Lambda 会将事件返回到事件队列
记住，在异步模式下
有一个内部的事件队列
Lambda 将会尝试在 6 小时内再次运行该函数
因此，由于限速等原因，会有很多重试
然后重试间隔会以指数倍递增
从 1 秒到最大 5 分钟
这允许您的 Lambda 函数继续尝试
并希望有一天能找到可用的并发容量来正确运行
好的 接下来
让我们谈谈冷启动和预定义并发
你可能以前听说过
冷启动
这意味着您创建新的 Lambda 函数实例时
您需要加载代码
并且需要运行除处理程序之外的所有代码
这对应于所有初始化代码
如果您的初始化代码很大
因为您有很多代码
很多依赖项
您正在与许多数据库连接并创建许多 SDK
这个过程可能需要很长时间
这意味着由新实例处理的第一个请求的延迟比后续请求更高
这可能会影响您的用户
所以如果你的用户可能需要等待三秒才能得到请求响应，这可能对他们来说非常慢
他们可能会经历冷启动，可能对你的产品不满意 那么你能做些什么呢
你可以使用一个叫做配置并发的东西
这意味着你在函数甚至被调用之前就分配了并发
所以你提前分配了这个并发
这样冷启动永远不会发生
所有的调用都会有更低的延迟
来管理这个并发
你可以利用这一规定实现并发
你可以使用应用程序自动扩展
例如，为了安排或目标位置
以确保您有足够的预留lambda函数准备就绪以供使用
并最小化冷启动问题
所以请注意
在你希望启动一个在VPC中的lambda函数之前
这将花费很长时间
所以现在有一个在十月和十一月的博客
2019年由aws发布
这是链接 这个博客展示了他们对vpc所做的改进
显著减少vpc中的冷启动
好消息是，如果你之前使用lambda，冷启动对你的vpc影响很小
好的 最后有两个图表
你可以自己查看
了解保留并发和提供并发的概念
而且这些抓取动作我很喜欢它们
所以这里在幻灯片上有链接
你可以去看看它们 它们会向你解释它们是如何工作的
我认为它们很难描述
就像幻灯片一样
但请根据自己的时间来看看它们
希望它们能帮助你更好地理解这些概念
如果我现在没有帮助你 好的 那么现在我们进入实践环节，看看并发是如何工作的
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/098_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p98 35. Lambda Concurrency Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们快速看一下我们在lambda函数中的并发设置
在配置中我们可以在左侧找到并发选项卡
目前我们正在使用未预留账户并发
每当这个函数运行时
我们有一个未预留账户并发为一千
这是全账户共享的
但你可以编辑它
你可以说
好的 这个lambda函数可能需要20个并发
你可以预留它
这样当你保存时
那么我们就有20个预留并发给这个lambda函数
你的账户有920个未预留账户并发给其他函数
为了测试并发
我们可以预留零并发
这意味着函数总是被限制
这是对用例的好测试
所以现在如果我们进入我们的代码
或者点击测试并点击测试
调用invoke api操作失败
因为我们超过了权限
你会得到这样的错误信息
当你超过预留并发时
这就是为什么把它设置为零的好理由
以便能够处理这个用例
也许在你的应用中
好的 但我们可以通过回到并发
使用未预留账户并发来修复它
或者为我们的功能预留特定的并发
如果我们现在测试这个函数
那么执行将正常工作，我们将直接从这个窗口获得结果
就在这里 好的
太好了 回到我们的功能
我们也可以为去除冷启动而提供并发
冷启动是当你的应用首次启动时
需要一些时间来初始化
在这种情况下，我们希望保持一个温暖的池子
功能可用以降低冷启动
这就是提供并发的配置
在这种情况下我们需要添加一个配置
你可以设置提供并发
要么是alias的首选，要么是版本
我们会很快看到alias和version
所以目前我们没有任何alias，我们不能应用到最新
因为最新 嗯，不适用于提供并发
我们需要发布一个版本
所以我们将在未来的讲座中看看如何做
但现在我只想告诉你设置在哪里
然后无论何时你有一个储备货币
例如 我们说嘿
我们希望有五个作为储备货币
我们将得到与之相关的一些成本
所以请确保你设置一个数字，对你来说有意义
这不是免费的 所以我们不会保存这个
我们现在不能这样做
但这就是lambda并发设置的全部
我希望这有道理 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/099_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p99 36. Lambda External Dependencies.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


到目前为止，在本课程中
我们一直在做一些非常简单的函数
只是一些代码
现实中，不需要外部依赖
你肯定需要添加更多的依赖项，包括包等
如果你的lambda函数依赖于额外的库
例如x sdk
数据库客户端 等
那么你需要将包和你的代码一起安装并打包
所以，如果你使用node js
你可以使用npm和node underscore模块目录来处理python
你可以使用pip -t选项来处理java
你可以包含相关的jar文件
每种语言都有自己的打包依赖的方式
但你需要记住的是，你需要将它们全部打包在一起
所以，代码和依赖一起打包
将它们全部打包在一起
然后将zip文件直接上传到lambda
如果小于50MB
否则首先进入亚马逊s3
然后从lambda引用
关于原生库怎么办
嗯 它们首先需要在亚马逊linux上编译
然后它们就会工作
那么关于SDK的A呢
默认情况下 SDK随每个lambda函数一起提供
如果你只使用SDK
你不需要把sdk和你的代码打包在一起 好的 那么我们继续进行实践，看看它是如何工作的
```

### /content/drive/MyDrive/bilibili/Udemy-UltimateAWSCertifiedDeveloperAssociate2025DVA-C02part3/100_Udemy - Ultimate AWS Certified Developer Associate 2025 DVA-C02 part3 p100 37. Lambda External Dependencies - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 所以，在这个实践环节中
我们将进行一个操作并创建一个带有依赖项的lambda函数
让我们进入带有依赖项的lambda
这里有两个对你来说有趣的文件
index.js和steps.js
为了能让你重现所有步骤
我们将能够使用云终端
云终端将给我们提供一个直接进入我们账户的终端
这个终端支持npm install
Npm 是在 node js 中管理包的一种方式
这就是我们为什么想使用云 shell 的原因
因为云 shell 为你做好了设置
所以另一件事是你需要创建一个 lambda 文件夹
所以我会删除一个 因为我刚刚创建了一个
但创建一个 lambda 文件夹
所以你做 mec 文件夹 lambda
然后你进入 lambda 文件夹
所以现在你在 lender 文件夹
里面什么都没有
首先你需要添加这个索引或js文件
所以我将快速进行伪yum install -y nano
你将拥有一个非常快速的文本编辑器
所以nano已经安装
我现在将nano index.js
这将允许我将所有代码复制到这里
我将删除这个提示
我将复制所有代码并粘贴到nano控制
X y进入，现在我们清除并做cats index.js
我们可以看到文件已经正确上传到我们的云外壳环境中
接下来，让我们进入安装一些依赖项的步骤
以确保线性函数正确打包并上传到lambda服务中
首先，如果我们看到这index.js
我们可以看到它需要x射线sdk核心
这是我们需要与我们的lambda函数一起打包的东西
然后我们打开了与亚马逊is free的通信
我们将返回一个列表的操作到亚马逊is free
所以我们需要做的是确保我们的lambda函数可以访问aws的x sdk
x sdk for aws
所以这就是这个命令在这里要做的事情
npm安装x射线SDK
这将在本地安装
所有必要的文件和文件夹，以便可以访问此SDK
所以现在如果我清除我的屏幕并列出我的目录
我们有index.js
我们有node_modules
如果在node_modules中查看
你将会获得很多不同的包
这些包安装了x射线SDK
最后，我们需要打包lock json文件
它将锁定这些包版本的版本
现在我们可以开始了
在这里，我们需要编辑这些文件的权限
我们将在这里执行一个命令
接下来我们就可以开始了
我们需要将这些文件打包成一个zip文件
名为functions
现在我们看一下
我们有一个名为functions的zip文件
最后，我们需要将这个zip文件上传到lambda控制台
我们可以手动下载并上传
我们还可以使用cli
我们将使用cli
首先，我们需要创建一个lambda角色的角色
让我们进入服务
然后进入iam
我们将手动为我们的lambda函数创建一个角色
我们进入角色，创建角色
这将为lambda服务
我需要向下滚动
然后取消缩放并点击下一步
这只是暂时的
好的
我需要添加一个权限策略
我们希望添加的基本执行角色是lambda
然后点击下一步
标签
下一步，审查，我将其命名为demo lambda with dependencies 创建这个角色，我们就可以开始了
所以现在这个角色已经创建
我可以复制这个角色arn
然后粘贴到我的命令行中
请确保更新你的代码中的这个arn
好的 让我们复制整个代码
进入我的云壳
粘贴并按回车
现在显示已成功
所以确实我的lambda函数已经创建
让我们进入我的功能
刷新 现在我们有八个函数
我们可以找到我的lambda x ray with dependencies函数
所以已经创建
如果你查看代码源
我们可以找到nodes模块
以及之前的index.js和package-lock.json文件，非常好
我刚刚执行的所有命令
你也可以直接在终端运行
但你首先需要安装npm才能使其正常工作
所以这取决于你
如果你想要代码源
你可以不用做zin 你可以从CLI上传
你可以选择一个你创建的zip文件
或者一个亚马逊s3重定位
如果你将zip文件上传到亚马逊s3，它将是免费的
好的 但想法是，我们已经将我们的lambda函数上传到了lambda控制台，包括依赖项
所以现在我们可以测试我们的lambda函数
如果我们测试它 让我们进行测试
我们创建一个样本事件
我们测试它
现在我们得到一个失败并且我们得到访问被拒绝
因为我们的lambda函数试图访问亚马逊s3
好的 如果你在这里
我们可以看到它正在做一个s3列表存储操作
但结果是，我们的lambda函数没有访问权限亚马逊s3
并且另一件事是我们启用了x射线
并且我们需要进入配置，也为x射线
所以监控 监控和活动跟踪
我们将启用x射线
这将也会给我们的角色添加x射线权限
所以，我们的角色缺少一些权限
所以让我们在这里刷新这个角色
现在我们有lambda基本执行角色和lambda活动跟踪角色
但我们需要添加一个更多策略
这将是围绕s3的只读访问
所以让我们做amazon s3只读访问
这将允许我们做列表存储api cop
所以这很好
让我们在这里，我们将测试我们的函数
让我们再次测试它
我们再次得到一个失败
我们得到一个访问被拒绝
这可能需要一些时间，这里的权限
在我们的lambda函数中反映
但这没关系
让我们再试一次
让我们测试它
现在我们得到一个执行结果成功
我们可以看到我们账户中的所有桶都被列出在这里
但由于我们启用了x射线集成
我们应该能够进入x射线控制台
它应该可能对我们来说
进入x射线控制台 看看所有API调用和调用由我们的lambda函数执行的服务图
让我等几分钟，让服务图被绘制
看这里，这就是我们的服务图
所以酷的地方是我们可以看到客户端
当我们调用lambda函数时
然后函数本身调用亚马逊S3的API调用
我们可以看到其中一半是成功的
绿色表示成功
一半是失败的
这是我们权限问题的时候
所以我们可以真正地看我们的执行情况的细节
所以我认为这是一个好例子，我有一个错误
50%是正确的，50%是错误
现在我们也可以详细查看这些追踪
所以我们可以查看这两个追踪
这是一个产生了错误的追踪
所以我们可以查看并说，好的
这个函数被调用
初始化是正确的
调用不是正确
因为我们在lambda上得到了四或三
使用列表格桶操作
因此我们可以从X光中真正看到
发生了什么事
它是三点
我们得到了一个四零三
然后我们可以查看操作
这是一个列表
我们可以看一下异常
这是不被允许的过度行为
所以s三和x射线非常有帮助
在这种情况下，看看发生了什么错误
如果我看成功的x射线轨迹
我们可以看到s三的调用是好的
我们可以看到它列出了多长时间
运行列表桶操作
然后获取响应
所以再次 这些轨迹真是太棒了
因为它确实给你提供了访问和概述
进入你正在做的lambda表演
这是一个很酷的小动手实践
因为在这个动手实践中，我们看到了很多不同的东西
我们看到如何打包一个函数并将其上传到lambda
使用CLI
我们看到如何打包依赖项
我们还看到了
如何使用X-Ray
我们看到了如何修改权限
以便我能够访问S3
所以这是一个全面的例子
我希望你喜欢它 我会在下次讲座见到你
```