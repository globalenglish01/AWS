### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/001_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p01 01. Course Overview - Services we will Cover.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


欢迎各位参加我们AWS认证数据工程师副学士考试预科课程
Dea co one
我是弗兰克 凯恩
本课程的一位讲师
我们大约在五分钟后开始
但为了快速介绍和什么的
我们在这里为AWS认证数据工程师考试做准备
Dea c zero one
希望你在正确的地方
这是一个具有挑战性的认证
对于助理级别的考试来说，它非常广泛且深入
实际上 我认为为这个做准备甚至更具挑战性
比准备认证数据分析专业考试更困难
这本应该是另一个层次的考试
所以请期待这门课程会很长
这是我做过的最长的一门课程
但它会很有趣
你将会在学习过程中学到很多
我们将学习很多关于不同aws服务的知识
其中很多
我们发现我们建议您在参加这个课程之前有一些AWS的经验
在开始之前
例如 正如我所说 这是更具有挑战性的Associate级别考试之一
我期望您
至少需要 了解 云计算实践水平知识
如果你是AWS的新手
这不是开始的地方
所以至少知道 EC two是什么，至少对AWS的网络工作有一些粗略的想法
你需要基础知识
至少我们不会从这里完全从头开始
并且最好有一些数据工程背景
所以考试指南说你应该有一到两年的数据工程经验
你知道
我认为如果你通过了这门课程
你将在途中学到你需要知道的很多东西
但无疑地，比起
至少知道数据工程是什么
如果你甚至不知道数据工程是什么
或者你知道不知道数据库是什么
或者对sql一无所知
你可能会发现一些材料难以理解
只是想设定期望值
你知道 如果你需要回去复习一些基础知识
你可能想先做这件事
我们将复习一些基础知识
尽管 当我们开始
我们将涵盖与考试相关的所有AWS数据工程服务
这是一个非常长的列表，正如我们将要看到的
系好安全带，朋友们，我们要开始一段旅程，慢慢来
这不是一场比赛 这里有很多材料要学习
考试不会自己走开
所以直到你准备好之前，不要给自己安排时间
因为准备这个可能需要一段时间
这是一个相当大的考试
让我来介绍一下我们自己
斯蒂芬·马雷克 我们的联合讲师
斯蒂芬，给我们介绍一下你自己
那么关于我自己
我叫斯蒂芬·马雷克
我很高兴能成为你们的讲师，为你们授课
我在udemy上教过接近二十万名学生
我非常高兴能算作你们的一员
我希望你们到目前为止都享受了这门课程
我已经通过了十多个aws认证，这个数字可能会很快改变
我在aws上工作了很多年
我构建了网站和应用程序
我构建了流媒体和大数据平台
我教授几乎所有的aws认证
所以你可以在不同的方式找到我
例如 领英
如果你想在完成这门课程后在Instagram上祝贺你
如果你想知道我的近况并趁我旅行的时候有机会见到我
推特 GitHub 中等
那就是全部
所以我很高兴你能在这里
现在我要把它传给弗兰克·卡
谢谢你 斯特凡和斯特凡
顺便一提，他是有史以来最成功的讲师之一
所以是一个真正的超级巨星
不仅仅是AWS
而且是在线教育
非常荣幸能与他一起在这里
嗯 你将在本课程中看到大量他的内容
所以我们在这里将生成内容分成五五开
我是弗兰克 凯恩
我在亚马逊工作了九年
完全 在总部 在西雅图
作为一名资深软件工程师，我通过自己的努力晋升为高级经理
所以我在他们建造的时候在那里
AWS（Amazon Web Services） 是我的焦点
当我在亚马逊时
专注于机器学习和推荐系统
还处理
你知道 大数据 数据分析和分布式系统
我在那里发明了很多东西
那时我在那里 所以这在当今是很酷的
我是Sundog教育的所有者
这是这门课程的出版商
你现在正在观看
我们专注于数据分析
最近也开始涉足机器学习和技术管理主题
这里有一些我的社会链接
如果你想去看看
到目前为止，对我来说
至少我有超过七十五万的学生
可能超过一百万
如果你算上所有其他平台，你也能找到我
现在我们开始学习这门课程中我们将要学习的所有服务
这是非常长的列表
令人惊讶的长列表
实际上再次
这比你需要覆盖的数据分析专业考试还要多
这非常广泛
让我们从分析开始
所以亚马逊
Emr弹性地图减少
当然 是处理数据的一个工具，我们需要
你现在将要摄入的东西
记住，我们将始终通过数据工程的镜头来看待这些服务
很多这些服务
它们确实与其他课程中你可能学过的课程有一些重叠
再次 如果你参加过我们的数据分析预考
这些材料中的很大一部分可能会显得熟悉
如果你在这门课程中已经对某个服务感到舒适
快速浏览它没问题
你知道 只需简单刷新
将播放速度提高到两倍
无论你想做什么
没关系 但这里也有很多新内容
对于你可能之前没有深入研究的服务
Emr 虽然我们可能之前见过
这是一个用于数据处理的分布式系统
aws湖仓
你肯定想专注于这一点
这是一个重要的工具
不仅用于设计你的数据工程管道
也用于保持它们安全
Redshift仍然是拼图中非常重要的一部分
不仅用于数据分析
也用于数据工程
我们还将深入研究亚马逊Kinesis以处理流数据
以及亚马逊管理的Apache Kafka
AWS Glue是数据工程中非常重要的一部分
这真的是对etl转换和移动你的数据有很大的影响
亚马逊开放式搜索服务
我们将深入探讨 以及快速可视化你的数据的网站
以及athena用于实时查询你的数据湖中的数据
基于aws app集成构建，这也是考试中的重要部分
我们有亚马逊事件桥，步函数
App flow sqs和亚马逊管理的apache airflow工作流
这些都是将事物结合在一起形成更大管道的工具
我们将深入探讨每个云财务管理
嗯 并不是特别针对数据工程
是的 但考试指南确实指出了这些事情
你应该了解 仅仅是用于管理你的开销的工具
我想数据工程的角度是，如果你处理大量的数据和大量的服务
把所有东西都联系起来
它可以很快加起来
它
如果你不小心 在建立这些系统时，密切关注你的开支非常重要
我们将讨论计算的常用对象
我们将再次简要讨论e C
Two
我假设你已经知道e
C Two已经在高水平上
Lambda 将这些服务连接在一起并在自定义代码中进行转换的一个大部分
我们还将讨论AWS批处理和AWS无服务器应用程序仓库
在途中
再次，容器
数据转换代码部署的一部分拼图
这些是高于数据工程的高级主题
所以请尽量思考它们
在如何应用工具的背景下
部署代码片段或应用程序
这可能是我在途中转换我的数据
我们将讨论ECR
ECS和EKS
数据库技术
你知道你的数据必须去某个地方
也许它会进入一个数据库
有很多种类型
你知道 我们有关系型数据库如RDS
然后我们有NoSQL
如DynamoDB和Cassandra的Key Space
Redis的数据库
以及亚马逊Neptune
以及用于其他场景的文档数据库
我们将深入探讨这些开发者工具
我有点惊讶地看到
它在考试指南中占据了多大的比例
因为开发者工具并不是你通常与数据工程相关联的东西
我猜这里的逻辑是，如果你需要开发自定义代码来转换你的数据
你可能需要使用这些工具，所以，好吧
我们必须覆盖它们，所以我们将讨论命令行界面
你可能如何使用那种云九
AWS CDK代码构建代码
提交代码部署和代码管道
我们也会谈论一些前端网页东西
这些只是种额外的东西他们附加在考试指南的末尾
亚马逊API网关通常用于
你知道在你的后端和AWS服务之间有一个API
如何与外部的网站相关
这与数据工程有什么关系呢，可能你有一些外部接口
网关
或者一个间接消耗你数据的网站
API网关可能是控制流量并决定其去向的工具
机器学习
现在我们必须谈谈这个话题
但亚马逊的sagemaker中有一些组件
这是他们的大型机器学习服务，直接与数据工程相关
所以我们会讨论与数据工程相关的sagemaker部分
以及数据转换，例如sagemaker 事物
数据整理师和sagemaker特性故事，特别是
所以，这门课程中特别专注于机器学习
我们将讨论管理和治理
这对于任何aws考试都很重要
好的，嗯
不仅限于数据工程
如果你参加过其他aws认证
你可能已经知道一些这些东西
你已经知道的东西可以略过
但我们会讨论云形成
云轨迹 云观察
aws config
亚马逊管理的grafana
那可能对你来说是一个新的aws系统经理和aws well
架构工具
那些都在考试指南中被点名
我们将讨论迁移和转移
回到一些东西 这更直接地适用于数据工程
包括应用程序发现服务
应用程序迁移服务
数据库迁移服务
数据同步 以及aws转移家族和雪家族服务再次
那只是关于将你的数据从a点移动到b点
而a点可能完全在外部
这对考试很重要
确实再次
在更高层次上 我们将讨论网络和内容交付
云前沿和route fifty three再次
工具 也许以规模化方式暴露你的数据给外界
然后内部使用vpcs和aws私有链接来保护你的数据
我们将讨论安全身份和合规性再次
你需要知道一些通用的东西，以便通过任何aws认证
我们将回顾 我是kms亚马逊
可能会看到更多与数据工程相关的东西
因为它更多地涉及你需要处理的个人身份信息
我们将讨论秘密管理器以保护你的凭据安全
aws waft防火墙和aws盾以保护你的系统免受dos攻击
以及其他什么的最后存储
这是一切基础的东西在这里
这确实是数据工程的一个基本东西，对吧
所以你必须将你的数据存储在某处
特别是如果你有大量的数据
数据去哪里s3是默认解决方案
特别是如果你选择更半结构化的数据湖
存储环境 稍后会解释我们指的是什么
考试还希望你了解efs和ebs以及aws备份
我们也会提及这些
当我们谈论存储时，在这个上下文中
它实际上是存储服务
与数据服务相对
所以我在哪里放我的原始数据
或者你知道我的数据湖
就是这样
那么嗯 让我们深入探讨一下，大家再次开始
我们将从数据工程的基本原理开始
然后我们会回过头来，逐一介绍这些服务
一个接一个 系好安全带，朋友们
我们要开始一段旅程
和我一起踏上准备 AWS 认证数据工程师 - 关联考试的旅程 从现在开始
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/002_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p02 02. Get the Course Materials.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在我们深入之前，还有一些家务事需要处理
如果你想获取这门课程的学习材料以便跟上进度
请前往 sundog education dot com
斜杠 aws dash data
斜杠 dash engineer
这将带你到这一页这里
我会在资源中提供链接 以便更方便一些
你可能需要本课程中练习的材料，这些都可以在这里下载
每个人都想要一份幻灯片的副本以便学习
你可以在这里找到它们
请前往获取课程幻灯片
你应该能找到一个方便的下载链接
顺便说一下 你可以阅读我们的相关新闻
如果你想的话，你可以订阅我们的邮件列表
完全自愿 不必要
如果你想和我保持联系
我的社交链接也在这里 那么，让我们继续
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/003_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p03 03. Udemy 101.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


嘿
只有几点 快速提示，如何使用Udemy的用户界面
以便您充分利用此课程
您在学习时
首先 如果您在学习过程中有任何问题
可以点击这里的浏览问答按钮
这将打开本课程的问答窗口
很可能您的问题已经有人问过了
已经回答了 所以你可以在这里浏览与这个讲座相关的以前的问题
如果你确实有一个新的问题
只需点击“问一个新问题”按钮，输入一个标题，尽可能详细地描述。
并且，太阳狗教育确实有一支团队，他们每天都在监控这一切
所以你会在两到四小时内收到回复
如果你在这里提出一个新的问题
如果你的母语不是英语
或者在一个嘈杂的环境中
在很难听清并且跟上我所说的话的地方
当你播放视频时
这里有一个速度控制
你可以默认使用
这是1x 但你可以将其减速到0.7
5x甚至减半速
或者你可以加快速度 如果你想更快
所以记得这是你的选择
你也可以在这里查看字幕
那实际上包含了我所说的实际文本
所以你也可以跟着一起看
或者你也可以点击字幕按钮
这里的cc
选择你的语言
那样实际上会给你提供字幕
那样实际上可以让你跟着我的文字一起听
那样可以帮助你加强你所听到的内容
也很实用 非常实用的工具
如果你在视频流播放方面遇到任何问题
点击这里的齿轮图标
你可以选择不同的分辨率
自动通常是最佳选择
但你实际上可以减慢速度
或者如果你需要，可以将其设置为更低的分辨率
以确保它能更有效地流式传输
也不要对
如果你在课程早期看到要求你为我打分的提示感到惊讶
如果你还不准备留下评价
然而底部有一个稍后观看按钮，你可以点击它
你可以稍后再回来观看
如果你还没有准备好，请点击那个按钮
不要随意点击一些随机的星级评价来关闭窗口
因为每一条评价都很重要
这对我有能力直接为你制作更多课程有很大的影响
当你被提示时，请留下真实的评价
你随时都可以更新你的评价
也可以在课程控制面板编辑它
我希望这些对你来说会有一些有用的提示，以便你最大限度地利用这门课程 那么让我们回到课程本身
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/004_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p04 01. Intro Data Engineering Fundamentals.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们开始吧
这一节将会与您通常所见的有些不同
AWS认证课程
因为我们在这里完全不会关注aw
数据工程的考试指南
考试列出了几个不是AWS特定的概念
但更多的是关于数据工程的一般情况
因此，重新审视数据工程基础是合理的，这些基础是考试期望你知道的。
在我们深入探讨可以帮助你实现这些具体aws服务的细节之前
在这部分中，我们只触及了数据工程的冰山一角。
我只专注于考试指南中明确提到的概念
这些是需要复习的重点
记住，考试假设你已经有几年实际的数据工程经验
没有课程可以完全替代实际工作经验
我假设你至少知道什么是数据工程
如果你不知道 那么你会发现这门课程和考试对你来说相当具有挑战性
让我们开始，回顾一些你需要的数据工程基础知识
需要掌握的高级知识，高于aws特定的知识
比如数据结构
数据建模 抽样技术
使用git 以及SQL的审查来转换和查询您的数据
在这一节之后 我们将开始深入研究涉及的AWS服务
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/005_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p05 02. Types of Data (Structured, Unstructured, Semi-Structured).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


再次 本节我们的关注点会有点不寻常
因为我们不会讨论aws相关的内容
主要内容都不是 我们只是回顾一些超出aws的数据工程基础知识
考试指南确实提到你需要了解这些知识
不仅仅是aws服务
再次，我们不会触及所有数据工程的内容
只涉及考试指南中明确列出的内容
其中之一是三种数据类型
所以我们需要理解这些是什么意思，以便在考试中取得成功
让我们回顾一下，我们拥有结构化、非结构化和半结构化数据
让我们回顾一下结构化数据
我们指的是已经按照预定义方式或模式组织起来的数据，通常存在于关系数据库中
即已经按照预定义的列信息组织起来的数据，这些列具有特定的数据类型，并且我们已经考虑了这些列如何相互关联以及如何搜索这些数据
结构化数据的特征包括
它们易于查询
由于它们具有结构，很容易对其进行SQL查询
因为你已经知道列的名称，知道数据类型，知道可以期待什么
它们已经按照行和列组织起来，具有一致的结构
里面没有惊喜，已经清理完毕
一些例子包括数据库表，当然
Oracle，Redshift，MySQL，PostgreSQL，无论它是什么
也是一个CSV文件，只要数据一致
只要它具有一致的列，就不会有奇怪的东西
就像CSV那样，可能会有行具有不同的列数，但只要它是结构良好的CSV，那就是结构化数据
当然，Excel电子表格也是一个例子
显然，可能制作一个Excel电子表格，里面充满了乱七八糟的东西
但你知道，典型的Excel电子表格，组织成行和列的明确信息，就是结构化数据 然后在另一边，我们有非结构化数据 没有预定义的结构或模式，就是一堆数据，我们需要在弄清它是什么之前
数据没有预定义的结构或模式，就是一堆数据，我们需要在弄清它是什么之前
然后在另一边，我们有非结构化数据
数据没有预定义的结构或模式，就是一堆数据，我们需要在弄清它是什么之前
我们可以开始查询它
因此，在没有首先预处理数据的情况下，我们无法查询非结构化数据
并从中提取意义
首先，索引可能以多种格式出现
例如 未经格式化的原始文本文件
也许你正在处理
你知道的 维基百科上的所有文本或类似的东西
或者所有书籍中的文本
因为你想在稍后进行全文搜索
或者用它来训练一个大型语言模型
谁知道呢 在这种情况下，显然需要一些预处理来首先索引该文件视频
音频和图像文件是另一个例子
你不能直接搜索这些
你需要首先从其中提取一些元数据
图像或视频或音频文件没有结构
我们需要提取该结构
并且说 嘿 嗯
这段视频的转录是什么
嗯 我怎么组织它
嗯 它是何时创建的
它有多长，谁制作的它
它关于什么对吧
它的主题是什么
诸如此类的东西需要从数据中提取
首先 电子邮件和文字处理文档也是如此
与文本文件处于同一类别
或者仅仅是原始文本信息再次
我们需要索引该信息
首先 确定其意义
它都是关于什么 然后我们可以
我们可以开始查询该信息
然后我们在中间有半结构化数据
有点灰色地带
你确切的意思是什么
但是 官方定义是它不像结构化数据那样有组织
但它以标签、层次结构或其他模式具有某种结构
中间地带
所以结构在某个地方
但你需要做一点工作来提取它
所以它可能有标签或分类的元素
它将比结构化数据更灵活
但不如非结构化数据混乱
你可以在那里放不同类型的东西
也许可以逃脱
但我们仍然可以提取我们需要的信息
XML和JSON文件是这种例子
你可以在同一个文档中拥有不同种类的schema
但文件中仍然有足够的标签来确定我们在谈论什么
所以在这种情况下schema可能不一致
但至少它存在
所以那是半结构化的
电子邮件头是另一个例子，可以有任何数量的信息
如日期和主题
以及邮件正文中的非结构化数据
当我们不确定那里是什么时
你知道那是半结构化的
如果我们至少知道那里的东西
是什么在那里
这有道理吗？日志文件可能是数据工程中最重要的例子
因为它是最常见的，如果你有一个Apache日志文件
或服务日志或服务器日志
它们可以是任何格式，而且并不总是一致
他们写的信息
那里可能有很多缺失的数据
在那里可能有数据在某些行中
但其他行中没有 你可能需要对每行日志进行大量解析
来确定它 all about
和那行日志的结构，所以 again
半结构化
结构在那里
但可能不会在文档中一致
我想那是总结它的最好方式
所以那是结构化
非结构化和半结构化数据 考试家伙在数据工程基础中提到了一点
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/006_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p06 03. Properties of Data (Volume  Velocity  Variety).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以我们讨论了数据的类型
考试指南还要求你了解数据的属性
它称之为三V，即体积，速度，多样性
我也听说过有第四个V
在很多你可能会遇到的文本中
那就是真实性
但考试指南只提到三个
所以我们就专注于体积，速度和多样性
暂时忽略真实性
我们将
嗯 我们会忽略真实性 暂时
体积就是字面上的意思 我们谈论的数据量
你正在处理的数据大小
在任何给定的时间
这可能会影响你存储和处理数据的决定 所以可能是GB级别的数据
也可能是PB级别的数据
理解这一点又会给你带来不同的挑战
以及如何存储，处理和分析那个数据
你知道的
例如
将大量数据从本地导入AWS 我们谈论的数据量
可能会影响你的决定
我是否应该把所有的数据都上传到互联网上
使用控制台
还是呼叫AWS雪橇，实际物理传输这些数据
诸如此类
一些例子
假设你是一个社交媒体平台
嗯
我不确定他们还能流行多久 他们似乎正在走下坡路
但我在这里不会发表评论
但他们可能是每天产生TB级别数据的一个例子
人们发布东西，发布图片，发布视频，所以数据量很大
你如何处理所有这些数据
如何访问所有这些数据 你知道的
显然你需要一种访问和查询这些数据的方式 并在分布式方式下进行分析
也许你有一个零售商
收集了几年的交易数据
嗯 几年来的交易数据
嗯 如果这是一个足够大的零售商
也许这是多个太字节的信息
是的 所以如果你处理大数据，这将伴随着大问题
你需要考虑分布式系统，它可以并行处理和移动东西
而不是可能只有一个单一的、独立的关系数据库
但是如果数据量不大
那么这可能是正确的决定，数据量在您的决定中起着作用
关于您如何创建数据工程管道
第二v是速度
再次就是字面上的意思
指的是新数据生成、收集和处理的速度
所以
你知道
你是否能够以批量方式处理这些信息
或者你需要实时流处理并持续处理
如果数据量很大
你可能需要实时或接近实时的处理能力
实时与接近实时的区别
考试喜欢深入挖掘的
你知道 通常这是在
我是选择kinesis数据流还是kinesis数据火枪对于一个特定的应用程序
快速的摄入和处理对于某些应用程序也是至关重要的
再次 做出决定
是否在当天结束时处理此信息
或者你是总是连续实时处理它
在它收到一些例子时
物联网的传感器数据
我可能拥有的设备
流媒体和阅读 每一毫秒都至关重要
似乎正在从整个物联网考试主题上后退
所以不要把太多时间花在具体思考物联网上
但这只是一个流数据应用的例子
也许一个更相关的例子是一个高频交易系统
正确 因此，人们正在交易股票
每一毫秒都很重要
你必须确保交易顺序正确
事情立即处理
并以一致方式
我们要讨论的最后一个V是多样性
这回到了我们之前的数据类型课程
我们处理的数据类型是什么
它是结构化的吗 它的来源是什么
它是结构化、半结构化还是无结构化
并且它来自哪里
它可能来自多个来源
也许每个来源都有自己的格式，你需要处理一些例子
嗯 也许我们有一家企业正在分析来自关系数据库的数据，这是有结构的
无结构的数据电子邮件
和半结构的JSON日志
你如何将这些东西混合在一起
或者一个医疗系统正在收集来自电子
医疗记录的数据
健康设备 或患者反馈表
再次 你处理的数据的多样性可能会影响你选择存储这些信息的方式
也许你将其存储在多个地方
但你需要一个统一的解决方案来查询这些数据，跨越所有这些数据存储
这些解决方案专门处理来自你数据多样性的不同格式的数据
这就是三个V中的体积
速度和多样性 记住考试
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/007_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p07 04. Data Warehouses vs. Data Lakes (and Lakehouses).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们回顾一下数据仓库和数据湖，以及它们之间的区别
以及何时选择其中一个
我们将从数据仓库开始
这是大数据工程的传统方法
这是一个优化分析的集中存储库
来自不同来源的数据以结构化格式存储
结构化格式是这里的关键
我们已经在传统的关系型数据库中很好地定义了它
它们设计用于复杂的查询和分析
数据已经清理
转换和加载
我们使用etl提取
转换和加载过程来获取数据
我们稍后会详细讨论
通常以星型或雪花型模式存储
当我们进入数据建模时会详细讨论这一点
它优化了读密集型操作
数据仓库旨在收集大量数据
可能从不同来源的大量数据
并以一种方式组织它
以便可以高效查询用于不同的应用
一些数据仓库的例子
对于aws，那就是亚马逊
Redshift是他们的主要数据仓库产品
当然，考试不会问你谷歌
Bigquery或微软
Azure SQL数据仓库
但那些是其他平台上等效的技术，我们不会讨论
在我在亚马逊工作时，甚至在Redshift存在之前
我们使用一个巨大的Oracle数据库进行这个过程
而且这非常昂贵且难以维护
我得补充一下 这是一个数据仓库的例子
概念上
让我们想象一下，我们又是亚马逊了
有一个庞大的数据仓库
从多个来源摄取信息
也许我们有一个点击流数据的存储库
直接从我们的原始服务器日志中提取并预处理
也许我们还有购买数据
实际下订单的人
以及他们购买的东西
你知道的，这些物品的实际信息
你可以想象这些数据都会相互关联
所以购买数据和点击流数据可能都需要与目录数据关联
以了解人们点击和购买的内容
所有这些数据都输入到这个庞大的数据仓库中
数据仓库可能针对不同类型的查询或应用提供不同视图
一个尺寸并不适合所有
您可能需要不同的信息子集和不同的索引
也许对于不同的应用程序和不同的查询，你可能想要这样做
也许会计对数据仓库有看法
其中包括其他人不需要的信息
只做客户行为分析的人
可能有他们自己的数据集市
如果你愿意 而且如果我想在那个数据上做机器学习
这也有自己的数据集市
我可以做大量的消费者行为信息提取，我可能想用来训练
一个机器学习模型
例如 一个推荐引擎现在
让我们将这与数据湖进行对比
与数据仓库相反
数据湖
它只是一个巨大的存储仓库
它包含大量原始数据以原生格式
这可能包括结构化
半结构化 和非结构化数据
所以我们把所有的数据都放在一个地方
然后我们稍后会找出一种方法来处理它们
所以我们可以存储大量的原始数据，而没有预定义的模式
数据被加载
原样 我们不会提前预处理它
如果我们这样做，也只是最基本的处理
这可以支持批量处理
实时处理 或流处理
并且可以用于数据转换或探索目的进行查询
例如亚马逊S3
你知道 当你将其用作数据湖时
你可以把所有东西都扔进去
你所有的日志
你所有的信息
然后我们可以使用其他工具后来自该数据提取结构
因此，数据湖中
我们只是存储原始数据
我们将后来解决结构化和查询数据的问题
在aws的情况下
通常这个管道看起来像使用aws的
Glue来提取那个无结构数据的结构和模式
它存放在s3中
然后可以使用诸如amazon的工具
Athena 以及其他工具可以使用glue数据目录来确定数据的结构
以及如何查询它 但数据本身总是以原始格式存储
你知道我们不会复制那个数据
我们不会把它放入关系数据库
它以原样存储在s三中
如果我们谈论其他竞争性的平台
Azure 数据湖
或hadoop的hdfs
生态系统是存储数据湖数据的替代地点
让我们更具体地比较两者，所以再次在模式上与数据仓库
它被称为模式在右边
我们知道我们的模式是什么
我们知道那个数据的结构是什么
在我们将其写入磁盘之前
因此当我们处理数据仓库信息时
我们会从其来源提取数据
我们将其转换为我们事先知道的模式
然后将其加载到我们的数据库中
好的 与数据湖不同，数据湖是模式在读取时确定
我们不知道那个结构的直到我们去读取那个原始数据
所以，有了数据湖而不是etl
我们做elt提取
加载转换 我们从其来源提取信息
将其加载到s3或其他地方
然后在我们需要的时候进行转换
可能需要多种类型的转换发生在那原始的数据上，用于不同类型的应用 但数据本身以原始格式存储
这就是主要区别
数据仓库存储结构化数据
数据湖只是存储原始形式的原始数据
数据仓库再次更适合结构化数据
当你知道你得到了什么
数据湖可以处理结构化和非结构化数据
所以它不在乎你把什么扔到s三
它可以是任何东西 它就是一个对象存储
数据仓库往往不太灵活
因为你有一个预定义的模式
有时候你会改变你对这个模式的看法
当你这样做的时候
这通常涉及一些大数据迁移项目，涉及数据仓库的停机时间
并且需要一些昂贵的人来确保它顺利进行
与数据湖相比
因为我们只处理原始数据
而且我们事先并不知道或关心其结构
你可以继续往里面添加更多的东西
并且可能在将来改变这个模式
在你处理所有事情的上层
因此这种方式更具敏捷性，只是为了强调
数据仓库通常使用etl管道，我们从中提取信息
形成它 然后将其加载到系统中，加载到数据库中，处于其转换状态
与数据湖不同
数据湖使用elt，我们只是加载原始数据
或者我们只是加载数据用于存储目的
然后我们会决定是否需要处理这些数据
并在稍后进行分析
你知道的 我们只是想在某个地方囤积它
也许那仍然是一个数据湖
数据仓库通常更昂贵，因为，嗯
需要更多的人和更昂贵的工具来做所有的转换和结构化
我们需要优化复杂查询
因此需要更多的思考去组织数据以
以确保后续快速处理和快速查询
数据湖可能更具成本效益
例如s3非常便宜
但如果你有大量数据
成本会迅速增加 当然
与任何事情一样
如何选择其中一个
所以总结一下
使用数据仓库 如果你有结构化数据源
你知道那个模式是提前的
并且你需要快速而复杂的查询
因为你知道那个模式
你知道如何构建索引
你知道如何提前优化那些查询
不同数据源的数据集成是至关重要的
因此你的数据仓库通常从不同的数据源中摄取数据
否则它就只是一个数据库
商业智能和分析是数据仓库的主要用例
当有大量结构化
半结构化或非结构化数据时，数据湖是合适的
也许你需要更可扩展和更具成本效益的
因为你有大量数据
也许你还不知道你将来会用这些数据做什么
我的意思是，我想这通常是这种情况 所以数据湖在存储和后续处理上提供了更多的灵活性
你知道，你不需要再去重新加载所有数据
只是因为你想要用不同的方式分析你的数据
数据湖通常用于高级分析
机器学习和数据发现系统
因此，拥有原始日志数据或原始行为数据的数据湖非常普遍
数据湖通常与先进的分析，机器学习和数据发现系统一起使用
因此，拥有原始日志数据或原始行为数据的数据湖非常普遍
无论它是什么，将数据提取为机器学习的特征并训练模型
你知道类似的东西
有时你需要两者
所以同时拥有数据仓库和数据湖是可以的
你可能在同一个数据中拥有不同的应用
也许你将原始数据存储在数据湖中
在那里你可以有更多的灵活性来处理数据
但如果你想要做
你知道的业务分析和数据挖掘
也许你还会将数据加载到数据仓库中
这更优化了那些用例
所以这不是一种非此即彼的选择
它更多地是关于拥有正确的工具来完成正确的工作
还有一个选项被称为数据湖屋
嗯 这在数据砖的世界里被广泛传播
它的定义是一种混合数据架构
结合了两种世界的最佳部分
我们拥有数据湖和数据仓库的最佳功能，试图提供性能
数据仓库的可靠性和能力
在保持数据湖的灵活性和低成本存储的同时
因此，数据湖屋也支持结构化和非结构化数据
它允许在写入时和读取时定义模式
提供详细分析和机器学习任务的能力
它通常基于云或分布式架构，如aws s
它可以利用像delta lake这样的东西
这将acid事务带到大数据中
稍后会更多地谈论acid
这就是数据库的承诺
以及数据是如何被处理和处理的
一些示例
AWS湖形成与S3和Redshift Spectrum一起使用
是数据湖房的一个示例
我们拥有一个存储在S3中的大量数据块
但我们使用Redshift Spectrum来查询这些数据
就像它是一个数据仓库一样
但底层存储是非结构的
它实际上是在幕后访问S3
所以它又是这种混合体
介于数据仓库和数据湖之间
这似乎是现在世界正在走向的方向
Delta lake建立在Apache Spark之上
Data bricks 湖屋平台
另一个是Azure Synapse Analytics
不打算多谈最后三个
因为它们与aws无关
因此你们在考试中不会看到这些
我不这么认为 但aws湖形成与s3和红移光谱肯定是一个用例 你要注意 随着我们完成这门课程
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/008_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p08 05. What is a Data Mesh.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们谈谈数据工程领域中一个更近的热门词汇
那就是数据织网
考试可能会期望你知道这个术语的含义
至少 如果不深入
它并不是关于技术
更多关于组织与管理
以及你如何结构
在大型组织中数据的访问和所有权
所以它更多是关于治理和组织而不是实际技术
想法 尽管 是各个团队拥有自己的数据
所以如果一个给定的团队或部门
或者无论你在组织中的位置
是某一种类型数据的专家
或者他们收集这些数据
或者那是他们的责任
他们就负责维护这些数据
并且也向其他组织提供这些数据
其他团队 组织内的其他部门
所以这种类似去中心化的世界
数据由最了解这些数据的团队拥有
但有一些中心的组织原则关于如何访问和治理这些数据
在每个数据域之外
这可能是一个特定的团队拥有特定的数据产品集
组织中可能有用例需要访问这些数据
也许有某个人需要执行一个分析
这个分析涉及来自多个数据域的数据产品
这是一个用例可能与多个数据域连接
连接到这些域提供的数据产品
有特定数据分析需求的人
不需要去访问所有数据
他们可以直接访问这些数据产品
这有时被称为域数据管理
这不令人惊讶，这个想法在亚马逊获得了一些牵引力
因为，嗯
这就是亚马逊内部的结构方式
我记得自从我有记忆以来，他们就一直采用这种去中心化的方法
他们有一套治理原则
但大多数情况下，各个团队拥有自己的东西
然而 你需要有联邦治理，中央标准
所以每个这些域都负责维护数据的完整性和安全性
并确保根据中央标准应用适当的访问控制
当然
亚马逊 当然喜欢这个概念
因为aws是实施数据织网的好方法
正确 所以你可以想象使用类似湖泊形成的东西
来组织这个数据的实际管理和存储和访问
并且也管理不同数据组不同的数据权限
并且可能aws glue被用作一个集中的数据目录
这样人们可以看到有哪些数据产品
这也需要自助服务
工具和基础设施
所以它
它假设这些不同的领域不会完全自生自灭
有一些兴趣的基础设施供他们构建这些数据产品
再次 这就是aws可能发挥作用的地方数据湖
数据仓库 s3 glue 湖形成
无论它是什么
可能是一个数据网格的一部分
但是数据网格更多是关于数据管理范式
你知道 关于谁拥有这个数据
谁维护它 这个数据如何访问
这个数据如何在一个大型组织中分布
它没有规定特定的技术或架构 但是aws可能是其中之一
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/009_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p09 06. Managing and Orchestrating ETL Pipelines.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以我们讨论了ETL在数据仓库的背景下，提取
转换和将数据加载到数据仓库中
让我们更深入地了解每个字母的含义
再次 ETL
提取 转换和加载
对于数据湖来说，将是ELT，只是将最后两个字母互换
但无论是哪种情况，字母的含义都是一样的
E代表提取
那就是从数据来源中检索原始数据
我们将稍后讨论数据来源
但这可能是外部数据库
可能是客户关系管理系统
如Salesforce
可能是平面文件
如日志文件
在某处，对吧 它可能是对某个系统的完全另外的API
也可能是其他数据仓库
因此，您的数据可能来自多个地方
您需要了解如何与该信息进行交互并将数据提取到数据仓库中
您还需要确保在提取过程中不遗漏或损坏数据
您需要确保数据的完整性
当数据被提取时
如果其中一次API调用提取数据失败
您是重试它
您多久重试一次 您在那里的政策是什么
那可能会有点棘手
您需要考虑数据的速度
此外 回到三个概念的那个
您是要实时提取数据
它是实时生成的 或者在几分钟内
或者只是在批量模式下
一次晚上或一周一次
取决于您的要求
因此，您需要了解数据的生成方式
它是如何被查询的
以及围绕这一点的要求
在做出提取决策之前，您需要了解这些
转到T转换
这是我们将提取的原始数据转换为适合目标数据仓库的格式
再次，在大数据仓库中
我们将在前期进行处理，在大数据湖中
我们将在后期进行处理
ELT 但无论哪种方式，字母的含义都是一样的
也许我们在最后更多是按需进行这种转换
无论是哪种情况 我们提到的转换是什么意思
我们可以有很多意思
多种意思 实际上我们需要清理那些数据
也许我们有一些坏数据
也许数据中有错误需要我们修复
也许有重复的数据需要我们删除
也许有缺失的数据需要我们填充
我们可能需要丰富那些数据
也许需要添加其他数据源的数据
所以我们可能需要将两个提取合并在一起进行转换
我们想要一个非常常见的转换是改变格式
嗯 你经常看到的转换是改变格式
也许你的数据以原始字符串的形式存储
但你需要将其转换为日期时间格式
是的 这是非常常见的格式转换
只是 通常你处理的文本数据很多
有时需要将其转换为整数
二进制数据
无论用于机器学习
甚至可能需要进行独热编码
但我现在不会深入探讨
聚合或计算
也许我们需要计算总和或平均值
而不是原始的数据
也许 我可能需要对数据进行编码或解码
也许数据以某种奇怪的格式到来
你需要首先解密或解码
才能将其写入你想要的格式
压缩 或某种列格式
也许你需要将其编码为列格式
最终存储在你想要的地方
嗯再次取决于你的要求
你知道的 如果你有一个要求，即某个列不能有空值
那么你必须处理
你是要删除有空值的行
还是要填充一些占位信息
你是要创建一份报告说嘿
我拒绝了所有信息
去处理它
取决于你的要求
最后，加载将我们的转换数据移动到目标数据仓库
或者数据仓库的情况下是一个仓库
这可以再次批量进行
一次性全部进行或者实时流式传输
当数据可用时再次
这取决于你谈论的数据量
以及数据的速度
你对分析数据和从中提取意义的要求
我们必须确保提取阶段的数据完整性
我们也需要在加载阶段确保数据完整性
有时磁盘写入会失败
你知道 有时候事情会卡住
你需要注意这些情况并处理它们
你不想只是让数据掉在地上而不知道
当你将其加载到你的数据仓库时
我们也需要管理这些管道
正如你所想象的，我们谈论了很多东西
很多步骤 需要有东西来协调
所有这一切 有些事情需要确保一切都按照正确的顺序发生
它应该在正确的时间发生
所以我们需要以某种可靠的方式自动化这些管道
AWS提供了许多服务来实现这一点
AWS Glue
是其中之一，可以自动对数据进行ETL或ELT，一旦数据接收
并且它会对数据到来的事件做出响应
在更高层次上，我们有调度服务，如EventBridge
亚马逊 管理的Apache工作流
Airflow -> 气流 AWS Step Function
Lambda 和工作流在 aws glue 中
我们将在后续的课程中深入探讨这些内容
所以现在 我只是试图把那些想法放进你的脑袋，并理解这些服务如何适应其中 对于ETL管道的更广泛问题
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/010_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p10 07. Common Data Sources and Data Formats.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们来谈谈不同的数据来源和数据可能采用的格式
这稍微不那么高层次
所以我期望考试希望你知道这些内容
即使这不一定特定于AWS
一个数据来源可能是JDBC连接
也许你有一些外部数据库需要提取数据
JDBC可能是一个接口
访问和查询数据的一个常见接口
JDBC代表Java数据库连接
JDBC的一个好处是它是平台无关的
因为它基于Java
它也依赖于语言，因为，嗯，它是基于Java的
Java的好处是你可以在几乎所有设备上运行
你可以想想它的缺点
那就是它需要你用Java语言访问数据
如果你在Java中构建提取工具
那么JDBC就很有意义
然而，如果你不在Java中
你需要一些中介层
这可能是ODBC，开放数据库连接
它依赖于特定的驱动程序，因为ODBC是平台依赖的
但它是语言无关的，因为它不仅仅基于Java
在实际中
大多数数据提取工具都支持JDBC和ODBC接口
只是 嗯
那种支持
是在较低的层次上，隐藏在你之外
所以我们只需要知道这些代表什么，以及它们的区别
你也可能直接从原始日志文件中读取数据
你知道的 也许你只是写日志到S3
你需要摄入它
这没问题
你可能有一个外部系统的API
所以可能不是JDBC或ODBC
有其他接口
一些应用程序编程接口，你可以从你的提取应用程序中访问信息
也可能有数据流
你可以处理流式信息
Kafka Kinesis
我们会深入探讨
但有些数据源会提供实时数据流，当你接收到时
你需要有正确的软件来摄入这些流并进行处理
一些常见的数据格式
这很重要 朋友们
CSV，你可能已经知道那是什么，逗号分隔值文件
一些常见的数据格式，这对大家很重要
基本上这是一个基于文本的格式
这是人可读的 这就是关键
数据以表格形式呈现
每一行数据对应表格中的一行
数据值之间用逗号分隔
不一定非得是逗号
分隔符可以是任何东西啊
使用逗号可能会很复杂
如果数据本身包含逗号
正确 然后，你必须找出
哦 我逃离这里的规则是什么
这些数据和引用
等等 有时你会看到CSV文件
分隔符不是逗号
它可能是一根管子，一个制表符，或者其他什么
正确 那没关系
你可能称之为tsv文件，如果是用制表符分隔的
但是同一个想法
你通常在什么情况下使用这个东西，适合中小型数据集
因为它没有编码
它是人类可读的对吧
所以它不是存储信息的最有效方式
但它容易阅读
它也是不同系统之间的一个常见分母
所以几乎任何东西都可以处理csv文件
所以，如果你需要将数据在不同系统之间互换，CSV是一个很好的选择作为通用语言。
如果你想找到一个将数据在任何东西之间转换的方式，CSV是一个很好的选择。
如果你希望数据可以被人类阅读和编辑，CSV在这方面有很大的优势。
CSV文件很容易在文本编辑器中打开，阅读，理解其中的内容，甚至直接修改，而不需要中途解码和编码。
这对于从数据库或电子表格中导入导出数据也很有用
电子表格的暗示是它可能没有多少数据
所以CSV是可以的
通常你会在基于SQL的数据库中看到这种用法
如果你将数据导入到SQL数据库中
Microsoft Excel就是这样
这使得导入和导出CSV对Pandas来说非常容易
如果你在使用Python笔记本
可以很容易地处理CSV，许多ETL工具也是如此
这也是JSON（JavaScript对象表示法）
你看到这种情况更频繁
你在应用程序开发世界中看到，在后端服务和前端网站之间传递数据
但是 更普遍地说
它是一种轻量级的文本格式，用于数据交换，人类可读
它基于键值对，表示结构化或半结构化数据
主要的区别在于它可以是半结构化的
它仍然是人类可读的
就像CSV文件一样
但你可以在不同的行上拥有不同类型的信息
对的，所以因为所有事情都被标记成键值对
你可以在每个行中拥有不同的键值对
这在json中是可以的
就像我说的
这更常用于Web服务器与Web客户端之间
作为交换信息的一种方式
这基本上是默认的标准
也用于软件应用的配置和设置文件
你会看到这在json格式中很常见
以及用于需要灵活模式或可能嵌套的数据结构的用例
这不是用CSV就能轻易做到的事情
但是用JSON就可以
你知道 每一行中可以有更多的结构层次
这是一件相当酷的事情
这在网页浏览器中可以看到
它在许多编程语言中得到了广泛的支持
JavaScript Python
Java 宁静的
APIs 以及非SQL数据库
所以，如果您需要存储半结构化数据
也许这就是您存储的格式
这种半结构化数据存储在您的基础数据库中
像mongodb就很适合这种数据
让我们也谈谈avro
所以我们正在离开人类可读的信息世界
Avro是一个二进制格式
这就是存储数据及其结构的地方
允许在后续使用不同的系统处理数据，无需原始系统的上下文
这是一个数据及其结构的小包，采用二进制格式
使其变得紧凑
适合大数据和实时处理系统
其二进制特性意味着更有效地利用了数据的比特
它拥有的
如果你的结构要改变
如果你的数据结构可能会随时间变化
这可能是编码结构本身的一个好理由
与数据一起
如果你的模式没有改变
那么你在编码该模式时可能会浪费一些空间
每次 真正的用例在这里是
如果该模式可能会改变
并且你需要将该模式紧密地与它附着的数据联系起来
这也是数据系统之间高效序列化的好方法
所以如果你需要从A点将数据推送到B点
对其进行编码和解码可能是一种高效的方法
因为它是二进制的
并且解码信息是如何嵌入到格式本身中的
Apache Kafka
Apache Spark Apache Flink和Hadoop是处理Avro格式的系统示例
稍后我们将详细讨论所有这些系统，Parquet
这个经常被提到
这就是我们所说的列式存储格式
因为它以列而不是行存储数据
它被优化用于分析
当你的查询可能只关注特定列的信息时
而不是一行中的所有内容
对吧 我们在那里颠倒了东西
按列恢复信息
因为我知道当我查询这个数据时
我可能只对特定列感兴趣，而不是整行
这就是分析的优化
这就是为什么Parquet是数据分析平台的一个很重要点
这允许高效的压缩和编码
因为列通常具有相同的格式
对吧 这使我们能够更好地压缩
这对分析大数据集在分析引擎中非常有用
读取特定列而不是整个记录的情况是有益的
再次
你知道 想想你可能有很多特征
每行很多列的情况
但特定的用例
特定的分析只需要这些列的很小子集
这就是Parquet变得非常强大的地方
它也用于在分布式系统中存储数据
因为我可以根据被查询的列将东西分开
也许我将一些列存储在不同的服务器上
对吧 这可能是一个非常重要的优化
我正在尝试最小化
IO 存储 overhead
基于我想做的事情
所以 使用Parquet Hadoop的例子
再次使用Apache Spark Apache Hive
Apache Impala和Redshift Spectrum
这在AWS的数据工程和数据分析世界中是一个非常重要的部分
所以Parquet
记得那个 如果你有一个用例
你有很多列
但你可能不需要分析它们所有
Parquet是一种非常有效的存储信息的方式
查询信息 并根据列分布处理信息
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/011_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p11 08. Quick Review of Data Modeling, Data Lineage, and Schema Evolution.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们快速且不完整地概述一个数据建模
接下来，有意识地不完整地概述一个数据建模
考试指南说，你需要知道什么是数据建模
但它没有谈论具体的数据模型
所以它并没有深入到星型模式和雪花模式等细节
因此，我们不会深入探讨太多
但只是做一个简短的概述
这是一个星型模式 好的
假设我们有一个数据库
你知道像Udemy这样的网站
也许这里有一个事实表在中心，包含课程ID
学生ID
支付ID
以及订单日期和时间
每当学生报名参加某个课程时
这个事实表可能会扩展到维度表
因为我们有这些挂在事实表旁边的维度表
它有点像一个星形
我们称之为星型模式
所以课程ID可能用于将事实表与包含相同课程ID的课程维度表连接起来
对于给定的课程ID
我们可以查找更多关于该课程的信息
名称 描述
讲师 该课程的价格
也许学生ID将事实表与学生维度表连接起来
因此给定学生ID
我能查到那个学生的名字，地址，邮箱，可能他们还有信用卡，最后还有支付ID
也许这些信息可以链接到一个支付维度，包含支付类型，金额，收取的税种，授权码，来自支付处理器的信息
无论它是什么 所以，我们有这些主键和外键
I can look up in dim student
What the name of that student is the address
The email
Maybe they're saved credit card
And finally for the payment id
So the idea is that we have these primary and foreign keys there
那些正在将这些维度表连回到事实表的
为了能够最小化每个注册所需的信息量
并且只需在外部维度表中包含那些事物的具体细节
所以数据建模101，正确
因此我们有事实表
我们有维度通过主键和外键相互关联
我们将这种图表称为
实体关系图
或者一个erd
简短的 这可能是你需要记住的事情
让我们谈谈数据血缘的概念
这也可能出现在考试中
我们什么意思数据血缘
这是一个数据流和转换的可视化表示，追踪数据在其生命周期中的运动
从其来源到最终目的地
作为数据工程师，你将会提取数据
你将会转换它
你将会在某些地方加载
它将会被到处推送并按不同方式进行转换
数据血缘的概念是记录你沿途所做的事情
就是这样
为什么你需要它呢
如果在途中出现错误
数据转换不正确
这可能有助于追踪错误到其来源
如果你有这个数据的记录，随着它移动
也许这可以帮助你调试管道中的问题 它也可能出于遵守不同法规的需要
你知道
也许你正在处理某种非常敏感或安全的数据 你正在处理
嗯 法律
围绕这些数据
他们可能要求你详细记录数据的转换
但更普遍地说，它只提供了数据在系统中移动、转换和消费的清晰理解
文档是好事
是的
所以如果有人新加入 如果他们想要理解你的数据如何通过你的管道进行转换和移动
这是一个让他们快速上手的容易方式
这是一个在aws上下文中数据血缘的例子
S是该博客文章的来源，来自aws
亚马逊
com 我提到这一点
因为考试倾向于基于那些晦涩的博客文章提问
所以你知道，当你能阅读它们的时候，阅读它们是好的
在这个特定的例子中
他们通过使用称为spline agent的东西来说明数据血缘的创建
这是一个附在aws glue上的apache spark东西
因此，在这种情况下，我们从aws glue中提取数据
从s3 glue
glue在s3的原始数据中导入数据到glue的数据目录中
并在etl管道中进行转换
因此，在这个特定的用例中
我们有一个称为spline agent的东西附在glue上
以记录它沿途所做的事情
以某种方式
它有一个被称为 lineage api 的东西
那么我们就可以直接使用样条工具来消费，并得到那些漂亮的可视化效果
稍后我们将看到一个名为sagemaker lineage的工具，它会做同样的事情。
但在这个例子中，我们在使用这款第三方工具 spline agent
也许我们希望把那些数据存储在我们的系统中
在这种情况下，在这里的底部
我们可以说我们正在使用aws lambda从spline消费那个数据信息
然后我们将其写入到亚马逊Neptune中
这是一个图数据库
正如我们看到的数据血统具有这种图形格式
这个图表结构
因此，图形数据库似乎是存储这个数据的合理地方
然后我们可以使用我们想要的任何外部工具来查询亚马逊涅普顿
所以处理数据血缘关系在W中的一个例子
S
让我们也谈谈模式演进
我们再次需要了解这意味着什么
这在考试指南中称为模式演进
我们指的是随着时间的推移，能够适应并改变数据集的模式，而不会干扰现有的过程或系统
我们之前讨论过这个数据湖的优势，就是说我们没有提前固化格式
这确保了数据系统可以适应不断变化的业务需求
这经常发生
你知道 你不想每次有新需求时就回去处理数据迁移
而且这允许你添加
删除
或者在数据集中修改列和字段
根据需要，而不会干扰您现有的所有系统
这样您就可以与旧数据记录保持向后兼容，并引入新数据
在不破坏旧东西的同时，随着时间的推移，引入新字段或修改字段
这就是我们所说的模式演进
就是随着时间的推移，在不破坏东西的情况下改变模式
在这个过程中
一个例子是胶水模式注册表
这是一个模式发现
兼容性 验证和注册工具
所以，Glue可以管理你随时间的不同版本的模式
并且确保你的数据与旧版本向后兼容 如果需要
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/012_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p12 09. Database Performance Optimization.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们快速回顾一下数据库性能优化技术
一些基本的工具可以使你的数据库运行得更好
最重要的工具是拥有正确的索引
所以你永远不想进行全表扫描，如果能避免
如果你需要从你的数据的每一行中搜索
寻找你需要的
那么你做错了
这意味着你需要一个索引
你需要查看你的查询是什么
并确保你理解你需要构建哪些索引
确保你能快速访问所需数据
索引也是维护数据唯一性和完整性的有用工具
如果你在尝试索引数据时遇到冲突
这可能会提醒你处理你可能不知道的问题
否则
另一种优化技术是分区
如果你有大量数据
可以通过分区减少被扫描的数据量
基于你可能查询的不同内容
例如 也许你是按日期划分的
你知道你可能只是需要搜索过去一个月的信息
通常情况下，按月份划分你的数据
你可以减少需要扫描的信息量
如果你确实需要对一个月的数据进行全表扫描
这也有助于数据生命周期管理
所以如果你按时间划分
这意味着处理这些较旧的分区变得非常容易
并将它们转移到成本较低的存储解决方案中
或者甚至随着时间的推移删除它们以节省存储成本
也许还有合规要求
这也可以启用并行处理
如果你以逻辑方式对数据进行分区
也许你可以并行处理它们，一个分区与下一个分区并行处理
因此分区也是提高性能的一个非常重要的方面
压缩也是一个可以加快数据传输速度的重要方面
同时也可以减少存储和磁盘读取
很多时候，你的数据库的运行速度被磁盘限制
我同意，如果是这样的话
那么你需要确保你存储你的数据
压缩的 一些常见的压缩格式是gzip
L p b zip two和z标准
这些都是亚马逊红移支持的压缩格式的例子
它们之间都有各种权衡，包括压缩和速度
所以你不想从一个情况转换到你的i
O到cpu受限
因为你的压缩格式太复杂
所以你可能需要做一些妥协
还有列压缩
我们之前谈论过parquet以及按列存储数据
你可能也想按列压缩数据
这可能更有效率
因为你的列都在同一
相同的格式 相同的数据格式对吧
它们可能有相似的结构
因此压缩这些信息可能更有效率
然后压缩一行
这是全部不同种类信息的一行
所以再次 快速回顾数据库性能
优化 索引 分区和压缩是你使数据库查询性能更好的主要工具
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/013_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p13 10. Data Sampling Techniques.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


考试指南提到了数据抽样
所以我们来做一个快速的回顾
我们需要了解的有两种
一种是简单的随机抽样
现在 抽样的目的是为了从大量数据中
抽取一个小样本
也许你只是想尝试一下
也许你不想承担
处理这个大数据集的费用
你可能只想抽取一个数据集
但它仍然能代表原始大数据说明
分析目的
一种方法是从数据集中随机抽样
在随机抽样中，每个数据都有同等被选中的机会
你只是在掷骰子，看看结果如何
如果你的样本
包含了所有你关心的内容
如果你的数据中没有不同的分类
随机抽样是有意义的
然而 有时候它并不适用
这就是分层抽样的作用
想象你有一个大数据集
但你关心的数据中有不同的分类
你想要确保
你的样本数据集从每个类别中捕获了示例
对吧 例如
也许我们有白色、黑色和灰色的东西
如果你只是随机抽样
你可能抽到的都是白色或灰色的东西
而不是黑色
或者你可能抽到白色和灰色的东西
而不是足够的黑色
这就是右边的例子试图向你展示的
这里的想法是将我们的人口分为同质子群
你称之为层 我们随机从这些层中抽样
这样我们确保从每个子群都有良好的代表
这样我们不会错过原始数据集中的整个类别
如果我们进行分层抽样
这样就保证了我们从每个子群都有代表 对吧
所以我们不用担心错过整个类别
如果我们进行分层抽样
这样就保证了我们从每个子群都有代表
对吧
这样就保证了我们从每个子群都有代表
这在当今非常重要
其他类型的抽样技术包括系统抽样、聚类抽样、便利抽样和判断抽样
系统抽样 聚类抽样
我认为系统抽样是唯一你可能听说过的抽样方法
让我们更深入地看看一些例子
随机抽样
假设我们有
这些购买信息的集合
它们由这些小钱包表示
如果你愿意 我们就随机选择三个
所以从这堆数据中
我们选择这些并标为红色
这将成为我们的新样本
我们随机选择了它们
那里没规律
那里没韵律或原因
随机抽样
分层抽样
让我们想象一下，我们希望思考特定种类商品的购买
所以也许我们有购买书籍的人
我们有购买音乐的人
你知道的，CD或数字下载
或者我们有购买家居园艺物品或服装的人
我们希望确保在我们的样本数据集中，每种类别都有均匀的代表
所以也许我们说，我们希望从书籍中选择两个
从音乐中选择两个
从家居园艺中选择两个 从服装中选择两个
并且两件来自服装
并且 即使这不代表我们数据集中这些不同类型事物的实际比例
这确保了我们在每个数据类别中有足够的样本覆盖
好的，有道理
所以我们在这里将我们的数据按我们关心的类别进行分层
我们确保在我们的样本数据集中每个类别都有平等的代表
我们从每个分层中抽取所需的样本数量，这就是分层抽样
最后，让我们看看系统抽样
唯一的区别是，而不是仅仅随机抽样
我们在说，我们将选择每个第三个项目
所以我们有系统规则来采样我们的数据，而不是随机进行
所以在这种情况下，这就是我们在做的
我们说每个第三个
我们将选择那个并取走它，所以1 2 3 1
2 3 1 2 3
我们在每个第三个尝试中得到了一个红色的
所以这就是系统采样的例子
这就是数据采样的精髓 很简单但重要的是在考试中复习
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/014_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 我知道你迫不及待地想进入最佳服务的时代
我正在尽我所能尽快带你去那里
但考试先生确实提到了数据偏斜
也必须知道那是什么
那不是AWS特定的东西
我们指的是数据偏斜是什么意思
嗯 它可以意味着几件事 但通常指的是分区中的不均匀分布
所以我们之前讨论过分区作为数据库优化的方法，那就是我们将数据不同的部分存储在不同的物理存储中，或者不同的数据表下面，以确保我们可以更有效地处理它们，并且可以并行处理它们。
偏斜就是当分区不平衡时发生的情况，这意味着我们在节点之间的数据不平衡。
在分布式计算系统中，分区是指数据在不同节点上的分布。有时候我们称之为'名人问题'。
如果分区不平衡，那么它就不起作用。
在分布式系统中，分区是指将数据分成多个部分，每个部分存储在不同的节点上。
当分区不平衡时，就会发生偏斜，这意味着我们在节点之间的数据不平衡。
有时候我们称之为'名人问题'。
如果分区不平衡，那么它就不起作用。
在分布式系统中，分区是指将数据分成多个部分，每个部分存储在不同的节点上。
当分区不平衡时，就会发生偏斜，这意味着我们在节点之间的数据不平衡。 嗯 如果你的流量不均匀
你不能均匀地划分东西
如果你的入站流量本身不均匀
让我们以一个例子来说明
好的 所以想象一下，我是imdb
我是一个关于演员和电影的数据库
好的 也许当我尝试存储每个演员的信息时，我只使用演员ID
我把它哈希
我用它来将数据分布在不同的分区中
底层实现 听起来不错
但是 一些演员的流量比另一些多，对吧
所以
想象一下我们有布拉德·皮特
他所映射到的分区可能会比一些不知名的演员获得更多的流量
无论什么分区
来自三十年前的电影
所以，在这个例子中
名人问题
像布拉德·皮特的名人会过度占用他所在的分区
因为他将获得其他分区可能无法获得的大量流量
这再次归因于他的知名度
这里的根本问题在于流量不均匀
与流入的数据相比
这可能由数据非均匀分布引起
所以，再次 如果我们仅仅根据某些ID的哈希值均匀划分
这可能与实际读取数据时的分布不一致
我们的分区策略可能不够有效
或者可能存在时间偏斜
是的 另一个问题是
嗯 如果你的数据随着时间的推移增长得非常快
而你只是按月份或年份进行分区
那么五年前的数据可能比今天的数据小得多
这会导致我们称之为时间偏斜的问题
较新的分区将比较旧的分区大得多
因此，监控数据分布非常重要
并在偏斜出现时设置警报
如果你的偏斜开始成为问题
你需要确保在监控它
你意识到它 并收到警报
你知道的 云监控所有这些东西
我们将在后续课程中详细介绍
但数据偏斜的根本问题是
你的数据以不均匀的方式被访问
这与你在分区数据时假设的不一致
如何解决这个问题
有几种方法
我不需要你记住这些不同解决方案以参加考试
因为这些并不是来自AWS文档
但只是为了你知道
一些潜在的解决方案
一种称为自适应分区
你可以根据观察到的分布随时间动态调整分区
在实时重新分区是可能的
基于你实际观察到的情况
负载均衡器就是这样工作的
盐的概念是在你分区键之前引入一些随机值
这可以用于更均匀地分布数据
也许你想定期重新分区
嗯
那是解决方案 但这是一个非常破坏性的解决方案
如果你还在尝试读取数据时重新整理所有数据
那可能会很难看
所以那是我尽量避免的
如果你能避免的话
抽样是另一个解决方案
也许你只是抽样数据来确定实际分布
并根据实际情况调整处理
也许那就是你自适应分区方法的一部分
正确，并且自定义分区
也许你可以根据领域知识为分区数据定义自定义规则或函数
也许你事先就知道
你知道布拉德·皮特会吸引很多流量
所以如果是布拉德·皮特
也许他可以有自己的分区
一种hacky解决方案
但这是一个解决方案
所以数据倾斜 以及处理它的一些方法
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/015_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p15 12. Data Validation and Profiling.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们也讨论一些关于数据验证和数据概况的关键概念
以确保您的数据是好的
这又是考试指南中提到的内容
因此，我们可以从几个不同的角度来思考数据验证
一个是数据完整性
我们是否有缺失数据
如果是这样 我们是如何处理的
这意味着我们是否拥有所期望的所有数据
它是否所有 是否有任何关键的数据缺失
这是非常容易检查的事情
你知道 你可以很容易地计算出在给定列中缺失的字段数量
你的空白计数是多少
这占您所有数据的百分比是多少
这是否符合您接受的要求
这可以非常重要
所以想象
例如 我们有一个数据集，包含人们的薪水
我们希望计算这些人群的平均薪水
如果其中有很多零，因为没有人报告他们的薪水
那会大大拉低您的平均值
因此，如果您有缺失数据，并且没有处理或意识到它
这可能会导致不准确的分析，并且人们从您的数据中得出错误的结论
因此，您需要考虑如何处理缺失数据
我是否删除包含缺失数据的行
我是否以某种方式填充数据，放入某种占位符数据
您需要考虑这一点
首先，您的数据是否完整
如果不完整，我将如何处理
数据一致性
假设我有来自不同来源的数据进行连接
或者来自不同的表
这些数据是否以一致的格式表示
我们可以通过跨字段验证来检查这一点
只是比较这些数据来自不同来源的样子
但这很重要
例如
让我们看看这个例子
我们在这里看人们的电影评分
如果我们有一个表，评分是1到5星
而另一个表是1到10星
这些不一致
评分值范围
如果我们尝试将它们结合在一起
我们肯定会有很多混淆和错误的结论
数据一致性
它是五 那可能看起来像是一个非常差的评分
但我们正在尝试将其拉入不同的表格中
评分从一到十变化
这就是一致性的一个例子
可能成为一个问题
我的数据是否正确也是数据准确性的一部分
你知道 我信任它是正确的，可靠的
这代表它应该做什么 测试稍微难一点，确保这是对的
如果你有一些真实的数据来源
你可以检查它 那么很好
否则，你就得确保它通过一个常识检查
这 嗯
这个数据的整体性质和分布
大致符合我们对现实世界的期望
显然这很重要
不准确的数据导致不准确的洞察和结果
以及不准确的决策
最后还有诚信问题
你知道 这是我的数据 嗯
随着时间的推移，失去其有效性
通常这在不同数据表之间的关系中表现出来
这就是外键检查的作用，对吧
检查这些表之间的关系的有效性
它们可能会随着时间的推移而脱节
如果随着时间的推移，事情发生了变化
但再次重要的是，您需要确保数据元素之间的关系得到保留
这意味着您的数据随时间保持可信
因此，数据验证和概况
我们需要考虑数据的完整性
我是否有缺失的数据
数据一致性
我的数据在不同表之间是否以一致的格式表示
我的数据准确吗
我的数据完整性好吗
我是否会随着时间的推移在不同的表格中失去我的数据之间的关系 这就是数据验证和概况的一个小小总结
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/016_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p16 13. SQL Review Aggregations, Grouping, Sorting, Pivoting.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


考试指南说你需要了解结构化查询语言
或者sql和一些特定的东西，你想要做数据操作
所以让我们在这里做一个回顾
现在我将假设你知道什么是sql
如果你对sql是完全新手
你从未做过 甚至你对屏幕上的这个东西都没有任何概念
我建议你在学习路径中添加一门sql课程
我可以将整个sql课程作为这门课程的一部分
包括在内
这只是对内容的快速回顾
考试期望你理解的主要要点
如果你需要更深入的了解
有很多优秀的SQL课程
只需找到最热门的一个
你会得到很好的照顾
他们肯定说你需要理解聚合
这是很基础的东西
让我们从这里开始
如果你曾经做过任何SQL
你知道如何获取表格的行数
你只需说选择计数星
在这个例子中，我说作为总
下划线行
作为只是分配列名的名称，我将在结果中看到
从那个查询 和从员工意味着我正在计算它们
从名为员工的表格中
这将给我从员工表格的总行数
计数星那样做，如果我想在员工表格中加总所有薪水
我可以说一些薪水并在名为total underscore salary的列下显示结果
在这个例子中 如果我想得到平均薪水
Ag是那个操作符
我可以只说abg salary as average underscore salary again
as只是命名了从employee's table中结果所在的列
我可以得到最大值和最小值
如果我想得到最大薪水
我们整个表中最高的薪水
我可以说select max salary and call that result highest underscore salary from employees
所以这是非常基础的东西
如果你不明白这一点
你可能想要去参加一个单独的进阶课程
因为这是一个快速的复习
有一点比基础更复杂的是使用case语句
让我们谈谈那个技巧
所以这里的上下文是尝试对你的结果应用筛选器
当你正在聚合时
如果你只需要在一个条件下筛选
你不需要case语句
你可以直接在where子句中使用
这是非常常见的做法
所以如果我想获取员工总数
但我只想获取工资超过7万英镑的员工数量
无论你的单位是什么
我可以在语句末尾添加一个where salary > 70000的条件
对 这样会做什么
选择计数星号是高工资计数
所以我会有一个名为高工资计数的列从员工表中
但是，而不是去计算那张表格中的每一行
我正在数行
在工资列大于七十万时
有道理
那么如果我想要做多于一个多于一个where子句的话会怎样呢
如果我有多个过滤器，并且我想要它们表现良好怎么办
一种做法 那就是一个case语句
因此，case子句允许您指定一些条件
实际上，我可以一次做多个。
所以，where子句的事情在于，因为你在聚合语句之后指定它。
我只能一次过滤一件事
使用 where 子句
但如果我将那个过滤器移动到实际的选择本身中
然后我可以同时做不止一件事
所以在这个例子中，我正在说
选择计数情况
当薪水大于七万时
然后一个 并且这意味着我将在这里应用这个小逻辑片段
在每个行中
如果工资超过七万
我将返回值一
这将给我所有值为一的计数
因为他们的工资超过七万
这个计数将显示为高薪账户
同时，我还有另一个条件
在这里，工资在五万到七万之间
则返回一 那么一意味着我将累加那一个
为了得到那个条件的总数
我可以称之为中等工资计数
同样，对于少于五万的任何人
同样的想法 只是案例一工资少于五万
然后一端
这将计算出所有
那些来自那个条件的结果并显示为低工资计数
所以用案例语句做一次多个过滤器的小技巧
使用案例语句
你可能没有见过这样的组合方式
快速回顾一下 如果我想按给定的字段来分割和分解数据，该怎么办呢
例如，我想计算每个部门中员工的数量
假设我们的员工表中有每个员工的部门ID列
我们可以这样做
所以选择部门ID和员工数量
这将显示部门ID列的结果
然后查询结果的总数量，并标记为员工表中的员工数量
从员工表中获取员工的数量
我们在这里应用一个条件
只是为了好玩 当它连接8大于2020年1月1日时
哦天啊 如果他们知道几个月后他们将面临的情况
我们将说 按部门id分组
这就是重点 这就是按部门id分组的意思
按部门id分组
我将为每个唯一的部门id获得不同的结果行
该id存在于员工的表中
这是该操作的示例输出
它将包含部门id
以及员工数量
这些都是我在SELECT语句中选择的标签
这些都是在2020年1月1日后加入的人
但按部门id分组
所以我在这里看到 人力资源部门总共有5名员工
在2020年1月1日之后加入的部门
在信息技术部门，总共有八名在1月之后加入的员工。
2020年1月20日
所以，仅作为一下子提醒你组by是如何工作的
我们也可以根据我们称之为嵌套分组的多个事物进行分组
那么如果我说按销售年份分组的话
逗号产品ID
这里发生了什么 这里是一个不同的例子
假设我们这里有一个销售表
我们在哪里 嗯
当东西被出售时
什么产品被出售
以及以多少正确
所以这里我们说
选择销售日期的年份并显示其为销售年份
然后我们将要有下一个事情
我们结果中的下一列只是产品id
然后那个产品id在那个年份的所有金额的总和就是它的意思
最后我们将这个最终和称为总和
销售总额来自销售
这只是我们正在处理的表的名称
然后我们将说按销售年份分组
逗号产品ID
现在销售年份在上面
只是指的是销售日期的年份
所以，我们将按销售年份分组
也按单个产品ID分组
这将给出单个行
每个销售年份和产品ID的组合结果
对于每个产品
我将查看每个年份的结果
如果我想按特定标准排序怎么办
这就是order by的作用
这是在排序我的结果
在这个例子中，我们是按销售年份排序
然后按总销售额降序排列
所以这将给我一个表格，每个年份
它将给我列出在该年份销售的产品ID列表
按总销量排序
该产品在该年的总销售额
这是一个稍微复杂一点的例子
包含同时嵌套分组和排序
试着理解这一点
旋转也值得讨论
当我们谈论旋转时
通常是在微软Excel电子表格的背景下
但在电子表格中也可以进行旋转
但也可以在电子表格中进行旋转
语法可能会有所不同
取决于你使用的数据库
所以我不指望考试会考你
旋转工作方式的具体语法
所以不要对语法过于纠结
以及它在SQL层面的运作方式
我几乎可以肯定他们不会真的考你
重要的是要知道旋转是什么
所以 这里的主要要点
那是pivot（旋转）是将行级数据转换为列级数据的行为，对吗
所以我正在将一张表翻转
而具体如何操作则取决于数据库
一些数据库有pivot命令 这里有一个具有pivot命令的数据库示例
我们要从查询的内部开始
所以让我们看看查询中的第二个select语句
选择salesperson, month, sales from sales as source table
所以让我们想象我们有一个包含销售金额的销售表
每一行包含salesperson
但我们想报告销售人员的销售额
为了做到这一点，我们必须颠倒事情
好的 这就是中间这个pivot语句在做的事情
我们说pivot
一月和二月每个月的销售总额
我们将汇总一月的销售额
汇总二月的销售额并颠倒过来
我们将从那个pivot表格中创建一个pivot表格
我们将选择销售人员和月份
并且从那个转换的表格中的总销售额
我们将那个源表格称为外部
我们还有一个选择语句
这真的只是重命名那些结果
所以我们说对于1月
我们将其称为jan_销售
对于2月我们将其称为feb销售
这里的输出是转换的结果
而不是有销售人员的行和金额
我们现在有每一行个销售人员
一月和二月他们销售额的总和
pivot是实现这一目标的一种方式
另一种更灵活的方式是使用条件求和
再次回到我们的朋友
case子句那里
我们可以通过只说select salesperson来做同样的事情
some case when month equals january
然后sales l zero
在这种情况下 我们将汇总所有一月销售额的结果
如果是不是一月份
那么我们就会加上零，以便我们不会实际计算其他月份
在这种情况下 对于二月份也是一样，我们会得到同样的结果
这可能是一种使用聚合来执行转换的有点hacky的方法
这可能不是最高效的方法
但如果你没有特定的转换操作
这也是另一种方法
主要的收获就是
转换是一种将行级信息转换为列表的方法 这只是把桌子翻过来
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/017_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p17 14. SQL JOIN types.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在任何时候你被测试SQL
你可能期望被测试不同种连接方式如何工作
这种类型的考试话题有点喜欢
不仅是为了这次考试
但任何涉及SQL的考试
所以现在让我们谈谈不同种类的连接
如果你在SQL中只说连接
你将得到一个内连接
所以想象我有两个表名为A和B
它们两者都有一些共同的列
也许这些都是关于某个客户的信息
关于那个客户的一些信息在表A中
其他信息在表B中
但它们通过共同的客户ID联系在一起
如果我想从两个表中引用信息
我可以做一个内连接
基于我想结合它们的表，基于这个连接
做一个内连接
我只会得到两个表中交集的结果
对于每个交集，都有一个共同的客户ID
或者这两个表之间的标识符是什么
让我们看一个例子来使它更清晰
所以在这个例子中，我们在连接两个表：客户和支付表，通过客户号码字段
所以这里有一个客户客户号码字段和一个支付客户号码字段
在这个情况下，我想要做的是从客户表中选择客户名称，从支付表中选择支付日期和支付金额，这些记录是通过客户号码连接在一起的
所以看看这个语法
我们说 select c customer name p dot payment date p amount from customer c
所以我们给客户表起了一个别名c
我们正在说选择c customer name p dot payment date p amount from customer c
所以我们给客户表起了一个别名c
所以我可以在选择语句中把它作为c引用，而不是customers
然后我会说再次连接payments p
我给payments表起别名p，所以在顶部
我可以在c customer number中引用payments作为p
这意味着customers表中的customer number字段等于p中的customer number字段
由于那个别名，这意味着payments表中的customer number
所以内连接只会给我返回那些在那里有匹配的记录
在customers表和payments表中有customer number共同的记录
在那些确实有customer number共同的记录中
我会选择customer name
支付日期和金额
这就是那些结果的一个例子
再次使用默认的连接类型
如果你只说连接，它将只给你那个交集的结果
在那些表中，你连接的条件存在
我们也可以做所谓的左外连接
在这种情况下，我们将得到表a中的所有结果
无论它是否在表b中有匹配的标识符
在这个例子中，同样的事情，除了说左连接
在这个查询中唯一的区别
但现在你可以看到，我们有一些null的结果，对吧
所以对于美国纪念品公司和港口进口公司
无论它是什么 我们在支付日期和金额上有null
因为显然在支付表中没有匹配的客户号
对于客户表中的那个客户号
所以无论那个左表是什么
我们将从该表中获取所有内容
无论它是否有匹配
如果它在右表中没有匹配
我们将得到一个null结果
我们试图从那个右表中选择内容
我们也可以做一个右外连接
同样的想法，但我们将获取右表中的所有内容
无论它是否匹配
但不获取左表中的所有内容
这里语法相同
我们说右连接
这意味着
你知道的 无论我们放在右边的表将获取所有内容
无论它是否在左边有匹配
但不一定获取左边所有内容，即使没有在右边匹配
你也可以做一个全外连接
这将给你表a和表b的所有结果
无论它是否匹配
如果有匹配 你将得到那个连接语句的结果
如果没有，你将得到null结果，对吧
这通常用于调试和故障排除
如果你想获得一个好的匹配数据的图片
如果你没有匹配的键，这两个表
这可能是一个寻找它的好方法
并看看为什么你有些id在两个表中不匹配
最后我们可以有一个交叉外连接
我想不出为什么要这样做
一个交叉外连接将给你两个表所有组合的结果
a和b 对于每个行和列a
我将给你a和b所有组合的结果
你可以想象
这会爆炸得非常快
非常非常快
所以没有很多理由这样做
但为了完整性
这就是交叉外连接所做的，它给你a和b所有组合的结果
无论它是否匹配
并且为了完整性
这就是语法看起来的样子
交叉连接是这种语法，再次
这将给你带来许多 许多结果 因为它正在给你所有可能的客户和摊位的组合
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/018_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p18 15. SQL Regular Expressions (a quick intro).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我想花几分钟谈谈正则表达式
正则表达式和序列可能是一门课程的主题
所以我只会给你们一些基础知识
但总体而言，正则表达式只是一种模式匹配语言
它是在字符串中搜索模式的一种方式
以及在数据库列中
例如，字符串中的一个子字符串
或者你可能正在寻找某种模式
这可能用于从更长的字符串中解析信息
例如 日志文件中的文本
你可以把它想象成一个比 like 操作符更强大的工具
进行模糊搜索，而不是对列做精确匹配
但你想做的更复杂和强大
tilde 通常作为正则表达式操作符
如果你说 where tilde
这意味着你将对正则表达式进行匹配
而不是字符串
但 tilde star 意味着你将做同样的事情 但它将不区分大小写
如果你想做敏感搜索
你可以使用 tilde
而 tilde star 则是不区分大小写的
ube tilde star 和 bang 操作符
感叹号感叹号点
为什么这么难说
当然意味着不
所以 例如
感叹号 tilde star 意味着在不区分大小写的方式下
不匹配以下表达式
让我们看一些例子
这是真正的基本正则表达式语法
你可能不会在考试中期望知道更多
但这里有很多深度
如果你想深入研究正则表达式
反斜杠符号意味着你正在匹配模式的开头
而美元符号意味着你正在匹配模式的结尾
例如 如果你的正则表达式是 a boo
美元符号将匹配单词 boo
因为 boo 的单词结尾匹配 boo
但它不会匹配单词 book
因为 book 的结尾是 k
而我想要匹配的是结尾
然而 反斜杠 boo 将匹配两者
因为 boo 是 book 和 boo 的开头
boo 和 book 因此，正则表达式反斜杠 boo 将匹配 boo 和 book
boo美元符号 然而，只有匹配boo
因为这意味着我正在匹配字符串的末尾
此外，如果您想要匹配多个东西
如果您想要实现某种或操作
这就是管道操作符的作用
这将给您提供一个您正在搜索的字符集的替代字符集
所以 例如
sit管道set将匹配您正在搜索的字符串中的sit或set
你正在搜索的列
你也可以做字符的范围，所以在方括号内
如果我说从a到z
小写这将匹配从a到z之间的任何小写字母
你可以用许多范围组合起来
所以我可以说从a到z和大写字母
从a到z和零到九
例如 如果我想匹配所有数字和字母，向上
我们的小写字母，这本身并不特别有用
如果我想要匹配 说一个四字母的小写单词
你可以使用大括号操作符来表示你想要匹配多少个
所以方括号a到z
然后大括号4意味着我想要匹配任何四字母的小写单词
单词由小写字母组成
在a和c之间 明白了吧
最后还有一些特殊的元字符你可能想要知道
反斜杠d将匹配任何数字
反斜杠 w 匹配任何字母、数字或下划线
反斜杠 s 匹配任何空白字符
例如空格或制表符
反斜杠 t 专门匹配制表符
这些都是一些方便的快捷方式，用于你的常规表达式
而不是说 uh
方括号 0 - 9
我可以说反斜杠 d 匹配任何数字
例如
这里有一个具体的例子，说明这如何实际应用于实际的 SQL 查询
假设我想查找所有以fire或ice开头的行
我不知道 也许这些是神话元素的名字或者类似的东西
这种语法可能是选择所有列
从表的名称开始，名字以星号结束
然后在单引号中输入表达式本身
然后是胡萝卜 然后在括号中输入fire和ice
让我们分解一下 所以关注where子句，名字以星号结束
这意味着它是一个不区分大小写的正则表达式匹配引号
然后包含正则表达式本身
而反斜杠再次意味着它需要匹配字符串的开头
所以每行名称列中找到的字符串需要以fire或ice开头
正确 这就是竖线所表示的意思，要么
或者正确 这就是全部
就是这么简单 所以请记住一些正则表达式的基本知识
它的语法看起来像什么
希望您在看到波浪线和反斜杠以及SQL命令中的其它符号时不会感到困惑 等等
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/019_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p19 17. Git review architecture and commands.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


令人惊讶的是
考试指南提到git是你需要了解的东西
git是 当然，这是一个近年来非常流行的版本控制系统
它已经相当普及了，所以
我不会在这里给你深入浅出的基础教程
如果你以前从未使用过它
那么你可能想找个地方找一整个课程
那里有很多很好的课程 那里还有很多很好的课程
这只是为了快速回顾考试可能期望你知道的东西
从架构上讲
这是对git工作方式的一个小提醒
这样我们就可以有远程仓库和本地仓库了
远程仓库可能在github上
例如 这是服务器上的东西
在某个本地位置
虽然我想开发某些文件，你知道的
做一些开发者的事情，对吗
所以我可以使用git
通过拉取来将东西下载到本地仓库中，到我的工作集
我可能会使用克隆来实际创建一个副本
我可能会使用分支来实际创建专注于特定新功能的分支
我可能在开发
或者我正在尝试修复的特定bug
这意味着我可以独立地工作在这些修复上，与其他人分开
整个想法是允许多个开发者同时一起工作
尽可能少的干扰彼此
没有干扰彼此
当我对我的更改感到满意时
如果我想添加一个文件
我可以使用添加命令将其放入我的暂存区
然后将其提交到我的分支中
然后将其推送到远程仓库
当我准备好时
我也可以将其他分支的内容合并到我的工作文件中
如果我想与我的主分支保持同步
或者类似的操作
所以让我们来学习一些常见的Git命令，你可能会被问到
我们来做个简单的点名，看看都有谁
他们都在为创建仓库而努力
你可以用git init来初始化一个新的仓库
如果我想设置用户名和邮箱等信息
Git config是处理这些的命令
一些你经常使用的基本命令
Git clone会克隆或下载一个仓库从一个给定的URL 如果你想将一个远程仓库克隆到本地
Git clone是你要做的第一件事
这是开始工作的第一步
获取状态是一种检查方式
嗯 你到目前为止在工作目录中所做的更改
所以如果你想知道你改变了什么
并提醒自己你做了什么
那是其中的一种方式
Git add 是将更改添加到暂存区的方式
你也可以说
Git add 星号是一种通配符，将所有更改添加到暂存区
一旦你准备好提交这些更改
你可以说 git commit -m 加上你的消息的
Git log 会查看之前的提交日志
分支又是并行工作的一种方式
这里的想法是你可能有一个用于开发特定功能的分支
或者你正在尝试修复的某个错误
无论它是什么
如果我想查看本地所有分支的列表
以便我可以在其中切换 git branch
将列出它们所有 如果我想创建一个新的分支
我可以只是说 git branch
并给该分支起一个名字
Git checkout 会将你切换到给定的分支
就是你想工作的分支
具体来说
-b 可以用于同时创建并切换到一个新分支
如果你想合并一个分支到当前分支 git merge 就是这样做的
如果我想获取其他分支的更改
比如主分支 并确保这些更改被集成到我正在工作的内容中
嗯 Git merge 可以做到这一点 git branch -d 用于删除你已经完成的分支
在与远程仓库工作时
你可以说 git remote add name
然后加上仓库的URL
这将添加一个远程仓库
在某个地方
Git remote 会列出你所有正在工作的远程仓库
Git push 可以将你的本地分支推送到远程仓库
一旦你完成了所有本地更改的提交
你可能想把这些更改推送到远程仓库
以便其他人也能获取这些更改
Git pull 另一方面
用于从远程仓库分支获取更改到你当前的本地分支
无论那是什么
如果你需要撤销某些操作
Git reset 会将你的暂存区重置为最近的提交
不会影响到你的工作目录
你也可以添加减号
在栈区重置时添加减号硬减
并将工作目录与最新提交相匹配
Git revert 用来撤销一个先前提交的所有更改
如果你改变主意了
你造成了一些错误，并没有意识到
最后 嗯，好吧
不是最后 但我们正在
我们正在接近 一些高级命令
get stash 用来暂时存储一个更改
你还没有准备好提交
但更改 所以，我常常发现我自己在使用这个
如果你发现一些临时文件被错误地拾取，不想提交
你可以使用 stash 来暂时隐藏它
在提交时
git stash pop 可以用来恢复你之前存储的更改
所以，假设我想存储一些临时文件
并在提交后恢复它
我可以存储它
然后恢复它
当我完成提交时
git rebase 用来重新应用更改从一个分支到另一个分支
这是用来将一个分支的更改集成到另一个分支
有时，如果你想要切换分支，可以使用 cherry pick
我从来没有使用过那个
但那是用来从一个特定提交应用到当前分支的更改
你也可以使用 git blame
查看一个文件所有更改的历史
如果你想知道为什么更改以及谁更改的，可以使用它
git diff 可以用来查看提交之间的更改
以便你知道你正在提交什么
首先 fetch 用来从远程仓库获取更改而不合并
维护和数据恢复，让我们结束这个话题
我真的怀疑考试不会问你这个问题
但为了完整性
git fsoc 用来修复仓库中的文件系统错误
基本上
git gc 清理和优化本地仓库
垃圾回收
git ref log 会记录本地仓库中 rest 的更新
如果你需要恢复一个丢失的提交，这可能是一个方法
这就是 git 一个非常非常简短的概述
如果你需要更深入的了解
有关于 git 的课程
有很多 但这些应该只是对基础知识的复习，你可能需要它们来参加考试
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/020_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p20 01. Intro Storage.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


如果你要处理大量数据
你需要一个存储的地方
所有 这就是接下来的部分要讲的内容，存储技术
AWS提供了我们
我们现在正在转换方向
从数据工程的高级主题深入到AWS服务的长名单中
这个考试希望你了解并开始
是我的同事
Stefan marek
他将一步一步向你展示S3的所有细节，通过大量的实践操作
他会用很多实用的例子向你展示S3的多种功能，这些功能对于数据工程来说非常有用
他还会提到亚马逊EBS
亚马逊FS和亚马逊备份作为这部分内容的一部分
在最后 我们有一些测验问题来测试你的知识
关于课程中即将到来的测验的一个快速说明
它们旨在与实际考试中的问题是相似的
AWS认证考试通常在特定的场景或现实世界中的问题中提出问题
你可能会遇到
你必须选择最佳解决方案
有时候一个以上的解决方案实际上会起作用
但你必须注意哪一个最好地满足了问题本身明确列出的要求
你被提供的一些选择可能没有意义
它们可能涵盖我们甚至没有讨论过的技术
或者可能根本不存在
但就像在真正的考试中一样
你将不得不使用排除法来排除选择
当你确定了一个符合要求的选择
问题明确指定
我们已经提供了详细的解释，说明为什么每个答案是正确的或错误的
尽管 这样你就可以从这些问题中学习
无论这些并不是典型的快速测验
它们旨在让你 思考
因为考试会
也 现在，就让我将它交给斯蒂芬 以及你需要了解的AWS存储系统
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/021_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p21 02. Set up an AWS Billing Alarm.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


如果你选择跟随本课程中的实际操作活动
你可能想设置一个计费警报
只是为了确保你没有无意中留下正在运行的东西
这可能会花费你钱
如果你只按照这里的指示进行操作并清理现场
就像我们向你展示的那样 完成本课程不应该花费你超过几美元
但无意中留下正在运行的东西太容易了
最终会在aws账单上给你一个巨大的不愉快惊喜
所以，去你的控制台是一个很好的主意
一旦您创建了AWS账户
搜索账单
让我们设置一个警报
这样我们就可以收到通知
如果我们的开支开始超过舒适阈值
从这里开始 向下滚动到预算和规划，然后选择预算
并创建一个新的预算
如果您不熟悉任何支出，请使用模板
如果您不熟悉任何支出
你可以选择零花费预算
但是，你又不会免费完成这门课程
如果你真的不想花费任何费用
那么你应该只看那些活动的视频
而不是亲自动手跟着做
但如果你有一个月想要坚持的预算
你可以选择每月成本预算
输入你愿意花费的金额
比如20美元，并指定一个你想要在超支时收到通知的邮箱地址
如果你这个月超过了那个金额
所以通过设置这个
如果我在月内从aws产生的费用超过20美元
我会收到一封邮件 所以我可以去看看
我忘记关闭什么并且尝试修复
在产生更大的费用之前
完成后点击创建预算
然后你会自动收到通知
如果你有任何未关闭的资源可能会产生账单
这不是一个好主意
只是为了保护自己，保护自己
因为很容易忘记
关闭某物并让昂贵的资源在整个月内运行
你不想那样发生
所以花点时间保护自己，在这里设置计费警报，就这样 让我们继续前进
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/022_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p22 03. Amazon S3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


欢迎来到关于亚马逊S3的部分
这部分非常重要
因为亚马逊S3是AWS的主要构建块之一
它被宣传的方式
是无限扩展的存储
实际上
许多网站依赖于亚马逊S3
例如 许多网站使用亚马逊S3作为骨干
许多AWS服务也会使用亚马逊S3进行集成
所以亚马逊S3有很多用例
因为它的核心是存储，所以主要用于备份和存储
它可以是你的文件
它可以是你的磁盘
等等，用于灾难恢复目的
例如 你将你的数据移动到另一个区域，以防某个区域崩溃
那么你的数据在某个地方得到了备份
这是为了归档目的
所以你可以在亚马逊的s3中存档文件，并在稍后阶段检索它
这对于混合云存储要便宜得多
所以，如果你有本地存储
但你不会扩展到云中
你可以使用亚马逊免费存储应用程序
托管媒体
例如视频文件
图片等等
创建一个数据湖
存储大量数据
为了进行大数据分析以提供软件更新
用于托管静态网站
依此类推 并且两个用例是纳斯达克将七年的数据存储到
S三冰川服务
这与亚马逊的档案服务类似
S三个数据在运行分析
并从亚马逊的S3中获得商业洞察
所以亚马逊的三个商店
文件放入桶中，而桶可以被视为顶级目录
实际上，这些s three桶中的文件被称为对象
这些桶在你账户中创建
它们必须有一个全球唯一的名称
这意味着名称必须在你账户中所有地区的名称中唯一
但也必须存在于aws中所有账户中
好的 所以这是aws中唯一必须全球的唯一的东西
桶在地区级别定义
即使桶的名称在所有地区所有账户中唯一
桶必须在特定的aws地区定义，所以s three看起来像一个全球服务
但是这些桶实际上是在一个区域创建的
这是初学者常见的错误
S3桶有命名约定
你可能不记得 但了解总是好的
因此，桶名不能有大写字母
不能有下划线
长度必须在3到63个字符之间
不能是IP地址
必须以小写字母或小写数字开头
然后有一些前缀限制
只要你使用字母、数字和破折号
你就可以了
好的 所以现在让我们谈谈对象
这些对象是文件
它们有一个被称为键的东西
亚马逊S3对象的键是文件的完整路径
如果你看我的桶
这是顶级目录
然后，我的文本文件的密钥是我的文件点txt
但如果你想把它放在我们称为文件夹中
那么密钥将是完整的路径
所以，我的文件夹一斜杠
另一个文件夹
斜杠我的文件点txt
因此，密钥由前缀和物体名称组成
所以我们可以
例如 将之前的路径分解为前缀
这是我的文件夹吗
一个文件夹和另一个文件夹
物体的名称
这是我的文件.txt
亚马逊行业本身并没有目录的概念
尽管当你查看控制台时
用户界面 你会有不同的看法
你会实际上创建目录
但在亚马逊S3中，一切都是键，键实际上就是
非常长的名称包含斜杠和键是由前缀和对象名称组成的
好的 所以对象
那么它们是什么
值是身体的内容
所以你可以上传一个文件
你可以将任何你想要的内容上传到亚马逊
所以最大对象大小为五太字节
所以这为五千千字节
如果你上传一个非常大的文件
如果这个文件大于5GB
那么大文件
好的 那么你必须使用多部分上传将该文件上传到多个部分
如果你有一个5TB的文件
那么你必须上传至少1000个5GB的部分
现在，对象也可以有元数据
它们的键值对列表
这可能由系统或用户设置，以指示有关文件的一些元素
一些元数据
它们的标签 例如
它们的唯一key和value对至10
它们对安全和生命周期非常有用
有时对象会有一个版本ID
如果你启用了版本控制
这就是对亚马逊S3的介绍
我相信你对这是如何工作的感到好奇 所以让我们在控制台开始
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/023_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p23 04. Amazon S3 - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以我现在在亚马逊的s3中
我要去创建一个桶
你会注意到这里已经选择了区域
是欧洲的伦敦区域
这是因为我在这里选择了区域
所以选择你想要创建桶的区域
我们会看到亚马逊是免费的
你可以看到所有桶的概览，横跨所有区域
这里有一个桶类型，你可能看不到
如果你在某些区域中可以看到，
你会看到通用目的或目录新
随着时间的推移
嗯 它将在更多区域中可用
如果你在你的区域中看不到它
这没关系 你应该选择的选项
如果你看到它是通用目的
如果你看不到这个选项
它将自动设置为通用目的
所以不要碰任何东西，不要感到惊讶
如果你看不到这些选项
目录桶是为一种特定的用例，考试中不会覆盖
所以我不会讨论它
所以如果你看到屏幕
选择通用目的 如果你看不到屏幕
一切都好
不要担心 好的
所以你选择了区域，接下来你需要选择一个桶的名称
如果你输入一个已经被占用的桶名，例如test
你尝试创建你的桶
你会得到一个错误
说这个桶名已经被占用
所以你的桶名在所有区域和aws的所有账户中都必须唯一
这就是我为什么用非常个人的东西来命名我的桶
例如可以是stefan
然后加上demo s three，我经常加一个版本号v5
因为我已经多次创建了这个视频，随着界面的变化
所以stefan buckets
stefan demo s three v5应该可用
我应该没有错误
但如果有人已经用了，
那我就需要改个名字
好的
接下来是对象所有权 现在默认是acl禁用
这是被推荐的
你可以看到所有桶的概览，横跨所有区域 这是一个安全设置
别担心
我们将其保留为默认设置
用于阻止公共访问这个存储桶
我们再次 我们将其保留为启用状态
所以我们将阻止所有公共访问
我们希望在我们的存储桶中具有最大的安全性
这样只有我们可以上传文件到它
用于存储桶版本控制
所以我们现在想要禁用桶版本控制
我们将稍后看到如何启用它
不需要标签
并且对于默认加密
我将使用亚马逊的服务器端加密，它是免费的
管理的密钥 所以所有我的对象都将被加密
然后我们会选择第一个选项
我们将在后续讨论加密和桶密钥
我将启用它
所以你可以看到，所有设置都默认
我们唯一设置的是桶的名称
所以我将创建一个桶
现在已成功创建
你现在会在这个UI中看到
你所有的桶 如果你启用了目录
你也会看到目录桶，目前我没有
但你的通用目的桶在这里
你应该看到一个桶 如果你刚刚创建了这个课程，你有三个三
因为我一直在使用我的账户
这将显示所有aus地区的桶
不仅仅是你现在所在的一个
但你可以看到所有地区
我有爱尔兰伦敦
我滚动并获取us east
一法兰克福等等
所以你所有的桶都将在这里显示
你可以做一个小搜索
例如Stefan演示
这是我的桶
所以我要点击它并查看里面的内容
现在我的桶里我想开始上传对象
因为目前你没有任何对象
让我们点击上传
然后我们可以添加文件并导航到你的代码
进入S3文件夹
然后你会发现一个咖啡
JPEG文件 所以选择这款咖啡
那是jpeg文件 如你所见
这是一个图像 jpeg
它有100KB的大小
然后目的地是s3 stefan demo
那是我的桶
好的 那么让我们上传这个文件
我们完成了所以我可以关闭右边的
现在我回到我的s3桶
我可以看到咖啡
jpeg文件在我的对象下
所以我可以做的是现在点击它并获取更多关于该文件的详细信息
现在我们在这个对象页面上
我们可以查看一堆概览
一堆属性，它是如何上传的
大小类型
这里有一个对象URL，我们将稍后使用它
那么我们怎么做
现在我们想要打开这个对象并看看是否能打开它
我们可以查看它因为我们已经将其上传到了亚马逊免费桶
所以我要点击打开
如果我点击打开
如你所见，我可以看到我的咖啡
jpeg文件 这是我上传的
它在互联网上，太棒了，对吧
但如果我回到概览并点击这个对象
你在这里 所以我复制它
我粘贴它，正如你所见
我获得拒绝访问
并且这个访问被拒绝
它告诉我我不能使用公开的方式访问对象
所以正如你所见
公共URL 所以正如你所见
这个公共URL不起作用
但是这个是的URL起作用
所以有什么区别呢
这个URL这里 如果你看看它
开头是完全相同的
但剩下的是一个非常复杂且冗长的URL
因为它叫做s3预签名URL
为什么，因为它的URL实际上包含了一个签名，验证了我就是请求者
并且因此它包含了我的凭据
因此因为我的凭据编码在这个URL中
是的，URL 然后亚马逊S3说
当斯泰凡被允许查看自己的物体时
因此我将显示它
因此这个公共URL不起作用
但是，我的凭据的预签名URL起作用
当然，这个URL只对我有效
所以我们将看看如何使该物体公开
以便公共URL也能工作
因此让我们回到我们的桶
斯泰凡的S3
我有一个物体
但我可以创建一个文件夹，文件夹名为图像
因此我们滚动并创建此文件夹
因此现在我在我的桶中有图像文件夹
我可以点击它，并在其中再次上传文件
这次我将将海滩JPEG文件上传到
如您所见 目标为我S3桶中的图像文件夹
让我们上传此关闭
如您所见 现在我们有海滩
JPEG物体在图像文件夹中
如果我向上一级移动
我们可以看到文件夹在这里
这看起来就像
你知道你曾经知道的云存储服务
例如Google Drive或Dropbox或任何你想要这里
在亚马逊S3中，我们具有非常相似的用户体验
当然，我可以去图像
我可以删除整个文件夹
这将删除文件夹中的所有内容，为了删除东西
我只是输入永久
删除到文本输入中
删除我的物体
我将去
这就是本讲座的全部内容
我们看到如何将物体上传到亚马逊S3
我们看到我们如何以两种不同的方式打开它们
创建文件夹
删除文件夹等等
我希望你喜欢它 我将在下一个讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/024_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p24 05. Amazon S3 Security - Bucket Policy.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈亚马逊S3的安全性
第一部分是用户基础
作为用户 你可以有策略
你和这个策略将授权特定的IAM用户哪些API调用应该被允许
你也可以有基于资源的安全
所以这是新的
我们可以使用称为S3桶策略的东西
并且您可以直接从S3控制台分配桶规则
这将允许
例如，允许特定用户访问
或允许来自另一个账户的用户访问
这被称为跨账户访问您的s 3桶
这也是我们如何使s 3桶公开的方式
正如我会在几分钟内向你展示的那样，您有对象访问控制列表或acl
他们的更精细的安全性
并且可以禁用
如果您需要到桶级别
您可以拥有桶 acl
这要少得多
也可以禁用
目前保护亚马逊s三号的最常见方式
是使用桶策略
那么i在原则上可以访问s三号对象在什么情况下呢
如果i am权限允许
或者资源策略允许
并且没有明确的拒绝操作
那么i在原则上可以在指定的api调用中访问s三号对象
所以我们将在一分钟内看这些用例
最后，另一种在亚马逊S3上实现安全的方式
是使用加密密钥对对象进行加密
所以S3桶策略实际上看起来是什么样的
因为这是我们关注的S3安全的焦点
所以它们是基于JSON的策略
它们看起来像这样
所以这是一个JSON文档
而且很容易阅读
首先，你有一个资源块
资源告诉策略
这个策略适用于哪些桶和对象
在这里我们可以看到，这个策略适用于example桶中的每个对象
这就是星号的作用
我们有效果，允许或拒绝
那么我们允许或拒绝什么
我们拒绝操作
所以我们有一组api
我们可以选择允许或拒绝
在这个例子中，我们允许的操作是获取对象
所以这允许任何人，多亏了主体
校长介绍账户
或用户应用到政策到原则是星
所以这里我们允许任何有星的人获取对象
或从我的示例桶中检索对象星
这意味着其中的任何对象
因此，这个s三个桶设置所有对象的公共读取
所以我们可以使用必要的桶策略来授予桶公共访问权限
如右图所示
或强制对象在上传时加密
或授予另一个账户访问权限
那么让我们看看当前的情况
这里有一个公共访问的桶策略
我们有一个用户
他在万维网上
他是一个网站访客
他想访问三个桶中的文件
我们将添加一个允许公共访问的S3桶策略
这就是你在前一个幻灯片中看到的策略
一旦这个桶策略被附加到桶中
那么我们就可以访问其中的任何对象
这就是我们在手机上看到的
但另一种方法是，如果您账户中有一个用户
这是一个IAM用户，如果这个用户想访问亚马逊
我们可以通过策略为该用户分配IAM权限
因此，由于策略允许访问S3桶
那么用户现在可以访问S3桶
如果我们有一个EC two实例
并且想要从EC two实例访问S3桶
我们已经看到IAM用户并不适合
我们使用的用户
我们需要使用我是规则
所以我们创建一个e c
两个实例角色具有正确的我是权限
并且这个e c 两个实例将能够访问亚马逊
S三号桶更先进的
如果我们想要允许跨账户访问
那么我们必须使用桶策略
所以我们有一个IAM用户在另一个AWS账户中
并且我们创建一个S3桶策略，允许该特定IAM用户进行跨账户访问
因此，用户将能够对我们的S3桶进行API调用
您需要了解的其他安全设置是存取控制设置
这是我们设置为开启的
当我们创建名为tes的桶时
这些设置是由AWS发明的，作为额外的安全层，以预防数据泄露
即使您设置了一个使桶公开的S3桶策略
如果这些设置已启用
桶将永远不会公开
这是为了防止数据泄露
如果您知道您的桶本不应该公开
然后保持这些设置不变
这样你就能获得足够的安全防护，以防止那些设置错误的S3存储桶策略的人
如果你知道你的S3存储桶永远不会公开
那么你可以在账户级别设置
好的 这就是关于安全的所有内容 现在我们进入实践环节
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/025_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p25 06. Amazon S3 Security - Bucket Policy - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们开始制定一个存储桶策略
以便我们可以从公共URL访问这个咖啡文件
为了做到这一点，让我们在权限选项卡下
首先我们需要做的是允许存储桶设置中的公共访问
因为目前所有内容都被阻止
我们编辑这个
我们将取消这个
因此我们将允许公共访问
但是再次，只有在您知道想要设置公共存储桶策略时
才会禁用此选项
这是危险的操作
所以我们说好
当然 如果您在S3存储桶中设置公司数据
并在其上设置公共访问
您将面临数据泄露 并且这永远不会是好事
所以现在在权限概述下
对象可以公开访问
这是第一步，接下来
我们滚动并查看存储桶策略
目前我们没有任何策略，我们希望创建一个
以便我们可以使整个存储桶公开
首先您可以查看策略示例
这是文档，它将在右侧显示许多用例
这将显示您应使用的适当存储桶策略
但对于我们，我们将使用策略生成器
这是AWS策略生成器
我们将创建一个S3存储桶策略
让我们选择正确的类型，我们将允许
然后主体将是星号
因为我们希望允许Amazon S3服务中的任何人执行
因为我们将读取存储桶中的物体
我们希望执行获取对象操作
这就是它，我们允许获取对象
Amazon资源名称必须是桶名加斜杠
然后加星号
让我们先看看 回到S3存储桶
我们有这个存储桶
Amazon资源名称在这里
我们复制它
我们粘贴到Amazon资源名称
但这还没有结束
我们添加一个斜杠
然后添加一个星号
我们这样做的原因是这个操作
获取对象操作在这里适用于存储桶中的物体
因此存储桶中的物体在斜杠后面
并且物体在斜杠后面
并且开始代表这些对象
让我们添加声明
然后生成这个策略
而这个策略就是我们复制到这里的
这是一个公共的s3策略
这意味着任何人都可以从这个桶中获取对象
好的 很好
让我们保存这些更改
这里有一个空格
让我们删除这个，完美
保存这些更改
现在起作用了 所以我们可以看到我们的桶策略已经正确应用
所以现在让我们进入我们的对象咖啡
这个jpeg
让我们找到这个对象的URL
就在这里 我们复制它并输入
正如你所看到的，现在我的咖啡图像完全可见
并且它也是公开的，以及其他任何在我亚马逊免费桶中的对象
这就是本讲座的内容
我们看到了 嗯
桶策略 我们看到了策略生成器
并且我们看到现在我们的图像是公开的
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/026_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p26 07. Amazon S3 - Versioning.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈在亚马逊S3中的文件版本控制
因为我们已经知道如何创建一个网站
但是有一个安全的方式来更新它将会很好
你可以在亚马逊S3中版本你的文件
这是一个需要在桶级别启用的设置
我们有我的桶
并且它启用了版本控制
所以每当用户上传一个文件
它将会创建一个文件的版本，选择在指定的键
如果我们再次上传相同的键
我们应该覆盖那个文件
那么它将会创建一个版本2，然后是版本3等等
因此，最好实践是穿越你的桶
为什么 首先，它会防止意外的删除
例如 如果你删除一个文件版本
实际上你只添加了一个删除标记
因此你可以恢复之前存在的版本
你也可以轻松地回滚到之前的版本
如果你想回到两天前发生的事情
你可以选择一个文件并回滚
这里有一些注意事项你需要知道
首先 在启用版本控制之前，任何未版本化的文件将会有一个版本null
并且如果你暂停版本控制
它不会删除之前的版本
这是一个安全的操作 好的 现在我们进入控制台，看看我们如何使用版本控制
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/027_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p27 08. Amazon S3 - Versioning - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来试试s三版本
首先我们需要进入属性
然后我们有一个桶版本设置
我们将编辑这个
我们将启用它
这将启用桶版本
因此我们覆盖的任何文件
现在只是添加版本到我们的桶
这很好 让我们进入我们的对象并说我们想要更新我们的网站
那么我们回去找网站URL
它就在这里
好的 我们有一个高爱咖啡
但如果我们说我们要写我真的很喜欢咖啡
因此让我们回到这里我们的文件
我将编辑它并说我真的很喜欢咖啡
我已经保存了
现在我再次上传此文件
所以我要添加一个文件
并且这将成为我的index.html
现在我们在那个文件中更新了内容
所以如果我上传它
成功了
所以现在它被覆盖了
如果我进入我的第一个网页并刷新
我得到了这个
我真的很喜欢咖啡
但是在后台发生了什么呢
如果我们在这里，这里有
这个开关显示版本
我们将展示文件中的实际版本ID
因此我们可以注意到几件事，第一
我们之前上传的文件
比如海滩的jpeg和咖啡
JPEG没有版本ID
那是因为它们在我们启用版本控制之前上传的
但是，这个文件是index.html
正如你所见，它有两个版本
一个版本号
这是我们在启用版本控制之前必须放在那个文件
但我们刚刚上传的文件有一个版本ID
因此，通过更新此文件并将其上传到我们的三个存储桶中
我们已经创建了一个新的版本ID
这就是在你启用这个开关时你可以看到的东西
所以现在 多亏了版本控制
我们可以做的事情是 我们可以实际上回滚我们的页面
所以我们有 我爱
我真的很喜欢咖啡 但我们想回到
我爱咖啡
那么我们该怎么做呢
我们点击这个特定的版本id
好的 确保显示版本已启用
然后我们将删除
在这里我们必须删除我们对象的特定版本id
因此当我们删除我们对象的特定版本时
这叫做永久删除
所以它是一个破坏性操作
它无法撤销
所以我们肯定在这个文本框中输入永久删除并点击删除对象
现在我们回去看看
我们可以看到我们的存储桶回到了之前的状态
因此如果我刷新这一页
我只会看到i love coffee
但如果我们禁用显示版本
现在我们只有有我们的对象
我将拿这个咖啡
这个jpeg文件 我将删除它
这次我们实际上没有删除底层版本id
我们通过添加一个删除标记来删除
因此它实际上没有删除底层对象
正如我们将看到的 所以让我们只是输入删除
这次它不是永久删除
这只是删除，我们删除了对象，完美
现在我们从桶内部看一下
看起来像咖啡
jpeg文件已完成
但如果我们点击显示版本
我们看到我们的咖啡上有一个删除标记
这个版本id的jpeg文件和真实的
之前的 至少咖啡
jpeg文件仍然在我们的桶中
但至少目前正在被覆盖
从版本角度来看
由删除标记覆盖
所以回到我们的网页
如果我刷新这一页
如果我强制刷新
通过执行命令shift r来强制刷新
那么我们看到图片无法加载
那么我们如何恢复这张图片
如果我只是尝试
例如 在新标签页中打开这张图片
它不起作用 我收到一个404未找到
所以为了恢复之前的对象
我可以点击这个删除标记
我将删除这个删除标记
所以我将永久删除这个删除标记
这样做的效果是它会恢复我对象的上一个版本
这是之前的版本
所以回到我的网页
如果我刷新现在可以看到咖啡
JPEG文件在那里
你可以玩版本控制
你可以添加你想要的文件版本
你可以开始删除它们并查看结果
但我希望你喜欢这个讲座 我将在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/028_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p28 09. Amazon S3 - Replication.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈亚马逊S3的复制功能
它有两种风味
所以CR是跨区域复制，而SRR是同区域复制
理念是我们在一个区域有一个S3桶
和一个目标S3桶在另一个区域
我们希望在这两个桶之间设置异步复制
为此
首先必须在源和目标桶中启用版本控制
如果我们做CR，即跨区域复制
这两个区域必须是不同的
如果我们做SRR
这两个区域是相同的
你可能在这两个AWS账户中有这些桶
复制是异步进行的
复制机制在后台幕后运行
为了使复制工作
你必须给S3服务适当的
权限，以便它有权从指定的桶读写
复制的使用场景是多样的
首先，如果你使用跨区域复制
这可以有助于合规或提供更低的延迟访问您的数据
因为它是另一个区域
或跨账户复制数据以进行SRR
所以同区域复制
这可以非常有助于聚合多个S3桶中的日志
或进行生产与测试账户之间的实时复制
所以你有自己的测试环境
好的
这就是关于复制的全部内容 下次讲座再见 我将进行一些练习
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/029_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p29 10. Amazon S3 - Replication - Notes.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


嘿 所以关于亚马逊S3的复制，有几个要点
所以，当你启用复制后
正如你所见 只有新对象才会被复制
如果你想复制现有对象
那么你需要使用S3批量复制功能
这将复制现有对象和已失败复制的对象
如果你有删除操作
你可以从源桶复制这些删除标记到目标桶
这是一项可选设置
但如果你有带有版本ID的删除操作
它们不会被复制
所以，如果你要进行永久删除
因为你想避免从一个桶到另一个桶发生恶意删除
最后，没有复制链
这意味着，如果桶一复制到桶二
然后，桶二复制到桶三
那么，桶一的对象不会复制到桶三
就是这样 希望你喜欢 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/030_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p30 11. Amazon S3 - Replication - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来练习在亚马逊s3上进行复制
为此我们将创建一个新的桶
名为s3 stefan桶
起源v2
我将其设置为我想要的一个区域
例如eu west one
这将是我的起源桶
然后数据将从这个桶复制到另一个桶
我需要做的事情当然就是启用版本控制
因为复制只有在版本控制启用时才起作用
所以我会创建这个桶
然后打开这个桶在新标签页中
这会创建一个第二个桶
而这个将是我的目标桶
所以我会进行s3 stefan桶复制
复制v2
这次区域可以是相同的
例如如果你想要进行同区域复制
或者完全不同的
例如，如果你想在美国
你可以做 嗯，美国东部1从欧洲复制到美国
好的 让我们向下滚动，让我们再次
启用目标桶用于运行的桶
我们准备好了
所以现在我们有我们的主桶和我们的次级桶
我将要做的是在源桶中
我将上传一个文件
所以我会添加一个我的沙滩的文件
例如 沙滩点jpeg
好的 这已经完成，我们可以关闭这个
所以现在这个有一个文件
但当然，这还没有被复制
因为我们还没有设置复制
所以让我们继续做这件事
源存储桶
我需要做的是进入管理
滚动向下 目前没有复制规则
让我们创建我们的第一个复制规则
我将其命名为演示复制规则
好的，完美
我们将其设置为源桶启用
我们将其保留不变
在规则范围内，我们将其应用于桶中的所有对象
现在设置目标
我们可以指定在这个账户或另一个账户中的桶
我们将选择这个账户中的桶
这个桶的名称是
我的目标桶
所以我需要实际输入名称
我们将使用这个桶
复制并粘贴
好的 如您所见
目标区域被识别为us east one
因此这是跨区域复制
好的
对于i am roll 我们需要为这创建一个新的角色
这里有选项
然后我们可以查看一些设置
但现在对我们来说并不重要
让我们保存
所以我们会收到一个提示
您是否想要复制现有对象
事实证明，当您启用复制时
它将只复制从您设置那一刻开始的对象
所以是新上传的对象
所以如果您想
从源桶复制到目标桶的先前对象
您可以使用称为s3批处理的东西
来做到这一点
您需要说
复制现有对象
但这与复制功能本身是分开的
所以我会说
不要复制现有对象
现在我们可以继续
让我们看看 我们有这个
嗯 管理有一个准备好的复制规则
现在我要做的是检查我的复制桶
当然 如果我刷新
现在我们看到对象还没有被复制
所以我要做的是 现在上传一个新文件
例如 上传咖啡的jpeg文件
上传
完成
这是咖啡的jpeg文件
展示版本
所以这就是咖啡的jpeg，版本号是g bk
好的 完美，现在
如果我们去我的目标桶并刷新这个
这将需要大约五秒钟
第一次复制时，这花了大约十秒钟
但我们可以看到我的咖啡
jpeg已经被添加到我的复制项中
如果我显示版本，
我们可以看到我的咖啡的版本id
这张jpeg与原始桶的完全相同
因此版本ID被复制
这很好
如果我想把海滩转换为jpeg
我需要上传该文件的新版本
让我们再次上传海滩的jpeg
现在已上传
我们可以查看版本 因此有新版本
就在这里的dk
我的两张海滩点jpeg文件
现在我在这里刷新
让我们再看一个重要的设置
这是考试中重要的
所以我回到管理并编辑这个规则
我们可以滚动并查看一个设置，称为删除标记复制
默认情况下，删除标记不会被复制
但也有一个功能可以做到这一点
所以如果你启用删除标记复制
那么它们将被复制
好的 从一个桶到另一个桶
所以让我们保存这个
所以我的复制规则已经保存
这意味着如果我进入这个桶并选择删除此文件
例如我删除我的咖啡
JPEG文件 让我们删除它
这将实际上创建一个删除标记
因为我的桶是带版本的
我们已经完成了
现在我的jpeg文件已经被删除，让我们在这里看看
让我们刷新一下，我们需要等一会儿
现在您可以看到删除标记已经复制到我的副本桶
如果我不显示版本
我看不到我的咖啡
jpeg文件 但是如果我显示版本
我会看到它 这里也是真的
当然这在这里也是正确的
所以删除标记将被删除
但如果你决定删除某个文件的特定版本
例如删除这个版本，这是一个删除版本
特定版本 ID
所以这叫永久删除
如果我在源桶中永久删除一个对象
它将不会复制到我的复制桶
所以这张jpeg永远不会被删除
因为只有删除标记才会被复制
不是删除
好的 这就是这节课的全部内容
希望你们喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/031_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p31 12. Amazon S3 - Storage Classes.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么我们来讨论一下亚马逊云存储的不同类别
首先，我们有亚马逊S3标准通用存储
然后我们有亚马逊云存储频繁访问
然后我们有亚马逊云存储一区频繁访问
然后我们有冰川即时检索
冰川灵活检索
冰川深度归档
然后是最后，Magens3智能分层
我们将深入了解这些类别在本课中
但你必须了解它们以便于考试
然后你在s三中创建对象时
你可以选择它的类
你也可以手动修改其存储类
或者正如我们将看到的
你可以使用亚马逊s三生命周期配置将对象自动移动到这些所有存储类之间
所以首先在我们深入到类之前
让我们定义耐久性和可用性的概念
所以耐久性代表亚马逊s三将丢失一个对象多少次
并且亚马逊具有非常高的耐久性
它被称为119
所以99分
然后99%的九倍
这意味着平均而言
如果你在亚马逊s3上存储一千万个对象
你可以期望每十万年丢失一个对象
所以它是非常耐用的，耐用性是亚马逊所有存储类别的相同
S3的可用性表示服务是多么容易获得
因此这取决于存储类别
例如 S三标准有99.9%
99%的可用性
这意味着大约5
3分钟一年中
服务将不可用
这意味着当你处理服务时，你会遇到一些错误
所以你在开发应用程序时需要考虑这一点
因此S三标准有99.9%
99.9%的可用性
将被用于频繁访问的数据
这就是你默认使用的存储类型
它具有低延迟和高吞吐量
它可以在aws方面承受两并发设施故障
它的用例将会很大
数据 分析
移动和游戏应用
以及内容分发
我们有s三不频繁访问
这就是说，这将是较少频繁访问的数据
但需要快速访问
它将比标准S成本更低
但你将支付检索成本
因此，S3标准A的成本是99.9%
可用性为99.9%
因此，可用性略低
其用例将是灾难恢复
备份在亚马逊是免费的
一个区域在访问中
一个区域具有高耐久性
好的 仅在一个AZ内
数据将丢失
如果AZ被破坏
以及耐久性
它更低 因此为99.5%
可用性为99.5%
因此，S3A1的用例是存储备份的次要副本
或者您在本地可以重建的数据
我们有冰川存储类
冰川是一个敌人非常冷
因此它是低成本的对象存储，用于存档和备份
定价是您将支付存储费用
加上检索费用
您在冰川中有三种存储类别
您有亚马逊S3冰川即时检索
这将给您毫秒级检索
这对于每季度访问一次的数据非常好 最低存储时间为90天
因此这是备份
但您需要在毫秒内访问它
然后我们有冰川灵活检索
它以前被称为亚马逊冰川
但当他们添加更多级别时，他们会改名
因此，亚马逊冰川灵活检索有三种灵活性
因此，您可以快速访问，1到5分钟
您可以在3到5小时内标准访问，或者批量访问
这是免费的，您将在5到12小时内获取数据
最低存储时间也是90天 因此，即时意味着您将立即获取数据，灵活意味着
您愿意等待，例如12小时获取数据
然后我们有冰川深度归档
这是用于长期存储的
我们有两个层次的re
我们有标准12小时和批量48小时
好的
所以你可能准备好等待很长时间来检索数据
但这将给你最低的成本
并且最低存储持续时间是一百八十天
所以你知道这是一个大量的存储类别
并且有一个最后的叫做s的智能分层
这将允许你根据使用模式将对象移动到不同的层
为此
你将承担一个小型的月度监控费用和自动分层费用
并且在s的智能分层中没有额外的费用
因此频繁访问是在这里是自动的
这里有默认的
然后我们有很少访问的层对于未访问的对象
例如三十天
然后你有存档即时访问层也是自动的对于未访问的对象超过九十天
然后有存档访问在这里是可选的
你可以从九十天到七加天进行配置
然后你有深度存档访问在这里也是可选的
你可以为未访问的对象进行配置从一百八十天到七百加天
好的
所以工程学实际上是允许你坐在后面放松 而as free mood为你移动对象
所以如果你比较所有的存储类别
你不需要记住这些数字
但这只是为了让你理解它们是什么
所以你得到十一个数据冗余的每个地方
然后能力下降到较少的层你拥有的
当然
嗯 它只是给你展示像
例如
最低存储持续时间 费用等等
所以花些时间自己看这个图表 你应该理解它
但你不应该记住它
所以如果我们看看一些定价
例如在美国东部
所以这是你在所有存储类别中会有的定价
再次你不应该记住一切
但这对你自己的时间看看它是好的
只是为了确保你理解
因为你应该能理解这些类别如果你理解了类别的名字
好的
这就是这节课的内容
我希望你喜欢它 我将在下节课见到你 这就是这节课的内容 我希望你喜欢它
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/032_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p32 13. Amazon S3 - Storage Classes - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们在三中创建一个新的桶并命名为s三存储类
演示2022
好的 然后我创建在任何地区
我将继续创建这个桶
所以回到我的桶
我可以继续上传对象并点击添加文件
我将选择我的咖啡jpeg并看看选项
我们可以查看该对象的属性
在存储类别下
我可以看到广泛的存储类别
这是为最佳对象设计的
所以我们有s三标准
好的，我们有设计为列
以及我们有多少个az
以及一些其他作为最小存储持续时间
最小计费对象大小和监控
和o二级存储费用 那么让我们看看所有这些
我们有标准 这是默认的基本
然后我们得到智能分级，如果我们不知道我们的数据模式
因此我们希望它为我们执行数据点分级
标准a如果我们想要数据不经常访问
但具有低延迟
一a您可以重新创建此数据
它将存储在一个az中
因此您可以运行列表
运行丢失对象的风险
如果az被摧毁
然后我们有冰川
所以有冰川瞬时检索 冰川灵活检索
或冰川深度归档
它们确切地告诉我们在这里的条件
最后注册在c
这是一个弃用类型的存储类
因此我没有在课程中描述它
那么如果我们选择标准，例如
并创建一个对象在那里
所以我们在那里 然后我们说上传
回到我们的桶
所以现在这个对象有存储类标准
正如这里所示
但我可以做的是如果我想改变存储类
我可以更改存储类别
所以我可以进入属性并滚动到下方
如果我想要的话
所以我可以进入属性并滚动到下方
我们可以实际上编辑存储类以做不同的事情
所以我们可以移动它
例如将其移动到一个区域
在这种情况下这个对象将仅存储在一个区域
让我们保存这些更改
现在我的对象已成功编辑
因此对象类已更改
所以我们向下滚动
我们现在在一个区域a中，再次
您可以编辑它并前往
例如前往冰川实例检索
现在它将被归档
或者您可以前往智能分层
它将被自动设置为正确的层
基于我们的模式等
因此您可以看到使用存储类有很多强大的功能
最后我不会向您展示如何
我们可以自动化这些对象在不同存储类之间的移动
所以让我们回到我们的桶
它们在管理下
您可以创建生命周期规则
您可以创建一个规则
我们将其称为demo规则
然后您会说嘿
应用于桶中的所有对象
是的当然
然后您可以说哦
在存储类之间移动当前版本
您会说嘿
您将去标准a之后
例如
三十天
然后您将去智能分层后六十天
然后您将去冰川灵活检索后一百八十天
等等 因此您会得到一些过渡
在这里您可以查看所有已执行的过渡
因此您可以自动化对象在不同层之间的移动
好的 就是这样
我们已经看到了所有需要了解的存储类信息
我希望您喜欢它 我将在下次讲座见到您
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/033_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p33 14. Amazon S3 - Lifecycle Rules.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈我们如何将对象在不同存储类别之间移动
你可以转换它们
这是它可能的图表
正如你所见，你可以从标准
例如到标准A
到智能分层到A
然后从WASA
正如你所见，你可以通过灵活检索或深度归档进行
因此，图中显示了所有不同类型的组合
事实上
如果你知道你的对象将被很少访问
那么将它们移动到标准A
如果你知道你将存档对象
将它们移动到冰川层或深度归档层
移动这些对象可以手动进行
当然 但我们可以使用生命周期规则来自动化这一点
因此，这些生命周期规则由多个部分组成
首先，转换操作用于配置对象以将其转换到另一个存储类别
例如 你说
在创建后60天移动到标准A类别
或移动到冰川进行存档
在6个月后
你也可以设置过期操作
因此，配置对象在一段时间后删除
例如 你的访问日志文件
你想在365天后删除它们
或者 例如
如果启用了版本控制，可以使用过期操作删除旧文件版本
或者我们可以使用这个删除不完整的多部分上传
如果 例如 多部分上传已超过2周
因为东西应该现在已经完全上传
规则也可以指定特定前缀
因此，它可以应用于整个桶或您桶中的特定路径
你还可以指定特定对象标签
因此，如果你想只为部门财务做规则，你可以
因此，这里有一些场景
例如 你有一个在E上的应
C 2 并且上传了亚马逊3上的个人资料照片后创建了图像缩略图
但这些缩略图可以从原始照片轻松重新创建
并且它们只需要保存60天
但源图像应该在60天内可以立即检索
用户可以在接下来的6小时内等待
你会如何设计这个呢
这是考试中你会遇到的问题
s3源图片可以存储在标准类别中
通过生命周期配置在60天后将它们转换为冰川
缩略图图片
这就是你如何使用前缀来区分源和缩略图
例如 缩略图可以存储在一个区域中
因为它们很少被访问
并且可以很容易地重新创建
你可以使用生命周期配置在60天后过期或删除它们
另一个场景
公司规定你应该能够在30天内立即恢复已删除的
s3对象
尽管这可能很少见，但在接下来的365天内
删除的对象应该在48小时内可恢复
为此 我们可以启用s3版本控制以保留和保存对象版本
这样删除的对象实际上被删除标记隐藏
然后可以恢复
然后你将创建一个规则将非当前版本的对象
过渡到标准iso这意味着不是顶级版本
然后过渡到这些非转换对象冰川深度归档以存档目的
莱斯利 我们如何确定
从一类转换为另一类对象的最佳天数
你可以这样做，感谢亚马逊s3分析
它将为你提供标准和标准a的建议
它不与a或冰川工作
因此s3桶
我们将在s3分析之上运行它
这将创建一个csv报告，它将给你一些建议和一些统计信息
报告将每天更新
然后可能需要2
4到48小时才开始看到数据分析
这是一个很好的第一步
csv报告以合理地制定生命周期规则或改进它们
好的 这就是这节课的内容 希望你喜欢 我将在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/034_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p34 15. Amazon S3 - Lifecycle Rules - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们开始为我们的桶创建一个生命周期规则
那么我们在管理下创建一个生命周期规则
这个将被称为演示规则
我们将其应用于桶中的所有对象
我承认
好的 正如你所看到的
我们有五种不同的操作规则
我们可以将对象当前版本之间的存储类别移动
非当前版本的对象
在特定类别之间移动 过期当前版本的永久
删除非转换对象
最后删除过期对象
删除标记或不完整的多部分上传
所以五种不同的使用案例
让我们一个接一个地看它们
所以将当前版本对象移动到存储类别
这意味着你有一个版本桶
当前版本最新版本是用户显示的版本
例如
我们可以在30天后过渡到标准 然后60天后我们可以进入智能
然后90天后我们可以进入说冰川以供即时检索
然后180天后灵活检索
然后也许365天后的归档
所以你可以有多少个过渡你想要多少个
好的
我们需要把这个带回来承认我们做了什么 我们也可以
例如 嗯移动非当前版本更快
所以这一个我们要移动一个非当前版本的对象
因此一个被一个新版本覆盖的对象
所以我们可以说
好的
这一个我们要移动它到冰川灵活 因为我们知道在90天后我们不需要它来检索
所以这完美了我们可以继续
但我们可以添加更多的过渡
例如我们希望过期当前版本的对象后
您可以在下面设置它后700天
同样对于非当前选项
我们希望在700天后永久删除它们
好的
所以这是我们可以做的 现在我们可以看看所有这些过渡和迁移操作
所以这很好
因为它显示了你当前版本和非当前版本的时间线 所以这很好因为它显示了你当前版本和非当前版本的时间线
当前版本的对象
如果我们对这一切都满意
我们可以继续创建这个角色
这个角色会在后台执行它应该执行的任务
就是这样了
你知道如何自动化在亚马逊S3中不同存储类别之间的对象移动
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/035_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p35 16. Amazon S3 - Event Notifications.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈S3的事件通知
想法是您的事件将在亚马逊S3中发生
什么是事件
嗯 事件是事物
例如，对象被创建或对象被删除
或者对象被恢复
或者有复制发生
您可以过滤这些事件
因此您可以说，我只想考虑以JPEG结尾的对象
因此事件通知的用例是
例如 自动响应在亚马逊s三中发生的某些事件
例如 您想要生成上传至亚马逊街的所有图像的缩略图
因此您将创建一个事件通知
然后您可以将其发送到几个目的地
它可以是s主题
它可以是sqs队列和一个lambda函数
不用担心 如果你到现在还不知道
那么我们将在接下来的讲座中学习这些特性
这样你就可以创建任意数量的s three事件
并且可以将它们发送到你想要的任何目标
所以，理念是这些事件通常会在几秒内发送到这些目的地
但有时可能需要一分钟或更长时间
为了使事件通知起作用
我们需要有在权限
所以s three服务将数据发送到s主题
例如
所以为了实现这一点
我们需要添加一个称为s资源访问策略的东西
这是一个你添加到s和s主题的策略
这将允许s3桶直接将消息发送到主题
同样地 如果我们使用sqs
我们需要创建一个sqs资源访问策略
授权s3服务将我们的数据发送到sqs
最后对于lambda函数
你猜到我们需要一个附加到lambda函数的lambda资源策略
确保亚马逊S3有权调用我们的函数
所以这里我们不使用
我的角色为亚马逊S3
相反，我们在主题上定义资源访问策略
在SNS Q或Lambda函数上
它们工作方式类似于我们使用S3存储桶策略时
所以你必须记住SNS、SQS和Lambda函数作为事件通知目标
但现在你需要学习第四个集成
因此，您的事件将进入您的亚马逊免费桶
所有事件最终都进入亚马逊Bridge
无论什么 所以所有这些
好的 然后从您还不了解的事件桥
但你可以设置规则
并从桥中
多亏了这些规则
可以将这些事件发送到超过18个不同的AWS服务作为目的地
这真的增强了S3事件通知的能力
再次，我们将在后续课程中看到事件桥
但通过事件桥，您将获得比之前更多的高级过滤选项
您可以根据元数据进行过滤
对象大小和名称
您可以同时将事件发送到多个目的地
例如 您可以说 两个工作流
您可以看到流或云火炬
或者您甚至获得直接从亚马逊桥提供的功能
您可以存档事件
重放事件 您将获得更可靠的交付
好的 这里没有
这节课中您还不了解的新服务有很多
但我们专注于亚马逊S3事件通知
ID是您可以对亚马逊S3中发生的事件做出反应
多亏了将其发送到SQS、Lambda或亚马逊桥 好的 就是这样 我将在下一节课见到您
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/036_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p36 17. Amazon S3 - Event Notifications - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么让我们开始演示s三个事件通知
为此我将创建一个存储桶
我称之为stefan v three事件通知
然后当ireland和我将一起创建我的存储桶
好的，我已经创建了存储桶
我将进入它
现在我将确保事件通知已设置
我进入属性并滚动
然后我们在这里有事件通知
如你所见，我们有两个选项
第一种是创建事件通知
我会在短时间内向你展示
或者第二种是启用亚马逊事件桥接
以将此存储桶的所有事件发送到事件桥接
为此只需将其设置为开启
这样你就可以正常工作了
所以现在如果我想这样做
我可以使用亚马逊事件桥接来捕获我的3个存储桶中的事件
但我会向你展示更简单的方法
因为它有点复杂
是创建事件通知并例如发送到sqs
我称之为演示事件通知
然后我们可以设置前缀
后缀 但我不会这样做
接下来我们需要选择事件类型
我们希望对所有对象
创建事件做出反应 这意味着每当创建一个对象
则会创建一个事件
但如果你想要 你可以选择你想要的事件类型
为了简单起见
我将在这里选择
你还可以包括
例如 对象删除
对象恢复 右侧显示了你可以捕捉的所有事件
我将保持简单
我将滚动下去
但你可以看到 在亚马逊s三中你可以对很多不同的事件做出反应
然后你想要发布到一个目的地
我们有三个选项
我们有lambda函数
主题和sqsq
我将选择sqsq
但我们首先需要创建一个队列
然后授权亚马逊免费发布消息到那个目的地
所以我现在要做的就是进入亚马逊
SQS然后创建一个队列
我称之为demo s三通知
我将继续创建这个队列
它已经创建了所以现在我需要做的是增强访问策略
以允许我的S3桶写入我的SQSQ
要做到这一点 让我先演示问题
所以我回去这里然后我刷新这一页
看看队列是否出现
我刷新它
我说demo s三事件
所有对象创建
然后滚动到底部
然后选择SQSQ
我可以选择队列在这里的下拉菜单中
对不起 我可以选择队列在这里的下拉菜单中
demo s三通知
如果我尝试保存我的更改
我会得到一个未知错误
他说你不能验证目的地配置
因为这个SQSQ还没有接受来自我的S3顶部的消息
我的S3桶
所以我需要通过点击编辑来更改访问策略
滚动到底部 这是我的访问策略
我需要去生成新的策略
我去到策略生成器将是一个SQS Q策略
效果是允许任何人非常宽容地发送消息
我的亚马逊资源名称在这里
我需要复制并粘贴它
我添加一个声明然后生成这个策略
所以现在我想要使用的策略
允许任何人向我的SQSQ写入
非常宽容
但是会起作用
保存这个
现在我的访问策略已经更新所以现在
如果我回去这里并尝试保存我的更改
你可以看到操作已成功完成
发生了什么
如果我进入我的SQSQ并点击发送和接收消息
然后点击拉取消息
你可以看到亚马逊S3发送了一条消息
这是测试测试事件
测试连接性
所以我可以做的是
我可以取这条消息并删除它
所以现在我们要测试sqs事件在s3事件通知是否工作
与sqs
因此我们将上传一个对象
点击添加文件并选择我们的咖啡点jpeg
我将现在上传此文件文件已上传
如果我进入我的桶
我可以确实看到我的咖啡jpeg已被创建
想象我们要自动化这并创建其缩略图
然后我们需要一个消息到我们的sqsq
然后处理并创建缩略图
因此我将拉取消息
如你所见，已创建了一条消息
如果你查看消息本身
我将尝试增大此窗口大小
我们可以看到事件名称是对象创建
放入所以对象被创建了吗
如果我们看更深入
我们将看到消息的键是咖啡点jpeg
所以咖啡jpeg被创建
并生成了我的sqs整个事件
因此显示了s3事件通知的力量
我在这里可以做的是 我可以删除消息，我们就完成了，好的
就是这样，我们看到 s3事件通知
你需要记住的是，你可以将消息发送到sqs和cs以及lambda
以及将所有事件发送到亚马逊桥进行进一步处理
并将其发送到更多目的地
好的 就是这样 我将在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/037_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p37 18. Amazon S3 - Performance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以我们必须讨论s三的基本性能
默认情况下
亚马逊s三会自动扩展到非常高的请求数量
并且具有非常低的延迟
从s三获取第一个字节的时间在100到200毫秒之间
这相当快
在每秒可以处理的请求数量方面
你可以每前缀每秒处理3500个put、copy、post、delete请求
或者每前缀每秒55000个
获取和头请求
所以这就是你可以在网站上找到的
但我认为它并不很清楚
所以我会解释给你听每秒每前缀是什么意思
但在rl中这意味着它具有非常高的性能
而且你的桶中前缀的数量没有限制
让我们以四个名为file的对象为例
让我们分析那个对象的前缀
第一个在你桶的文件夹中
一级子文件夹
一个文件
在这种情况下，前缀将是桶和文件之间的任何东西
因此，在这种情况下它是斜杠文件夹一
斜杠减一
这意味着对于在这个前缀中的这个文件
你现在可以每秒得到3500个put和5500个get
如果我们有一个名为“one”的文件夹，然后在其中创建一个名为“sub two”的文件夹
前缀在bucket和file之间
所以/文件夹一子文件夹二
因此我们也得到了3500个保护性期权和5500个购买性期权
对于那个前缀等等
所以如果我有一个和一
我们有不同的前缀
所以现在很容易理解什么是前缀
所以很容易理解三万五千个put和五个
每秒每前缀的五百次获取
这意味着如果你将读取均匀地分布在上述四个前缀上
均匀地 你可以实现每秒22000次请求以获取和读取
让我们谈谈s3的性能
我们如何优化它
第一个是多部分上传
因此，对于超过100MB的文件，建议使用多部分上传
对于超过5GB的文件，必须使用多部分上传
多部分上传会将上传并行化
这将帮助我们加速传输，以最大化带宽
所以，图示总是有意义的
所以我们有一个大文件，我们希望将其上传到亚马逊S3
我们将其分成部分
文件的小片段
这些片段将并行上传到亚马逊S3
在亚马逊是免费的
一旦所有部分都已上传到
它足够聪明，能够将它们重新组合回大文件
好的 现在非常重要的是，我们拥有S3传输加速
它适用于上传和下载
并且通过将文件传输到边缘位置来增加传输速度
这将会转发 然后将数据传输到目标区域的S3桶
所以边缘位置比区域多
今天有大约200个以上的边缘位置
并且正在增长，让我来向你展示在图表中这意味着什么
并且这种传输加速与多部分上传兼容
让我们看看
我们有一个在美国的文件
并且我们希望将其上传到在澳大利亚的免费桶中
因此这将做的事情是，我们将通过边缘位置上传该文件
在美国 这将非常快
并且非常快 然后我们将使用公共互联网
并从该边缘位置将文件传输到亚马逊免费桶在澳大利亚
边缘位置将通过快速的专用网络进行传输
这就是传输加速
因为我们最小化了通过公共互联网的数量
并且最大化了我们通过专用航空网络通过的数量
因此传输加速是加快传输速度的好方法
好的，现在获取文件的方式
如何以最有效的方式读取文件
我们有一个称为S3字节范围获取
并且它是通过获取您文件的特定字节范围来并行获取
因此它也在您获取特定字节范围时发生故障的情况下
然后您可以重试较小的字节范围
并且您在故障情况下具有更好的弹性
因此它可以用于这次加快下载
所以让我们假设我有一个文件在S3中
它非常大 这就是文件
也许您想要请求第一部分
这是文件的前几个字节
然后是第二部分
然后是第n部分
因此我们请求所有这些部分作为特定字节范围获取，这是范围
因为我们只请求文件的特定范围
并且所有这些请求都可以并行进行
因此，想法是我们可以并行化获取并加快下载
第二个用例是仅检索文件的一部分
例如 如果您知道在S3中的文件的前50个字节是一个标题
并且给您一些关于文件的信息
然后你就可以发出一个头文件请求
获取头文件请求的字节范围
使用第一个 比如前50个字节
你可以很快得到信息
好的 这就是s三性能的全部
我们看到如何加快上传
在基准性能中加快下载
确保你知道这些内容以准备考试 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/038_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p38 19. Amazon S3 - Encryption.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在让我们谈谈在亚马逊云服务平台上的对象加密
因此，您可以使用以下四种方法之一在S3桶中对象进行加密
第一个是服务器端加密（Server-Side Encryption，简称SSE）
你有多种口味的它
所以，你有ssc s三
这是使用亚马逊S3管理的密钥的服务器端加密
并且这是为您的桶和对象默认启用的
然后我们有ssc kms，我们在那里加密
这次使用KMS密钥来管理加密密钥
然后，我们有使用客户提供的密钥的sscc
所以这次我们提供自己的加密密钥，不用担心
我们将在下一张幻灯片中详细地看到这些。
所以这只是一个概述
然后我们有客户端加密
当我们想在客户端进行所有内容的加密
然后上传到亚马逊是免费的
所以在考试中
理解哪些适用于哪种情况是很重要的
那么，让我们深入探讨所有这些，并理解它们的具体细节
所以第一个是亚马逊的s3 for ssc的s3加密
所以这种情况下，加密使用了由aws处理的密钥
由aws管理和拥有
你从未接触过这个密钥
对象将由aws服务器端加密
加密的安全类型是aes two five six
因此你必须设置头为x和z
服务器端加密as two five six
请求亚马逊免费为你加密对象
使用ssc s three机制
现在ssc s three是默认启用的，适用于新桶和新对象
那么这是怎么工作的，我们亚马逊是免费的
和我们的用户
用户你
你将上传文件并带有正确的头部
然后它将成为亚马逊三和三的对象
它将与s三拥有的密钥配对
好的 因为我们使用ssc s三机制
然后我们将通过混合密钥和对象进行加密
这将存储在你的s三桶中
所以这是比较简单的ssc s三
然后我们有sskm
这次 而不是依赖由aws和ds免费服务拥有的密钥
您想使用kms服务自己管理自己的密钥
密钥管理服务
因此使用kms的优点是您对密钥有控制权
因此您可以在kms中自己创建密钥
您可以使用cloudtrail编辑密钥使用
因此每当有人在kms中使用密钥
这将是一个处理aws中发生的所有事情的服务
称为云追踪
因此，我们需要一个名为x-z服务器的标题
服务器端加密aws kms
然后对象将被加密
我所看到的一切
当然，服务器端
那么这是如何工作的？再次
我们上传对象这次有一个不同的标题
在标题中，我们实际上指定我们要使用的kms密钥
然后对象将出现在亚马逊s3中
这次 将使用的kms密钥将来自aws kms
这两者将结合在一起
然后你将得到加密
文件将最终出现在s3桶中
因此，现在从estuary buquette读取
你不仅需要访问对象本身
还需要访问用于加密此对象的底层kms密钥
因此，这是另一层安全
ssc kms有一些限制
因为，现在你从亚马逊s3上传和下载文件
你需要利用kms密钥，kms密钥有自己的api
例如 生成数据密钥
当你解密时 你将使用解密api
因此，你将向kms服务发出api调用
并且每个api调用都将计入kms
每秒api调用配额
根据区域
您拥有5000到30000个请求每秒
尽管他们可以通过服务配额控制台增加
因此，如果您有非常高的吞吐量
嗯，
s3桶并且所有使用kms密钥加密
您可能会进入一种限速使用案例
所以这就是考试可能会测试你的地方
我们有sse c类型的加密
这次密钥在外部管理aws
但它仍然服务器端加密
因为我们将密钥发送到aws
但亚马逊是免费的
永远不会存储您提供的加密密钥
它们将被丢弃
因此，因为我们将密钥发送到亚马逊s3
我们必须使用https
并且我们必须将密钥作为http标头传递
那么这是如何工作的
用户将上传文件以及密钥
但是用户在aws外部管理密钥
然后亚马逊就免费了
我们将使用客户提供的密钥和对象进行一些加密
然后将文件加密后放入s3桶中
当然，要读取该文件
用户必须再次提供用于加密该文件的密钥
最后我们有客户端加密
如果我们利用一些客户端库，这将更容易实现
例如客户端加密库
并且 客户端加密的想法是，客户必须自己加密数据
在将数据发送到亚马逊s3之前
你也可以从亚马逊s3中检索数据
然后在客户端外部进行数据的解密
因此，客户端完全管理密钥和加密周期
那么这是如何工作的
我们有一个文件
并且我们有一个在aws外部的客户端密钥
客户端本身将提供并执行加密
因此现在我们在该文件中有一个加密文件
可以发送到亚马逊s3进行上传
我们已经看到了对象加密的所有级别
但现在让我们谈谈传输加密
所以传输加密或飞行加密也称为ssl或tls
因此你的亚马逊s3桶有两个端点
http端点没有加密
和http端点有飞行加密
所以每当你访问一个网站并看到绿色锁或锁
通常这意味着它使用飞行加密
这意味着您与目标服务器之间的连接是安全的并且完全加密
因此当你使用亚马逊s3时
强烈建议使用https以安全传输数据
当然 如果你使用ssc c类型的机制
你必须使用https
现在这不是现实生活中需要担心的事情
因为嗯大多数客户将默认使用http端点
那么您如何强迫传输加密
我们可以使用桶策略
您可以将桶策略附加到s3桶
并附加此语句
这意味着您拒绝任何get object操作
如果条件是aws secure transport false
所以secure transport将在使用https时为真
在未使用加密且加密连接时不为真
因此任何尝试在您的桶中使用http的用户将被阻止
但使用https的用户可能允许
好的 这就是加密的全部内容
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/039_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p39 21. Amazon S3 - Encryption - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来练习加密
为此我将创建一个名为demo encryption的桶
Stefan v2并滚动下来
我们将保留此设置
我们将启用桶版本控制
然后在默认加密下
如我们所见 我们有三种不同的选择
但我们必须为我们的桶选择一个默认加密
所以我将现在查看ssc s3
稍后将查看ssc kms和d ssc kms
所以我们点击创建桶
现在我们已经创建了一个默认加密已打勾的桶
所以我们通过实际上传一个对象来验证这一点
我们需要添加一个文件
我们将添加一个咖啡的jpeg文件
然后我们点击上传
如您所见
我可以点击此文件并滚动下来
查找服务器端加密设置
确实该文件已用服务器端加密
使用亚马逊s3管理密钥
ssc s3
我们也可以为文件编辑加密机制
所以我可以点击编辑
如您所见如果我们编辑服务器端加密
这将创建一个新版本的对象带有更新的设置
因此这就是我为什么为我的桶启用了版本控制
是为了向您展示文件的一个新版本将被创建
让我们更改加密
为此我们将覆盖桶设置以更改默认加密
对于此文件 我们可以选择使用ssc kms或dsc kms
dcc kms
我不会花太多时间
这是对kms的两级加密
这只是更强的kms
我们将使用kms
它更简单而且不会让我们花钱
所以我们将使用ssc kms如我们所学
然后我们必须指定一个kms密钥
我们可以输入kms密钥arn
或者我们可以选择您自己的kms密钥
如果我们选择kms密钥
您应该只有一个密钥
可用的aws/s3密钥
它被称为s3服务的默认kms密钥
如果我们点击它
我们可以使用这个密钥
而且这不会花我们一分钱
因为这就是服务的默认密钥
如果你创建了自己的kms密钥
那么它就会出现在这列表中
但如果你自己创建
kms会每月收取一些费用
所以为了这次目的，我们就会使用默认的
地址 斜杠s3 kms密钥
好的 让我们
保存更改
我们关闭这个
现在我们转到版本
如我们所见 我们现在有两个文件的版本可用
所以当前版本
如果我们滚动并转到服务器端加密
如我们所见，它确实使用ssc kms加密
使用此加密密钥
它对应于默认
aws s3 kms密钥
好的 这真的很好，接下来
我们在这里做同样的过程
我们可以通过上传文件来完成
然后我们会添加一个文件
例如 海滩jpeg
在属性下我们会找到服务器端加密
在这里我们可以指定加密密钥
要么使用默认的加密机制
要么用ssc kms或dsc kms覆盖它
这就是一种做法
最后让我们看看默认加密属性
让我们滚动
我们会找到默认加密
编辑这个
在这里我们有选项
我们可以启用ssc s3 ssc kms作为默认加密
如果我们使用ssc kms
我们有桶密钥选项可供使用
这样可以减少API调用aws kms的成本
并且这是被默认启用的
如果我们只使用ssc s3
那么这个设置就不起作用
所以我们已经看到可以更改默认加密
你可能会问我
sec不见了
确实 它缺失了 因为sscc你只能在命令行界面做，而不是在控制台
这意味着你不能在这里启用sscc
嗯 你必须在客户端进行加密
然后将其上传到aws
然后在客户端解密
因此你不需要让aws知道
数据是客户端加密的
所以 因此你在控制台中唯一可以处理的选项是s c s three
Ssc kms和dsc kms
就是这样 我们已经看到了aws中的所有加密选项
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/040_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p40 22. Amazon S3 - Default Encryption.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以，关于默认加密与桶策略的简短讲座
因此，现在所有桶都默认使用ssc s三进行加密。
因此它会自动应用到新的对象，指向新的空桶
但你可以更改这个成为不同的默认加密
例如km
尽管如此 你也可以通过使用桶策略来拒绝任何API调用，从而强制加密。
为了将s添加到三个对象中而没有正确的加密头文件
因此，例如ssc
公里或秒速
所以这就是这种啊
但是但是桶策略你可以有在
例如这个说的是嘿
如果你做一个put object
但是你没有加密标头说aws kms
然后拒绝这个请求
或者嘿 如果你正在上传这个
但是客户侧算法没有
所以没有sscc
然后否认这个对象
所以这只是一个例子
但是至少 你可以看到这个桶策略
也可以强制一种方式在你的桶中实现加密
顺便说一下
桶策略总是要在你的默认加密设置之前被评估
这就是全部 只需记住默认加密是默认开启的，使用ssc s ray
但你可以更改它 你可以为它设置一个桶策略
提前为想要加密的文件启用强制加密
就是这样 希望你喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/041_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p41 23. Amazon S3 - Access Points.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在我们来谈谈s三个接入点
那么我们以一个有大量数据的桶为例
我们有财务数据
我们有销售数据
我们有不同的用户或组想要访问自己的数据
我们可以创建一个非常复杂的s免费桶策略并使其随着时间的推移增长
用户越多 你有越多的数据
就越难以管理
这可能会变得如此，那么解决方案是什么
嗯 我们可以创建一个称为s three access points的东西
这样我们就可以 例如
创建一个财务访问点，它将连接到财务数据
它是如何连接到财务数据的
嗯，我们将定义一个访问点策略
这个策略看起来就像一个s three存储桶策略
它将允许财务前缀读取和写入访问
然后我们可以定义并销售接入点
再次这将连接到销售数据
感谢一个接入点策略
一个不同的附加到该接入点
这将授予
对销售前缀的读写访问权限
如你所见，我现在有两个策略
如果我想要一个分析接入点，嗯
我们可以创建它，使它指向财务和销售
但在只读访问
所以我们要在分析访问点上创建我们自己的只读策略
所以你可以看到这里
我们已经将安全管理从s3存储桶策略移到了访问点
每个访问点都有自己的安全设置
因此，有了适当的权限
我们的用户就可以访问财务访问点，并只连接到我们桶的财务部分
销售用户也可以只访问单元格
分析团队可以同时访问财务和单元格
通过使用访问点
我们定义了访问我们桶的不同方式
并且结果是我们有一种非常简单的方式来管理安全
我们有每个访问点关联的政策
我们也有一个非常简单的亚马逊s3的桶策略
因此我们可以真正地扩展我们对桶的访问
总结一下访问点
简化s3桶的安全管理
每个访问点都会有自己的dns名称
这就是你连接到访问点的方式
你可以选择将其连接到互联网作为源
或vpc用于私有流量
然后你再次附加一个访问点策略
这与桶策略非常相似
这允许您按VPC来源对访问点进行安全管理
我们可以定义它们为私有访问
所以 例如 一个
E C实例在一个VPC访问中心中没有通过互联网
我们的S3桶通过VPC访问点
通过vpc起源
为了访问这个vpc起源，我们需要创建所谓的vpc端点来获取访问权限
我们需要创建一个vpc端点，以便我们能够私有地访问访问点
这是我们vpc的一部分，它将允许我们私有地连接到vpc起源
然后，vpc端点有一个策略
这个策略必须允许访问目标存储桶和访问点
vpc端点的策略将允许我们的EC two实例连接到vpc
存储桶 访问点
亚马逊S3上的点访问和S3桶
因此，在这种情况下，我们为安全设置了VPC端点
我们还在点访问策略和S3桶级别设置了安全
好的 这就是访问点的全部 希望你喜欢 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/042_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p42 24. Amazon S3 - Object Lambda.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


因此，S3访问点还有一个用途
被称为S3对象Lambda
所以，想法是你有一个S3桶
但你想修改对象在它被一个彩色应用程序检索之前
而不是
例如 复制我们的桶以拥有不同版本的每个对象
我们可以使用S3对象Lambda
为此我们需要我们刚才看到的S3访问点
那么它是如何工作的
假设我们有云并且我们有一个S3桶
所以电子商务应用程序可能拥有S3桶中的数据
因此它们能够直接访问S3桶
并放和获取原始对象
然后一个分析应用程序可能只想访问删减对象
这意味着从对象中删除了某些数据
而不是为了这个创建新的S3桶
我们可以创建一个S3访问点在我们的S3桶上
并且连接到一个Lambda函数
我们还没有深入研究Lambda
但是Lambda函数允许你在云中很容易地运行一些代码
因此这个Lambda函数将在对象被检索时删减它
并且在这个Lambda函数上我们创建一个S3对象Lambda访问点
这就是分析应用程序将访问S3桶的方式
总结一下，分析应用程序访问S3对象Lambda访问点
这将调用我们的Lambda函数
我们的Lambda函数将从S3桶中检索数据
并运行一些代码来删减数据
因此分析应用程序将从相同的S3桶中获得删减对象
电子商务应用程序
现在，一个营销应用程序可能想要访问一个增强的对象
并且他们有一个客户忠诚度数据库来增强数据
因此，而不是再次
创建一个新的S3桶并创建所有有所有数据增强的对象
我们可以再次使用Lambda函数
因此这将是另一段代码
并且这将通过查找客户忠诚度数据库来增强数据
因此我们也可以在这个上面创建一个对象Lambda访问点
因此我们的营销应用程序可以访问这个访问点
这个S3对象Lambda访问点以再次
获取增强对象 正如你所看到的
我们只需要一个S3桶
但我们可以创建访问点和对象Lambda来修改数据
正如我们所愿
因此，它的用例是拒绝
例如 PI数据
即个人身份信息用于分析或非生产环境
或者例如将数据从xml转换为json
或者执行任何你想要的转换
例如动态调整图像大小和水印
但水印特定于请求对象的用户
这就是s3对象lambda的一种酷炫用法
我希望你喜欢它 下次讲座再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/043_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p43 25. Amazon EBS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


欢迎来到这个部分，我们将探讨EC two的不同存储选项
EC two 两个实例
首先，最重要的将是EBS卷
所以让我们定义它们是什么，EBS卷代表弹性块存储
这是一个网络驱动器，您可以将其附加到正在运行的实例中
我们在使用它们，甚至不知道
因此，EBS卷允许我们在实例终止后持久化数据
这就是整个目的
我们可以重新创建实例并从之前挂载相同的EBS卷
我们将恢复对我们非常有帮助的数据
好的 当你创建一个EBS卷时
它会绑定到一个特定的可用区
这意味着你不能在一个可用区创建EBS卷，然后在另一个可用区挂载它
例如 在美国东部1a创建了一个EBS卷，你不能将其挂载到美国东部1b的实例上
我们会在几秒钟后的图表中看到这一点
那么，你对EBS卷怎么看呢？
你可以把它们看作是网络USB
棒 所以它是一个USB棒
你可以从一个电脑上取下它，并将其插入另一台电脑
但你实际上不需要物理地将其插入电脑
它是通过网络连接的
免费层给我们提供了30GB的免费EBS
存储，类型为通用目的或SSD或磁性每月
在本课程中，我们将使用这种类型的G P 2或G
P 3卷
让我们看看它 所以是空的
您的网络驱动程序
我说这不是一个物理驱动器
好的 为了实例和EBS卷之间的通信
它将使用网络
并且因为他们的网络被使用
可能会有从一台计算机到另一台服务器之间的一点延迟
现在 Ebs 卷
因为它们是网络驱动器
它们可以迅速从 EC two 实例中脱离并连接到另一个实例
并且可以很快地连接到另一个实例
这使得在需要故障切换时非常方便
例如 EBS 卷锁定在某个可用区
这意味着 正如我所说
如果它在每个可用区创建
它不能与这个连接
但在本节中，如果我们做快照，
然后我们能够将卷从一个不同的可用性区域移动到另一个
最后，它是一个卷，所以你必须在先进行容量规划
所以你需要在先进行规划你想要多少千兆字节
并且IOPS，每秒操作
O 每秒操作
你基本上定义了你想要你的EBS卷如何表现
你将为那个预留的容量付费
你可以随时增加容量
如果你想要更好的性能或更大的容量
所以作为一个图表
它看起来像什么
我们有一个a
我们有一个e C
两个实例 我们可以连接
例如 一个ebs卷到那个e
C 两个实例 如果我们再创建一个e
C 两个实例 正如我所说
一个ebs卷不能同时连接到两个实例
在ah认证云实践者级别
因此，我想说的是，这个其他e c
两个实例需要各自有自己的ebs卷附加到它上面
但我们有可能将两个ebs卷附加到一个实例上面
想象成两个网络USB闪存驱动器插入到一个机器中
这很有道理
现在ebs卷与可用区相关联
所以，正如我们所见，到目前为止，所有图表都使用us east one a
所以，如果你想在其他az有其他的ebs卷
那么你需要在其他区单独创建
区域，所以就像你的ec
两个实例绑定到一个az
所以EBS卷也是如此
最后，我们可以创建EBS卷并保持它们不附着
它们不需要必须附着到EC two实例上
可以按需附加到实例
这使得它非常强大
最后，当我们创建EBS卷时
通过EC two实例
有一种叫做删除终止属性的东西
这可能会在考试中出现
所以，如果你看到这一点，当我们在控制台中创建一个ebs卷时
当我们创建两个实例时
最后一列叫做删除在终止时
默认情况下，它被选中为根卷
并且未选中为新的ebs卷
因此，这控制了ebs的行为
当e C Two实例正在被终止时
所以，按默认设置 正如我们所见，根EBS卷在与实例一起终止时被删除
所以它被启用了
并且默认情况下，任何其他附加的卷不会被删除，因为它默认被禁用
但显然，正如我们在这个UI中看到的
我们可以控制是否要启用或禁用
终止时删除
因此，它的一个用例是
例如，如果您想保存根卷
当实例被终止时
例如，为了保存一些数据
然后你可以禁用
在根卷上删除在终止时
你将会准备好
这可能是考试场景在考试中
所以我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/044_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p44 26. Amazon EBS - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来看看我们实例附加的ebs卷
如果你点击一个实例
然后你在这里转到存储选项卡
你会发现有一个根设备和一个块设备
正如你所看到的，我们当前附加了一个1GB的卷到我们的EC two实例
所以我们可以看到我们有一个2实例 所以我可以做的是
我可以点击这个卷
这将我带到aws的卷界面
我们可以看到是的
确实，我们的数据量存在，并且已经使用
正如这里所示，它在使用中
并且它正在这里与实例相连
所以我们有一个不同的控制台，为了访问它
你可以在左侧点击卷
正如你所看到的，我们有一个8GB的EBS卷
我可以创建一个第二个卷
让我创建一个卷
我可以从多个选项中选择，包括gp2，gp3等
等等 但我将只使用gp2类型的存储
2千兆字节
然后对于可用区
我需要选择与我的e
C 2实例相同的一个
我将进入我的e
C 2实例在这里
我将找到它在哪个可用区
所以我往下滚动
它将在网络部分出现
我在网络部分往下滚动，这里可用性区域
它显示eu west one b
因此我将创建的卷将是eu west one b
因为ebs卷由特定的az绑定
这很好
我将完成并创建这个卷
现在我的卷已经创建了，我可以点击它
这个卷目前尚未附加
好的 所以它正在创建
让我来刷新一下，看看它是否已经创建
好的 它可用并且尚未附加
因此，由于它可用
我可以执行操作
然后我可以附加卷
我们需要找到一个实例
所以我们这里有一个正在运行的
所以我们要将这个卷附加到我的实例上
点击附加卷，搞定
我的实例现在有两个ebs卷附加在上面
我们怎么知道的呢
我可以刷新这一页
转到存储在我的EC two控制台
向下滚动，你可以看到现在块设备
我有两个块设备
我有一个8GB的
和一个2GB的实际上使用这个新的块设备
这更复杂，超出了本课程的范围
但你可以去格式化ebs卷
挂接e c two，你应该会发现是的
使亚马逊ebs卷在linux上可用
这给你如何做它的指示
但再次，这超出了本课程的范围
所以现在如果我进入我的区域并创建一个卷
我可以创建一个2gb的gp2卷
但这次az将是eu west one a而不是eu west one b
所以它与我的e c two实例的az不同
我之所以这样做，是为了向你展示，我们现在有三个GPU存储卷
让我来刷新一下这个
最后一个是可用的
它在不同的AZ
所以eu西一a，如果我执行操作并附加卷
如你所见，我无法将其附加到我的eu西一b的EC two实例
因为我的EC two实例是eu西一b
因此我们可以看到ebs值确实受特定可用区的限制
最后 我可以做这件事
执行操作
删除卷，它就不见了
这真的可以展示云服务的强大
我可以请求卷
在几秒钟内就可以在移动中删除卷
好的 所以我们有两个evs卷在这里
现在我想向你展示一个酷的行为
如果我终止我的实例会发生什么
记住，我会再向你展示一遍
这个根卷有几千兆字节，具有删除在终止属性
那么我们怎么知道呢
如果我进入我的存储
然后转到我的块设备，进入这个表格，在这里滚动
是的 你看第一个有删除在终止
是的，第二个没有
所以为什么这个是是的
嗯 我不知道你是否记得
当你启动实例的过程
好的 然后滚动到存储在这里
如果你点击高级
你可以看到它是你根的千兆字节
并且默认情况下，这个删除在终止属性是yes
这是有道理的 但你可以设置它为no
如果你想在终止实例后保留根
所以这解释了为什么我们在之前提到的yes
因此如果我去终止我的实例
我将这样做
它说已成功终止
所以它真的要从这里移除
我可以回到我的ebs卷
我可以刷新它们
并且会发生什么，这个很快将可用
因为它将脱离我的EC two实例
并且将被终止
所以我将暂停，直到这完成
这里是
所以我的8千兆字节卷现在已经消失 只有我的2千兆字节卷剩下
如果我去我的e2控制台
它说我的第一个实例已被终止
这就是本讲座的内容
我希望你喜欢它
我将在下次讲座见到你 这就是本讲座的内容
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/045_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p45 27. Amazon EBS Elastic Volumes.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们来谈谈ebs弹性卷
这是考试可能希望你了解的事情
这没什么 尤其是你不必显式启用这一点
如果你的实例类型支持它
这些天大多数都支持
ebs弹性卷的理念是，你再也不需要断开一个卷
或重启你的实例来更改那个卷
这有点像魔法 我真的不知道它是如何工作的
但是不知怎么的，他们做到了
如果你想改变你的音量类型，或者它的大小，或者它的性能特征
你所要做的就是去操作并修改控制台中的音量
输入你的更改
它将在不需要任何停机时间的情况下完成
这相当令人印象深刻
例如
你可以在不关闭它连接的实例的情况下增加音量大小
这很有帮助 正确 如果你磁盘空间不足
只需添加更多
这很容易做到 然而
你可以增加卷的大小
你不能减少它
我的意思是你可以想象这会带来一些复杂性
如果你尝试缩小一个已经满的卷
所以这很有道理
另一个酷的地方是 你也可以在飞行中更改音量类型
那么假设你想从gp二升级到gp三存储
实际上你可以那样做
只需前往操作
修改音量 更改音量类型
在你这样做的同时
你也需要指定你的期望的iops或吞吐量性能
如果你不做 它将试图做出一个明智的猜测
基于最大gp two性能或最小gp三性能
你将会得到 但是更好的做法是明确说明你想要什么
但是你可以做到 你可以实际上更改卷类型
而不需要停机或卸载卷
它会自动完成
我不知道怎么再次操作
这有点神奇
你也可以增加或减少性能属性
所以，如果你想要提高iops或吞吐量性能，
你也可以这样做
这就是cbs 弹性卷 嗯 只需知道这些都是你可以用ebs做的很酷的事情
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/046_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p46 28. Amazon EFS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


你好，欢迎来到关于亚马逊EFS（Elastic File System，弹性文件系统）的讲座
EFS是一个管理的NFS（网络文件系统）
它是一个网络文件系统
因为它是一个网络文件系统
它可以在多个EC two实例上挂载
EC two 实例
这些EC two实例也可以位于不同的可用区 EC two 这些EC two实例也可以位于不同的可用区
那就是efs的全部力量
所以它是高度可用的
它非常可扩展
它很昂贵 它的成本大约是gp2 ebs卷的三倍
你按使用付费
所以你不需要提前预留容量
让我来解释
你有你的文件系统fs
你围绕它设置一个安全组
然后你可以有e
C 两个实例 美国东部的很多
一个可用区
例如 或者e
C 美国东部的两个实例
一个b可用区
或者设置一个可用区（AZ）来为你的e
C 两个实例
它们可以同时连接到同一个网络文件系统通过etfs
efs的使用场景包括内容管理
网页服务
数据共享 WordPress
它内部使用NFS协议，为了控制对您的EFS的访问，您需要设置安全组
现在 请注意，这仅与Linux兼容，基于AMI，而不是Windows
您可以使用KMS在ESSS驱动器上启用存储加密
在Linux上是标准文件系统，因此适用于POC系统
它有标准的文件API
ES的一个酷之处是，您不需要提前规划容量
文件系统将自动扩展
每GB数据使用EVs的费用
其费用为每GB数据使用EVs的费用
然后我们有不同的性能和存储类别
所以首先关于efs的规模
您可以获得数千个并发的nfs客户端和十千兆字节以上的吞吐量
您可以自动扩展到PB级的网络文件系统
这真的很好
您也可以在创建efs网络系统时设置性能模式
您有几个选项
第一种是通用目的
这是默认的
它用于延迟敏感的使用案例，例如Web服务器
一个cms等
但如果你想最大化吞吐量
你有最大 我 O
这是一种高延迟的网络文件系统
但吞吐量更高并且高度并行
所以如果你有大数据应用或媒体处理需求，那是很好的
现在吞吐量模式你有不同的选择
第一个是爆发
所以你有一个太字节
这意味着它是每秒十五兆字节
加上每秒一百兆字节的突发
这就是你得到的突发类型
你不必记住这些数字
但只是为了给你一个概念
配置是当你想要设置你的吞吐量时
无论你存储的大小如何
之前的一个是随着我们更多的存储增长吞吐量
但配置中你可以有一个太字节每秒的存储量为一太字节
这没关系，因为你从存储中获得了吞吐量
最后，为了简化事情
你有弹性来自动根据你的工作负载调整吞吐量的大小
例如
你可以获得每秒3GB的读取速度
以及根据你的工作负载每秒1GB的写入速度
这将非常适合你有不可预测的工作负载的情况
现在我们有存储类别
我们有几个选项
我们有存储级别
这是生命周期管理功能
允许您在特定天数后将文件移动到不同的源级别
因此，您有标准级别，这是用于频繁访问的文件
然后你有efi级别，这是不经常访问
这将给您一个检索文件的成本
但存储文件的价格较低
然后你有存档存储级别
这是为很少访问的数据
因此您只访问 例如
年度几次的数据
这将大大降低存储数据的成本
自动将文件移动到不同存储级别
您可以实施生命周期策略
您可以定义文件在多少天后应移动到哪个级别
这是一个例子，我们有标准文件
其中一份文件60天未被访问
通过设置正确的生命周期策略
我们可以将其移动到新存储级别
例如e 在可用性和耐久性方面，标准将非常出色
当你有多区域设置时
你的efs跨越多个可用区
这对于生产工作负载非常好
这将使你抵抗灾难
但如果你想进行开发并希望有更便宜的选项
那么你可以选择一个区域
这将给你一个可用区
您仍将拥有备份
它与a类型的存储级别兼容
因此，您有一个区域的efs
i a类型的选项总体上
通过使用正确的efs存储类别
您可以节省高达90%的成本
这非常有帮助
这就是本讲座的内容 我希望你喜欢它 我将在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/047_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p47 29. Amazon EFS - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们开始实践使用亚马逊弹性文件系统服务
那么让我们创建我们的文件系统
在这里我们可以给它一个可选的名字
但我会留空 我们必须选择一个VPC，我们希望连接到我们的文件系统
所以我们也会留下默认的VPC
我们可以点击创建并完成
但我想向你展示选项
所以点击自定义
所以这里我们再次留下名称mt和可选的下一个
我们需要选择一个文件系统类型
所以我们有两个选项
我们有区域性的 这将为您提供该区域内的文件系统，跨多个可用区
这将为您提供数据的高可用性和耐久性
但如果您想降低成本
您可以使用单区选项
在这种情况下，您必须选择一个特定的可用区
这将对开发环境有益
但在生产环境中并不理想
因为如果该可用区变得不可用
那么您的数据将不可用
因此，在生产设置中，您肯定想使用区域性的
我们将使用区域性的，用于当前的动手操作
我们可以启用或禁用自动备份
但建议保持启用状态
我们有生命周期管理
因此，这将移动数据到不同的存储级别以节省成本
结果表明，您可以将数据转移到稀疏访问或归档
然后切换回标准
因此，我们正在说，嘿
如果一个文件在过去30天未被访问
但你当然可以自定义这个时间
如果一个文件在过去30天未被访问
然后移动到稀疏访问存储这里
这将为您节省成本，除非您访问该文件
但可能性是，30天后您很少访问该文件
然后，如果文件未被访问
例如，自上次访问以来，90天过去了
然后移动到归档
这将是更便宜的存储类别
然后 例如
您说在这里
当文件首次被访问时
所以首次访问时切换回标准
因为 例如 我们假设它将被使用得更多
这就是生命周期管理
所以我们可以保持这个状态
加密保持不变
我们保持它启用
那正好 然后我们有性能设置
所以对于性能设置
我们有吞吐量模式，你有三个选项，所以
因此它是一个类别来重新分组弹性和配置
但你有弹性吞吐量模式
你有预定量吞吐量模式以及突发吞吐量模式
那么我们从爆发开始
爆发是你让吞吐量按比例增长的一种方式
与你实际使用的存储量成正比，稍微超出一点
这就是为什么它被称为爆发
如果你有一GB
你将获得基于1GB的吞吐量
如果你有1TB 你将获得更高的吞吐量
因为你使用了更多的存储
然后有增强模式
现在推荐使用弹性
这意味着
无论你的s文件系统多大
我们都将提供你所需的所有i/o，并且会自动扩展
并且你只需为你使用的付费
因此，当你有一个工作负载时，它是最好的，这个工作负载的i/o是不可预测的
例如
你可以从零兆字节每秒扩展到一百兆字节每秒 在很短的时间内
这就是为什么它是推荐的模式
因为它不需要您考虑任何设置
然后是最后一个，我们有爆发弹性
最后一个是预配置
这是在您提前知道
您将需要的吞吐量
这就是预配置模式
所以你说 嘿 我需要100兆字节/秒是肯定的
然后你的爆仓限制也是三百兆字节每秒
因为你预先配置了吞吐量
你将预先为此付费
所以弹性是推荐的设置
然后如果你看其他设置
所以我们有通用和最大
I o所以在弹性的情况下
你得到 I o你需要的基于性能
你需要的性能，所以通用是性能模式的唯一选择
但如果你使用爆裂模式
或者如果你使用预分配
那么你可以选择两种设置之一
所以通用目的
这将为您提供高性能和延迟敏感的应用程序
这意味着延迟非常低
但如果您想要获得更大数量的I/O模式
那么这是为高度并行的工作负载设计的
你可以看到它的延迟更高
以牺牲更高的延迟为代价
你也能得到更多
我哦 这在大数据类型的设置中是好的
但是最佳推荐的aws设置是使用增强型与通用目的和弹性
好的 这就是所有选项
希望这不会让人太困惑
我不喜欢在增强型下面有弹性和预配置的事实
实际上只有三个选项
我们有膨胀的弹性和提供
这就是你在考试中应该记住的
好的 让我们点击下一步
现在我们有网络访问设置
它们非常重要
我们必须选择一个vpc
我将选择默认的vpc，然后挂载目标
因为我们选择了一种区域性的fs文件系统
有三个可用的az类型
所以每个az都将被分配到一个子网
我将保持不变 这是默认子网
IP是自动的，我们需要为它分配一个安全组
因此我们需要创建一个特定的安全组为我的文件系统
所以我们将进入e c two控制台
然后我将进入安全组
我将创建一个安全组
我将其命名为sg e s demo并将其命名为e s demo
Sg目前我们不会有任何输入
我点击创建安全组，我们不能这样做
所以演示足够好了
好的 所以我的演示创建成功
要让它出现在这里
我需要刷新页面
所以我们从头开始
但设置是基本的
我们默认的设置
现在我可以删除这些安全组并选择efs演示
我之前创建的安全组
好的 我们很好
现在我们已经完成了所有网络访问配置
我将点击下一步
我们有一个可选的文件系统策略
我们现在不会碰它，这是高级的
我们现在不需要它
所以我将点击下一步，在这里我们可以查看和创建所有文件系统设置
所以我们对此感到满意
当我们完成时 我们只需点击创建
现在我的文件正在创建
文件创建后我会再联系你
我的文件系统现在可用
我可以进入它并看到
事实是现在有6KB的大小正在被使用
当你有一个fs文件系统时
你只支付你所使用的单词费用
所以现在我们的成本为零
所以这是好的
这是由我们创建的，现在我们想要熔化它在e c two实例上
因此，你知道下一步我们将创建e c two实例
所以让我们启动一些实例
我会将这命名为实例A
因为我们将在A子网中启动它
我们将在亚马逊Linux版本二中运行
我们准备就绪 我们将使用t2微实例
因为它是免费试用版
我们将 禁用密钥对，我们将只使用e c two实例
连接到我们的e c two实例，设置网络
我将保持不变
会有一个新的安全组创建成这些规则在这里
正如我所说
来自任何地方的访问，很好
然后我们有8GB的gpt2存储
但现在因为我们想配置62实例的存储到亚马逊
Fs 我们现在实际上可以在e c two控制台中进行操作
这非常令人兴奋 所以让我看看如何做之前，我们需要运行一些命令
所以没有零x文件系统，您需要编辑
它说在您选择子网之前，您无法添加文件系统
我们滚动回上
我们去网络设置
我们编辑它，在子网中我将选择eu west one a
所以现在我的子网已创建
我可以回到文件系统
正如你所看到的 我可以添加一个s或fsx文件系统
所以我们将添加一个efs文件系统
然后我们点击
添加共享文件系统将链接到我的efs
就在这里 关键点是斜杠m和tesfs1
这对我们来说足够了
这将自动为我们创建并附加安全组
这真是太棒了
然后它将自动挂载共享文件系统
通过附加所需的用户数据脚本
所以以前一直需要我们手动在这些实例上运行
或者我们自己创建用户数据脚本
但现在这由EC two控制台为我们完成
这真是太好了
好的 让我们创建一个实例并启动它
好的 这个实例已经启动
我可以去所有你的实例
我将启动一个新的
好的 我将这个实例命名为B
我们将再次使用amazon 为了加快速度
我将不使用密钥对 我将前往eu west one b
我将选择launch wizard two安全组
那是之前创建的
再次
我们需要编辑并添加一个文件系统类型s
我们将使用相同的系统并保持相同的数量
我们将保留这些选项
我们很好
让我们启动该实例
现在让我们看看发生的有趣事情
所以我将立即状态等于运行并刷新
直到我看到我所有实例
所以现在他们都在运行
有趣的事情是，如果我们进入es控制台并转到网络选项
我们可以看到每个可用区现在有多个安全组
我们有之前创建的eas demo
但也有efs g1和efs g2
这些是由EC two控制台自动创建的，并为我们附加到fs文件系统
所以如果我进入我的EC two实例并转到安全组
我可以查看 例如这个efs g2
查看入站规则
正如你所看到的，它允许协议nfs在2049端口
并且它的来源是
如果我们看一下流入的规则他自己
这个的来源是这个安全组
并且这个安全组是附加到我的e
C两实例实例b
所以这允许我的实例b访问s文件系统
因为右边这个安全组叫es sg2
附加到我的es文件系统
所以所有的设置都是aws为我们做的
这真是太好了
所以现在如果我进入这些实例之一
我们将使用e
C两实例连接在这个标签上
然后我也会通过连接实例b over e
C两实例连接做同样的事情
所以现在我可以
例如 验证事实是的确在mit es f s one
有一个es文件系统
现在我们需要在它上创建文件
为了简单起见
我将提升我的权利并键入sudo su
然后我可以执行echo
Hello world到m and t e s f s one作为hello.txt
所以我们创建了这个名为hello.txt的文件
如果我执行cat然后这里整个文件名
如您所见，它说Hello World
所以该文件已创建到我的fs文件系统
来自这个e c
Two实例 这是eu west one a
但是现在如果我进入我的第二个EC two实例并做
然后相同的fast as them
所以，我在它上查找文件
如您所见
我们也看到这hello.txt文件
如果我执行cat然后cut the foul
Uh hello.txt
它说Hello
所以，正如您所看到的 Efi系统确实作为网络驱动挂载到我的e
C Two实例
它们在不同的az
并且它们共享相同的es
所以这太棒了 这就是你刚才演示的一种不同存储类型
所以这就是演示的全部内容，那是相当完整的，现在只是清理它
你可以做的是终止这两个e
C 两个实例
所以你在这里终止它们
你可以进入fs文件系统
你可以通过进入文件系统删除它
ID
当所有数据都被删除后
你可以进入你的安全组
删除在演示中创建的额外安全组
好的 这就是这节课的内容 希望你喜欢 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/048_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p48 30. Amazon EFS vs. Amazon EBS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在让我们谈谈ebs卷和efs文件系统的区别
所以，ebs卷它们一次只连接到一个实例上
在极少数情况下使用i的多点触控功能时，除外
一种和两个类型的体积
但那是为非常特定的用例
EBS卷在Z级别上也是锁定的
所以这里有一个例子
我们有一个EC two个和a z一个
并且我们有一个ebs卷附加到它上面
它不能与一个在z2中的e c two实例连接。
对于gp2类型的存储容量
输入输出会随着磁盘大小的增加而增加
对于gp3和输入输出
一种类型的存储容量
您可以独立增加输入输出，而不受磁盘大小的限制，以迁移EBS存储卷
我们需要先创建一个快照
它将进入EBS快照
然后我们可以将快照恢复到另一个可用区
这就是如何从一个可用区迁移到下一个
现在EBS存储卷的备份
他们将使用i
O 因此，在你应用处理大量流量时不应该运行它们
因为这可能会影响你e的性能
C 两个实例
默认情况下，你实例的根ebs卷将被终止
如果e C 两个实例被终止
但现在你可以禁用这种行为
对于efs 它有点不同
所以它是一个网络文件系统
目标是真正地将其连接到百来个实例跨可用区
所以我们在这里真的看到了区别
所以有一个fs文件系统
我们可以在不同的az中有不同的挂载目标
然后多个实例可以共享同一个文件系统
所以它非常有帮助 例如
当你有WordPress并且它只适用于Linux实例时
因为它使用的是POD系统
EFS的价格点高于EBS
但你可以通过利用存储级别来节省成本
希望您现在理解了EFS和EBS之间的区别
至于实例存储
它是物理连接到E
C 2实例 因此
如果你丢失了你的
E 两个实例 你也会丢失存储
好的 就是这样
我希望你喜欢它 我将在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/049_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p49 31. AWS Backup.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


你好，欢迎来到本关于aws备份的讲座
所以这是一个完全管理的服务
它允许您集中管理和自动化所有服务的备份
而且列表每天都在越来越大
所以想法是您不会有一个中央地方
您不想创建任何自定义脚本或进行任何手动过程
您想要一个对备份策略的中央视图
支持的服务范围很广
例如 亚马逊e
C 两个 eps
亚马逊的三个 rds
所有数据库引擎都受到支持
Aurora Dynamo
Db 文档 db
在 nem 上 Churn esfs
Fsx 包括光泽和Windows文件服务器
以及可能还有其他的
它是存储网关
例如卷网关
并且随着时间的推移可能会有更多
但我不一定会更新这门课程
因为嗯 这并不重要
想法是你能理解背后的概念
备份和最重要的服务在幻灯片上显示
因此它支持跨区域备份
这意味着您可以将备份推送到另一个区域以进行灾难恢复策略
所有都在一个地方，并且还支持跨账户备份如果您在使用策略中使用多个账户
因此它支持支持服务的时间点恢复，如aurora
它支持按需和定时备份
有基于标签的备份策略以确保您只备份
可能被标记为生产的资源
您可以创建becca策略称为备份计划
您定义频率
例如 每12小时或每周或每月
或者任何cron表达式
如果您想将备份本身过渡到冷存储，那么备份窗口
或者某些天后
某些周或月或年
和您的备份保留期，所以总是或天
周 月和年
所以它相当支持且全面
它支持大多数服务
所以它是空中客车服务的一个很好的补充
如果我们看一下aws备份
正如我所说，我们创建一个备份计划
然后你可以指定对你来说重要的特定aws资源
这里有一个列表
但它可以更大
一旦完成，它会自动进行
你的数据将被备份到亚马逊s3
在特定的aws备份内部桶中
在aws备份中，另一个你需要了解的特性是保险库锁
所以你执行了一个暖读
一次编写，多次阅读政策
这意味着您在备份保险库中存储的所有备份都无法被删除。
所以想法是，你知道得很确定
你可以通过保险库锁政策来证明这一点
你不能删除你的后备文件
并且它为你的备份提供了额外的防御层，以防御
例如 无意或有意的删除操作
或更新缩短或改变了保留期
即使启用了，根用户本身也无法删除备份
所以它给你提供了对备份安全的强保证
好的 这就是你需要知道的关于aws备份服务的一切
我希望你喜欢它 我会在下次讲座再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/050_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p50 32. AWS Backup - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 那么我们来练习使用aws备份
我将在搜索栏中输入备份并打开备份服务
我们将创建我们的第一个备份计划
我将点击创建备份计划
我们有三个选项
我们可以从模板开始
或者我们创建一个新的计划
或者我们使用json定义一个计划
对我们来说最简单的是从模板开始
我们可以有不同的模板
例如，每日三、五日保留
每日、每月，当你的保留期等等
让我们选择每日、每月、一年保留
我将其命名为测试计划
我们看备份规则
你可以看到我们有多个备份规则在我们的备份规则中
我们有两个
我们有每日备份和每月备份
所以 如果我点击每日备份
我们可以看到有一个真实的名字
备份库是备份所在的地方
我们可以使用AWS的默认一个
或者我们可以创建一个我们自己的新备份库
如果我们想要备份频率
备份所以何时开始
这是5点AM UC开始8小时内
但你可以自定义
如果你想 无论你是否想在一些天后转换到冷存储
周 月或年
以及你备份的保留期
例如，这一个被保留五周
我们也可以将这些备份复制到特定目的地
例如，另一个地区以备灾难恢复
所以我要保存这个备份规则
每月
好的 我们也得到了类似的东西
所以它会进入默认备份金库
每月第一天
其余部分看起来相同
实际上我们在一个月后把这些转移到了冷存储
然后我们保留它们一年
好的 我们有这些准备好了
然后我可以滚动并点击创建计划
所以现在我们的测试计划已经创建，我们需要为它分配资源
所以我要点击分配资源
然后我会叫它测试分配
在这里我为我滚动
我们将使用默认角色
这将为我们创建一个具有正确权限的角色
或者你可以选择你自己的
但我们选择默认角色容易
然后对于资源选择
我们有两件事可以做
第一，我们可以包括所有资源类型
或者选项二，我们可以包括特定的资源类型
例如 如果你只想有一个dynamodb表
然后你可以在那里选择你想要的资源
你可以这样做
或者如果你想要
你可以有所有表
所以它是一种做法
或者如果你选择所有资源类型
通常我们会与标签结合使用
你会说好吧 如果环境变量等于值
那么就做一个备份
这将是备份的使用案例
但你可以自由做任何你想做的事情
当然 然后你完成之后
你点击分配资源
所以只是为了让它非常
非常清楚 如果我进入EC two，
EC two 我和我将创建一个EBS卷
这个卷将有
例如 1GB
然后关键是环境
生产 这将自动由我的备份计划备份
因为它有正确的标签
所以我们看看我们的当前体积，然后我们进入标签
如我们所见 环境生产
这与我为我的备份计划设置的标签相对应
好的 所以这就是分配在这里，我们可以在这里有多个分配
好的，然后就这样
备份计划将自动运行
然后备份将在这里
在我的备份保险库中
好的 工作是
工作将被安排并执行
所以我们有备份工作
恢复工作和复制工作如果我们想要的
然后我们可以查看设置
所以设置是关于
您是否想要备份策略
跨账户监控
跨账户备份等等
但我们已经看到了备份的基本原理
就是这样
我想向你们展示这一切
好的 这就是你需要知道的
我将删除一切
请确保删除您的EBS卷
或者如果您想要看到备份是否工作您可以等待一天
然后当你完成时，您取得上的指派并删除它
所以在这里输入指派的名称
对于每日备份方法
您可以删除它们或直接删除备份计划
对于这一点，请输入备份计划的名称并按删除
就是这样，我们已经看到了备份 我希望你喜欢它 我将在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/051_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p51 01. Intro Database.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


接下来我们将深入探讨各种数据库技术的细节
亚马逊提供存储您的结构化或半结构化数据的服务
斯特凡将覆盖dynamo db
它有很多功能和细节
这些认证考试试图通过
我将覆盖亚马逊RDS
除了考试指南中提到的几个关于rds的具体点之外
使用其最佳实践
斯蒂芬将触及文档数据库
Redis 的内存数据库
亚马逊为Apache Cassandra和Amazon Neptune提供的服务
然后我会深入探讨Amazon Redshift
Redshift是亚马逊的数据仓库解决方案
它是数据工程和数据分析中一个非常重要的组成部分
你可以期待在考试中看到很多
就像每个部分一样
我们会以一系列示例问题结束，进行小测验
以巩固你所学的知识
并给你一些按照考试期望的方式思考的实践
仅仅了解每个服务的琐碎信息是不够的
你需要思考
如何将这些服务和功能组装成更大的系统
这些测验将给你一些这方面的经验
这是课程中较长的部分之一
那么我们开始吧 让我们深入aws的数据库系统
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/052_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p52 02. Amazon DynamoDB.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在让我们看一下 dynamodb
这是一个无服务器NoSQL数据库
那么，如果你考虑我们在这门课程中看到的传统架构
我们有客户 并且它们连接到一个应用层，该层可以是一个弹性负载均衡器和e组成的。
C 两个实例被分组并使用自动扩展组进行缩放
然后数据必须存储在某个地方
因此我们有一个数据库层
它可能正在使用亚马逊RDS
这是由mysql或postgres或这类技术支持的
这些传统的应用程序将利用关系型数据库管理系统(rdbms)数据库
我们做到这一点因为我们有sql查询语言
它真的很好 然后我们可以定义关于数据应该如何建模的严格要求
因为我们有表 我们有模式等等我们可以做连接聚合
复杂的计算
并且这是非常好的和工作的我们得到的
尽管 在扩展方面，通常是垂直扩展
所以，如果你想要更好的数据库
我现在只谈论数据库层
如果你想垂直扩展
你需要更换数据库，获得更强大的CPU
更多的RAM或更好的IO硬盘
你也可以进行某种水平的扩展
但这只是增加了读取能力
所以，要么通过添加
EC 两层应用实例
或者在数据库层添加RDS读副本
但如果你添加读副本
你将会被你拥有的活副本数量所限制
因此你的水平读扩展将被限制
我不是在谈论水平读扩展
因为你在RDS中没有那个
所以介绍给你nosql数据库
这意味着不是只有sql或非sql数据库
根据定义
所以想法是存在不是关系型数据库，并且它们是分布的
这将给我们带来一些水平扩展性和一些非常著名的无SQL技术
这些数据库是mongodb和当然还有mob
现在这些数据库不支持查询连接
或者支持非常有限
因此为了简单起见
我假设你没有查询连接
现在所有需要的数据
因此必须存在于你数据库的一行中
再次简化事情
我知道它们在进化
但让我们假设nosql数据库也不执行聚合计算
例如总和或平均值等等
但好事是，多亏了设计
nosql数据库将水平扩展
这意味着如果您需要更多的写入或读取能力
您可以在后台有更多的实例
它将非常容易扩展
所以nosql没有对错
这是一个序列 它只取决于您对数据建模的想法
关于您的应用程序
关于您的用户查询
以及您的扩展需求
所以让我们谈谈dynamodb
dynamodb是完全管理的nosql数据库
并且高度可用，具有跨多个az的复制
所以它是一个nosql数据库
它不是关系数据库
所以它与rds不同，可以扩展到巨大的工作负载
并且是完全分布的
这意味着您可以扩展到每秒数百万个请求
万亿行和数百TB的存储
无论您的工作负载如何
所以快速和高性能
这意味着您在检索时将获得极低的延迟
它是一个服务
所以它将与我完全集成
我是安全的
授权和管理
您可以启用与an mob流的编程
正如我们在章节中看到的那样
它成本低廉
它具有自动扩展能力
并且您具有标准和稀疏访问
表类用于不同存储级别
所以让我们看看dynamodb的基本知识
所以dynamodb由表组成
每个表将具有主键
我们将在下一页看到主键可以是什么
您必须在创建表之前决定主键是什么
现在每张表可以有无限的行
也称为项目 所以我将在课程中使用行和项目术语交替
每个项目将具有属性
现在这些属性可以类似于表中的列
但是这些属性也可以嵌套 所以它比列更强大
并且可以在将来添加
它们
你不需要在创建表格时定义所有数据类型
一些数据类型可以设置为空
因此，属性缺失是可以接受的
每个项目或每行数据中现在包含的数据将高达400KB
这是一个限制，支持的数据类型将是标量类型
包括字符串、数字
二进制、布尔 没有文档类型，如列表和映射
这样给你一些嵌套的能力，并且有字符串集合的类型
数集和二进制集
现在要理解的一个非常重要的点是如何为dynamodb选择一个主键。
考试肯定会检验你对这方面知识的掌握情况。
因此，你有两种主键选项
第一个被称为分区键
也被称为哈希策略
因此，在这种情况下，分区键必须为每个项目唯一。
这与一个普通数据库非常相似
因此，分区键必须足够多样化，以便您的数据将被分布。
例如 如果你考虑用户的ID
那么我们可以将分区键设置为用户的ID
属性是名字
姓和年龄
然后你有一个用户的ID和一些属性被填入
你的第二个用户 你可以看到
没有姓
但这在NoSQL中没问题
并且第三个分区键再次有三个属性附加在它上面
这就是它看起来的样子
它看起来像一个数据库，到目前为止，它很简单
但你可以有第二个选项，分区键和排序键
或者被称为哈希加范围
现在，这两个项目的组合必须为每个项目唯一
因此，数据将按分区键分组
这就是为什么选择好分区键非常重要
如果你考虑一个用户的游戏表
那么用户ID作为分区键，游戏ID作为排序键
让我们看看这意味着什么，这意味着用户可以参加多场比赛
所以我们有四个列属性
但第一个将是我们的分区键
我们希望数据按用户ID分组
第二个将是排序键
这将给我们提供分区键和排序键的组合的唯一性
所以它们都将构成主键
其余的将是属性
如果你考虑一个用户ID
那么它有一个排序键，那是游戏ID
然后我们将结果评分92归因于再次
另一个不同的用户ID和另一个不同的游戏ID
所以这也有效
我们有一场输掉的游戏，得分为14，更有趣的是
在这第三行
我们所拥有的是，我们有相同的分区键
好的 所以第二行和三行有相同的分区键
但是不同的排序键
当然，一个用户参加多个游戏是合理的
因此，您希望用户ID和游戏ID的组合显然是唯一的
但是有相同的分区键和不同的排序键是合理的
而这是为什么选择一个非常好的分区键非常重要
这样数据将被足够分布
这是一个练习
这也是考试可能会测试你的地方
所以你在建设 你正在构建一个电影数据库
你想要选择最好的分区键来最大化数据分布
是电影ID
是制片人名称
是主演名称
还是电影语言
嗯 想一想
如果你选择第一个
我们选择第二个 等等，答案是你选择电影ID
因为电影ID对于每一行都是唯一的
因此它是一个非常好的候选者来通过分区你的表
如果你有一个电影语言作为分区键
那么你不会有你想要那么多的语言
有那么多值
并且你可能大多数电影都将面向英语
因此这不是一个很好的选择
因为不够多样化
并且有数据向一个特定值排队
因此考试将问你为某些表选择最好的分区键
基于这意味着 总是选择具有最高卡纳迪蒂的
并且可以接受最多的值
这就是关于短概述的dynamodb
我们有一个长的部分 但是让我们通过手来练习一下使用dynamodb
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/053_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p53 03. Amazon DynamoDB - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来看看 dynamo db 服务
DynamoDB 服务将允许我们创建表
正如你所看到的
我们可以创建表
不是数据库 因为，数据库已经为我们创建好了
这是一个无服务器服务
所以我们只需创建表
表名必须有一个名字
我们将输入 users
然后我们需要定义分区键，可选择排序键
对于分区键
我将使用 user_id
然后可以更改类型
可以是二进制数字或字符串
但我将保留为字符串
然后我们可以使用排序键
但我稍后会告诉你
目前我们将其留空
快速启动允许您使用默认设置开始
它会为您设置一些设置
或者您可以自定义设置
因为我们正在学习 DynamoDB
让我们学习自定义设置
首先关于表类
它是标准或标准 A
标准 A 是通用目的表类
适用于大多数用例
但如果您有数据 将长时间保持不变
并且您不会进行大量读写
则标准 A 会说数据不经常访问
并给您一些成本优化
但现在我们将使用默认值
即 mob 标准容量计算器
稍后会看到 因为我们需要了解如何在 mob 中计算容量
但现在这里不做任何操作
然后读写容量有两种模式
按需或预留，预留在免费层内
稍后我们会详细讨论这些模式
但我们将使用预留
因为它在免费层内
接下来，我们需要设置读写容量
我将为读写都禁用自动缩放
我们只提供固定的读写容量
在免费层中有两个容量单位
所以我将设置 我们有十抱歉，在免费层中有两个
所以我将设置两个预留容量单位用于读写
我们将看看如何随着时间的推移让他们进化
我们现在要为此创建二级索引
因为这将在课程的后期得到进一步发展
在这里我们可以看到这张表的估计成本
这是一点
三二美元每月
因为我们处于免费层
你可以忽略这个数字
好的 但如果你不处于免费层
这张桌子每月的费用大约是两份
然后我们会对静态数据进行加密
使用DynamoDB密钥
我们就这样留下 但我们有其他选择
当你准备好时
你点击创建表
好的 所以我的表已经创建
我可以点击它
我将移除左侧面板
正如我们所见
我们桌子上有很多信息
所以我们桌子的设置
所以哪个是分区键
排序键 容量模式
还有一些复制和创建等
有很多信息
对我们来说重要的是关于物品
所以我向下滚动
这里有像查看项目
如果我去右边
这里也有查看项目现在
正如我们所看到的我可以扫描或查询我的表格
但我要做的就是创建一个项目
所以在这个创建项目我可以选择一个用户id
我们需要定义分区键
例如 约翰一二三
这就是一个用户的想法
随机一个 你可以输入任何你想要的东西
然后我们可以为通用添加属性
一、二、三，所以我们可以有一个字符串
例如 字符串将是first_ name
值将是well
约翰 然后我们有一个字符串和它的last_ name
然后我们可以做面团
约翰·多伊，正如你所看到的，我们可以添加许多属性
就像我们想要的这些类型
所以我们可以出发 我们将创建一项
正如你所看到的 这可以通过表单
所有通过相邻文档
所以我们将保持其为表单并创建此项
所以现在这个项约翰·多伊出现在我的表格中
正如你所见，我们拥有用户ID、名字和姓氏
所以我们可以做的是开始添加第二个项目
所以让我们创建一个第二个项目
如果我保持约翰一二三作为我的值
然后我只是说我的名字是约翰尼
例如 只是为了向你展示一些东西
如果我这样做 然后点击创建项目
我将会遇到一个问题
因为我在使用相同的用户想法
并且必须唯一
当我只有一个分区键时
所以这不起作用
好的 所以我可以做的是
我可以创建alice four five six并且第一个名字将是alice
我们不知道她的姓氏
所以我们不会指定姓氏
但我们知道她的年龄，她的年龄是四一，现在如果我尝试创建这个项目
会发生一些非常有趣的事情
所以你可以看到请求成功了
所以在rds
sql数据库中，你可能会遇到一个错误，说列未定义
一些值是空的
随便 但这里我们可以让约翰有一个名字
和爱丽丝有一个年龄和一个名字
所以在modb中 随着时间的推移，你可以完全自由地添加属性
唯一不能为空的是用户ID
但我们可以看到
默认情况下，所有东西都是空的
所以约翰的年龄是空的，爱丽丝的姓氏也是空的
但这是可以接受的 这也是数据库的力量，也是风险
但也是它的力量，你可以随时间添加属性而不影响之前的数据
这是完全可以接受的
好的 你不能在模型中定义
这列的限制从未被知晓，那就是它根本不存在
好的 所以我们正在创建第一个表
但创建表非常容易
如果我回到主界面并点击创建表
我们可以创建一个名为用户的第二个表
帖子
好的或者用户帖子
好的 现在分区键仍然是
用户ID 但现在我们有一个排序键
这是帖子的ts，一个时间戳
我输入了字符串
二进制或数字
我们想要创建的是数据的表
这将包含用户的帖子
因此，我们将自定义设置
我们将使用配置
这是关闭的 我们将有2和2
然后滚动并创建第二个表
因此，我们可以看到我的数据库中有两个表
再次，无需说明正在发生的事情
底层数据库
你真的可以创建你想要的表数量
你的动态数据库
这是在区域级别完成的
现在让我们进入用户帖子
现在我们可以看到有一个分区键和一个排序键被定义
如果我去查看物品
然后我将创建一个物品
我们需要指定一个用户
例如 约翰123和帖子的时间戳
例如 2021
嗯10:09
然后确保这是正确的时间
但让我们希望它是是的
然后嗯
时间 所以
嗯1234
009z
好的 接下来
我们需要为我们的帖子添加些内容
所以我会说内容并说
你好世界
这是我的第一篇博客
好的 现在很好
让我们创建这个项目
正如你所看到的，我们现在有用户ID
约翰和发布时间戳，这些
所以现在如果我们创建一个第二个项目会发生什么
嗯 我们可以保持约翰一、二、三作为我的用户ID
对于发布时间，我将使用2021年
也许稍后
所以11:04 t
然后再次添加一个随机时间戳
好的，我们将添加一个新的内容并说第二篇帖子耶
好的
创建这个项目
所以，正如我们所见，这成功了
即使我们有相同的用户ID
因为发布时间戳不同
我们能够将数据输入到我的表中
所以唯一性必须在用户ID和发布时间戳的组合上
这意味着数据按用户ID分区
所以这就是为什么约翰是可点击的
因为我们可以查询并搜索约翰一、二、三作为我的用户ID
然后我们可以按发布时间戳排序数据
好的 这叫做排序键
所以这非常、非常、非常有用
正如我们所见
如果我们想要创建一个最后一项
这是为爱丽丝四五六再次
您需要输入发布时间戳和一些内容
你将会好的
并且 所以这是为什么在选择这种时刻选择一个非常好的分区键非常重要
因为如果你选择分区键它会不断回来 所以如果约翰一、二三是唯一发布用户
并且你有一万个帖子
并且数据将严重偏向于约翰一、二三
所以这是需要注意的
好的
所以这就是这节课的内容 我希望你喜欢它 我将在下节课见到你 再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/054_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p54 04. Amazon DynamoDB in Big Data.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在动态数据库在大数据世界中是如何运作的
实际上，有很多常见的使用场景，包括移动应用
游戏 数字艺术
广告服务 实时投票
现场活动的观众互动
传感器网络日志
数据摄取 基于网络的内容访问控制
亚马逊的元数据存储是三个对象
电子商务 购物车
网络会话管理
用例非常多样化
但基本上这意味着每当你有一些需要高速处理的数据
需要在数据库中进行大规模摄入的数据
那么它在这方面对于反模式来说是很好的
动态数据库中你不做什么
例如 一个使用RDS像传统数据库一样的应用程序
就像RDBMS一样
那么您可能不会使用RDS
因为你不想完全重写它
或者如果您需要执行连接或复杂的事务
那么也许这不是最好的选择
也许再次一个RDS数据库可能更适合您
如果您需要存储二进制
大对象或blob数据
所以大数据
你知道 也许最好存储在
S三中和将元数据存储在dynamodb中
这是一个非常常见的模式
总的来说
如果你有大量数据且读写频率很低
对吧 所以读写很少
S三对你来说是一个更好的存储选项
所以想想看
Dynamodb 将会更适合于你的数据是热的且较小的情况
嗯 S3 将会更适合于你的数据稍微冷一些的情况 但是大得多
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/055_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p55 05. Amazon DynamoDB - Throughput (RCU & WCU).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们来谈谈那个表的读写能力模式
这就是你控制表能力的方式
你必须提前指定读写吞吐量
你有两种模式 实际上第一种叫做预定模式
这是我们默认的模式，我们在其中指定每秒读写
也被称为读能力单位和写能力单位
你需要提前规划你的能力
你将为所提供的能力支付费用
如果你说我想要10个读能力单位和5个写能力单位
你将每小时支付这些费用
你有选择自动缩放的选项
正如我们很快就会看到的
第二种模式叫做按需模式
这种模式会根据你的工作负载自动调整读写
不需要规划能力
你不需要提供能力单位
它们将随时可用，你将为你使用的支付费用
这将比预定模式昂贵得多
所以你有不同的用例
我们将在本课中详细讨论
你可以在两种模式之间切换
预定和按需模式每两到四小时切换一次
我们将深入探讨这两种模式
所以现在不要担心，这只是一个介绍
但现在让我们深入探讨预定读能力模式
你必须提供
读和写能力单位
也被称为rcu，它是读吞吐量
和w cu，它是写吞吐量
现在你可以选择通过需求自动缩放吞吐量
你不需要太担心你的rcu和wcu值
你只需说你的目标能力使用情况
然后mob将根据您的需求缩放这些
如果你超过rcu和wcu
因为你消耗的读写超过了你提供的
你可以临时使用称为突发能力的能力
但如果你耗尽了突发能力，因为它已经被完全消耗
你将得到一个名为超出预定吞吐量的异常
这很明显
如果你得到这些东西
你需要显然重试
重试策略称为指数后退
现在我们来看看wucu的详细信息
考试将要求你进行一些计算
因此你需要理解计算wcu和rcu的公式
一个写能力单位
Wcu将代表每秒对一个最多1KB大小的项目进行一次写
如果你的项目显然大于1KB
然后你会消耗更多的w
所以让我们通过例子来理解计算
你可以暂停这个视频，如果你想自己计算
所以如果你每秒写10个项目，平均项目大小为2KB
你需要多少w
嗯 我们做数学
我们需要每秒10个项目，所以10乘以
然后项目大小为2KB，除以1KB
这将除以1KB
这是多少个wc你需要来处理1kb的数据
你得到的结果是20c
所以这是一个非常简单的例子
在例子二中
我们每秒写6个项目
这次项目的大小是4.5kb
所以这比前一个例子更难
所以我们需要6乘以5除以1
这是三十rcu y well
因为4.5kb总是被四舍五入到最接近的kb
通过db 来估算你消耗了多少w
所以记住，你需要将w的数目向上取整到KB
如果你每分钟写120个项目
而项目大小为2KB
这里的窍门是我们有每分钟的项目数
我们需要进行一些小的计算
即120除以60来得到每秒的项目数
然后这就给了我们4个w
好的 完全正确
容量需求是非常基本的，老实说，非常容易理解
更复杂的部分将会围绕
首先，读取 我们需要为DynamoDB定义两种读取模式
一种是强一致性读取，另一种是最终一致性读取
所以如果你转换了mob
这是一个无服务器数据库
当然 但背后有服务器
你只是看不到它们或者管理它们
所以我们有服务器
让我们只考虑三个服务器现在让它非常简单
但这显然更多
你的数据将分布在这些服务器上并复制
如果你考虑你的应用程序
你的应用程序将向这些服务器的一个写入
在内部
然后mob将把这些写入复制到不同的服务器
例如服务器二和服务器三
现在当你的应用程序从modb读取时
你可能正在阅读的可能性是存在的
不是从服务器一，而是从服务器二现在
如果我们处于最终一致性读取中，两件事可能会发生正确。
哪个是默认模式
然后如果我们在写操作之后立即进行读操作
有可能我们会得到陈旧数据，因为复制还没有发生
如果我们非常非常迅速
但是，大约一百毫秒后
显然你可以去做
但如果你进行强读操作
你正在说嘿
我想在写操作后立即读取数据
你将会得到刚写入的正确数据
我们需要设置一个参数
在API中称为一致性读
它可以应用于GetItem查询和Scan
以及为什么我们不总是这样做
为什么为什么我们不总是想要强一致性读
好吧，它将消耗两倍
RC用户将成为一个更昂贵的查询
也可能有稍微更高的延迟
所以你需要问自己
我需要最终一致的读取吗
还是我需要强一致性的读取
现在 让我们谈谈rcu关于这两件事
一个读取能力单位
rcu代表每秒一个强一致性读取或两个
最终，每秒的读取次数保持不变
对于大小不超过4KB的项
这使得计算稍微复杂一些
如果你的项大于4KB
将消耗更多的rcs
再次将其四舍五入到最近的4KB上限
让我们再次通过示例来感受一下，随时可以暂停视频
如果你有10次强一致性读取每秒
项的大小为4KB
你需要多少rcs
我们需要10乘以4KB乘以4
这相当于10个rc
好的
如果你有每秒16次最终一致性读取
而且项目大小是12KB
所以这个更复杂一些
这个我们将16除以2乘以
12除以4
结果是2 4rc
我们 所以在这个例子中，显然我们需要将十六除以二
因为我们不需要 因为我们每秒有两次最终读取
嗯，在rcu中
然后我们将十二除以四
这给我们两个四个rc的
最后一个例子是每秒十次强读取
项目大小为6KB
好的 所以这个有点棘手
它是什么
嗯，它是十乘以八除以四和y八
嗯，我们将8KB四舍五入到最近的4KB
所以它将是8KB
你必须总是向上
好的，在这种情况下我们得到十乘以八除以四
这是两个 所以20个rc us
现在我们知道了w's和r's
让我们谈谈后端如何与分区一起工作
Mdb由表组成
每个表都有分区和分区
只是您数据的副本，它们位于特定的服务器上
当您的应用程序向Mdb进行读取时
会发生什么，您的应用程序将发送分区键
排序键，也许和一些属性 所有这些数据都将通过一个哈希算法进行处理
所以只有所有权限实际上会通过一个哈希算法进行处理
以了解应该去哪里
所以如果我们取分区键id 13将通过一个内部哈希
Mdb的函数，它将说嘿
每当我看到id 13
这将进入分区1
如果您有id 45在第二行
那么id 45将通过哈希函数进行处理
哈希函数将说嘿
这个id 45应该去分区2
这就是您的数据如何分布的，所以显然
如果您有一个所谓的热点分区
数据总是处于热点状态
热点键的数据总是处于同一分区
所以计算分区的数量
有一些复杂的公式，您不需要在考试中知道
所以我们快速过一遍
但你通过将rc's除以3000并将wc除以1000来计算分区的数量
并将它们相加
最后例子是每秒十次强读取
项目大小为6KB
好的
你也可以查看你的数据量
所以你的数据集的总大小除以10GB
然后分区的数量将是这两个数的最大值
现在你不需要知道这个公式
所以完全不用担心
好的 但你需要理解
虽然 如果你有10个分区
那么你提供一个新的配置
10个wc和10个r
那么他们将被均匀地分布在分区上
这意味着每个分区将得到一个wcu和一个rcu
这是我想让你记住的一点
好的 w和rcu将被均匀地分布在分区上
这引向了限速
所以在你超过r的情况下
rw
这是在分区级别
你将得到一个提供吞吐量超出的异常
也许因为你有一个热点
所以某个分区键被从一个特定分区读取得太多次
这可能是因为你有一个热门项或分区或非常大的项
因为显然当wu和rc被计算时
这取决于项的大小
所以如果你读取或写入一个非常大的项
你将消耗大量的rcu或w c
解决攻击这个提供吞吐量超出的异常的方案
方案一是在遇到异常时进行指数备份
这如果你使用sdk
这是已经包含的
你必须尽可能多地分布分区键
这是我们在第一节课做的练习，以了解我们如何选择一个非常好的分区键
如果这是一个rcu问题
因为你读取
嗯 一个点数在war分区上被非常重地读取
那么我们将看一下名为dynamodb加速器或dax的功能
现在，我们需要理解的最后一种模式
这是一种更容易理解的模式是按需读取/写入容量模式
这将自动接受任何读取和写入
并将根据你的工作负载进行上下文切换
因此不需要进行容量规划
你不需要指定rcu或cu
这是无限的
没有限速
但显然这更昂贵，你将为你的实际读取和写入付费 没有限速
但没有限速
这条路 这叫做读取请求单位
所以我们的骗局和读取请求
这是用于比赛的相同
但想法是，因为我们有每个成功的请求
这不是容量 我们谈论过
这只是请求现在给你一些概述
按需大约是2.5倍昂贵
比预置容量
所以请确保您仅在特定类型的使用案例中使用它
例如 未知工作负载
或者当应用程序流量不可预测时
这就是关于dynamodb的容量模式的所有内容 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/056_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p56 06. Amazon DynamoDB - Throughput (RCU & WCU) - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以 让我们看看如何定义我们的表的rcu和wu
如果我们以用户的表为例
例如 然后你去右边做额外的设置
你有读写能力并且可以编辑它
这就是我们在创建表时定义的
但mob的酷之处在于我们可以在容量模式之间切换
如果我们需要的话 然后我们也可以随时间改变它们
那么我们现在来考虑最简单的容量模式
那就是按需
这是为实际读取和写入你的应用程序支付费用的简化版本
但这比预留模式贵两倍或三倍
所以很明显，当你有一个非常不寻常、不可预测的工作负载时，就是这样
或者这可能是你的开发环境
让我们假设你24小时都不使用表
但可能一天中有一个小时
你会大量使用表
因此这是一个巨大的容量模式
因为它实际上根据你的使用情况来构建你
这真是令人惊讶
现在提供了容量模式
这是我们花了大部分时间理解的一个
为了理解并计算读写
所以我们进入容量计算器
如你所见
你可以指定平均项目大小
例如 六千字节
你想要每秒读取多少次
也许每秒读取三次，每秒写入两次
你想要读取的类型，所以最终一致性和强一致性
有事务 但我稍后会详细解释
现在他们想要压倒你
所以最终或强一致性
然后对于正确的一致性
相同的标准或事务
但是再次交易型 稍后会看到
正如我们所见，根据我所选择的，它给了我rcu和w cu
以及我的桌子我将为我的桌子估计的成本
这是一个相当实用的计算器
我建议你花一点时间练习这些设置
你试着猜对了
因为这张桌子的rcu和w cu
因为考试会问你
现在 让我们看一下表的容量
这样我们就可以明显地设置自动扩展
我不仅仅是为了读和写
因此您需要配置容量单位
它们不会随时间变化
除非您手动更改它们
但你也可以设置自动扩展，自动扩展真的很酷
因为我们只是在说
我的min和max
我愿意考虑
以及我的利用率百分比
B会尝试
例如 如果我们有100个最大容量的100个
它会设置为100
WCU 如果您实际消耗平均
70个WCU
但如果您消耗
说7个W
然后自动扩展将自动启动
对于该表，所需的容量单位将为10
所以扩展很好
因为你不需要太费劲地设置WCU和RCU
您只需要考虑我的min，max和我的目标利用率
然后您的应用程序
然后mob会做其余的
这是很好的定价和更好的扩展
好的
所以这对读和写的自动扩展都适用
这很好 然后你会得到估计的成本等等
如果我设置自动扩展 最大3和最小1
然后再次
最大3和最小1然后点击保存更改
现在 我将要做的就是
等待一些时间让自动扩展 踢进来看看自动扩展活动
现在
正如我们所见，提供是2和2的WU和RCU
但我们有1 2 3 嗯
在自动扩展的范围内
关于自动扩展活动的刷新 正如我们所见，对于这个表
嗯设置读取ACO设置为1，写入容量设置为1
因为我没有使用表，因此自动启动并运行
它工作
因此如果我刷新这页并移除这里
我们可以看到rcu和w的值都是1
这真的很酷
它工作方式与c2相同
但对于动态b
这就是本节课的内容 希望你们喜欢 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/058_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p58 08. Amazon DynamoDB - Basic APIs - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们看看这些数据API调用
我们可以这样做
如果我去我的表格
正如我们现在看到的
我们正在扫描并且可以选择一个表格
然后点击运行
所以扫描将扫描整个表格
当然会返回许多项目给我们
如果我们想创建一个项目
我们可以这样做，指定用户，所以爱丽丝
四五六
然后我们指定一个时间
让我快速做一下这个，然后t
零五 零六和零
好了
然后一些内容 爱丽丝博客
好的，现在让我们创建这个项目
这是一个put项目
为什么，因为我们将一个新项目发送到dynamodb
我们指定了用户ID，发布时间，时间
并且这是一个新的
所以这里我们创建了 如果你想查看更新项目
我可以做的是操作，然后编辑
然后我将编辑一个特定的属性
所以我编辑了一个博客，并点击保存更改
背后这将做一个更新项目
API调用
所以，我们已经看到了更新
嗯，现在让我们看看获取
例如，如果我点击这个
例如
然后我将进入项目编辑器 当点击这个项目的行
我能够检索这个项目的内容
所以这是一个获取项目
这是做的，所以这很好
现在我们可以做明显的批量操作
我们可以操作并删除项目
这将是一个批处理删除项目
好的，所以批量权利和批量删除
但如果你想删除表格中的所有内容
你可以做一个扫描和一个批处理删除
但这将不是很高效
另一种方法是简单地删除表格并完成
最后，让我们看看扫描查询
扫描确实给你所有的表格
然后你可以应用一个过滤器，如果你想
但这是在客户端完成的这个过滤器
所以这将在你的网页浏览器中过滤
而不是直接在那个mob中
或者我们可以做一个查询和一个查询非常有帮助
因为我们可以指定一个特定的用户id
例如john one two three
然后点击运行
这将给我们所有john one two three的物品
但我们也可以有一个查询并指定帖子时间戳的条件
这是排序键
所以我们可以有等于小于等于大于之间
和以开始所以
如果你想知道所有的帖子
在说2021年11点后点击运行
我们将只获得一个返回项
但如果我们做2021
2021年09
我们将得到两个项目
所以我们可以看到查询在这里只是用户id和帖子时间戳
我们不必 我们不能在内容上查询或搜索内容
如果我们想要的话我们可以在内容上过滤
但这将在客户端完成
这真正展示了使用分区键的力量
例如哈希键和排序键
好的 这就是全部
我们已经看到了mob的所有api
让我们去做一个扫描并检索数据
我希望你喜欢这个讲座 我将在下一个讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/059_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p59 09. Amazon DynamoDB - Indexes (LSI & GSI).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 现在我们来谈谈dynamodb的索引
你需要知道的有两种索引
第一种是本地二级索引
lsi将为您的表提供一种替代的排序键
您拥有基础表中的同一分区键
但你将获得一个额外的排序键
该排序键由一个颜色属性组成
它可以是一个字符串 一个数字或二进制
你可以每桌获得最多五元的优惠
现在我必须在创建表格时定义
所以你不能在表格创建后创建它们
所以你需要仔细考虑你想要如何设计你的表格
接下来是你的lsi
你可以从你的主表中选择一些或所有属性
所以你在你的lsi中选择
如果你想要只可能有一个特定的属性
因为这就是你试图查询的
因为这是你试图查询的
所以如果我们以这里为例
这是我们的表格
里面有用户ID
游戏ID 游戏
时间戳 分数和结果
好的，现在我们可以在用户ID和游戏ID上做简单的查询
但是我们不能在用户ID和时间戳上做查询
为了做这个 我们需要进行扫描
然后在服务器端做一些
嗯 一些客户端过滤
如果你想根据用户ID和时间戳进行查询
我们需要创建一个LSI并在属性上定义LSI
游戏时间戳 如果我们这样做
那么我们可以进行查询
给我所有由该用户在2020年和2021年之间的游戏
等等
好的 所以这是你必须理解的非常重要的事情
这是与之前一样的分区键
但我们有一个不同的排序键
感谢一个lsi
我们有gsi或全局二级索引
这将给您带来不同的东西
所以这是一个替代的主键
所以你可以有一个不同的哈希键
一个不同的分区键
或者你可以从基础表中获得不同的哈希键和排序键
这很有帮助
如果你想加快对表中非键属性查询的速度
所以索引可以由标量属性组成
一个二进制数字符串
再次你可以指定你想要在索引上投影的属性
并且对于这个索引
虽然它很特殊，因为它有点像一个新的不同表
因此对于这个索引你必须为rcu和w c's预留
现在gsi很强大，因为它们可以在表创建后添加或修改
那么我们来创建一个非常简单的表格，其中包含用户ID
游戏ID和游戏时间戳
有了这个表格
我们可以根据用户ID进行查询
所以给我这个用户的所有游戏
但我们不能根据游戏ID进行查询
正如你现在看到的那样 如果你需要根据游戏ID进行查询
在客户端引入扫描然后过滤将非常困难
因此我们将创建一个gsi
全局二级索引
好的 这将使我们能够通过游戏ID查询
因此，全局二级索引的分区键现在是游戏ID
排序键可能是
例如 游戏时间戳
这是我们想要查询的
属性是用户ID
因为我们已经对用户ID属性进行了投影
所以你可以看到，在这个例子中，我们通过定义一个新的分区键和排序键，创建了一些全新的查询。
通过定义一个新的分区键和排序键，我们可以创建一些全新的查询。
这就是为什么理解你如何查询数据非常重要。
理解你如何查询数据，理解你如何创建你的本地二级索引和你的全球二级索引。
我们已经看到了LSI在GSI中非常不同的目的。
让我们谈谈这些索引和限速。
当你有一个GSI时，如果权限在GSI上被限速，
那么主表也会被限速。
所以这是一个在考试中非常重要的注意事项
即使主表的w的没有问题
如果他们在gsi上被限制
那么主表 无论什么情况都会被限制
因此请仔细选择你的g签名批注键
并分配你的wxu容量
非常小心 而对于lsi所以局部次要索引
他们会使用主表的wcu和rcu
并且没有特别的威胁考虑
好的 这就是这节课的内容 我希望你喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/060_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p60 10. Amazon DynamoDB - Indexes (LSI & GSI) - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们看看如何创建索引，以便回到我的表
我将创建一个新表
我将其命名为demo indexes
我们需要选择一个分区键
让我们选择用户ID和排序键游戏时间戳
这将允许我们按用户ID和游戏时间戳查询
对于这一点，我将自定义设置
我将说我想要1rcu和1w cu的预留容量，太好了
在这里我们可以定义我们的二级索引
你可以看到我们可以创建本地索引或全局索引
现在，本地索引只能在创建表时创建
而全局索引可以在之后创建
所以我们可以创建一个本地索引
在这里我们需要指定一个不同的排序键
正如你所看到的，我们无法指定一个不同的分区键
因此，用户ID将仍然是这个索引的分区键
但我们可以指定一个不同的排序键
例如 假设我想创建一个本地索引
排序键将称为游戏ID
所以现在索引名称为游戏ID下划线索引
然后我们想要投影到这个索引的属性是什么
我们只想要所有键
或者只包括我们指定的特定属性名
所以我们保持简单，设置为所有
所以我们刚刚创建了这个索引
我们可以继续创建一个全局二级索引
我们可以选择指定不同的分区键
以及可选择不同的字段排序
以及投影一些属性
那么我们现在先不创建这个全局二级索引
这将创建一个本地索引
好的 然后点击创建表
好的 所以我的表现在已经创建了
让我们看看现在我们如何查询它
所以我去查询
如你所见 我可以查询表或索引，有两个选项
我可以查询我的演示索引
这是我要查询的表 所以我可以指定一个用户ID和一个游戏时间戳
或者我可以查询我的索引并指定一个用户ID和一个游戏ID
正如我们所见，这个本地索引允许我以不同的分区键进行查询
不同的排序键
在同一个分区键下
所以让我们回到表详情并转到索引
标签 我们可以看到已经定义了一个本地二级索引
所以这一个 我们不能再创建一个
所以我必须在创建表时定义，而不能在之后
而gsi
所以全局二级索引可以在之后创建
所以我们可以创建一个索引
我们可以输入一个完全不同的分区键
例如游戏ID，排序键可以是
例如游戏时间戳
好的 这给了我一个gsi
现在我们也需要为my gss创建一些容量
本地二级索引会消耗主表的rcu和wu
而对于全局二级索引
你需要为你自己的读写容量
所以要么我们从主表复制，要么我们自定义设置
我们可以再次指定自动缩放，开或关
我们就复制主表
有一个1和1的rcu和w
然后我们想要投影哪些属性
这个全局二级索引现在将被创建
记住，如果你查询很多，那么gsi可能会被限制
然后主表的读写也会被限制
而lsi只是消耗主表的rcu和wu
好的 现在我的gsi已经创建
我现在可以回到我的物品视图
我可以查看我的表
我现在可以按游戏ID，游戏时间戳索引查询
所以我们可以看到
分区键和排序键是我的游戏ID
我的排序键是我的游戏时间戳
这真地向你展示了索引的全部力量 我希望这说得通 我会在下一节课再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/061_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p61 11. Amazon DynamoDB - PartiQL.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们快速谈谈 party ql 对 dynamodb 的支持
它允许您使用类似 SQL 的语法来操作 dynamodb 表
这就是这些语句看起来的样子
然后你可以从这里插入
例如，或更新，或选择，或从 dynamodb 表删除项目
这是为了允许那些更自信使用 SQL 的人
仍然能够与 dynamodb 交互
它还支持批量操作
如果您需要 让我来向您展示如何在控制台中如何使用 party ql
所以我在我的表单中，左边是 ql 编辑器
所以让我们打开一些这些表
例如 让我们打开用户表，我已经清空了它
但我可以快速添加一个项目
我可以有一个用户 id 123，以及一个新属性
名字 stefan
这很好
至于我的另一个表，用户的帖子
我又可以添加一些项目
用户 123
帖子 id 456 并且创建项目，为了演示索引
我可以创建一个项目
用户 id 123 游戏时间戳 2022
即使这不太好
然后游戏 id 456
好的 所以我在我的所有表中创建了一些项目
现在如果你去 ql 编辑器
我们可以看看 例如用户表，我可以删除这个
然后我点击用户 我做表扫描
它有一个选择星从用户
这是一个 SQL 语句
如果我运行它
它说语句没有正确形成
现在完成了，你可以看到项目结果
是 stefan 和用户 id 123
我们也可以在相邻视图中看到
如果你想要 因为这是你将在代码中使用的
我们可以将结果下载为 csv 对于更复杂的东西
你可以看看 demo 索引表
我们可以再次扫描这个表
我们需要查看所有项目
但你可以做更有趣的事情
例如你可以查询表
当你查询表时
它会为你生成语句，你说
让我们从用户ID等于的演示索引开始
例如，一二三
然后你也可以有一个结束游戏时间戳等于排序键值
但这是可选的
如果你运行这个，显然你
然后我们得到正确的项目
因此，我们可以开始构建一些复杂的查询
因为我们这里有一个索引
我们可以实际上使用这个索引并扫描它
所以我们可以做选择
从演示索引开始
然后索引的名称
它将基于我的索引返回项目
你可以做很多事情
你可以运行插入语句
尽管它们直接从UI运行并不容易
因为它们不是自动生成的
你也可以设置一个项目
所以你可以更新一个特定项目
并设置属性值
分区键值和排序键值等等
或者你可以 例如
删除一个特定项目，你有一个删除语句
所以这个编辑器是为了那些将要使用SQL对抗那个mob的人
我只是想简要地触发未来
好的 就是这样 我希望你喜欢它 我会在下一节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/062_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p62 12. Amazon DynamoDB Accelerator (DAX).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在我们来谈谈mob加速器或dax
Dax是完全管理的
高度可用且无缝的内存缓存用于dynamodb
想法是您将缓存最流行的数据
因此 您将获得微秒级的延迟用于缓存的读取和查询
您不需要更改任何应用程序逻辑
它与现有的mob api兼容，您只需创建一个dax集群
然后就可以了
Dax 它解决了什么问题
它解决了快捷键问题
如果你反复阅读一个非常具体的键或一个非常具体的项目
那么你可能会遇到限速问题
但如果它被dax缓存
那么你已经解决了这个问题
所以让我们来看一个例子 我们有一个dynamodb
它由表组成，我们的应用程序正在尝试访问这些表
现在我们将在中间创建一个dax集群
这是由缓存节点构成的
我们需要提前为他们配置资源
现在应用程序将直接与dex集群交互
dex集群将从denmodb表中获取数据
这意味着默认情况下某些数据将被缓存
如果你认为缓存
你需要 你认为ttl
ttl将是五分钟
因此，默认情况下，dx集群中的缓存数据将存活五分钟
现在Dex集群由节点组成
因此您需要配置它们
集群中可以有多达10个节点
建议采用多可用区设置
在生产环境中至少推荐3个节点
每个可用区各一个，Dex完全安全
因此数据在休息时加密
您有身份验证
Vpc安全
文化集成等
所以记住 Dax 在这里帮助你缓存 DynamoDB 中最受欢迎的项目或查询
现在我们的问题是 Dynamo DB 加速器和 Dax 之间的区别是什么
所以 Dax 和 Elastic Cache 的区别是什么
嗯 它们可以在考试中结合使用，可能会测试你如何确定是否最好使用 DynamoDB Dax，或者你是否想使用 Elastic Cache
所以对于 Dax，你将会有一个单个对象的缓存
或者使用 Elastic Cache
所以对于 Dax，你将会有一个单个对象的缓存
或者对你的查询或扫描
这是非常方便的
这就是我所说的
简单的查询类型
你的对象 你的查询和扫描
但如果你是在做某种逻辑应用
你知道你在做扫描
然后你在做求和
然后你在过滤出一些数据等等
你不想每次这样做
因为这很耗计算资源
你可以做 你可以将你的应用程序刚刚执行的结果的存储在亚马逊弹性缓存中
并从弹性缓存中直接检索数据
而不是重新查询鸭子并重新形成聚合客户端
所以这可能是一个好方法，实际上可以使用它们两者在一个架构中 好的 所以现在让我们去看看我们如何创建一个dax集群
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/063_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p63 13. Amazon DynamoDB Accelerator (DAX) - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以在 dynamodb 控制台，左边
你有达克斯，而达克斯不是这里的未来一部分
所以创建一个dex集群不会是免费的
但你可以直接去看这个过程
所以你创建了一个集群
例如演示鸭子和节点家族
那么你想把哪种类型的节点添加到你的dx集群中
这可能是r类型的内存或t类型的爆发
因此，这适用于需要较低吞吐量的用例
并且这是为了随时准备好的容量
好的 或者你可以比较所有成员
在这里你可以选择你想要的节点类型
所以你想要一个r5大并且我有我们的far4x大等等
或者你想要有一个t2小等等
所以在这个例子中我将选择一个t2小
然后集群大小
所以你想要一到实际11个节点
它们会不断增加容量
3会给你一个多可用区设置
但是一个将会很好
例如
嗯，只是一个az或用于开发
但如果你有一个或两个节点
你可能会经历可用性降低
好的 所以让我们继续使用一个节点
我只是我只是要去创建这个给你
但你不需要继续前进，因为这会花费你一些钱
现在子网组是哪个子网组
你想把它与...关联
所以演示子网组
所以这必须在特定的子网组和vpc中生存
所以你选择你的vpc id
然后你选择你想要的子网，显然需要三个子网
这意味着你可以有三节点并在高可用设置中访问控制
所以什么是安全组以访问你的dax集群
你需要打开端口8111
好的或者9111
如果你做内在加密
所以我们需要从EC two控制台创建一个安全组
但现在我会保持简单
只使用默认的安全组
只是为了向你展示过程
然后az分配
你是想要自动的
还是你想手动分散你的节点
所以我们会保持自动
接下来为imiso
你需要提供一个iam服务角色
这将使DAX集群能够访问Mob
因此我们将创建这个
我是DAX，正在向DynamoDB进行角色调用
策略将被创建
我们提供了重写能力
嗯 重写 嗯，写入
我们将为所有表提供访问权限
我们可以显然限制某些表如果我们需要的话
然后我们将加密DAX集群中的数据传输和在线
然后在我们的DAX集群中，数据在传输和在线将被加密
这很好 然后对于参数组
我们将选择现有的一个
所以这一个，我们可以在左侧定义更多的参数
感谢参数组
这将基本告诉如何缓存项目
感谢时间到生命
以及查询时间到生命
所以这是作为参数组的一些设置
但默认情况下
这个给你5分钟的项和时间到生命，查询时间到生命
好的
维护窗口 显然DAX会偶尔进行补丁和升级
所以这是为什么有一个多设置是好的
所以你可以说没有偏好或指定你的时间窗口
你的标签 然后你就可以开始了
你可以审查并创建你的集群
所以我的DAX集群现在已经创建了，让我们看看
所以重要的是我想让你看的是这里有一个集群端点
这是您的应用程序应该利用的端点
只需利用DAX的功能
现在我们可以查看节点
所以我们可以查看节类型
每个节点的vcpu和内存等
如果我们想要的话，我们可以随时间添加节点
但正如你所见 我们不能更改节类型
好的，我们需要创建一个新的DAX集群，如果你想要的话
我们可以有一些监控
所以我们可以做警报和指标，关于缓存是否被正确使用
所以缓存命中 缓存未命中，对项和查询
CPU利用率等等
所以这非常有用，以便看到DAX是否对你有效，事件
以及数据库的事件监控
以及设置
如果你想修改一些设置
例如参数组
网络配置
安全配置维护窗口和标签
好的 这就是dex的全部内容
我希望你喜欢它，现在我只想删除这个集群
包括所有天际警报 我会在下一节课再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/064_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p64 14. Amazon DynamoDB - Streams.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们看看 dynamo db 流
流是项目级修改的有序列表
例如创建
更新 和删除
所以每当您插入项目或修改它或删除它时
那么修改将在流中可见
流将随时间在表中表示所有修改的列表
流记录可以发送到多个地方
例如 kinesis 数据流
所以你可以将lb流式传输发送到kinesis
然后根据你的需要进行处理
你也可以使用lambda函数直接读取你的dynamodb流
或者你也可以使用kinesis客户端库应用程序直接读取dynamodb流
从dynamodb流中读取
dynamodb流的数据保留时间为24小时
所以你需要确保将其保存到某个地方
你可以看到数据流，你可以有更长的保留时间
或者使用任何lambda或kcl应用程序将其保存到更持久的地方
使用dynamodb流进行实时响应的用例
在你的 dynamodb 表中发生
例如 有一个流程来欢迎你向你的用户发送欢迎邮件
进行数据分析
将流转换为衍生表并创建 mob 中的表
或者将数据发送到 open search 进行索引以在 mob 上提供搜索功能
或者如果你想实现全局表和跨区域复制
首先你需要有流
所以我们看一下 mob 流的架构
所以我们有我们的应用程序它在表中执行创建和删除操作
并且这些更改中的任何一个都将出现在 dynamodb 流中
因此，从那里你可以看到流可以接收你的 dynamodb 流
因为我们正在使用 cad
可以看到流和我们可以有而不是火喉作为结果
然后可能将其发送到 amazon redshift
以对你的数据进行一些分析查询
然后 modb 或者发送到 amazon
免费用于这些更改的归档，以防我们需要或者发送到开源服务
好的 对其进行索引
创建一个在您的dynamodb表上的搜索功能
这种架构的酷之处是几乎一切都是由aws管理的
如果您想添加自己的定制逻辑
您可以使用处理层，其中您可以创建 either a can you is client library app
也许运行在 e C
Two 或者一个lambda函数，该函数将从 mob streams 读取
从这里您可以实现任何您想要的逻辑
所以 例如，您可以使用 amazon s 发送消息或发送通知
你可以进行一些过滤转换
然后将数据重新插入到dynamodb表中
例如 你也可以使用lambda将数据发送到open search中
如果你想这样做 好的
这给你提供了不同架构
以及使用dynamodb streams时打开的所有可能性
如果我们考虑流
那么在流中我们有什么
我们有选择信息出现在其中的能力
所以你可以 例如
只使用键 它将只显示所有被修改的键属性列表
新图像表示修改后的新项目
所有图像表示整个项目
但在它被修改之前
它是什么样子的
如果你想获取所有信息
你可以获取新和旧图像
这给你提供了新旧项目的新和旧图像
因此你可以看到哪些变化
哪些变化已经发生
你可以看到 嗯 抱歉 流由分区组成
就像kenny的数据流一样
所以它们非常相似
这就是为什么kinesis客户端库可以对抗b流和kinesis数据流
b流酷的地方是
我们不需要配置任何分区
这是aws自动完成的
所以它是一个无管理的方法
如果你启用了流
你应该知道记录不会回溯到流中
在启用后 好的
这是一个考试技巧
一旦你启用了流
你将会 你会收到基于你dynamodb表中更改的更新
最后让我们看看dynamodb流和lambda是如何工作的
为此我们需要定义一个事件源映射来读取dynamodb流
然后你需要确保lambda函数具有适当的权限
从dynamodb流中拉取数据
然后lambda函数将被同步调用
让我们以一个例子来说明
表插入到dynamodb流中
Lambda函数会有一个事件源映射
这是一个内部过程
它将从动态流中拉取数据
并从webb流中批量获取记录
当一些记录被传递给事件源映射时
事件源映射将同步调用你的Lambda函数
以从你的bodb流中获取一批记录
好的 这就是本讲座的全部内容 希望你喜欢 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/065_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p65 15. Amazon DynamoDB - Streams - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来获取用户的帖子表
然后在上面我们将启用流
为了做到这一点，让我们转到导出和流
在这里，我们将有dynamodb流详细信息
我们将启用它
现在 我们可以选择我们想在dynamodb流中看到的类型
在我们的dynamodb流中
它可以是关键属性
新图像 旧图像或新和旧图像
所以我将保留最后一个选项，以获取尽可能多的信息
我将启用此流
好的 所以现在我的流已启用，在其中
如你所见 如果我滚动下来
有触发器和触发器是
这个流将触发什么
我们可以创建一个触发器
在这里我们有一个lambda函数可以调用
每次您的dynamodu流更新时
那么，让我们创建一个新函数 好的，我们可以使用蓝图
在这里我可以输入dynamodb
我们有一个dynamodb处理流python
这将记录对表的所有更新
这很好 让我们配置它
我将其命名为lambda demo dynamo db stream next
我们将创建一个新的具有基本lambda权限的角色
我们将确保编辑此角色
以添加读取mob的权限
对于mob触发器
我们需要创建触发器
这将是用户的帖子
是哪个表 用户帖子表
是的，确实
批处理大小为100
好的 这是同一时间读取的记录数量
批处理窗口 如果您想在调用函数之前收集记录
以便更高效
起始位置
您是否想从流的开始或结束开始
如果流已经创建
我们很好
我们能够触发 并且 正如你所看到的，它只是将记录打印出来
我们将记录输出到流中
这样我们就可以在clywatch日志中查看它
现在我们已经创建了一个函数
但是我们遇到了一个错误 错误是记录
函数无法访问我们的流
因为我们缺少
我是权限 所以我们要修复这个问题
所以我们点击我们的函数
然后在配置下我们将转到权限
这是执行角色
现在我们必须点击这个执行角色
我们将为读取Mob添加必要的权限
我们将附加一个策略
我将查找dynamodb
我们将拥有dynamodb只读访问权限
因为我们正在做的是，实际上我们从 dynamodb 读取
你知道 读取从 dynamodb
所以这很好
嗯，还有这个
它也很好读取
嗯，从 db 所以我们会附上这个以防万一
嗯 但这是针对 lambda 的
所以可能稍微好一点
让我们将此策略附加上
说实话 这些中的一个将会努力使这尽可能简单
这就是为什么我没有在这上面花费太多时间
所以让我们刷新一下这页
看起来我们可以继续
所以我们有更多的
嗯 在 dynamodb 的动作
所以这是好的
现在我们刷新这个
我们可以选择这个功能并将批次大小设置为一百
我们创建了这个触发器
所以现在这意味着我们的dynamodb流将触发我的lambda函数
如果我回到我的lambda函数并刷新此页面
我们可以看到mob确实触发了我的lambda函数
所以这是与这些设置启用的集成类型
好的，所以接下来
我将要做的就是测试它
我们将去我们的桌子，我将要做的是
点击查看物品 我们将做一些事情
例如 让我们取这个物品
约翰的第二个帖子
我们将操作
编辑它
然后我将进行修改
所以我将说这是一个第二篇帖子
编辑并点击保存更改
所以这很好 然后我们将取爱丽丝
我们将操作
然后复制
它将创建一个新的东西
我将添加一些更多的数据
嗯，一个新的爱丽丝博客
然后创建项目
最后我们实际上不喜欢这个博客
所以我将
嗯 删除它 所以我将操作
然后嗯
删除项目 是的
好的 所以我们做了三种类型的操作
我们有一个更新
一个创建和一个删除
所以我去了做我的lambda函数
但函数执行了这个代码
这是打印的 所以记录这些事件
所以我需要做的就是进入云观察日志
并查看我们是否在这些日志中看到了这些信息
所以点击查看云日志
在这里我们有一些关于这个日志流的信息
正如你所看到的，在这个日志流中
你得到了大量的信息
好的，我们得到了一行
所以这是一次修改
这是dynamodb记录
所以它给你键
用户ID以及新的图像
好的，内容
所以我们可以看到是的
第二篇帖子已编辑
我们可以看到旧的图像是什么样子的
所以这是为一个请求
然后我们有一个插入
所以我们可以看到它将会是db记录
然后新的图像和老的图像
因为显然我们是插入
所以之前什么都没有
然后我们删除并且再次删除操作被记录
我们有旧的图像并且显然没有新的图像
因为事物被移除
好的 这相当容易
我们只是启用了流
并且它到达了一个lambda函数并且lambda函数记录了它
但这是基础来有这些种集成与nb流
好的 最后
请确保只是禁用触发器
所以在dynamodb
你取这个触发器 并且禁用它
或者删除它 无论你想要什么
并且你会很好
所以这就是这个讲座 我希望你喜欢它 并且我将在下一个讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/066_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p66 16. Amazon DynamoDB - Time To Live (TTL).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来谈谈生存时间
生存时间允许你自动在过期时间戳后删除项
所以想法是你会定义一个列
然后你说现在的时间超过这个列的值
那么请删除项
有一个项目被删除的时间生存
约束不消耗任何wu
所以没有额外费用
这个时间戳必须是一个数字，代表Unix纪元时间戳值
正如我们在实践中看到的
现在过期的项不会立即过期
他们保证会在40分钟内过期
在过期后的8小时内
好的 但在现实生活中这实际上很好
如果我们看一张表格
例如 一个包含两列的会话数据表
用户ID和会话ID
我们希望添加一个过期时间
我们的桌子的ttl将是什么
我们将定义
每个会话的过期时间是什么
当你去那里时，mob有一个扩展过程
它会查看当前时间并说当前时间是这个
它会标记
扫描表格 并过期那些显然有ttl纪元时间的项目
小于现在时间
然后一个第二过程会扫描并删除这些项目从表格
这就是ttl的工作方式
这些已过期且已被删除的项在读取时仍会显示
查询和扫描 如果你不想要它们
你需要进行一些客户端过滤
因此，可能有一些已过期的项已经在你的查询中
你需要等待多达40小时才能看到它们被删除
当项被删除时
它们也会从您的索引中删除
包括您的本地二次索引和全局二次索引
每个实验的删除操作都会进入dynamodb流
这意味着任何被删除的项目
由于ttl特性，会进入该流
如果你需要，你可以恢复它
现在 ttl的使用场景包括减少存储数据，只保留当前项目
遵守法规要求
例如 对于会话数据，ttl是一个完美的使用场景
它是ttl的一个完美使用场景
好的 那么我们来看看如何在DynamoDB中定义一个TTL
那么我们开始创建一个表
我将其命名为demo TTL
现在分区键将是用户ID
我们现在不需要排序键
好的 我们将保持 嗯
我们将自定义设置 我们将设置物资和奥蒂斯即将到来
我们将有一个rcu和一个wcu
然后我们继续创建这张表格
所以我的表格现在已经创建
接下来我要做的就是添加一些数据
我要插入一些项目
所以我要创建一个项目
用户ID是约翰
一二三
然后我要添加一个属性
例如 名字将被设置为约翰
然后我希望有一个过期时间
属性或过期时间
实际上这不是一个字符串
它将是一个号码
所以我们过期
然后我们需要给约翰一个过期日期
所以我称之为
在线纪元转换器
让我们先来处理第一个
这就是我们如何将一个即将到来的时间戳转换为纪元时间戳
然后我可以将其输入到数据库中
例如
如果我从现在开始计算五分钟 那么这里就是转换为时间戳
这就是五分钟后纪元时间戳
我将其粘贴并点击创建项目
所以已经创建了一个项目
这就是一个项目
我将创建一个第二个项目
这个叫做爱丽丝
嗯 四五六是用户ID
爱丽丝的名字叫做爱丽丝
我们需要再次设置过期时间
我们可以说 例如
从现在开始一小时
所以我会在这里输入10，然后点击人类日期时间戳
把这个拿进来粘贴并创建项目
现在我们动态数据库表中有两行
好的 它们都有不同的过期属性
现在我们需要定义我们表的ttl
如果我们看我们的表
我们可以看到当前ttl已禁用
所以我可以去附加设置
向下滚动然后寻找ttl并点击
现在我们需要给ttl属性名称
我想过期的数据是什么
所以过期是我给的这个ttl属性名称
然后我们可以运行预览
好的 如果你现在运行预览
它说这两个项目将在一小时内被删除
例如现在的时间
就在这里 我做了运行预览
他说嘿 我想删除的项目没有
但如果我们在一小时后
如果我们做 嗯
例如1010和获取这个epoch
时间在这里粘贴并运行预览
只有约翰将被过期
好的然后我去稍后
如果我去1050并获取你的人性时间戳
获取时间戳并粘贴
运行预览 现在两个项目将被删除
你可以指定一个epoch值或自定义时间
或者在接下来的60分钟内
两小时或七天
这是为了运行一些模拟非常酷
我们可以启用tl
现在tl已启用并且自动
如果我等一小时
我的项目将被完全过期
好的 这相当酷
我们可以做所有在最近24小时内删除的项目的图表
多亏了这个功能
好的 这是一个云云指标
这就是这节课的内容 希望你喜欢 我会在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/067_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p67 17. Amazon DynamoDB - Patterns with S3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在我们来看看我们如何使用亚马逊s ray来使用modb的两种方式
首先，我们将讨论如何在modb中存储大型对象
正如你所知，在你的dynamodb表中
你只能存储最多400KB的数据
所以显然，如果你想开始存储一些图像
一些视频 所有这些东西
dynamodb并不是最好的存储地点
所以相反
我们将做的事情是，我们将有一个亚马逊
一个包含我们大对象的三个水桶
上传一个大对象的过程是什么
假设我们将一张图片上传到亚马逊S3
我们将得到
嗯 对象 键
并且 我们将要做的是
我们将把应用程序的元数据存储到DynamoDB中
所以我们会有一个产品ID
一个产品名称 然后是一张图片
是的，URL 这是一个直接指向亚马逊S3的指针
现在 我们做的是
我们在产品表中有效地存储了非常少量的数据
然后mob和存储了在亚马逊S3中的大型项目
从阅读的角度来看，想要读取这些数据的客户首先从Dynamo DB获取元数据
然后我们将从亚马逊免费获取图像回来
重建这些大型物体
因此我们可以继续下去，推出许多不同的产品，并采用大规模的策略
并且这个策略的酷之处在于，我们在为每个服务使用其最适合的功能。
它擅长于 所以亚马逊三号非常适合存储大型物体
好的 然后，群组对于存储小物件非常有用
那些将要被索引的具有特定属性的
因此，在这个例子中，我们有亚马逊s3的完美组合
然后组合或协同另一个组合
我们可以使用的组合作为索引s三个对象的元数据
所以应用程序将上传对象到亚马逊免费
亚马逊将设置通知
例如 调用lambda函数
该lambda函数将存储对象的元数据到mob表
例如 对象大小日期
谁创建了它
你对这些对象有什么想法
我们为什么要这样做
因为我们在 DynamoDB 表中构建查询要容易得多
然后在 S3 桶上
在 S3 桶上再次
S3 桶并不适合扫描
它用于存储大型对象
并且应该
你应该有一个知道这些对象是什么
它们的属性和如此等等的数据库
通过在 DynamoDB 之上创建应用程序
我们可以回答一些问题
例如 我们想要找到 S3 桶中特定时间戳的对象
或者我们想要找到客户使用的总存储量
或者列出所有对象的属性
或者找到在日期范围内上传的所有 S3 对象
通过查询该 DynamoDB 表
然后我们从 DynamoDB 读取结果
然后从您的 S3 桶中检索必要的对象 所以希望这两种策略有意义
它们很常见 它们可能会出现在考试中 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/068_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p68 18. Amazon DynamoDB - Security.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以，让我们谈谈DynamoDB的安全性和一些其他功能
所以，为了安全
我们有VPC端点，这将可供访问DynamoDB
而不使用公共互联网
并且只将所有流量保持在您的VPC中
访问DynamoDB完全由IAM控制
这使得它在AWS中成为一个伟大的数据库选择
您还具有在休息时的加密
使用KMS或InTransit
使用SSL和TLS
有备份和恢复功能可用
你有两个
所以你有时间点恢复
所以p i t r就像rds
并且没有性能影响
或者我们可以进行正常的备份并恢复它
现在dynamodb中有全局表的概念
所以想法是你有一个多区域
多活动完全复制的高性能表在dynamodb中，以及如何启用它
你需要首先启用modb streams
所以尽管摩比是一个云服务
你可以在本地计算机上获得一个摩比的模拟
称为摩比本地
想法是你有一个本地数据库
你可以用它在本地开发和测试你的应用程序，而不使用dynamodb网络服务
这真的很方便
如果你想要将数据从摩比迁移到或从aos数据库迁移服务
数据库迁移服务是一个很好的选择
例如 从unogodb到摩比
或者then a b到oracle
我的续集 s三等等
现在另一个特性你需要理解在mob周围，将是关于细粒度访问
例如 如果你有客户和应用程序
Web或移动 如果他们需要直接访问我们的动态modb表
那么我们不想给他们
I在权限 和i角色
你知道 直接从aws的用户
这将是真正低效和安全漏洞
相反 我们将使用身份提供者
可以是亚马逊点击用户池
谷歌登录 脸书登录
开放身份验证或 seml
或其他 用户将通过这些身份提供者进行简化流程登录
他们将能够交换凭据
他们只能使用临时的认证
想法是这些认证是临时的
因此它们更安全，并且可以与iam角色关联
但是这个iam角色必须受到限制
因为我们的客户和应用程序可以访问任何mob表
我们希望它们能够只对自有数据进行操作
那么我们该怎么做
这就是细粒度访问控制
好吧 我们有一个联邦登录来获取临时凭证
然后我们可以创建一个iam角色
并且这条我将会有一个条件
并且这种状况将影响用户可以做什么
所以这里是一个样本政策
因此，在这项政策中，用户可以批量获取项目。
获取项目查询 更新项目
删除项目和批量
在特定的桌子上写项目
但这里有个条件
条件是说
只有当主键对应于 dynamodb 时
然后连接器身份
伪变量，将在运行时由特定用户替换
因此实际上 我们所说的是，使用主键
我们只对用户基于主键值进行行级访问限制
因此我们确保用户只能修改和访问自己的数据
你也可以指定属性条件
这将限制特定属性
用户可以在您的无服务器DynamoDB表中查看
好的 总结一下
您可以通过使用联邦登录进行细粒度访问控制
并通过指定主键条件
如果您想限制行级别或属性级别
如果您在列级别限制
在属性级别限制 好的
这就是这节课的全部内容 希望你们喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/069_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p69 19. Amazon RDS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们来简要谈谈亚马逊RDS
关系型数据库服务
它并不是真正与大数据相关
它更适用于小数据
但它会在考试中出现
你需要知道它是什么 它通常是一种不要做的例子
或者可能是如何将RDS数据导入到大型大数据系统的例子
什么是RDS呢
它是一个托管的关系型数据库
并且它可以是下列数据库类型之一
亚马逊aurora
我们稍后会讨论
你也可以托管一个mysql数据库
一个postgresql数据库
Maria db
这基本上是mysql的开源版本
Oracle或microsoft sql server
所以它是一种方式让aws托管你自己的小数据库主机
所以你不必担心自己维护那个数据库主机
哪个 正如我们所知
做数据库管理员并不总是一件有趣的事情
有点实用
但这不适用于大数据
如我所说，这可能会出现在考试中
作为不要用于大数据问题的示例
或者在从rds迁移到redshift或类似的上下文中
它适用于较小的需求
你可以用一个数据库主机存储所有数据
例如 我用rds和亚马逊aurora来备份
嗯 我的网站
所以对于wordpress
它使用rds作为其存储
为此
这是一个很好的谈论酸合规的时间
这在关系型数据库的普遍世界中经常出现
并且所有的rds数据库都提供完整的酸合规
所以你知道 如果你需要一个满足这些要求的数据库
RDS可以是一个解决方案
前提是你不需要无法在一个主机上存储的大数据集
现在 在技术上 它实际上可能使用了多个主机
你知道这对我们来说都是一种黑箱
但是将RDS视为一种小型数据解决方案仍然有意义
ACID无论如何都代表原子
一致的 孤立且持久的
这里再给你们复习一下
原子性确保了事务整体要么成功执行
要么如果事务的一部分失败
那么整个事务都会被无效化
如果你发送的事务做了多件事
如果其中任何一部分失败
整个事务都会被丢弃
一致性确保了写入数据库的数据
作为交易的一部分必须遵守所有定义的规则和限制，包括约束、级联和触发器。
隔离确保每笔交易都是独立的，这在实现并发控制中至关重要。
最后，持久性确保一旦交易成功完成，数据库中的所有更改都将是永久的。
让我们谈谈亚马逊Aurora，这也是RDS的另一种选择。
作为交易的一部分必须遵守所有定义的规则和限制，包括约束、级联和触发器。
隔离确保每笔交易都是独立的，这在实现并发控制中至关重要。 最后，持久性确保一旦交易成功完成，数据库中的所有更改都将是永久的。
让我们谈谈亚马逊Aurora，这也是RDS的另一种选择。
作为交易的一部分必须遵守所有定义的规则和限制，包括约束、级联和触发器。
隔离确保每笔交易都是独立的，这在实现并发控制中至关重要。
它支持MySQL和PostgreSQL数据库
例如 如果你想用Amazon Aurora备份自己的WordPress网站或其他东西
你可以这样做 那么它看起来就像MySQL对WordPress
至少对WordPress来说 所以它是MySQL和PostgreSQL的托管替代方案
根据亚马逊网络服务的营销术语
它比MySQL快五倍
比PostgreSQL快三倍
当然，你的里程可能会有所不同
实际上，实现这些具体收益可能并不可能
这有点营销术语
但这更快
这也很便宜 它可以是商业数据库成本的十分之一
这有点不公平的比较
尽管 因为MySQL不是商业数据库，对吧
所以他们基本上说的是
与获取Oracle或类似的东西相比
这将会便宜得多
但使用开源
MySQL将会便宜得多
当前的存储限制高达128TB每数据库卷
所以请注意，Aurora的存储与实例是解耦的
它还提供了高达15个读副本
如果你需要更高的性能
你可以使用读副本获得更快的
更分布式的
可扩展访问您的基础数据
这是一个很好的功能
这也将复制时间减少到毫秒级
这也是一个很方便的事情
它还提供持续备份到S3
所以你永远不必担心丢失数据
它还提供跨区域和可用区的复制
所以你可以将数据复制到世界各地
无论您如何选择，它还提供了一个新的
或者我应该说 一个名为Aurora Serverless的服务
如果您不想分配硬件
并整个月支付那台硬件的费用
如果您的数据库流量更加动态
或不一致
或者无服务器可能是您更好的选择
它提供与流量相匹配的自动缩放
而不是仅仅支付服务器的费用
一个始终在那里等待您的数据库
这可能或不可能被使用
但如果您的使用案例中您频繁且持续地访问该数据库
您可能更倾向于使用专用数据库实例
但您在Aurora中有选择权
您可以拥有自己的数据库
但您在Aurora中有选择权
您可以使用自己专用的数据库主机
或者您可以使用Aurora Serverless并让该容量自动扩展
就安全性而言，Aurora
提供VPC网络隔离
当然它也可以使用KMS进行静态数据加密
所以数据备份
快照和副本都可以加密
并且可以在传输过程中使用SSL进行安全传输
这就是Aurora的概述，RDS再次
通常不涉及大数据
但Aurora正在朝着有趣的方向发展 所以我们将继续关注
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/070_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p70 20. Shared and exclusive locks in RDS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我想明确指出的一点是使用锁的概念在关系数据库中
这是考试指南中会出现的内容
所以我们最好谈谈这个话题
实现这一目标的一种方式是使用锁命令
锁的概念是防止两个人做同样的事情
同时对某事进行操作并得到冲突的结果
因此，关系数据库会隐式地锁定您的表以防止这种情况发生
您不希望两个人同时对同一数据进行写入
您也不希望人们在数据写入过程中读取数据
直到该数据块的写入过程完成
所以通常为了确保符合酸性
数据库会自动且隐式地锁定事物以防止此类事情发生
你不需要特别做任何事情
然而，你可以显式地锁定表或显式地锁定行，以确保自己的数据
完整性和并发控制
如果你不想仅仅信任数据库去做正确的事情
在某些特殊情况下，你可能想要更多的显式控制那些锁定
所以有两种类型的锁定
有一种被称为共享锁定和独占锁定
共享锁定的语法是for share
在下一页的幻灯片中，我们将看到一个例子
但共享锁允许读取
但阻止写入
它可以被多个事务持有
如果你想让人在事务访问的数据上进行读取
但防止人们在事务期间对它进行写入
你可以说共享
以强制共享锁
你也可以有一个独占锁，阻止对所有资源的读取和写入
并且一次只有一个事务可以持有独占锁
这就是为什么它被称为独占的
它的语法是这样的
那就是说 当我在访问这个数据时
没有人可以读取它
没有人可以写入它 没有人可以查看它或触摸它
除了我 一些例子
这些在我的序列中
语法再次因数据库而异
所以我不会在语法上纠结太多
但如果你想锁定整个表
你可以说锁定表
Employees是表的名称
我想锁定右边
这将锁定整个Employees表，防止写入
当我完成时
我必须说解锁表来释放该锁定
现在红移也有一个锁定命令，它工作得非常相似
为了相同的目的，采取相同的方式
如果我想在做某事的同时确保没有人能写入我的表格
锁定表格是实现这一目标的一种方式
你知道
以考试的角度思考 他们可能会问的大概就是这个
我不知道
我还没有参加过考试 当我录制这段时
我还没有参加考试 因为现在是在beta考试之前
所以我不会给你任何
你知道 禁止的知识
我只是一个受教育的猜测
这也是一个共享锁的例子
所以假设我想要允许读取
但防止写入 在这个事务期间
所以我没有明确地锁定和解锁这里
这些共享和排他锁仅适用于事务
当我在执行选择语句时
因为我正在共享
这意味着在整个执行过程中
其他进程可以读取表
但在执行过程中没有人可以写入
为了完整性，更新
这是一个排他锁的例子
在整个事务生命周期内
直到事务完成，没有人可以读取或写入
所以，确保任何带有锁定的交易都能正确完成非常重要
如果出于某种原因，该交易被中断或未完成
你可能会遇到所谓的死锁问题
这意味着锁定永远不会释放
这是一个潜在的故障模式 再次强调 这可能是考试会期望你知道的内容
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/071_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p71 21. Amazon RDS Best Practices.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


这次考试侧重于操作和数据工程
所以让我们来谈谈一些rds的最佳实践和操作
以优化数据库的性能和操作稳定性
第一条建议是使用云观察来监控你的内存
cpu、存储和rds实例的复制延迟
使用云观察几乎是不言而喻的
如果你要关心任何系统的性能
不仅仅是rds
如果你要进行自动备份
尽量在iops最低的时间段进行
如果你正在备份某物
而当它还在被积极写入时
这将变得非常复杂，不要只是猜测
不要只是说，嗯 没有人在我的数据库中访问2点
不要使用云观察指标来确定这一点
并且基于实际数据来基于此
请注意，如果您的实例的io能力不足
那么在失败后恢复将出现问题
所以最后一件事是你希望数据库
在你这里崩溃，并发现你难以切换到备份实例
因为io能力不足以进行故障转移
所以， 确保你的数据库实例具有足够的io
你可能需要迁移到一个拥有更多的实例
一种获得更好io能力的方法是
将实例迁移到具有更多io的一般用途或按需iops存储
以获得更好的io性能 此外，如果您的应用程序正在访问rds数据库
请确保DNS的生存时间
设置为30秒或更少
你不想处于一种需要故障转移数据库
而你的故障转移策略是更改DNS记录
从主机到另一个主机，然后你会发现
DNS的缓存时间为1小时
所以，而不是在30秒内切换
你现在必须等待1小时
直到应用程序的DNS缓存超时
所以请确保您考虑了DNS的生存时间
如果您打算使用DNS作为故障转移机制
并在需要之前进行故障转移测试
你不想在压力下才去解决这个问题
因为当您的应用程序在亚马逊上不再运行时
我们过去称此为游戏日
我们会在一个测试环境中模拟亚马逊的大规模故障
并练习我们如何处理这种情况
所以，在真正需要之前练习故障转移是一个好主意
确保你的rds实例分配了足够的内存
以包括你的全部工作集
再次
你不必猜测这一点
你可以监控读取IOPS指标
如果该指标较小且稳定
这暗示着你几乎没有触及硬盘
因此你可能拥有足够的内存来包含你的工作集
然而 如果它不稳定且高于你的预期
这可能意味着你触及硬盘的频率高于预期
因此你需要更多的内存
此外，如果你的
嗯 RDS中的数据通过应用程序对外部暴露
以某种方式暴露给外界或网站
你可能想要考虑在AWS API网关中实施速率限制
以保护你的数据库
如果你想保护你的数据库免受拒绝服务攻击等，
你可以在API网关中设置速率限制
以确保没有人可以超频攻击你的应用程序
超过你设计的合理频率
此外，RDS的性能也可以得到提升
你可以优化你的查询
查询优化一
零一是使用索引，只要你能，所以
只要你有一个选择语句
确保你看你的查询并确保你有索引
你需要使它们高效
如果你不确定，你可以使用解释计划
来识别任何索引
你可能需要支持那个查询
另一句话说同样的事情是
避免全表扫描
所以，如果你进行全表扫描
这意味着你的查询有问题
或者你没有你应该拥有的索引
全表扫描是邪恶的
索引是避免它们的方法
我将使用分析表命令
确保表本身处于良好状态
如果你有where子句
尽量使它们尽可能简单
它们可以造成很大的额外负担
然后有一些特定的引擎优化，我们将在下次讨论
所以在我的马里亚 db续集中
这里有一些具体的建议
一个方法是保持你的表格在十六太字节以下
理想情况下，少于一百千兆字节
否则，您可能会遇到我与我的近亲 sequel 的性能问题
玛丽亚数据库
确保你有足够的内存来持有你活跃使用的表的索引
尽量少于一万张桌子
因为更多的可能会导致问题
至于你的选择存储引擎
aws建议使用in o b 如果你使用postgresql
有一些提示当你加载数据到postgresql
起初 显然这可能会很慢
所以你要确保你禁用db备份
并且在你进行初始大量加载到postgresql时禁用多az能力
此外 有一些特定的参数你可以调整以加快速度
我不惊讶这些会出现在考试中
但一些是显而易见的，确保在操作期间关闭自动真空
所以，加载数据到postgresql可能会很慢
有一些特定的事情你需要做以加快速度，当你不加载数据时
尽管你想要在自动真空打开
这将对维护性能很重要
继续
最后对于sql server
嗯 你需要确保你使用rds sdb事件
以监控可能在sql server中发生的任何故障转移
此外，如果你使用sql server在多az可用性区环境中
不要启用简单恢复模式
离线模式或只读模式
所有这些都会破坏多az部署
所以很重要记住
他们建议你将sql server部署到所有可用性区
为了冗余目的
并确保它们能像预期的那样工作
最后，如果你使用oracle
嗯 那就是自己的野兽
嗯 优化和oracle可能是自己的课程主题
我真的怀疑他们会详细说明
因为嗯
人们通常使用rds的开源选项
不管怎样 这就是rds优化的概述 一些考试中需要记住的事情
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/072_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p72 22. Amazon DocumentDB.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈文档数据库
就像我们之前讨论的aurora
是AWS实现一种大型云服务的方式
原生版本的PostgreSQL和MySQL
我们有文档数据库
这是为MongoDB设计的AWS版本
MongoDB 如果你不知道的话，那就是屏幕上右上角的标志
它是另一种NoSQL数据库
你需要记住这一点，以便参加考试
所以文档数据库是一种NoSQL数据库
它基于MongoDB技术
嗯 技术
所以它与MongoDB兼容
MongoDB用于存储、查询和索引JSON数据
你有与文档数据库相似的部署概念
这意味着它是一个完全管理的数据库
它具有高可用性
数据跨三个可用区进行复制
文档数据库存储会自动增长，每次增加10GB
文档数据库已经经过工程设计
它可以扩展到每秒处理百万次请求的工作负载
在考试中
如果你看到与MongoDB相关的内容
想想文档数据库
如果你看到与NoSQL数据库相关的内容
想想文档数据库和DynamoDB
这就是本讲座的内容 希望你喜欢它 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/073_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p73 23. Amazon MemoryDB for Redis.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈亚马逊内存数据库for redis
它是一个兼容redis的持久内存数据库服务
那么，redis和内存数据库for redis之间的区别是
虽然redis的意图是用作具有一定耐久性的缓存
内存数据库实际上是一个具有redis兼容API的数据库
所以它提供了超快的性能
每秒可以处理超过1600万次请求
所以性能真的很高
它是内存数据
但它是多AZ事务日志的持久数据存储
这与redis的运作方式不同
它将无缝扩展
从数十亿字节到数百太字节的存储
内存数据库for redis的应用场景是你的Web和移动应用程序
在线游戏
媒体流等
想象你有很多微服务
它们需要访问一个兼容redis的内存数据库
那么这就是完美的
你使用内存数据库for redis
你将获得超快的内存速度
以及跨多个AZ的多AZ事务日志
这将存储在多个AZ中
并为您提供快速恢复和数据耐久性
如果你需要
好的 在复习中，这将足以参加考试
我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/074_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p74 24. Amazon Keyspaces (for Apache Cassandra).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在我们来谈谈亚马逊的key spaces和key spaces
这是一个在aws上管理的apache cassandra
所以cassandra是一个开源的无sql分布式数据库
因此，key spaces意味着cassandra直接在云中被aws管理
所以它将是一种无服务器的服务类型
它可扩展 它高度可用且完全由aws管理
它会自动根据应用程序的流量扩大和缩小表
根据应用程序的流量自动扩大和缩小表
数据表将跨多个az进行三次复制
在键空间上进行您的查询
你将使用Cassandra查询语言或SQL
因此，多亏了这个
你将得到个位数
毫秒级延迟在任何规模下
你可以每秒进行数千次请求
两个需要注意的容量模式
这就是像数据库一样
您拥有按需模式
然后你有自动扩展的配置模式
这就是和 DynamoDB 一样的东西
你可以获得加密功能
备份和 35 天内的时间点恢复
使用案例是存储 IoT 设备信息
时间序列数据
从考试角度来看
看到 Apache Cassandra 时
只需考虑 Amazon Key Spaces
好的 这就是这节简短课程的全部 我希望你喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/075_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p75 25. Amazon Neptune.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈亚马逊Neptune
Neptune 是完全管理的图数据库
所以图数据集的一个例子
将是 例如 我们所知道的一个例子是社交网络
如果我们看一下社交网络
人们是朋友 他们喜欢
他们连接 他们阅读评论等等
所以用户有朋友
帖子会有评论
评论有用户喜欢
用户分享 和喜欢帖子
所有这些东西都是相互关联的
所以它们创建了一个图
所以Neptune 是一个伟大的数据库选择
当涉及到图数据集时
Neptune 在三个可用区中复制，最多可达15个副本
它是构建的 它是用于构建和运行将与高度连接的数据集相关的应用程序
例如社交网络
由于Neptune 优化了运行复杂和困难的查询
在这些图数据集上
您可以在数据库中存储多达数十亿的关系
并以毫秒级速度查询图
它具有跨多个可用区的高可用性
它也是存储知识图的绝佳选择
例如 维基百科数据库是一个知识图
因为所有维基百科文章都是相互关联的
欺诈检测
推荐 引擎和社会网络
所以从考试角度来看
任何与图数据库相关的事情
不要再多想Neptune
就是这样 我希望你喜欢它 下次再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/076_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p76 26. Amazon Timestream.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈亚马逊时间流
名字表明它实际上是一个时间序列数据库
所以它是完全管理的 它很快
它可扩展 并且它是无服务器的
那么什么是时间序列
嗯 它是包含时间的一堆点
例如 这是按年份的图表
这是一个时间序列图
您可以自动调整数据库的规模以适应容量
您可以存储和分析每天数万亿的事件
如果您有一个时间序列数据库
它将比使用关系数据库更快
并且更便宜
这就是为什么需要一个时间序列数据库的原因
您可以进行定期查询
您可以有多个测量值的记录
并且有完整的sql兼容性
最近数据将存储在内存中
然后历史数据存储在成本优化的存储层中
以及您拥有时间序列分析功能
以帮助您分析数据并在接近实时中找到模式
此数据库就像AWS上的所有数据库一样，支持传输中及静止时的加密
因此，时间流的用例将是具有物联网应用的操作性应用，实时分析
但与所有时间序列数据库相关的一切
就架构而言，时间流就在这里
它可以从aws物联网接收数据
物联网可以接收数据 互联网事物可以接收数据流
Prometheus电报可以接收数据
有相应的集成
可以通过相同的过程将数据流发送到亚马逊时间流和亚马逊mk
Apache Flink可以进行数据分析
Flink可以将数据发送到亚马逊时间流和亚马逊mk
在时间流方面，什么可以连接
我们可以在哪里构建仪表板
使用亚马逊快速站点
我们可以使用机器学习
想象亚马逊sagemaker
我们可以使用grafana
或者因为你的数据库有一个标准的jdbc连接
任何与jdbc和sql兼容的应用程序都可以利用亚马逊时间流
就是这样 我想从考试来看
你只需要记住时间流的高阶概念
但是我也想给你提供更多的细节
这就是这节课的内容 我希望你喜欢它 我会在下节课见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/077_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p77 27. Amazon Redshift Intro & Architecture.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


接下来让我们深入亚马逊红移
红移是AWS的分布式数据仓库解决方案
所以它是一个跨整个集群的PB级数据仓库
但它是全面管理的 所以你知道
你不需要担心 嗯
管理那个集群
他们将负责所有服务器的维护
鉴于大数据的世界往往涉及数据仓库的世界
并且处理大规模的数据集
那么红移在考试中花费大量时间谈论这一点就不足为奇了
所以我们也会花很多时间在上面 红移需要很多深度
所以注意
伙计们
这些东西在高层次上都很重要 红移是什么
它是快速而强大的
全面管理的PB级数据仓库服务
亚马逊声称其性能比其他数据仓库高出十倍
因此它不仅具有巨大的可扩展性，而且非常快速
并且通过机器学习实现高速
大规模并行查询执行
称为MPP
以及使用列存储
我们之前讨论过的
并且使用高性能磁盘
请注意
红移是数据仓库
因此它专门设计用于在线分析处理
OLAP 它用于查询您的数据并从中获取见解
从分析角度来看，它并不适合OLTP，适合OLTP
通常您将希望更多的基于行的存储 因此您不会期望在红移数据仓库上以巨大的事务率进行大量交易
期望快速响应
它是作为分析工具设计的
这就是为什么它在这里属于分析部分
他们还声称，除了超级快速和超级可扩展之外
它还超级便宜
他们声称它是最经济的云数据仓库
并且使用红移没有前期成本
这与在数据中心构建大规模数据仓库形成鲜明对比
我可以告诉你，亲自体验过，只需支付您消费的资源费用
并且这可能会降低成本十倍
您只需支付您消费的资源费用
并且在数据中心构建大规模数据仓库形成鲜明对比
并且这可能会降低成本十倍
只需支付您消费的资源费用
或者更少的传统数据仓库，这些存储在机房内
它还提供了对结构化数据的快速查询能力
使用熟悉的SQL基于客户端和BI工具
只需使用标准ODBC和JDBC连接
所以它对外界看起来就像另一个关系数据库
您可以连接任何分析或可视化工具
您可以在红移之上使用它
它也很容易扩展
您可以轻松扩展或缩小您的分簇
只需在AWS管理控制台中点击几下
或者通过单个API调用
所以如果您需要扩展它或缩小它
这很容易做到
但它不会自动弹出 但至少它是容易的
它还使用复制来增强您的可用性，并使用持续备份来提高数据耐久性
并且它可以自动从组件和节点故障中进行恢复进行监控
它与CloudWatch集成并为计算使用情况
存储使用情况
以及对集群的读写流量进行监控
所有这些都在CloudWatch中免费提供
您还可以添加自定义指标
使用CloudWatch的自定义指标功能
它还通过AWS管理控制台提供查询和集群性能信息
这可以帮助您诊断性能问题
例如哪个用户查询消耗了大量资源
列出的红移用例包括
加速您的所有分析工作负载
如果您只是想让数据仓库更快
您可能希望将数据迁移到红移
正如我们所说 机器学习
MPP和列存储在高性能磁盘上
以及结果缓存使其超级快速
您可能还想使用红移
因为您想统一您的数据仓库和数据湖
稍后我们将讨论的红移光谱
这是一种将未结构化数据导入到S3的方式
作为存储在数据仓库中的另一个表
因此您可以在结构化
数据被导入到红移服务器本身
与存储在S3中的数据湖信息一起进行连接
有点酷
也许您只是想现代化您的数据仓库
并且您知道 使其更快速，更易于扩展，更易于管理
红移可能是一个简单的方法
AWS大数据白皮书中列出了一些更具体的用例
这可能包括分析全球销售数据
存储历史库存数据
分析广告印象和点击
聚合游戏数据
并分析社会趋势
这些都是使用红移或任何数据仓库可以做的例子
更何况 让我们深入研究红移本身的架构
所以基本上我们有集群，这是最高级别的东西
涵盖了整个图景
集群是亚马逊红移数据仓库的核心基础设施组件
一个集群由一个节点组成，你看到这里
并且一个或多个计算节点
您可以包含一个或多个计算节点，数量在1到128之间
取决于节点的类型
因此它不是无限可扩展的
但是128个节点可以存储大量数据
并且每个集群可以包含一个或多个数据库
现在用户数据将存储在计算节点上
领导者节点只是管理与客户端程序的通信以及与计算节点的所有通信
所以它是您外部客户端与红移之间的接口
以及隐藏在计算节点之下
它接收来自客户端应用程序的所有查询
解析这些查询
并制定执行计划
执行计划是处理这些查询的一组有序步骤
然后它协调这些计划的并行执行与计算节点
同时还汇总这些节点的中间结果
最后，领导节点会将这些结果返回给客户端应用程序
让我们更深入地讨论计算节点
计算节点负责执行执行计划中指定的步骤
即从领导节点获取数据并相互传输数据以服务于这些查询
然后它将这些中间结果发送给领导者节点进行聚合
在发送给客户端应用之前
现在每台计算节点都有自己的专用CPU内存和附加的磁盘存储
这些由你选择的节点类型确定
所以在计算节点上
我们有节点切片
所以每台计算节点都被分成切片
并且 节点内存和磁盘空间的一部分将被分配给每个切片
它处理分配给该节点的工作负载的一部分
每节点的切片数量由集群节点的大小决定
那里深度很大 但你真的需要知道
所以，一个集群由一个领导节点和多个计算节点组成
一个或多个计算节点
而计算节点本身 由处理分配给它的数据块的节点切片组成
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/078_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p78 28. Redshift Spectrum and Performance Tuning.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


接下来让我们深入探讨红移光谱，红移光谱允许您查询艾字节的数据
艾字节 请注意
我们已经超越了太字节或拍字节
我们进入了大数据时代
这里肯定如此
在未将其加载到您集群的情况下，S3中未结构化的艾字节数据
所以以几乎相同的方式
雅典娜可以使用AWS Glue目录
在S3数据之上创建表
红移光谱可以做同样的事情
这是同一个想法
只是 而不是在这个雅典娜中拥有一个基于控制台的查询SQL引擎
它实际上看起来就像你的红移数据库中的另一个表
这样你就可以拥有体现你S3数据湖数据的表
以及实际存储在红移集群本身的数据
你可以将它们视为同一件事，并在它们之间进行连接，无论你想做什么
这真的很酷 它允许你对S3中的EB级无结构数据运行查询
不需要将数据加载到红移集群本身
也不需要对数据进行任何转换
它通过允许多个查询同时访问同一数据，提供无限的并发性
在S3中
它可以根据需要扩展到数千个实例
无论数据大小如何，您的查询都将快速运行
它让您可以将存储和计算能力分开
允许您独立缩放每个部分，因此，您可以根据需要缩放存储和计算
所有存储都在S3中进行，Spectrum只做计算
分析数据的一部分
红移光谱目前支持许多开源数据格式
包括avro
CSV Grok
Ion JSON
Orc Parquet
RC文件 Reserta
序列文件
文本文件和tsv
几乎任何常见的开源数据格式
你可以想象如果你有它放在某个s3桶里
Redshift可以解析它并对其进行查询
Spectrum目前还支持gzip和snappy压缩
所以如果你希望你的s3数据进行压缩以节省空间和带宽
你也可以这样做
他们几乎已经想到了一切
回到整个红移这里
红色移位为何如此迅速？嗯，再次
它使用大规模并行处理或 MPP 来实现这一点的数据
查询负载将自动分布在所有节点上
向数据仓库添加节点是很简单的
这也能实现随着数据仓库的增长快速查询性能
它会并行处理所有查询
如果你需要更快的速度或更多的容量
只需向集群添加更多节点
它将自动利用这些额外容量
它还使用列式数据存储
你的数据按列组织
列为基础的系统对于数据仓库和分析来说是理想的
对于大型数据集查询
因为你通常只查看大量列中的特定列
通过按列而不是按行组织你的数据
你可以节省大量带宽和查找时间
列式数据在存储介质上按顺序存储，需要远少于
I/O 从而提高查询性能
通过使用列式存储
每个数据块存储多个行的单列值
当记录进入系统时
Amazon Redshift 透明地
将数据转换为每列的列式存储
这可以避免扫描和丢弃不需要的行
列式数据库通常不适合 OLTP 在线事务处理
所以记住，Redshift 的一个反模式是 OLTP
它适合 OLAP
就像任何数据仓库一样
Redshift 使用 1MB 的块大小
这更有效率，进一步减少了所需的 I/O
请求数量，以执行任何数据库加载或其他查询执行操作 它也可以做列压缩
与基于行的数据存储相比
列式数据存储通常可以压缩得更多
因为它在磁盘上以同一类型的数据格式顺序存储
通常使用多种压缩技术以获得更好的效果
在 Redshift 上不需要索引或材料化视图
因此它占用的空间比传统的关系数据库系统更少
它会自动采样数据
并在数据加载到空表时选择最合适的压缩方案
压缩是列级操作，减少数据存储时的大小
它可以节省存储空间并减少从存储中读取的数据大小
它减少了磁盘
I/O 从而提高了查询性能
当你将数据加载到 Redshift 集群时
通常你使用 copy 命令来最有效地做到这一点
这允许你以分布式并行方式将数据复制到集群中
当你发出那个 copy 命令时
它会自动分析和应用压缩
你不需要做任何事情 它只是自动为你做
但如果你想了解正在发生的事情
它提供了一个分析压缩的命令
这将进行压缩分析并生成一份报告，建议对表进行压缩编码 分析
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/079_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p79 29. Redshift Durability and Scaling.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈红移的耐用性和可扩展性的具体细节
红移会自动将数据仓库集群中的所有数据复制一遍
你的数据将自动备份到s3中
数据将保留三个副本，原始副本、计算节点的副本和s3中的备份
你的数据存储在三个不同的地方
原始副本在你的集群中
还有一个备份副本在你的集群中
此外，它会定期将数据备份到s3中
对于灾难恢复
红移异步地将你的数据快照复制到s3中
并且在另一个地区
它可以启用数据仓库集群的自动快照
默认情况下，保留期为一天
你可以将保留期延长到3到5天
如果你将保留期降至零
然而
自动备份将被关闭
如果你需要从备份中恢复集群
你可以选择一个自动备份 aws将为你创建一个新的data warehouse集群并恢复你的数据
然后你可以从旧的集群切换到新恢复的集群
红移复制数据仓库集群中的数据
并将数据备份到s3中
它会将每个驱动器的数据镜像到集群中的其他节点上
红移将自动检测并替换故障驱动器节点
在驱动器故障的情况下
红移集群将保持可用，某些查询的性能略有下降
红移将从该驱动器的副本重建该驱动器
该副本的数据存储在该节点的另一个驱动器上
单节点集群不支持数据复制，因为没有东西可以复制
在这种情况下
你将不得不从s3中的快照恢复你的集群
在单个节点故障的情况下
红移将自动检测节点故障 并替换你的data warehouse集群中的故障节点
直到替换节点被分配并添加到数据库
集群将不可用进行查询和更新
然而，最常访问的数据将从s3中加载到新节点
所以你可以尽快恢复查询数据
单节点集群不支持数据复制
因此，你又需要从s3中的快照恢复集群
在单节点集群的节点故障情况下
aws建议你的集群至少包含两个节点
在红移集群的可用区断电的情况下
在这种情况下
你将无法使用你的集群，直到可用区的电力和网络恢复
在单节点集群的节点故障情况下
aws建议你的集群至少包含两个节点
现在，在红移集群的可用区断电的情况下 在这种情况下，你将无法使用你的集群，直到可用区的电力和网络恢复
因为红移目前仅限于单个可用区
然而 您可以从任何现有快照恢复集群到同一地区的新可用区
因此，在这种情况下
您最常访问的数据将从S3首先恢复
这样您可以尽快恢复查询
亚马逊正在努力移除此限制
然而 截至2022年11月
他们宣布了三可用区支持，特别是对于A3集群
红移如何实现良好的扩展性
红移集群支持垂直扩展
即增加节点的实例类型，以及水平扩展
即增加节点数量
您请求的更改将立即应用于数据仓库集群
这是操作流程
当您进行扩展时
现有数据仓库集群将保持可用，用于读取操作
同时创建一个新的数据仓库集群，用于扩展操作
当新集群准备好时
现有集群将暂时不可用
而 现有集群的C名称记录
将切换到新数据仓库集群的一个点，只需几分钟
通常在维护窗口内进行
红移 会将现有数据仓库集群的计算节点 并行移动到新集群的计算节点
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/080_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p80 30. Redshift Distribution Styles.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


当我们讨论红移架构时
我们谈到了数据如何在多个计算节点上分布
以及在这些节点上的多个切片中分布
你需要理解实际进行这种分布的几种不同方式
当数据被加载到表中
红移会按照你创建表时所选择的分布样式
将表中的行分布到计算节点和切片上
创建表时，数据分布的两个主要目标是
将工作负载均匀分布到集群中的节点
并在查询执行过程中最小化数据移动
有四种不同的分布样式，它们是
自动分布，如果你没有指定分布样式
亚马逊红移会使用自动分布
并且根据表数据的大小
红移会为你分配一个最优的分布样式
这可能是键分布或所有分布
所以让我们独立地深入研究每种方式
让我们谈谈均匀分布
所以均匀分布
无论任何特定列中的值如何
领导节点会以轮询方式将行分布在切片上
它会依次遍历每个切片
并按圆形方式循环为新切片分配新数据
这在表不参与连接
或者当没有明确的键分布或所有分布的选择时
是合适的
均匀分布只是试图尽可能均匀地分配数据
而不考虑尝试将可能需要同时访问的数据聚集在一起
键分布这里
行是根据一个列中的值分布的
领导节点会将匹配值放在同一节点和切片上
匹配列的值会物理上存储在一起
这可以在通常基于数据特定列进行查询时派上用场
通过使用键分布
你可以确保特定键值的所有数据
会物理性地位于同一切片上
这可以加快查询速度
所以这里显示的图表是，随着新行从输入数据中加入
这些键会被哈希并分配到特定切片
基于键的哈希方式
然后我们有所有分布
在所有分布中
整个表的副本会分布到每个节点
这确保了每个参与连接的行
都会在每个节点上被聚集
参与所有分布的表
这会使存储需求乘以集群中的节点数量
因此加载、更新或插入多张表的数据需要更长时间
更新 插入数据
所有的分发实际上只适用于相对不活跃的表
那就是 那些不经常或很少更新的表
因为重新分配的成本较低
小维度表从全分发中获益不大
如果你需要查看表的分发风格
你可以查询pg类信息视图
或者查询svv表信息视图
反射磁盘风格列 pg类信息将指示该表的当前分发风格
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/081_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p81 31. Redshift Data Flows and the COPY command.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们来谈谈如何将数据导入到你的红移表
以及如何高效地从中提取数据
这是一个考试似乎很喜欢的话题
所以将数据导入红移表的常用命令是复制命令
这将是加载红移表的最有效方式
您可以使用复制命令同时从多个数据文件或多个数据流中读取数据
这可以从亚马逊
S3 从弹性
MapReduce Dynamodb
或任何远程主机
使用SSH协议
现在 您需要基于角色的或Keybase访问控制来在那里进行身份验证
但一旦您解决了所有问题
这相当直接
如果您从S3导入
需要manifest文件
这只是一个JSON格式的文件
列出你想要加载的数据文件
当然也需要一个IAM角色，以便你访问Redshift的S3存储桶
如果你想要从Redshift中提取数据
卸载命令是实现这一目标的方法
这将是一个快速卸载数据库表中数据的方式
到S3存储桶中的文件集
还需要考虑的是增强的VPC路由
这将迫使你的数据复制和卸载流量在你的集群
和存储库之间通过你的Amazon VPC
如果你不那样设置
你所有的网络流量都将通过互联网路由
所以你需要确保你的VPC正确设置和配置
否则复制将失败
你需要确保你的VPC端点在网关中
互联网网关都正确设置以在VPC中实现这一切
如果你想避免数据通过互联网路由
所以另一个考试可能期望你知道的细节
2023年有一些新特性
所以我不指望在考试中看到这些
直到2024年及以后
但如果你在2024年及以后观看
这可能很重要
所以，一个是从亚马逊s3自动复制，这个只是坐在那里监控s3桶
并且当在那个桶中看到新数据
它会自动将该数据复制到您的redshift集群
这是简化从s3导入数据的一种方式
您可以只是坐在那里，随时寻找新数据
并且自动将该数据复制到redshift，以便您使用，这样会更容易
不要再手动运行那些复制命令了
还有一种东西叫做亚马逊aurora零ETL集成
与自动从S3复制的想法类似，它一直在那里
自动从aurora数据库复制数据到redshift
所以，如果你有一个aurora关系数据库
并且你想将数据复制到你的redshift表中
这是一个非常容易实现的方法，并且可以自动持续进行
还有一种叫做redshift流式摄入的东西
它会一直在那里寻找kinesis数据流中的新数据
或者m s k为你管理的kafka集群
在复制命令上深入探讨
考试似乎越来越关注这一点
所以记住 您想使用复制来从Redshift外部加载大量数据
到Redshift表上您的Redshift集群
如果您看到关于如何高效地将数据从外部加载到Redshift的问题
几率答案是复制命令
如果您的数据已经在Redshift的其他表中
您不想使用复制用于外部数据
这是正在导入到您的Redshift集群中
如果您的数据已经在Redshift自身的其他表中
你想使用插入选择语句或创建表语句
实际上创建一个只是其他表的视图的表
你可以引用的表
所以记住创建表
是你将要使用的
来引用已经在红杉树中的其他表中的数据
如果它在红杉树之外
你想使用复制命令
复制命令的一些酷功能
它可以在从s three加载数据时解密数据
所以如果你的s三个数据是加密的
Copy可以解密它，因为它在加载中
它可以很快地做到这一点
因为它有一个硬件
加速的ssl能力，以保持解密尽可能快
它也可以通过在发送过程中压缩数据来加快速度
所以它支持gzip
Lp和b zip two压缩，以进一步加快那些数据传输
当你使用Copy命令时
Copy命令的另一个酷功能是自动压缩
这是一个选项，它将分析正在加载的数据，并自动确定存储的最佳压缩方案
因此，如果您有数据，它可以很好地压缩，自动压缩将确定如何高效地存储数据
如果您有数据 您知道
可以很好地压缩的数据
自动压缩将确定如何高效地存储数据
这用于优化您集群中的实际存储使用
文档中指出了一个特殊情况
我可能不会对考试感到惊讶
如果您有一个窄表
这意味着你有一张有很多行的表格
但是极少数的柱子
你想用单一的复制交易来加载它
如果可能的话
问题是 如果你有多个复制交易
有一些隐藏的元数据列出现了
并且这些隐藏的列用于跟踪事情中断的地方，消耗了太多的空间
所以，如果你要加载一个拥有许多行的表格
但是，很少有列尝试在一个复制命令内这样做
不要把它分散在几个复制命令上
好的
同样重要的是记住，复制的目的是并行处理事物
尽可能地高效地做事情
所以，如果你能在一个复制命令中做这些事情
为什么不呢 那总是能很好地发挥作用
实际上相当令人惊讶
在这个问题上，考试期望你对深度的理解水平
那么，让我们来谈谈一个非常具体的情况这里
让我们假设 你想自动将红移图的快照复制到另一个区域
这样你就可以跨区域复制你的快照以用于备份目的
假设你有一个使用kms加密的红移图
并且该集群的快照存储在某个s 3区域
现在你想将快照复制到另一个区域以获得更好的备份
你将这样做
方法如下
在你的目标aws区域
如果你还没有一个，创建一个kms密钥
然后你设置一个快照复制授权
在目标地区指定那个快照复制授权的唯一名称
作为设置那个复制授权的一部分
你指定用于创建的kms密钥ID
然后回到源aws地区
你会启用将快照复制到您刚创建的复制授权，所以
通过使用您设置使用kms密钥的复制授权
您可以安全地复制canvas
您的红移集群加密快照到另一个地区
另一连接性趣闻是数据库链接
和 Db链接 是一个扩展，允许您将Redshift集群连接到PostgreSQL实例
这可能是由Amazon的RDS服务托管在高级水平上
您可能想要这样做，以获得两种世界的最佳
之间的列存储的红色和基于行的存储PostgreSQL
或 您可能正在使用它
作为将PostgreSQL实例和Redshift之间复制和同步数据的一种方式
所以 如果你想要一个非常高效的数据复制方式
并且保持PostgreSQL和Redshift之间的数据同步
数据库链接扩展是一个实现这一目标的方法。它工作的方式如下
所以基本上，你启动一个Redshift集群
同时在同一可用区启动一个PostgreSQL实例
然后你将配置VPC安全组以允许来自RDS PostgreSQL端点的传入连接
然后你将连接到RDS PostgreSQL实例
并运行你看到的SQL代码
以在PostgreSQL实例和Amazon Redshift之间建立数据库链接连接
所以请记住
数据库链接存在以连接Redshift到PostgreSQL 并获取两者的最佳效果 或者可能更有效地复制和同步两个实例之间的数据
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/082_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p82 32. Redshift Integration  WLM  Vacuum.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


红色偏移如何与AWS其他服务集成
嗯 让我们来看看其中的一些
亚马逊S3
您可以使用并行处理从Amazon Redshift导出数据
到多个S3数据文件
当然，您也可以从S3导入数据
或者直接在Amazon Redshift上使用数据
Amazon DynamoDB
通过使用复制命令
您可以使用单个
Amazon DynamoDB表加载Redshift表
因此，可以从DynamoDB导入数据到Redshift
使用复制命令在EMR主机或E
C 2实例上可以导入数据使用SSH
再次 通过复制命令
可以加载来自一个或多个远程主机的数据
例如EMR集群或任何在E
C 2上运行的 顺便说一下
它也与AWS数据管道集成
您可以使用数据管道自动化在Redshift表之间的数据移动和转换
使用数据管道
最后，AWS数据库
迁移服务或DMS可以将您的数据迁移到Amazon Redshift
或者至少可以帮助您进行这个过程
AWS数据库迁移服务本身就是一个庞大的主题
基本上 它是一个允许您从现有数据仓库迁移数据的工具集
迁移到Amazon Redshift
通常，这个过程比你想象的要多得多
您还需要 至少了解Redshift工作负载管理是什么，简称WLM
它是帮助用户优先处理工作负载的一种方式，以便短
快速运行的查询不会卡在长运行的慢查询后面
它通过在运行时创建查询队列来实现
根据服务类和服务类定义的各种配置参数
现在 您可以通过修改WM配置来创建不同的队列
用于长运行的查询和短运行的查询
从而提高系统性能和用户体验
您可以通过Amazon Redshift管理控制台
Amazon Redshift命令行界面
或Amazon Redshift API设置这一切
关于如何扩展和调整您的Redshift集群的话题在考试中经常出现
您需要了解的一个功能是称为并发扩展
一个您需要了解的功能是称为并发扩展
这个功能允许您自动为处理突发并发读取查询增加集群容量
因此，如果您的红移集群存在大量访问
当外部突然涌入大量读取查询时
并发扩展可以自动扩展集群以处理
它可以支持几乎无限的并发用户和查询
这样 它将根据读取查询的流量增加所需资源
您可以使用工作负载管理队列
我们将很快讨论
以管理并发扩展集群发送的查询
这样您可以管理将查询分配到哪个队列
哪些查询可以利用并发扩展，哪些不
这可以让您 例如
隔离那些您认为可能具有突发性质的读取查询
或者它们的频率随时间变化
并自动为该特定查询扩展容量
这可以减少
您知道 无意中为某些
嗯 离线作业添加大量容量
不必要 所以您可以选择哪些查询可以利用并发扩展
显然这不是免费的
所以您知道
您需要思考
哪些查询可以自动增加更多资源
工作负载管理wm有几个不同的模式
一种是自动工作负载管理
因此，自动工作负载管理可以定义多达八个队列
默认情况下，您有五个队列，它们之间有均匀的内存分配
但您可以根据需要更改
如果您有大量大型查询进入队列
如大型哈希连接或类似
并发会自动降低
如果您有大量小查询进入队列
如插入、扫描或简单聚合
队列上的并发水平可能会提高
并发不就是一次可以运行多少查询吗
显然大型查询需要更多资源
您可能希望降低那些查询的并发
以便它们获得更多资源
而小型查询可以少用资源
通过将这些查询分开
我们可以更好地利用硬件
每个自动工作负载查询队列可以以多种方式配置
您可以设置优先级值
这定义了队列中查询的相对重要性
您还可以设置并发扩展模式
这就是你可以说的地方 我想要这个特定的队列可以访问并发扩展集群
并且能够自动添加更多的资源
在底层添加更多的服务器来处理容量
这对队列来说需要花钱
显然，所以你需要仔细考虑是否启用它
你也可以将一组用户组分配给一个队列
你可以通过指定用户组名称来做到这一点
或者使用通配符
因此，当列表中的一个用户组成员运行查询时
该查询将自动在相应的队列中运行
因此，你可以根据用户将队列分配给查询队列
你也可以设置查询组
那只是一个标签
所以基本上在运行时
你可以将查询组标签分配给一个系列的查询
这将定义查询进入的队列
所以基本上啊 一个标签
一个分配给查询本身的标签可以定义它进入的队列
你也可以设置查询监控规则
这些非常酷
它们允许你为工作负载管理队列定义性能边界
并且你可以指定当查询超出这些边界时采取何种操作
例如
你可能有一个专门用于短运行查询的队列
你可能有一个查询监控规则，如果查询运行时间超过60秒，则终止这些查询
这样你就可以确保你的短查询队列确实处理短查询
如果这些查询中的任何一个出现问题
它不会阻碍队列中的其他查询
所以这是一个非常有用的工具
你也可以将查询踢到不同的队列
如果它违反了查询监控规则
手动工作负载管理是wl m的另一种形式
并且默认情况下
这有一个队列，并发水平为5再次，并发水平 我可以同时在这个队列中运行多少查询
此外，有一个超级用户队列，并发水平为1
这是一个用于进行管理查询的队列，这些查询总是必须运行
你可以定义多达8个手动队列
每个队列的并发水平最高可达50
你可以为每个队列定义
是否可以访问并发扩展集群
它是否可以自动
添加更多的容量到该队列
你也可以为该队列设置手动并发水平 定义我想同时在其中运行的查询数量
你可以为该队列设置手动并发水平
定义我想同时在其中运行的查询数量
你可以为该队列设置手动并发水平，定义我想同时在其中运行的查询数量
你可以为它分配用户组，并根据之前所讨论的那样查询组
自动队列
只需允许您根据运行查询的用户自动路由查询到队列
或者根据已附加到查询的查询标签
你也可以定义给定队列分配的内存
在该队列中运行查询的超时值
以及可能拥有的任何查询监控规则
你也可以启用称为查询队列跳跃
如果你有一个在给定队列超时的查询
你可以配置它
跳到下一个队列 并在不同的队列中尝试
那个可能有更高的超时值
或者有更多的资源可供使用
这里还要讨论的一件事是短查询加速或SQA
这里的想法是自动优先处理短运行查询过更长运行查询
短查询将在自己的专用空间运行
因此它们不会最终在日志查询后面排队
因此，如果您只想加速短查询，可以使用工作负载管理队列
它可以与创建表为语句一起使用
记住
也可以只读查询或选择语句
因此，两者都是短查询加速的候选人
它可以自动将这些运行在自己的空间中
因此它们不会困在更长的分析查询后面
所以它实际上试图使用机器学习算法自动预测查询的执行时间
因此它可以根据查询本身进行某种猜测
估计可能需要多长时间
并确定是否应该将该查询放入短查询专用空间中
并且您可以配置认为短的秒数
因此，短查询加速的设置是您拥有的一个旋钮
因此，请记住，短查询加速是wm工作负载管理的替代方案
如果您只想做的是
加速短查询
并确保它们不会困在更长的查询后面
并且它可以与创建表为语句或只读选择语句一起使用
最后，您需要了解vacuum命令在redshift中的作用
Vacuum是一个用于从删除的行中恢复空间并恢复排序命令
Vacuum是清理您的表的命令
有四种不同的vacuum命令
第一种是vacuum full
这是默认的vacuum操作
它会对所有行进行排序并从删除的行中回收空间
还有vacuum delete only
这与full vacuum相同
只是跳过排序部分
因此，它只是回收删除的行空间，而不实际尝试排序
你也可以做vacuum sort only
这将重新排序表格，但不会回收这个空间
最后还有真空重新索引，用于重新初始化交错索引
记住我们谈论过的不同排序键
你可以有一个被交错的
所以重新索引会重新分析表格中的值的分布
排序键列
然后在那之后执行完整的真空操作
最后
让我们谈谈红移的反模式 这也直接来自aws大数据
白皮书中他们不希望你用红移做的事情之一就是小数据集
记住红移的强项是它巨大且高度可扩展
如果你只有小小的表格想要存储，rds
可能是更好的选择，oltp再次
他们无法强调红移是为分析查询，olap设计的
如果你需要执行事务非常快的查询
你想要使用rds或dynamodb
嗯
他们也列出了非结构化数据给我 这有点奇怪
因为红移光谱实际上存在
让你查询s三中的非结构化数据
但如果你真的需要做一些etl，你需要
你应该先用emr或glue etl做
或者在那之前
不适合存储blob数据，那就是意味着大二进制文件
如果你确实需要在数据仓库中存储大二进制文件
最好的方式就是存储这些文件的引用，它们位于s三中，而不是文件本身
所以这是关于红移的很多
但再次，你需要对红移有很深的理解
为了考试
花时间去理解和记住这些幻灯片中的一切将会非常有价值 33 34
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/083_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p83 33. Redshift Resizing.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么如果并发扩展不足以满足需求
你可能需要实时调整集群大小
你可能需要为其添加更多容量
你需要理解它们之间的区别
有一种方法叫做弹性调整
你可以使用这种方法来快速添加或移除相同类型的节点
如果你对节点的类型感到满意
即运行你的红移集群的EC two实例类型 EC two 实例
你可以使用弹性调整来添加或删除它们
您的集群在添加容量时只会停机几分钟
它还试图在停机期间保持那些连接开放
你可能不会丢失任何查询
它可能会保持那个连接打开并让它恢复
一旦您的集群中添加了容量
弹性调整的一个限制是，对于某些数据中心
2和RA3节点类型
您只能加倍或调整集群的大小
您不需要记住考试中的具体类型
但对于某些类型的数据，这就是你需要做的事情
你只能加倍或保留它们
如果你需要做一些更复杂的事情
那么你需要回到被称为经典缩放的状态
这样可以让你实际改变节点的类型或节点数量
经典缩放的问题是，如果你确实改变了节点的类型
可能需要几个小时甚至几天才能让你的集群再次可写
所以整个集群将处于只读状态，直到新硬件准备就绪
这可能是一个耗时的过程
所以你希望在可以弹性调整时使用弹性调整
但是如果你需要更改你的主节点类型
那么你必须使用经典调整
这就是主要区别 在那
处理事物的一种技术
在那经典调整场景中是使用称为快照恢复调整的技术
这是一种在经典调整操作期间保持集群可用的策略
所以如果你需要更改你的主节点类型
或者你需要增加容量
弹性调整不允许你做你能做的事情是
使用快照命令复制你的集群
然后调整新集群
这样你的数据仍然会流向旧集群
当你的新集群在调整和经历经典调整过程时
一旦你的新集群最终完成
你可以将流量切换到新创建的集群
快照恢复
然后调整是一种从一集群迁移到另一集群的方式 使用经典调整来最小化停机时间
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/084_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p84 34. RA3 Nodes, Cross-Region Data Sharing, Redshift ML.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们来讨论一下Redshift中一些更新的功能
这些功能是在近几年推出的
我认为是2020年，或者是2019年底
引入了三节点
这是一种专门为Redshift优化的节点类型
这是一件大事
这些年他们在此基础上不断扩展
这里的主要思想是
不过 它带有管理存储
所以他们已经将计算和存储能力解耦，使用了三节点
他们的观察结果是存储能力和计算能力以不同的速度发展
通过独立扩展计算和存储能力
这可以让你更好地利用你的红移集群的资源
这是一件大事
2020年还发布了另一个功能
我认为是的 2020年的红移数据湖导出
你可以直接将红移查询导出到
S3中，格式为Apache Parquet
所以，如果你在大红移数据仓库上进行一个大查询，你可以将其导出到一个数据湖中
只需使用数据湖导出功能，轻松将数据写入S3
这样做的动机是Parquet格式卸载速度是原来的两倍
而且它消耗的S3存储空间最多减少60%
这是用于将数据导出到数据湖的一种非常快速且紧凑的方式
最终得到的数据湖将与Redshift Spectrum、Athena、Emr或Sagemaker兼容
能够读取S3的任何东西
这也是自动分区的
所以你不必考虑这一点
最近
在2022或2021年
他们引入了空间数据类型
所以现在在红移中有几何和地理数据类型
所以如果你需要做地图相关的事情
这类应用
现在你可以使用这些新的数据类型在红移中完成
新功能是跨区域数据共享，2022年新功能
这基本上是随着时间的推移而演变的
但它最近确实发展得更快
这里的想法是，您可以在不需要复制它们的情况下，跨红移集群共享实时数据
所以，我们谈了很多关于如何在不同地区和不同实体之间复制数据
并讨论了这可能带来的麻烦，所以，跨地区数据共享
他们已经尽力简化这一点
这允许您再次在地区之间共享实时数据
这是新事物，甚至在帐户之间
如果您想以安全且非常简单的方式做到这一点
就可以这样做
你需要使用我们讨论过的新的三节点类型
它只支持在三节点类型上
这是一个大新闻
跨区域数据共享新功能
解决这个问题的简单方法
另一个更近的功能是亚马逊红移
机器学习或机器学习
我不会深入探讨这一点
而不是数据分析考试
但是至少你应该知道这存在
考试可能会提到它
这是从2021年中期引入的
所以现在是公平的
概念上有这样一个高层次的图表亚马逊给我们
它说我们首先将我们的数据收集到一个数据仓库中
这可能是s3
然后redshift ml涵盖了整个系统
我们在这里创建一个机器学习模型
只需使用sql命令
使用自动创建模型
这将启动到亚马逊SageMaker，自动调优和训练您的模式。
具体来说 它正在使用sagemaker autopilot
但我会在下一秒走完那个。
在这里它将部署你的模式
所以你可以直接用SQL命令和Redshift处理它
为了获得实时预测
使用SQL命令
所以，在实际操作中，你会从红移开始。
将您的训练数据导出到亚马逊S3，以便用于机器学习模型
Sagemaker Autopilot是特定技术，它将在这里运行
它在这个图表的“训练”部分下面
它会预处理您的数据，并尝试找到最佳的超参数
是的 找到最佳的模型使用
以及该模型的最佳参数
一旦模型被训练完成
它就能够进行预测
Redshift将注册您的预测函数
作为一个在你的红移集群中的sql函数
所以你可以直接访问红移数据库获取预测结果
基于你使用红移机器学习训练和部署的模型
当你创建模型时会启动很多底层操作
是的 我的意思是 构建和训练机器学习模型可能计算量大
这会花费金钱
所以你会在亚马逊sagemaker中看到一条单独的费用项
如果你使用红移ml
你也要为任何底层存储付费
使用s3存储训练数据
以及需要在redshift和sagemaker之间来回的数据
在整个过程中
所以这就是redshift ml的概述
这可能不是你在考试中需要太担心的事情
但为了完整性 这是redshift的一个重要功能
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/085_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p85 35. Redshift Security.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以，我想讨论几个与红移相关的具体安全问题
我们将在后续的课程中更多地讨论安全问题
但这里有几个可能会出现在考试中的内容
一个是使用硬件安全模块（HSM）与红移的问题
如果你在使用HSM与红移
你需要使用客户端和服务器证书来配置
以实现红移与HSM之间的可信连接
如果你试图事后进行这些操作
你试图将HSM添加到现有的红移集群中
你将不得不将其复制过来
所以，如果你想将一个未加密的集群迁移到一个hm加密集群，
你需要将一个未加密的集群迁移到一个加密集群
首先，你需要创建一个新的加密集群，
然后将你的数据迁移到那个加密集群
好的 这就是使用nhm与redshift的一些细节
你需要一个客户端和服务器证书来实现这一点
有一个很酷的功能 嗯
你可以在sql中使用grant或revoke命令来实际定义访问权限
对于个人用户或Redshift中的用户组
管理Redshift权限的简单方法是说类似这样的话
向Bob授予在food表中查询的权限
这将向Bob授予在名为food的表中执行查询语句的权限
你可以做类似于授予所有或删除权限的事情，以便让其他人删除数据
所有这些都可以单独管理到用户或组
只需使用grant命令
就像任何其他SQL命令或revoke命令
如果你想撤销这些权限 这就是在Redshift中管理安全和访问权限的基本方式
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/086_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p86 36. Redshift Serverless.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以这是一个最近的发展
就像emr正在走向无服务器
所以是红移
红移无服务器现在也可用
这承诺会自动扩展和为您的工作负载配置您的redshift集群
再次，您不需要考虑您需要多少容量
它将为您计算
想法是优化您的成本和性能
因为您只支付您实际使用的容量
这将为您节省一些钱
它也会优化您的性能
因为如果您正在运行某种强烈的查询
它可以自动为您扩展这一点，而不需要您考虑
这在底层使生活变得容易
它使用某种高级机器学习
他们没有详细说明
但ml以保持性能跨
可能变量和间歇性的工作负载
即使您以ad hoc查询击中它
它将学习如何处理这一点
这个的主要目的
尽管是使启动一个redshift集群变得容易
所以我不再需要考虑容量
我可以只是向前启动redshift
它将自动计算我需要的容量
并且只是为我构建这一点，很好
所以如果我想要启动一个小型开发环境或测试环境
我可以在这里做一点页面
只是设置我的新数据库
它将自动只给我我需要的容量
并且不再 这容易得多
如果我只想做一个快速的ad hoc商业分析事情
启动一个快速集群
回答一个问题 出去
也可以这样做 不要考虑太多
他们已经使它更容易设置您的集群
这使得其他人使用它更容易
并鼓励您使用它进行更多种类的应用程序
一旦您启动它
您只获得一个无服务器端点
您还获得一个用于通过jdbc或odbc连接到它的url
如果您只是想做一个快速的ad hoc事情
您可以使用我们在之前看到的控制台中的查询编辑器
您不需要外部连接
如果您不想那样，开始
现在设置redshift无服务器唯一的难点是实际设置iam角色
需要设置redshift无服务器
所以你需要从头开始创建一个iam角色
它附有这项政策
在这里的右边 你需要确保你有权访问redshift serverless操作
我肯定他们最终会简化这一点
但现在你需要设置这一点
你需要自己创建一个iam角色
当你设置新的redshift serverless集群时
你所需要做的就是告诉它你的数据库名称
管理员用户的凭据
Vpc 你想要在自定义加密设置中使用的任何自定义加密设置
它将使用aws拥有的kms密钥
这通常没问题
以及任何审计日志的特殊设置
就是这样 你只需填写一页信息
然后你就有了一个等待你使用的redshift serverless集群
这真是酷
创建后你可以管理快照和恢复点
这些都还在支持中
你可以定期备份你的数据
以及恢复功能
你可以使用恢复点
这些都还在支持中
让我们谈谈redshift serverless的资源缩放
因为我们正在转向无服务器
他们不能再以服务器的方式构建
他们不会再暴露服务器
相反，他们会让我们
考虑他们称之为redshift处理单元或rpus
这是他们的新计费指标
你按rpu小时计费
按秒计费
加上你使用的任何存储
redshift serverless的计费
基于你使用的红移处理单元
按小时计费 加上任何相关的存储费用
按存储时间计费
你可以指定你的基ru
与emr serverless类似
你可以调整你的基容量
默认情况下它会设置为自动
所以你根本不用担心
但如果你想提高查询性能
你知道你需要更多的容量
起步阶段 你可以给出一个提示
你可以说我希望将我的基础RPUs设置为312到512之间
在我的无服务器集群中开始
我也可以设置我的最大RPUs
所以如果我想确保我从不超出一定的资源消耗以控制成本
你也可以这样做
当然，他们希望你使用它来增加你的吞吐量
所以尽管在实践中
你可能希望使用最大RPUs来确保你不会被收费
比你预期的更多
你也可以用它来提高作业的吞吐量
如果你认为最大rpp使用设置得太低
关于红移无服务器服务的几件事
所以基本上它做了红移可以做的一切
除了少数例外
参数组不与红移无服务器一起部署
工作负载管理也不与一起工作
如果它这样做没有多大意义
整个要点是你不需要想太多
AWS合作伙伴集成目前不支持Redshift无服务器
维护窗口和版本跟踪也不支持Redshift无服务器
那是值得谈谈的一点
与正常Red Shift有一点不同
你有这些维护窗口
所以你大致知道更新何时应用到你的集群
与Redshift无服务器，你可以事先计划
如果对Redshift本身的软件更新被推出
你将在没有任何警告的情况下失去连接
所以与Redshift无服务器，没有为此进行真正的先进规划
这可能是你在决定是否现在使用这个时需要考虑的事情
也有没有公开的端点与红移服务器less
你必须在VPC内访问它
它将不会公开访问
但监控是他们在红移文档中讨论的
服务器less也改变了一些
所以有很多不同的视图用于监控目的
例如查询历史
Cis负载历史是服务器less使用
还有一些他们做的事情就是你认为他们做的事情
基本上这是一个查询的历史
还有一个查询详细视图
如果你想要更多信息
关于你的无服务器集群的历史信息
那个集群的使用情况
这些都可以在某种程度上对解决性能问题有用
嗯 也许你需要增加
也许你的最大RP使用设置得太低了
例如 这可能是找出答案的一种方式
它还会将数据发布到云观察连接
用户日志默认启用
也有可选的用户活动日志数据
如果你想将其也发布
这将在aws红移云观察主题下发布
发布的云观察指标包括
每秒查询完成次数
查询持续时间 查询运行诸如此类的东西
你可以根据各种维度来分解它
例如数据库名称
延迟
它被分为短
中等或长
查询类型
以及查询的阶段
查询的阶段在它完成时
所以这些都对你可用
简而言之
红移无服务器与红移基本相同
唯一的区别是你不需要考虑底层的容量
底层服务器会为你做这件事
因此，你不按服务用量计费
而是按rpu计费
你有几种控制它的方法 包括红移无服务器的基础和最大rpu容量
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/087_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p87 37. Redshift Materialized Views.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


你需要为考试了解物质化视图
让我们谈谈在红移中那些是什么
所以你知道数据库中视图是什么
它只是基本上将查询的结果看起来像另一个表
你可以查询 随后，物质化视图有点不同
所以它实际上是预计算查询的结果
并存储查询的结果，使其看起来像另一个表
如果你愿意，它与普通视图不同
并且它实际上是存储了查询的结果
不仅仅是查询本身
正如你所看到的
这可能是一个相当重要的性能优化
是的 如果你的数据仓库中有一个复杂的查询在大表中
你可以查询这个物质化视图
就像任何其他表或视图一样，那些保存了更复杂查询的结果
如果你需要在更复杂的查询之上构建一个查询
你可以将那个复杂查询的结果存储到一个物质化视图中
然后从其他查询中多次查询这些结果
既然你在使用这些预计算的结果而不是访问基础表
这可以是一个非常重要的性能优化
当然 但这以牺牲同步问题为代价
对 所以如果你的材料化视图的结果改变
因为底层你查询的东西改变了
这个材料化视图需要显式刷新
某种方式
所以可能是你想要使用的一个例子
如果你的查询可预测且重复，这就是方法
例如，从亚马逊填充仪表板
快速侧边或类似的
所以如果你知道 你的仪表板需要一组查询的结果
也许你可以使用物质化视图预计算这些结果
然后使用物质化视图构建仪表板以提高性能
而不是每次查看仪表板时运行该查询
我如何使用它们
它们相当容易 所以而不是创建视图
你只需说 创建一个物质化视图
就是这样
所以而不是基于查询的视图
你正在创建一个查询结果的快照
并将其转换为视图
我如何保持它们更新
所以正如我所说，存在一个同步问题
因为我存储了结果而不是只存储查询本身
可能会有同步问题
即我查询的材化视图的基础数据发生了变化
为了保持材化视图与这些变化同步
我可以手动和明确地刷新它
在我需要时 通过使用刷新材化视图命令
你也可以设置自动刷新选项
在创建时使其自动发生
所以这取决于你想要多少控制
如果你想要控制刷新频率以保持性能
也许你只需要每天刷新一次
因为你会使用它
用于每天查询一次的仪表板
那么也许你只需每天刷新一次材化视图
而不是每次数据变化时自动刷新
一旦你有了材化视图
你可以像查询其他表或视图一样查询它
它看起来就像其他任何东西
你也可以将它们堆叠在一起
所以你可以有材化视图，它们基于其他材化视图构建
这相当酷
这可能有用的一个例子是，如果你有多个表之间的昂贵连接操作
你可以将该连接的结果存储为材化视图
然后有其他材化视图使用该连接数据进行特定查询
所以你也可以将它们堆叠在一起 这可以加速你的查询性能
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/088_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p88 38. Redshift Data Sharing  Data Shares.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


红移的一个实用功能是数据共享
如果你想在红移集群之间共享数据
这允许您在红移集群之间安全地共享实时数据，仅供读取使用
所以，如果你想将你的数据发布到其他红移集群
并让其他人读取你的数据
这是一个很好的方法
你为什么想要这样做，嗯
一个是工作负载隔离
所以，如果你将你的数据共享到另一个集群
如果这个集群运行缓慢
这不会影响生产者的性能
你共享数据的主要集群
所以 如果你希望确保你组织中的某个顽皮部门
不能降低红移集群的性能
也许你只需将他们的数据共享到他们的红移集群
如果他们有性能问题
嗯 跨部门合作
这是一个使用案例
所以，如果你有一个需要读取方式访问数据的另一个部门或组织
这是分享数据的一种方式给他们，跨组织或组织内的小组
而且，这不仅可用于跨小组共享数据
也可以用于不同的环境
数据共享的一个良好应用是开发
测试和生产环境之间的数据共享
这将允许我在生产环境中使用的相同数据
对应用程序进行更改
再次，具有隔离
所以我的开发流量
我在开发中做的事情不会影响生产
这假设你可以使用只读数据进行操作
当然 你也可能想通过aws数据交换授权访问你的数据
所以，如果你想发布你的数据并实际上将其出售给其他aws用户
嗯 数据共享是您实际通过aws数据交换进行此操作的方式
你可以分享什么 你可以分享整个数据库
你可以分享模式
你可以分享表 你可以分享特定的视图和/或用户定义函数
所以你有细粒度的访问控制
谁可以看到什么
并且可以是任何
所有这些中的任何一个
我早些时候提到了
但数据共享依赖于生产者-消费者架构
所有这些细粒度安全都由生产者控制
即发布数据的人
我们有隔离 这样生产者集群的性能不受任何数据消费者的影响
使用数据共享
然而数据将保持实时和事务一致性
那些消费者将获得一个实时视图
以及生产者集群中事务一致性视图
为了使数据共享发挥作用
两个集群都必须加密
并且它们必须使用三种节点类型
如果您在地区之间进行数据共享可能会涉及传输费用
在这种情况下，请留意您的账单
有三种不同类型的数据共享
他们的标准 就是我们一直在谈论的
从一个集群到另一个集群
还有aws数据交换
如果您想将数据共享到数据交换中 第三种类型的数据共享是由aws湖形成管理
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/089_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p89 39. Redshift Lambda UDF.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


红移
Lambda UDFs
用户定义的函数是你需要了解的事情
这是一个相当惊人的功能
这允许你在AWS Lambda中的SQL查询中使用函数
在红移中 这很厉害，对吧
因为Lambda函数可以用任何你想象的语言编写
它们可以做任何你想象的事情
所以你可以有一个调用其他服务的Lambda函数
也许像击中一些AI服务
它可以访问外部的其他系统
它也可以与位置服务集成
这只是一些你可能做的事情的例子
使用AWS Lambda函数从SQL查询中访问它们
您只需使用创建外部函数来注册您的Lambda UDF，以便在查询中使用它们
并且在Redshift表本身上
您需要在此起作用之前授予对语言X函数的使用
并且所有事情都有正确的权限与Lambda交谈
这可能看起来像的例子
让我们想象一下我们有一个lambda下划线
一个我们定义的乘法udf
所以我们可以说选择a b从t one
Where lambda下划线和乘法a, b等于64
这可以用来说我想要选择表中的所有行
Where产品列a和b等于64
这是一个非常或许愚蠢的例子这里过度思考事情
但在这种情况下我们将实际调用aws lambda进行那个乘法
显然那里可以做更复杂的事情
任何aws lambda可以做的都可以在那个lambda下划线乘法函数中做
所以这里的想法是我们通过UDF将Lambda与Redshift连接起来
实际上注册该函数的过程相当酷
这是将语法看起来的样子
所以这里是一个不同的例子，我们将创建一个X函数
下划线一些UDF
这里是一个接受两个整数并相加的UDF
语法定义X_monk下划线UDF的语法
创建外部函数
该函数的名称
以及其参数的列表
它期望它返回的，在这个情况下另一个整数
所以它取两个整数并返回一个整数，那是
显然是它们的和，易失性lambda
然后lambda函数的名称是调用的
然后最后我们有必要将与该lambda函数关联的iam角色传递进去
以便给它所需的权限
关于该iam角色的更多详细信息
所以有一个aws lambda角色
iam策略您可以用于授予lambda对您集群的权限
iam角色 或者你可以自己制定策略
只需确保允许lambda调用函数作为该策略的一部分
因此你需要为该策略创建一个角色
然后通过您之前看到的创建外部函数命令的该参数传递该角色
在同一地区，你也可以调用其他账户中的功能
使用iam角色链这种方式
因此你可以使用别人的lambda udf使用角色链
这一切在底层是如何工作的
当它实际上与lambda通信时发生了什么
红移将使用json数据与您的lambda函数进行通信
所以这就是你的lambda函数可能会看到的输入
你会看到一个请求ID
集群 它来自Redshift数据库的用户
外部函数的名称
然后是查询ID
最后，你想要你计算的记录数
所以，我这次说的是，我想要你找出四件事
这里是每件事的参数列表
然后你的lambda函数处理这些并返回一个响应
那个响应可能看起来像这样
它会说成功为真或假
如果有错误消息
你也可以指定这一点
我将说这里我返回四条记录，是你要求的
这里是结果
你请求的四条记录的结果列表
所以相当直接
是的嗯 基本上红移说
好的 嗯 我在这里呼叫lambda
Lambda 这是你想要的参数
给我一个回应
我将其融入我的sql回应中
这是红移
Lambda udfs
用户定义的函数，简而言之，调用lambda 非常酷的功能
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/090_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p90 40. Redshift Federated Queries.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们来谈谈红移的联机查询
这是一种查询和分析跨数据库的方式
跨数据仓库，甚至跨数据湖
现在 让我们具体谈谈将Redshift与其他数据库连接的情况
特别是与RDS数据库
我们可以将Redshift连接到Amazon
RDS或Aurora for PostgreSQL
和我的SQL当前可能那样，未来可能会扩展
但这很令人兴奋
因为这意味着我可以访问RDS的实时数据并从Redshift中查询它
这样避免了ETL的需要
没错 我不需要担心从关系型数据库导入数据
从Aurora或RDS到Redshift本身
我可以直接查询这些数据库，避免移动数据
这样我可以在Redshift中创建查询，该查询访问表
这些表位于外部关系型数据库中
例如PostgreSQL和MySQL
这些位于RDS中
那真的很酷
它也将计算卸载到那些远程数据库中
因此这也进一步减少了数据移动
这意味着，如果我有一些复杂的查询
我可以将其拆分并分散那些rd s实例的负载
为了弥补一些差距
它是如何工作的
首先 你需要确保您的红移集群之间有连接性
并且你想要与之交谈的RDS或Aurora实例
现在 您需要确保它们要么在同一个vpc子网中，要么使用vpc对等连接使它们彼此可见
vpc对等连接再次只适用于两个vpc之间没有重叠的ip地址范围
如何访问它
因此，红移需要了解如何登录并访问那些rds或aurora实例
正确 因此，执行此操作的凭据必须存储在aws密钥管理服务中，以便其正常工作
然后，您将在iam角色中包含这些密钥，该角色将分配给您的红移集群 现在
您需要确保它们要么在同一个vpc子网中，要么使用vpc对等连接使它们彼此可见
为了访问那些外部数据库
创建一个访问那些外部rds或aurora表的外部表
你可以说创建外部模式
你也可以使用相同的语法来连接
S三或到红移光谱
所以记得早些时候 我说这不仅仅是为了联邦到rds和aurora
你也可以用这种方式联邦到数据湖
右边是同样的想法
顺便说一下是iam角色的一个例子
这包括访问aws secrets manager的权限，以便访问那些外部数据库
如果你想快速查看当前可用的外部模式
并定义了svv_外部模式视图
它将为你提供该列表
让我们看看一个例子
记住，在进行联合会询时
您只能对外部数据源进行只读访问
并且在外部数据库上可能会产生额外费用
这取决于您对它们的流量和负载
所以它不是免费的，作为redshift的一部分
任何你处理的数据
你都可以存储在aurora或rds或数据湖中
此外 没错
记住你可以从红杉查询rds和aurora
但是无法反向查询
这是一个单向的连接
并且是从红杉到rds和aurora的只读连接
让我们看看右边的例子
在这里我们说 创建外部模式
这样我们就可以在外部表引用这个模式了
在我的红移查询中，我将引用此外部表作为apg
这意味着我将与一个PostgreSQL数据库进行交互
该数据库可能位于RDS或Aurora中
我正在访问的数据库名为database one
该数据库中我正在访问的表名为my schema
但是 我将其重命名为apg
然后我们说 Urri
与 Aurora 主机名到点的连接
我传递了我们在上一个幻灯片上看到的 IAM 角色
其中包括我需要的所有 Secrets Manager 信息
然后，我需要连接到该 PostgreSQL Aurora 实例的密钥的 ARN
Aurora 实例
一旦我完成了这些
我可以像访问其他任何表一样访问该外部表
我可以说 select count star from apg line item
一个apg再次指的是这个外部的Postgres表
我的数据库下的 schema
Postgres远程的一个数据库
并且它像任何其他表一样工作
相当酷 那就是Redshift
联邦查询的概述 考试期望你知道的东西
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/091_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p91 41. Redshift System Tables and System Views.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


关于红移系统表和视图的几点说明
与大多数关系数据库一样
你可以通过查询
内部维护的表和视图来获取关于系统的信息，这些信息是自动为你准备的
这些包含关于红移自身如何运行的信息
从非常高的层次来看
存在不同类型的系统表和视图
让我们快速过一遍这个高层次的内容
因为要详细介绍所有的个表和视图是不可能的
你只需要知道它们是什么以及它们用于做什么
所以有一些系统视图以sys开头
这些都是CIS视图
它们用于监控
查询和负载使用情况
主要是 也有有以stv开头的系统表
这些监控瞬态数据，包含当前系统数据的快照
然后有svv视图，包含关于数据库对象的元数据，引用了那些
DV表
也有有stl视图
这些是从保存到磁盘的日志中生成的
然后有svcs视图
关于主要和并发查询的详细信息
为特定查询扩展主集群的集群规模
所有视图都将拥有此信息
具体的表和视图的可用性会有所不同
基于您使用的是功能实例还是无服务器实例
但它们确实有很多共同之处
让我们来看看这里右边的这个例子
所以这里有一个例子，我们在分析最近查询的执行时间
所以我们如果这里分解一下
我们可以看到这些是从stl查询获取的
所以stl查询是一个stl视图
这意味着它是从磁盘持久化的日志生成的
并且我们在svl q日志上进行连接
svl是关于主集群查询的详细信息
所以svl q日志可能是查询日志
我们在那里基于那里的查询字段对这些两个进行连接
所以我们在svl q日志和stl查询之间进行连接
以获取那些最近的查询
并且具体地说，我们在进行where子句以获取过去一天的数据
正确地，通过获取最近查询的信息
我们可以选择那些查询的属性
例如开始时间 结束时间
查询时间花费，我们将计算那个
并计算执行时间
使用date dip命令
以及查询结束时的状态
所以这是用系统表和系统视图获取一些信息的一个例子
关于红色偏移对你性能的表现
所以请记住它们为你服务 以及它们可以用来做什么
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/092_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p92 42. Redshift Data API.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在考试中出现的一个问题是红移数据API
所以我们花点时间来讨论一下这个问题
详细来说，这是一个安全的HTTP端点，用于向您的红移集群发送SQL语句
这可能是预配置的集群或无服务器集群
我可以处理单个和批量查询
因此，它提供了
其他事情之一 一个REST端点，您可以将其集成到自己的应用程序中
这就是我们在屏幕上底部展示的
因此，用户在与您构建的应用程序交谈
该应用程序可以通过AWS SDK与亚马逊红移数据API进行通信
并通过该API向您的红移集群执行查询
无论它在哪里
它让您可以在AWS之外使用
它可能是异步的
因此，您会向请求查询发出调用
无论是批量还是个人查询
然后您需要使用标识符进行另一次调用
它返回给您以后来获取结果的
它不需要管理连接
就像您与普通数据库一样
因此您不需要担心在您的应用程序中安装正确的驱动程序
或者诸如此类的事情
它通过数据API为您抽象掉了 从安全角度来看，您不需要担心
密码不会通过API发送
它使用AWS秘密管理器来管理凭据
或者您可以为应用程序设置红移的临时凭据
无论哪种方式
密码不会作为API的一部分通过网络发送 因为它可以通过AWS SDK调用
这意味着您可以通过SDK支持的任何语言访问红移
包括C + +
Go
JavaScript
Net Node Js
PHP Python
和Ruby 与大多数服务一样
它与CloudTrail集成
因此，如果您需要监控正在发生的事情或存档
通过该API执行的操作
CloudTrail可以捕获这些API调用并将其存储在S3中
这不仅适用于应用程序集成
它还与AWS生态系统中许多其他服务集成
并在这里右侧进行了可视化
所有
正如我所说
我们可以使用REST端点将其与您自己的应用程序集成
这就是我们讨论的
但你也可以将其与多种其他服务集成
一个非常受欢迎的是使用AWS步进函数
与Redshift数据API一起使用，以编排ETL过程，提取，转换和加载
所以，如果您想使用步进函数设置一个数据处理工作流
您可以将Redshift数据API作为该工作流的一部分调用
您可以使用数据API设置一个事件驱动的ETL管道
您还可以通过SageMaker笔记本访问Redshift数据API
如果您需要从SageMaker笔记本访问Redshift
您也可以这样做
它还与Amazon事件桥集成
这在数据工程的上下文中非常重要
因此，您可以通过事件桥将数据API的数据流式传输到其他地方
通过监控从数据API流出的数据
例如
您可以 例如
通过事件桥将数据从应用程序流式传输到Lambda
要这样做 您只需将宽度事件参数设置为true即可完成这种流式传输
您还可以使用事件桥调度数据API操作
因此，事件桥可以用于在一致时间表上调度操作
或者在响应于某种其他事件时
因此，事件桥加上数据API是您应该了解的内容
使用数据API的一些细节
因此，您可以对其进行许多大量限制
并且默认情况下
查询持续时间只能持续24小时
您一次只能拥有不活跃的查询500个
解压后的结果大小只能高达100MB
结果将仅保留2小时
因此，如果您在满一天后仍未收到结果
它将消失
您的查询语句大小只能100KB
下一个稍微更重要一点
查询包大小
这是每行结果中的数据量
为64KB
如果您从数据API调用中收到错误消息
说查询包太大
这意味着每行返回的数据量过多
并且最大限制为64KB
此外
客户端令牌的最大保留时间为8小时 用于访问API
并且每种API调用都有各种TPS配额
例如
你的交易限制在每份报表30笔以内
说到API调用
这些是你可用的
这里有执行语句，用于执行单个SQL语句
或者批量 执行语句，用于一次性执行多个语句，一旦你将该语句提交给数据库
你可以描述该语句或背后的表，再次
这是非阻塞的
一旦你调用并执行了语句调用或批量执行语句调用
它将只返回一个标识符
而不是实际结果
然后你需要再转回来并传递该标识符以获取语句
结果，以后获取该查询的结果
你也可以使用取消语句来取消正在进行的语句，使用相同的ID
并且有一些安全措施
确保你不能窥探他人的查询
所以你需要拥有相同的IAM角色或权限，以便在一个给定的语句上执行，无论是执行还是获取语句结果
或者诸如此类
显然，也必须在VPC中 除非你的红移数据库集群在虚拟专用云中，否则将无法工作
例如 当然
集群必须在VPC中
所以，除非你的红移数据库集群在虚拟专用云中，否则将无法工作 例如
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/093_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p93 43. Redshift - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


好的 让我们通过使用红移来获得一些实际经验
我将加载一个亚马逊评论数据集
来自杂志类别
我不认为亚马逊还在卖杂志
真遗憾 我宁愿要纸质书胜过电子屏幕
我说 但我跑题了
所以 这确实需要一些真金白银
红移目前提供一种免费信用
如果你是第一次使用
所以，你有很大的几率可以免费做这件事
嗯 即使你不
我们将产生的费用将低于一美元
如果你在一小时内完成
然而
这里有一个大警告
你知道的 如果你出错了
如果你没有遵循这里的指示
如果你选择了错误的红移实例类型
或者如果你在完成时忘记关闭它
它将花费你数千美元 所以，如果你对这里有任何担忧
不要跟着做
动手操作
只是看着我做 这里有风险
我可不负责 如果你没有遵循指示
并在月底产生一大笔账单
但如果你遵循指示并跟着做
它应该免费或低于一美元
首先，如果你跟着做，你得到课程材料
如果你还没有从课程早期下载它们
前往 sundog dash education dot
Com
Slash aws dash Data dash engineer
你会在那里找到一个方便的链接 课程材料在那里
只需将它们下载到你的电脑并解压它们
当你完成时，它应该看起来像这样
那里只有一个杂志评论文件夹
我们的数据就在那里
那么我们这里有什么 well
这个引用文本文件只是一个包含数据集所需引用的纯文本文件
它来自哪里 他们希望你引用的论文
每当你使用这个数据
所以这里有两件事
一个是这些杂志订阅的真实评论数据
这些人来到亚马逊
并为每本杂志写了一个产品评论
这是来自2019年的数据集
我猜是的 让我们看看那是什么样子的
嗯 在我的最爱文本编辑器中打开它
你可以看到这是json格式
它相当冗长
这里有每一行的实际评论测试
以及评论员的id，用于识别个人评论员
asin基本上是这里的主键
所以在亚马逊的世界里
asin代表产品的标识符
这就是这本杂志的唯一标识符
这就是我们用于主键的适当方式
对 我们还有这位评审员的可读名称
每个唯一的名称可能有多个id
没错，这不一定是一对一的映射
我们还关心这里的整体字段
这就是这本杂志的整体评分
所以泰德真的很喜欢某物
B零零零零五七p零是一本杂志
并给了它五星好评
所以我们剩下的问题是理解这个零五和七p零到底是什么意思
这就是那个文件的作用
另一个文件，元数据文件
也是json格式
让我们也看看那个
这里给出了每个asin的详细信息
我们可以看到里面有很多信息
包括推荐的其他杂志列表等
但杂志的名字在这里，品牌这里
理性杂志 至少
这是出版商的品牌，更加一致
它给你关于
你知道它的主要类别
并且它在那里谐音
被埋藏在那里，所以再次
这里是我们将在元数据中使用的主键
这是这本杂志的唯一标识符
这个文件包含所有围绕这本杂志的元数据，我们可以查找
所以你可能猜到我们要去哪里
我们将进行一些连接操作，将这两个数据集结合在一起
现在，我们需要将这些数据放在一个地方，以便红移可以获取它们
好的 首先，我们需要将这些数据放在一个地方，以便红移可以获取它们
现在，直接从本地磁盘上传数据到红移是可能的
但这被限制在5MB以内
这个数据超过了5MB
因此，我们必须通过一些中间渠道将其放入其中
S3是合适的
让我们开始将此数据上传到S3存储桶中
在你的AWS控制台中
嗯 转到S3
可能有一个链接到它 您可以在这里找到它
如果您需要查找它，则可以搜索它
让我们继续为这项活动创建一个新的存储桶
我将其命名为DEA-C01-SunDog
请记住，存储桶名称需要在全球范围内唯一
如果您尝试使用该存储桶名称，则将无法工作
因为我已经使用了它 因此，请用您自己的名字替换SunDog
一些独特的标识符，使该存储桶名称对您唯一
我们将禁用ACL，因为我将在最高级别设置公共访问权限
让我们谈谈安全性
如果处理一些敏感或专有或个人身份信息
显然，您不希望使这些数据公开可访问
然而，我将这样做以进行此练习
只是为了简化，避免您需要看到我
所有我个人的AWS帐户标识符
在实际世界中，您可能不会禁用阻止所有公共访问
但为了简化这里，我将禁用阻止所有公共访问
并实际上使整个存储桶公开可访问
现在，有一些合法的原因这样做
例如，如果您正在创建一个静态网站
从S3托管内容，那将是一个合法的原因
但请注意，这不应该是一个安全意识环境中的正常做法
我只是这样做以使此练习稍微简单些
我会谈论如何正确地做这件事，以及如何在更安全的方式下做
现在 有一些合法的原因这样做
例如，如果您正在创建一个静态网站
从S3托管内容，那将是一个合法的原因 但请注意，这不应该是一个安全意识环境中的正常做法
我只是这样做以使此练习稍微简单些
我会谈论如何正确地做这件事，以及如何在更安全的方式下做
正如我们所做的那样，一切都好
所以我们将去做那件事
我们将禁用桶版本
因为我们只是在这里玩玩
我们不需要任何数据的备份
没有标签 嗯
默认加密是好的，让我们继续创建我们的桶
好的 让我们选择我们刚刚制作的桶
嗯，它在那里 它又是
你的名字会不同
我们需要做更多的事情，使数据对红移可访问
为了使红移从s三读取数据
它需要权限 不仅限于获取此桶中的物体
还需要列出此桶中的物体
让我们先去处理那些权限
让我们去权限
并且你可以看到那个块
所有公共访问都关闭
然而，我们需要定义一个桶策略，以便允许我们需要的权限
我将在这里作弊并只是复制它
而不是让你看我打字
我将要求你做的
只是点击
暂停这里 当我们准备好时
让我们在桶上点击编辑
桶策略
在你点击暂停并开始输入之前
确保你小心地用你自己的桶名称替换这里的资源名称
你可以看到我刚刚使用的桶名称就在这里
也在这里
所以你需要用你自己的桶名称替换它
如果你想以一种安全的方式做到这一点，而不是向全世界开放
有两件事你会做不同
当然，首先你不会像我这样做以启用公共访问
以及而不是将我所做的打开主角域，而不是打开主角域到星
你将锁定那个到特定的i am用户
或者甚至锁定到红移服务本身
所以而不是星，你可以锁定到
你知道
你，
46: Arn:
Aws:
I am:
你的i am标识符
所以在真实的世界里，在一个安全的设置中
您可能希望有一个更安全的桶策略
记住我们想要遵循被称为最小权限原则
因此您希望将其锁定得尽可能紧密
并且仅提供执行当前任务所需的权限
所以这就是一个例子
嗯 照我说的做，而不是像我做的那样
但是再次为了使生活更轻松
只管向前冲 暂停并再次将此复制到您自己的桶策略中
用您自己的桶名替换那个桶名
当你完成时再回来
好吧 一旦你输入了所有这一切
我们可以继续保存它
它接受了 因此意味着
至少通过一些语法检查
至少 让我们把我们的数据上传到这个桶里
回到对象
点击 上传
你可以在这里拖放它们
让我们回到我们的课程材料
我们将从这里的顶级加载它们
我将选择元数据和评论文件夹
像这样将它们拖动进来
当你准备好时，点击上传
这是大量的数据
所以它可能需要一分钟
好的，这就是我们
如果我们回到查看那个桶
我们应该看到我们现在有一个元数据文件夹和一个评论文件夹
在每个文件夹中，我们都有一个单个文件，好的
所以现在我们的数据在s3中，理论上可以访问红移
因为我让它公开访问
现在每个人都可以访问它，再次
不是最佳实践
但请记住，在实际世界中，将此锁定到适当的原则
让我们回到服务并再次访问亚马逊红shift
您可以在这里搜索
现在让我们创建一个红shift集群
目前他们正在积极推广红shift无服务器
这可能是亚马逊红shift的未来
但它实际上比创建一个单一的成本更高
一个低成本的单台机器的集群
所以再次
在这里谨慎行事
以防你忘记关闭这个
我们将使用传统的集群
我们自己管理资源
而不是使用红移服务器
导入数据和查询的过程在两种情况下相似
但我想要更多的控制
是的 我想要更精细的控制
我将从头创建一个集群
好的 在这里要小心
看这里
每月4597.50美元
你不想那样
你不想在这里选择默认选项
因为 我不认为你想在月底收到账单
但不要担心 我们将将其降至更可管理的水平
我们的集群需要一个标识符
嗯 我们应该叫什么
如何称呼amc评论
我将选择节点类型
我不想使用a3 4x大
这可能是你在现实世界中用于实际数据仓库的东西
但我们只是在这里玩耍
所以我将选择最便宜的
我发现的是dc
2点大，每小时费用仅为25美分
这比3便宜多了
2.6美元/小时
我只需要一个节点
我不关心冗余
因为再次 我们在这里玩耍
你可以看到我们已经将其降至180.2美元/月
这更可管理
如果你做数学
使用这个一小时将不到1美元
所以这更合适
但请小心
嗯，不要跳过那个步骤
我不负责
如果你选择了错误的设置，并在一天结束时产生了大账单
也请记住在完成之前关闭这个集群
如果你没有看完这个练习
并再次忘记
那么
这不是我的错 好吧，好的
我们继续设置我们的集群
我们的管理员用户名符合用户名
让我们把它留在aws用户
我将继续在这里
给它一个我自己的密码
所以输入一个密码并记住它
现在我们需要做的是创建一个iam角色以供此集群使用
以便它能够做它所需要做的事情
我们需要去创建一个
现在 这里说
关键是与亚马逊红移一起使用
所有命令 全权政策附加
但这比那更多
尽管我们可以说在管理下创建一个iam角色
我在这里有角色
它会这样做
但我们也想给那个s3桶提供访问权限，就像我们刚刚创建那样
所以让我们选择那个，我有很多在那里
它是如此
选择你自己的那里 当然
并创建iam角色作为默认
好的 所以那自动为我创建了一个
很好 谢谢
让我们继续查看这些其他选项
所以我们需要定义一个子网组
我们不能只是留下这个 像这样
所以我必须继续选择有一个子网的vpc 你可以看到那个已经有一个叫做红移子网
如果你需要创建一个
你可能必须去vpc ui并创建一个可用区 我将选择
嗯
我正在参加的那个增强型vpc路由 嗯，我现在不需要那个
那就是网络流量通过vpc而不是通过互联网
所以这将更安全
但是再次
因为我们正在做一切公开访问，不管怎样
这并没有多大好处
但是再次 既然我们正在做一切公开访问，不管怎样
这并没有多大好处
红移聚集自身聚集
然而并不公开可访问
绝对不想那样做
因为红移可能会很昂贵
真的很快
让我们看看这里还有什么
数据库配置 我们的数据库名将是dev
记住数据库端口是标准的
5439加密注意默认是禁用的
如果你处理任何敏感或个人信息
显然你会想改变那个
让我们去加密
只因为我们可以所以
我将使用默认密钥的kms
如果比什么都没有好
这比默认的更好
维护嗯
这不会运行足够长时间需要维护窗口
但我们将使用当前的默认值
警报再次在现实生活中
当然你会想要警报
但像磁盘使用
你可以创建一个s主题通知你
并发送警报如果你超过
嗯 磁盘使用率的70%
70%那里 无论你想要什么
然而 我不在乎
因为我们只是在玩 所以我将留到没有警报
备份 我将其设置为零
因为再次我只是在玩
我不在乎是否丢失这个数据
这不是真实的数据再次在现实生活中
当然你会想到这一点
幸运的是你可以自动备份你的数据
然而那可能会很昂贵
也请注意你说
嗯 我想要配置一个跨区域快照
这里需要思考的是
你被允许存储数据的地方
可能有法规
限制你的数据可以存储的地方
特别是如果涉及个人身份信息
不同国家可能有不同的法律围绕那个
你可能不希望将数据存储在一个法律体系不同的国家里
你甚至可能不知道这些
所以这一切看起来都很好 假设
创建集群
现在我们只需等待它启动
几分钟后，我们的集群启动了
让我们连接到它并开始使用它
你可以在这里看到 我们有三种非常方便的连接方式
它会给你一个链接，让你通过自己的SQL客户端连接
或者，如果你有一个jdbc或odbc驱动器，你想使用它
它也可以为你生成
然而，我们将保持简单，使用他们的控制台查询编辑器
我将点击查询数据
现在我们仍然需要将其与我们加载到S3中的数据联系起来
在我们将数据加载到Redshift集群之前
我们需要选择那个数据库
让我们进行身份验证并登录
我们将使用创建集群时设置的用户名和密码
数据库名称为dev
你可能记得，默认的用户名是aws user
密码
希望你记得你设置的密码，然后点击确认
创建连接
看起来我们已经连接到
现在我们有了dev数据库
我们有一个公共模式
我们将在这里加载我们的数据到这些表中
让我们点击加载数据按钮
然后浏览到我们的评论数据
选择你刚刚创建的S3存储桶
让我们从你的评价信息开始
选择杂志订阅
JSON，这是一个棘手的事情
所以JSON并不总是结构化的
数据 它可以是半结构化的
你可能会在这些奇怪的嵌套结构中发现问题
Redshift并不支持
这可能或不会成功
让我们看看会发生什么
不过
好的 我们将创建一个新表
在公共模式下
让我们给这个表起个名字
让我们叫它reviews
我们需要选择一个IAM角色
让我们选择我们之前创建的那个
并且检查一下这里的数据映射
所以我们要从那个json文件中提取模式
它试图从那个json文件中提取模式
它大部分都做到了
它做得相当不错
这些大部分都或多或少有意义
然而，我无法理解最后一个
你看不到image下面的数据类型
所以 假设那是某种复杂的数据结构
我们无法直接在redshift中直接表示
如果我们有一个合适的etl管道
也许我们可以重新结构化那个数据
以便更适合我们的关系数据库
但我们还没有到达课程的这一部分
所以，我将删除那个字段
因为，嗯，我在这里不需要它
那是个简单的解决方案
其他一切看起来都应该没问题
嗯
我们可以顺便创建一个主键
正如我们所说，asin是每个被评论的物品的唯一标识符
所以这似乎是一个合理的东西，可以用来连接这些表
让我们选择asin列，作为我们的主键
现在我们应该能够创建表
最后检查一下，看起来不错
开始吧
开始
正如我们所说
它将从s3中的那个json文件中复制数据
并将数据加载到一个名为reviews的新表中
它成功了，非常好
让我们对metadata做同样的事情
所以，我们从s3桶中加载数据
这次我们选择我们的metadata文件，在你的桶名下
然后metadata然后meta杂志订阅
所以，这次状态有点乱
所以，一个问题是，有些字段比255个字符长
当我们尝试将其放入bar car时
255
嗯 这不会起作用
所以，我们去数据转换参数这里
我们说我们将截断数据以适应列规格
如果我们有一个列，比我们的数据类型宽
我们将截断它
这对我们的目的很好
我们再次选择一个iam角色
我们将选择公共模式
我们将制作一张新桌子
使用下面的表名
我们将称其为元数据
好的
所以再次 我们有一些问题
嗯 结构我无法处理
所以无论你见到一个空白的数据类型
这意味着我们无法将JSON数据强制放入关系数据库列
结果我只关心这一点
在这是品牌列和asin列
这些是我将用于我的使用案例的唯一东西
所以所有其他我都不关心
嗯 让我们删除这里asin字段
因为asin是实际主键
这是详细信息
我不想在这两个不同asin之间产生混淆
所以这就要去
此外，任何没有数据类型的都将被删除
因为可能大多数这些是数组
它们可以是事物的列表
例如 每个单独的项目可以有多个类别
但在这个数据库中没有好的方法来表示
同样描述
嗯，此外那是该功能的推荐列表
同样想法
再次，图像是我无法处理的
但我不关心
因为再次，对于我的使用案例
我只会查看asin和品牌
在我们忘记之前 让我们将asin设置为主键
我们应该可以创建表
检查一切
加载数据
成功了
如果我们刷新这个
嗯，这个小面板
我们应该能看到我们创建的那两个新列
那两个新表
在dev公共表中
它们就在这里，元数据和评论，很酷
好的 所以
让我们看看它是否起作用
所以我们将在亚马逊评论数据库中工作
dev数据库
让我们运行一些后续操作
我们从一些基本的开始吧
比如从元数据中选择10个星号
我们有数据
如你所见 也有很多缺失的数据
如果我们真的在构建一个etl管道
我们需要处理大量的缺失数据
并决定如何处理它们
但重要的是，asin已经通过了我们关心的数据
并且品牌也出现了，我们关心的那些
这些基本上是问题杂志的出版商
让我们对评论数据做同样的事情，确保看起来
好的
选择星级从评论限制十个运行那个
看起来不错 所以我们有总体评价分数
一至五星
和asin
这些都是我们真正关心的
这里充满了空值
大量的数据缺失 所以在一个真实的管道中，我们希望深入研究这是为什么
并且可能更好地处理这个问题
但对于我们的用例我们不关心
所以让我们做一些更有趣的事情
编写一个查询来排序
评分最高的品牌
所以给你们一个小小的挑战怎么样
嗯 让我们看看您是否能编写一个SQL查询来连接这两张表
并给我返回哪些品牌的平均评分最高
好的 所以我们在这张评论表中有这些asin，每个asin的总体评分
我们可以将这些asin与元数据表连接
以确定每个asin的杂志品牌
所以，您的挑战
如果您选择接受它，就是编写一个查询来排序
根据他们的平均总体评分，找出评分最高的品牌
您可以暂停并尝试自己编写这个查询
但是如果你不
我就在这里给你答案
看起来是这样 所以我们首先选择我们有一些别名在这里
所以元数据表被简化为m reviews有一个别名r
我们将选择m点品牌品牌名称
从reviews表中的平均整体
我们将其标记为reviews表中的平均评分
我们在r n等于m asin上做元数据m的连接
所以我们根据asin字段将这些两个表连接在一起
按品牌分组
这样我们就可以一起查看每个品牌的评分，并计算每个品牌的平均分数
最后按平均评分对最终结果进行排序
这里的平均评分就是上面显示的
让我们运行一下，看看结果如何
这就是结果
这看起来有点可疑
嗯 有很多杂志的平均评分是5分，我得怀疑他们是否数据量很少
也许这些品牌的每个品牌只有一个评价
并且那个评价是五星
所以让我们对这个问题有更多的上下文
你的下一个挑战
如果你愿意的话，是将这个查询扩展到限制这个
只包括那些有10个或更多评价的品牌，并且打印出每个结果有多少评价
这将过滤掉那些我们没有足够数据来真正确定
那个平均分数的真正含义的品牌
所以我们可以更准确地了解这些品牌的质量
所以 如果你想尝试一下
你自己暂停并尝试一下
如果不
我将在这里粘贴答案
所以你看这里我添加了一个减半条款
计数r点在大于十
所以我们将限制此查询
仅限有超过10个评价的品牌
我们还将打印count art at asin作为结果中额外的列
这样我们就可以获得关于有多少评论实际上进入了这个平均计算的额外上下文
让我们再跑一次
这样看起来更有意义了
我们看到，仍然有几本平均评分为5.0
来自超过10条评论
我猜这是有意义的
所以人们真的很喜欢这些出版物
来自KMT通讯
KVS通讯
克莱和克莱以及加拿大家庭出版商和历史企业
有限公司，但在这里我们有一点更真实的
所以你知道这些东西不到五
我不知道它们对我来说感觉更真实
因为你知道不可能每个人都喜欢某样东西
嗯，但我们可以看到这里，真地
嗯 史前时代和嗯
制作媒体 哦，是的
制作制作杂志
那是本好杂志
这些在数据集中的评审者中都得到了很好的反响
这是一个有趣的小例子，展示了如何使用红移与一些现实世界的数据
如果你想要尝试一下
你可以这样做 但请记住，时间在流逝
你正按小时被收取费用，因为这个集群正在运行
所以 为了节省你的钱
我建议你关闭这个并关闭你的集群
所以不要忘记下一步
因为如果你让这个集群运行
你将会永远不断地被收费
无论你是否在使用它
你不想那样对吧
所以让我们回到服务并回到红移
回到集群
我们刚刚创建了amc评论
我要去操作并说
删除
为了确保我真的想删除这个
我要说删除
因为这确实会删除那里的所有数据
然而它在s3中仍然存在
我们只是从s3中复制过来的
对 所以这里有一个快速笔记
顺便说一下 我们可以使用redshift spectrum直接查询s3中的数据
但这样做需要我首先创建一个数据目录
但我们还没有在本课程中涵盖这一点
这就是我为什么没有这样做的原因
让我们删除这个集群中的副本
确保删除完成
如果不这样做，您将永远为这个集群付费
您不想那样做
我会等待它从状态改为
修改到状态
其他事情
让我们回到集群
查看这里并留意它
仍然等待删除
嗯 奇怪
删除这个集群比创建它花费的时间还要长
但我们再等一分钟
等它彻底完成后我再回来
好的 大约五分钟后
它终于显示已成功删除amc reviews
让我们刷新一下以确保
我的集群不见了 所以我不会再为那个付费了
呼，好吧
这就是红移在行动
亲自动手 我们在红移集群中复制了一些来自S3的数据
而不是直接在原地访问
我们将在后续课程中完成这一点
但是，是的 这就是红移
我不会让你删除我们创建的那个S3存储桶
因为我们将在后续课程中重用那个数据
因为S3的费用不是很高
所以当你完成课程后
你可以删除那个存储桶
但是现在 如果你打算继续
就暂时保留它 目前 继续前进
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/094_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p94 01. Intro Migration and Transfer.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


接下来的这一部分非常快速，数据迁移和传输是
当然，数据工程的一大部分
但在这个领域，亚马逊的提供相对直接
你需要知道它们提供的迁移和传输工具，以及如何选择它们
Stefan将覆盖这一部分
他将教你关于AWS应用发现服务
AWS数据库迁移服务
AWS数据同步
AWS雪家族和AWS传输家族
一如既往 你将有一些实际的例子
我们将以考试问题的风格编写一个测验来结束
所以让我们学习如何将数据移动到aws 无论它在哪里
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/095_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p95 02. Application Discovery Service & Application Migration Service.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


当你转向云服务时，有两种使用场景
例如，你想从头开始，并希望直接利用云服务
在这种情况下，你不需要迁移
但如果你有本地数据中心
服务器和数据中心
并且你想迁移到云服务
那么你需要规划你的迁移
一种方法是使用aws应用发现服务来规划你的迁移
所以，你将会扫描你的服务器
并收集关于服务器的信息
包括虚拟化数据和依赖关系映射
这对于迁移至关重要
这样你就可以了解如何迁移以及首先迁移什么
我们可以进行两种类型的迁移
一种是称为代理最后发现的迁移
使用连接器
这将为您提供有关虚拟机的信息
您的配置
以及性能历史
例如CPU、内存和磁盘使用情况
或者您可以运行一个代理来执行应用发现代理
这将为您提供更多来自虚拟机的更新和信息
例如系统配置
正在运行的性能进程
以及您系统中的所有网络连接详细信息
这对于获取依赖关系映射非常有用
所有这些结果数据都可以在另一个服务中查看，即aws迁移中心
因此，应用发现服务真正帮助您了解需要迁移的内容
以及它们之间的相互关系
但您实际上需要迁移
从本地到aws最简单的方法是使用aws应用迁移服务
也称为mgn
以前称为云迁移
但现在已经更换
好的
使用aws应用迁移服务 即mgn，您可以进行重宿
也称为lift和shift解决方案
在这种情况下，您将物理
虚拟
或其他服务 转换为在aws本地运行的服务
嗯 这是如何工作的，假设你有一个企业数据中心，包含操作系统、应用程序和数据库
它们运行在磁盘上
接下来，你将运行应用迁移服务
并在数据中心安装复制代理
它将持续复制你的磁盘
然后，你将在aws上重新启动这些磁盘
并运行你的应用程序
这样你就有了
例如 低成本的e
C 两个实例和ebs卷，这些卷复制了数据
现在 当你准备好进行切割时，你可以从阶段转移到生产
并且有一个更大的
E c 两个实例的大小，你想要的，以及ebs
卷，满足你需要的性能
所以，理念是复制数据
然后在某个时刻进行切割
这无疑是最简单的方法
因此，这支持广泛的平台
操作系统和数据库
并且这给你带来了最小的停机时间以及降低的成本
因为，你不需要雇佣复杂的工程师来做这个
这由这个服务自动完成
好的 就是这样 我希望你喜欢它 我会在下次讲座见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/096_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p96 03. AWS Database Migration Service (AWS DMS).ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


所以 假设 您想将数据库从本地系统迁移到AWS云
在这种情况下，您应该使用DMS（数据库迁移服务）
它是一个快速且安全的数据库服务
它允许您将数据库从本地迁移到AWS
但酷的是，它具有弹性和自我恢复能力
并且在整个迁移过程中
源数据库仍然可用
它支持多种类型的引擎
例如同质化迁移
所以从Oracle到Oracle
或者从Postgres到Postgres
但也包括异质化迁移
例如 如果你想从微软SQL Server迁移到Aurora
它支持使用糟糕的CDC进行连续数据复制
即变更数据捕获
最后使用DMS
你需要创建一个e
C 两个实例 并且那个e
C 两个实例将为您执行复制任务
因此，您的来源数据库可能位于本地
然后您运行一个e C
两个实例安装了dms软件
它们将从源数据库中连续拉取数据并将其放入目标数据库
所以问题是
源和目标是什么，你不需要记住它们所有
但了解它们是重要的
只是为了理解背后的概念
源可以是本地数据库
或 云 基于数据库的实例，Oracle，Microsoft
SQL Server MySQL，MariaDB，PostgreSQL
MongoDB，SAP和DB2
它也可以是Azure数据库
例如Azure SQL数据库
它可以是Amazon RDS
包括Aurora在内的任何数据库
它可以是Amazon免费和文档DB在目标方面
嗯 我们也有不同的选项
我们有本地部署
和E C 两个实例数据库
这样我们就可以使用Oracle、Microsoft
SQL Server MySQL、Mario DB
PostgreSQL、SAP
我们也可以在Amazon RDS上使用任何数据库
我们可以使用Redshift
然后使用Amazon S3
开源服务
你能看到流吗
Apache Kafka
文档数据库和亚马逊Neptune
以及Redis和babel鱼
这样你就不需要记住所有这些
当然 但基本理念是DMS可以帮助你将数据库
例如 一个本地数据库
并将其放入和导出迁移到目标
这就是AWS提供的任何数据库
如果你理解这一点
那么你就对DMS有了大致的了解
那么，如果源数据库和目标数据库不使用相同的引擎怎么办
那么你需要使用称为AWS Schema Conversion Tool的东西
它会将数据库模式从一个转换为另一个
例如 如果你使用的是OLTP
我们可以从SQL Server或Oracle迁移到MySQL
PostgreSQL或Aura
正如你看到的，左边的数据库引擎与右边的不同
你也可以将其转换为分析过程，如Terra或Oracle
一直到亚马逊红移
这里的想法是，源数据库与中间目标数据库的引擎不同
我们有DMS 但它不会作为T或模式转换工具运行
在考试前要知道的是，你不需要
你不需要使用
如果你迁移相同的数据库引擎
所以，如果你在做本地 postgresql 到 rds postgresql 的迁移，使用的是相同的数据库代理，它是 postgresql。
因此，你不需要使用其他工具。
但如果你正在做如 oracle 到 postgres 的迁移，
那么你需要使用一些工具，你知道的，数据库引擎是 postgresql。
但 rds 只是一个我们使用的平台，用于运行这个数据库引擎。
那么，你怎么设置 dms 的不间断复制呢？
你会有你的公司数据中心。
好吧。
你会有你的公司数据中心。
例如，以一个Oracle数据库作为源
和一个Amazon RDS数据库作为MySQL数据库的目标
如你所见
我们有两种不同类型的数据库
在这种情况下，我们需要使用T
否则将无法工作
所以这个模式转换工具
所以我们设置一个地址安装SCT的服务器，我们可以在预置机上设置它
这是最好的做法
然后我们会将模式转换为运行在Amazon RDS数据库上的MySQL
然后我们可以设置一个dms复制实例
这将进行全量加载和变更数据捕获cdc以实现持续复制
它将通过读取本地数据库
源或代码数据库
并将数据插入到您的私有子网中
就是这样 这就是你需要知道的所有内容
关于dms 这是关于数据库迁移服务
记住你需要使用t
无论何时你有两种不同类型的数据库需要迁移
对于dms来说
有多个部署
当你有这样的情况
那么你会有一个dms复制实例在一个az
然后在另一个az中复制该实例的同步复制
这将是一个备用副本
使用这一点的好处是
当然，能够抵抗一个特定az的故障
同时也给你数据冗余
消除IO冻结，最小化延迟峰值
这就是这节课的内容 希望你们喜欢 下次课再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/097_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p97 04. AWS Database Migration Service (AWS DMS) - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么我们来看看aws数据库迁移服务提供的不同选项
或DMS
那么我们将开始
我们将使用屏幕来确定我们需要哪种类型的迁移
所以首先我可以发现一个SS
这将使用aws SDMS舰队顾问
它将查看您本地数据库的所有库存
并确定正确的潜在迁移路径
这将为您提供小时
结果在小时内 并且节省您使用第三方工具或聘请迁移专家进行规划的时间
第二个选项是转换
所以这就是使用GMS模式转换工具来
基本上将数据库模式从一个数据库技术转换为另一个
因此，这是一个好主意，以便了解您可以进行的转换类型
然后你有迁移选项
这就是实际上迁移您的数据
因此，您可以进行不同类型的迁移
第一种是同质数据迁移
因此，这就是您从一个
例如 从一个数据库技术到同一个数据库技术
例如 从Oracle到Oracle
这对我们来说非常有帮助
例如 你将使用本地数据库工具来获得一些速度和更快的速度
然后你有异构迁移
所以，它们是当数据库类型不同的时候
例如，您从Oracle迁移到Aurora
或者从Oracle到PostgreSQL
随便 在这种情况下，您可以使用无服务器复制或基于实例的迁移
所以，在这里的区别是，基于实例的迁移
有一个e
C 两个实例在后台，您管理它们以进行迁移
但是，DMS管理实例本身，并在其上执行此任务，而服务器无
您不需要管理任何类型的资源
但它不支持每种类型的数据库引擎
所以尝试使用无服务器
因为显然这稍微好一点，容易一点
但看看您的技术是否支持
如果不支持，请使用基于实例的迁移
我将向您展示基于实例的迁移
我们将创建一个复制实例并查看选项
您将给它起一个名字
然后您将给出描述
然后您将配置实例，所以
当然 根据需要传输的数据量来确定实例大小
你需要根据数据量来选择实例
你有从t三微到最后的大型实例的不同选择
这完全取决于你，根据你的负载来决定
根据你的负载选择dms版本
查看dms发布节点
查看不同引擎版本提供的新更新
然后选择高可用性
如果你在做生产工作负载的复制
通常在一个可用区（AZ）下线时，拥有多个可用区会更好
如果你在开发或测试中进行一个非常简单的迁移
那么单个可用区可能足够
所以我们使用多可用区，有时你会遇到关于数据库类类型的限制
所以你需要什么样的数据库类
所以 让我们选择一个单可用区，以免收到警告
然后你的EC上想要多少存储
两个实例 然后是连通性和安全性
所以ip
Vpc
子网组
你是否想要 例如，使其公开可用
然后你有更多的高级设置
如果你想要，并且维护设置来做实例的操作系统的维护
当你准备好 你点击创建复制实例
但我们不会这样做
因为这样会花费我们钱
而且我们没有任何数据库可以迁移到和从，所以取消这个
但我只想向你展示选项
所以，一旦你在左边选择了一个复制实例
我们可以创建一个称为端点的东西
所以，端点允许你定义你的数据库在哪里
你可以创建一个端点
它可以是一个源端点或目标端点
如果是在rds中的数据库
你可以通过选择这个选项得到一个简单的选择器
如果不是 那么你可以设置端点标识符
然后设置源引擎类型
所以你在这里有这些源引擎选项
如果你选择目标
在这里你也有这些选项
嗯然后你会选择端点设置
所以可以选择向导来连接或者编辑器
并提供相邻格式
所以这些非常具体于你的数据库
这就是我为什么不深入探讨的原因
但它们提供了连接到您的来源或目标数据库的信息
这样您就可以从特定的复制实例测试连接
这样您就可以定义您的来源和目标
然后您将进入数据库迁移任务
这里是您可以创建任务的地方
然后说
这是我的复制实例
我想要 这是我的源数据库端点
这是我的目标数据库端点
我的迁移类型是什么
在这里我们可以迁移现有数据
或者我们也可以迁移现有数据并复制持续更改
这就是持续数据复制
或者只复制数据更改
再次我们可以有测试设置
我们想要什么设置
我们使用向导并选择所有这些设置
或者我们只指定它
以JSON查看您的数据迁移任务可以配置的所有内容
如您所见，有很多设置
这就是为什么在某些时候Jason编辑器可能更好
好的 然后您可以进行评估并进行一些配置
然后创建您的任务
显然我们不会这样做
因为这会花费我们一些钱
但你明白了
您创建一个复制实例
然后端点 最后创建一个数据库迁移任务
并且DMS正在向无服务器复制演进
您可以直接从数据库创建复制，而无需管理任何复制实例
然后您将获得更多关于模式转换和舰队顾问推荐的功能
以及同质化denmigrations
以利用这些原生数据库工具来执行这些迁移
这就是DMS和其概述的全部内容
这应该足以通过考试
我希望您喜欢它 我将在下次讲座见到您
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/098_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p98 05. AWS DataSync.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在我们来谈谈aws的数据同步
数据同步是一个现在出现的服务
在考试中出现的频率相当高
这是一个非常简单的服务
但你需要知道它在核心能做什么
所以，这个名字的含义是数据同步，意味着移动大量数据到和从各个地方
这些地方可以是
例如，本地服务器或其他云位置到aws
你可以使用NFS连接到你的服务器
所以，你可以使用NFS连接到你的服务器
B
HDFS或其他协议
它需要在本地或云上运行代理来执行该连接
你可以进行其他类型的迁移
例如，你可以从一个aws服务将数据迁移到另一个aws服务
这无需代理
我会向你展示这意味着什么
所以，你可以将数据同步到亚马逊S3
包括任何存储类别
甚至冰川
亚马逊esfs
存储到您的网络文件系统或亚马逊fsx
它支持它们所有
复制任务不是连续的
它们是按计划进行的
因此您可以使数据同步每小时、每天或每周运行
因此存在一个延迟 好的
但数据将按照计划进行同步
数据同步具有保持文件权限和元数据的能力，这意味着安全
就这样继续
这意味着它与NFS POSIX文件系统兼容
以及b权限
这在考试中非常重要
这将是唯一能够保留文件元数据的选项
当你将文件从一个位置移动到另一个位置时
数据同步代理可以非常强大
它可以运行一个任务
可以每秒处理高达10千兆字节的数据
尽管如果你不想让你的网络达到最大值
你可以设置带宽限制
所以让我们在图表中看一下这意味着什么
所以这里是同步你本地文件用例的场景
使用b或nfs协议将文件同步到aws
这可能是s3 e fs或fsx
所以你在本地有文件，然后在aws区域运行数据同步
所以这里是你的nfs或smb服务器
你需要在本地进行安装
aws数据同步代理
并告诉它连接到你的nfs或b服务器
然后，异步引擎将建立连接
并且以加密方式连接到数据同步服务
从那里你可以告诉它去你想要的任何地方
那可能是您亚马逊S3桶的任何存储类别
或者它可以是AWS EFS
或者它可以是亚马逊FSX
同步可以从本地到AWS S进行单向进行
但你也可以从AWS同步到本地
这就是为什么它被称为数据同步
它可以任何时间工作
有时在考试中我们会告诉你我们要使用数据同步
但我们没有网络能力这样做
因此你必须考虑使用AWS Snow Cone设备
因为Snow Cone设备附带有预安装的数据同步代理
所以你可以在本地运行Snow Cone
然后它会拉取您的数据
运行数据同步代理
然后将数据发送到您的AWS区域
然后同步数据到AWS的存储资源
这就是从本地到AWS的同步架构
或者它可以是
例如 另一个云到AWS
使用数据同步代理
但你也可以使用数据同步来同步不同的数据存储服务
例如 如果您想同步亚马逊S3或亚马逊FS
或亚马逊FSX
回亚马逊S3
亚马逊S3或亚马逊FSX
为此我们将使用AWS数据同步服务
它将复制数据
当然 但也会保持不同源服务之间的元数据
这非常重要，这也是考试中可能出现的内容
所以提醒您
它们几乎可以同步任何东西
但它不是连续的
它是按小时、日、周安排的
也会保留元数据和文件权限
最后，您需要运行数据同步代理
如果您连接到NFS或SMB服务器
好的 这就是这节课的内容 希望你喜欢 我会在下次课程见到你
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/099_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p99 06. AWS Snow Family.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么现在我们来谈谈我们雪家族的八个人
所以这是一个高度安全的便携式设备
用于在边缘收集和处理数据，并迁移数据进和出aws
所以我们有两种
我们有雪锥
它是一个小型设备
我们有边缘雪球
它是一个更大的设备
所以每种都有自己的特殊性
所以雪锥是为一个非常小的存储容量
你有8到14太字节的选择
通常你会使用一个雪糕
当你的迁移大小不超过太字节时
雪球边缘是一个更大的设备
它有不同的口味
但存储容量可以
例如，从8太字节到210太字节
当你的迁移大小达到拍字节时，你想使用它
你订购了很多 很多不同的边缘设备
那么我们为什么一开始就需要了解所有设备
嗯 让我们谈谈数据迁移
这里有一张表格，显示了转移十太字节数据需要多长时间
或者基于你的网络连接速度，一百太字节或一太字节
例如 如果你想转移一百太字节
而你有一个每秒一吉字节
每秒一吉比特的网络连接
那么这将需要你十二天
显然这会消耗掉你所有的公司带宽
所以当你的连接性或带宽有限
或者你的网络费用非常高
例如 你不能最大化照明，因为你在共享带宽
或者你有连接稳定性的问题
那么你就想使用我们中的八个
没有家庭 因为那是离线设备
它们允许你进行数据迁移，作为规则
如果通过网络传输数据需要您超过一周的时间，
那么您应该使用雪球设备
那么这是如何工作的呢
这是从我们直接的客户直接上传到亚马逊s3
但是，使用雪球家族
我们订购一个雪球或一个雪锥设备
它被送到我们这里
然后我们将数据加载到它上面
我们寄回
并且我们将直接导入到您的亚马逊s3桶中
所以这就是离线数据传输
所以我们首先从空中控制台请求一个雪球设备进行配送
然后我们在客户端安装这个设备
或者在服务器上安装一个称为AWS Hub的工具来传输数据
然后我们将雪球设备连接到我们的服务器
然后我们开始在客户端复制文件
然后我们将设备寄回
当我们准备好时 它将直接进入AWS设施
数据将被加载到亚马逊免费存储桶中
然后您的雪球设备将被完全擦除并可以发送给另一个客户
所以这是用于数据迁移过程
但你也有利边计算
所以什么是边缘计算
这是用于在边缘位置创建的数据处理
这意味着它可以是路上的卡车
或海上的船
或地面上的采矿站
在这些位置它们可能没有或很少互联网连接
并且可能没有计算能力
所以这里我们又订购一个雪球边缘设备或雪球锥设备
然后我们进行边缘计算
雪球锥带有一个非常简单的CPU和极低的内存
但它仍然对某些用例有帮助
然后在雪球边缘您有这个计算优化实例
这是为那个用例专门设计的，具有强大的处理能力
或者存储优化也有一定的处理能力
当你有一个雪球边缘设备时
例如设备 你可以运行e
C 两个实例或lambda函数直接您的雪球边缘设备
直接在边缘
所以边缘计算的用例是在数据创建的地方预处理数据
或者在数据创建的地方进行机器学习
或者在将数据传输回AWS时进行媒体转码
所以让我们看看，我们已经看到了雪锥和雪球边缘设备
它们用于数据迁移和边缘计算
我希望你喜欢它 我会在下次讲座再见
```

### /content/drive/MyDrive/bilibili/Udemy–AWSCertifiedDataEngineerAssociate2025–HandsOn!part1/100_Udemy – AWS Certified Data Engineer Associate 2025 – Hands On! part1 p100 07. AWS Snow Family - Hands On.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


那么让我们看看aws雪家庭服务
从控制台你可以实际订购一个雪家庭设备
你必须给任务命名
例如示范任务
我们需要选择一个任务类型
我们可以将数据导入到亚马逊S3
这是最常见的用例
我们也可以从亚马逊S3导出数据
你可以订购一个雪设备用于本地计算和存储
这将给你一个设备
那个可以在偏远地方运行且不需要连接到互联网的服务器
或者你可以将虚拟类型导入aws存储网关
所以我们会选择第一个选项
将数据导入亚马逊是免费的
在这里我们有几个雪设备的选项
所以我们有雪锥
雪锥ssd
雪球边缘存储优化的80TB
然后我们有计算优化的
以及计算优化的gpu
所以，Aeris可能会随着时间的推移添加选项，可能不会重新录制这个视频
这没问题
我总是涵盖考试内容
所以别担心
正如你所看到的
我们有几个选项 在上一节课中，我们已经看到了每个选项的使用场景
所以我不会详细解释
但这是一个很好的知道你将得到什么的方式
所以假设我们选择 例如，在使用计算优化的雪球边缘时
我们需要选择一个定价选项
所以我们有按需定价
按月定价 或者一年的承诺或三年承诺
然后我们有存储类型
这是一个s3数据传输
然后我们想做什么
所以这是一个计算类型的实例
所以我们可以实际加载一个ami
例如，这个亚马逊Linux二家用户
但你可以创建自己的ami
以满足你自己的计算需求
那么你想把数据加载到哪里
所以这里有三个可用的桶
我有这个在这里
但你可以创建自己的自由桶
我们有几个功能和选项可以使用
我们有iot greengrass for snow以在你的雪设备上拥有iot能力
但这不是必须的
然后我们可以使用ups hub或这个noble ball客户端进行远程设备管理
所以我会点击下一步
那么我们想在snowball设备上使用哪种加密方式
所以我们这里有一个加密密钥
你可以创建自己的kms密钥并用它来加密
然后你需要授予访问权限
当然需要访问亚马逊s3和发布操作以及发送数据
所以你需要创建一个服务角色
然后你需要添加一个地址
所以你想把它寄到哪里
哪个国家 哪个州等等
以及发货速度和工作状态变更的通知
然后你会得到工作总结
就是这样 你已经看到了所有雪球雪设备的选项
并且没有家庭
记住 它最常用于将数据发送到亚马逊S3
并从亚马逊S3中取出
这给你带来了远程计算能力
我们也看到了不同类型的设备
雪糕
雪球和雪地摩托
就是这样 希望你喜欢 下次讲座再见
```