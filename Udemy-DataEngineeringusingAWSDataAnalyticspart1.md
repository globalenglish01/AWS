### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/001_Udemy - Data Engineering using AWS Data Analytics part1 p01 1. Introduction to Data Engineering using AWS Analytics Services.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


你好朋友们 这是座头鲸
来自一座城市 我们很高兴地宣布一个新的课程，名为数据工程
使用aws分析服务
这是由我精心策划和创建的
作为这门课程的一部分
你将学习到关于aws分析服务的许多详细信息
但请记住，这个项目仍在进行中
我们已经包括了大约60%的材料
然而，在接下来的几天里，我们将添加更多的材料，到目前为止
发布的材料除了
设置本地环境进行练习
我们也会看到如何设置一个练习环境
使用云九
你必须选择这两种中的一种进行进一步练习
然后我们将实际开始基础方面
在这里，AWS方面的设置一个桶
我是组和用户
我们也会走通关于trolls的细节
也会理解如何配置和验证aws cli
这对我们来说很重要
以便我们能够与aws服务进行工作
然后我们将通读pi spark的开发生命周期
这将实际设置虚拟环境并安装pi spark
还会设置一个使用pi charm的项目
最后我们将构建一个应用程序的形式为zip
并且这个zip文件将在稍后的时间被使用
一旦我们进入emr
我们将只通读基于python的典型开发生命周期应用程序
使用 pi spark 构建数据工程应用程序
利用 spark 的分布式计算能力
一旦我们完成了 pi spark 的开发生命周期
我们将实际遍历所有 glue 组件
我们将简要了解所有重要的 glue 会议
我们将详细讨论 glue 爬虫
Glue 数据库
Glue 表 我们将使用像 athena 之类的工具访问 glue 目录、数据库和表
我们还将详细讨论 glue 作业
胶水触发器 在这个战争中粘合工作流
一旦我们获取了胶水组件的值
我们将实际设置spark历史服务器以用于胶水工作
这将帮助我们调试与胶水工作相关的spark工作
一旦我们为胶水工作设置了spark历史服务器
将实际深入研究胶水目录
胶水目录是关于创建数据库和表的
这些不仅可以被胶水工作访问
也可以被aws cmr以及athena访问
在这种情况下，我们将在后续的细节中深入探讨仅使用目录的情况
我们将使用特定文件夹创建表
如果文件夹有多个子文件夹
并且每个文件夹都与与不同表相关的数据集相关联
那么我们也将了解如何一次性爬取所有文件夹
使用单个爬虫为每个文件夹创建多个表
所有这些方面都将在本节深入探讨Glue目录部分涵盖
然后我们将实际探索Glue作业API
我们将简要介绍这些细节
我们将创建一个基准作业
我们将运行基准作业
我们还将修改脚本以对数据进行分区
我们还将使用Etherea进行验证
在任何数据工程管道中
我们应该考虑
嗯 以增量方式加载数据
Glue提供了一个称为书签的功能
在本节中，我们将详细探讨书签
以便我们了解如何从源到目标以增量方式获取数据
使用Glue作业
到本节结束时
你将对Glue作业的书签及其与增量加载的相关性有很好的理解
与增量加载有关
一旦我们对Glue有了很好的了解
接下来我们将关注的是使用Lambda函数进行数据摄取
在此 你将了解开发生命周期的完整流程，以开发用于数据摄取的Lambda函数
我们将使用Python作为准程序语言
一旦我们开发并部署了Lambda函数
我们将使用事件桥接器安排事件，事件桥接器用于安排一些简单的工作
一旦我们使用Lambda函数进行数据摄取，接下来
我们将进入使用Kinesis的流处理管道
在此，我们将配置Kinesis文件以从源读取日志文件
数据将写入到称为Firehose流的地方
一旦数据推送到Firehose流
数据可以配置写入到S3
这就是我们在本节中要做的
一旦数据被传递到S3
我们可以从S3消费数据，使用Auto3
或者我们也可以使用Spark处理数据，目前
我们将关注如何使用Auto3从S3消费数据
在此之后，我们将了解有关Dynamo DB的详细信息
以及如何将GitHub数据填充到Dynamo DB中
使用REST DPS
到目前为止，已经涵盖了这些部分
在接下来的几个月中，将会添加许多其他部分
但是，你需要花费相当长的时间来浏览这些部分
在我创建此课程的其他部分时
我希望你会喜欢这门课程
每当它提示你进行评分时
确保你给予适当的评分和反馈
五星级评分总是受到欢迎
如果你认为课程不值得五星级评分
你可以自由提供反馈
如果你有任何不满
你也可以将不满作为udemy问题和建议的一部分写下来
我会尽快处理这些问题
根据你的经验
你可以给予更合适的评分，话虽如此
这只是一个草稿模式
我们将在一段时间内添加更多内容到课程中
请关注以获取更多内容
同时学习这些内容，了解与构建数据工程管道相关的重要方面
使用aws 分析服务如glue
yr
ethanol can quick site etc
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/003_Udemy - Data Engineering using AWS Data Analytics part1 p03 3. Taking the Udemy Course for new Udemy Users.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


欢迎使用AWS数据分析服务大师班
我将详细介绍如何有效参加这门课程
如果你熟悉Udemy
你可以跳过这个 然后可以直接进入下一节课
如果你刚接触Udemy
我强烈建议你去这个讲座
这样你就可以舒适地参加这门课程
有时候 可能会要求评分
确保你给出五星评价
如果不行，欢迎联系我们
我们会尽力解决你的问题
然后你可以决定
也请随意提供反馈
说完了
说到Udemy课程
它只不过是一系列章节
章节只不过是一系列讲座或主题
你可以在右边看到章节
这门课程有几个章节
你应该能够展开或折叠章节
你可以看到每个章节有多个讲座
你可以通过点击它去特定的讲座
一旦你完成一个特定的讲座
Udemy会自动标记为完成
你不需要手动标记完成
如果你没有观看视频到百分之八十或九十
它不会标记为完成
你应该能够查看这些并查看哪些已完成哪些未完成
你应该能够查看未完成的特定讲座
这就是你应该如何使用右侧栏
实际上去浏览章节和讲座或主题
关于参加这些课程的一些投诉是关于我的风格
对一些人来说可能太慢
或者太快
这些视频中有一些工具
你可以在这里看到 这是计划路径
这是倒带和快进
你可以倒带 或者你可以快进
此外 你可以通过点击这个来调整速度
你可以以半速或双速播放
最小和最大
你可以在这两者之间调整，你可以根据自己的舒适度来决定
它将实际显示视频的进度
你也可以在任何你想做笔记的地方做一个节点
这是一个非常有力的工具，实际上可以回来复习
这与书签相似
当你实际上开始使用书籍阅读时
你可能有书签
你可能在书中的某些地方放置了书签以便在任何时候返回
添加笔记将使你能够以类似的方式行事
你可以点击添加笔记
你可以实际上添加笔记
你可以通过点击这个查看以前的笔记
你也可以查看其他笔记
此外
添加笔记在标记重要信息方面是一个非常强大的工具
你不仅可以标记
还可以围绕它做一些笔记
如果你观察视频右下角
你会看到有一个声音图标在这里
你应该能够使用这个来增加或减少音量
此外，如果你去设置，
你应该能够更改视频的清晰度
我也听到关于视频模糊的投诉
这可能是因为你的网络速度
它可能会选择三六零p或四三二p或五七六p
在流式传输视频时
如果它选择这个
你的视频会模糊
你需要确保你选择1080p或720p
这样视频就会清晰
嗯 我们实际上使用非常高质量的设备进行录制
因此，从我们这一侧，视频以大量的清晰度录制
但它可能会模糊
这可能是因为你的网络速度
你需要调整这个以确保视频不模糊
有一个清晰的视频来有效学习是非常重要的
这就是你应该能够有效地使用视频播放器来参加课程的方式
所以在这节课中 我涵盖了你如何实际上能够通过侧边栏导航并查看完整内容 还涵盖了一些与有效使用视频播放器参加课程相关的重要细节
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/004_Udemy - Data Engineering using AWS Data Analytics part1 p04 4. Additional Costs for AWS Infrastructure for Hands-on Practice.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


你好朋友们 欢迎来到数据工程
本主题将使用aws分析服务
我将强调额外的费用
您可能需要支付此课程的费用
请注意，在udemy购买此课程时
您只能通过q获得内容和支持
您将无法获得任何亚马逊基础设施的访问权限，您需要支付
无论是从您的口袋、雇主还是客户那里
您需要支付在aws账户中的任何实践费用
如果您自己学习
您需要注册
您需要使用您的电子邮件地址进行注册
您还需要注册信用卡
如果您在印度
您可能需要使用国际信用卡进行注册
您可以尝试使用国内信用卡
如果它不起作用 然后您可以尝试使用国际信用卡
此外 我认为他们最近解决了这个问题
您应该也能使用国内卡
您需要记住的是，您需要注册aws
然后您需要恢复您的信用卡
aws提供免费试用
但为了参加此课程
免费试用是不够的
您将不会使用太多免费试用
除非您需要学习与aws相关的一些基本服务
分析ah 您可能需要花费50到100美元
然而 如果您处理的数据量过大
或者如果您没有注意到就留下了服务
您可能会支付更多的钱，这不在我的控制范围内
在这种情况下
您需要非常小心可能产生的额外费用
如果您的雇主或客户加载了环境
您应该没问题
但如果您从自己的口袋支付基础设施来学习 确保成本在控制之下
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/005_Udemy - Data Engineering using AWS Data Analytics part1 p05 5. Signup for AWS Account.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


这个主题的一部分 我将强调注册AWS账户和浪费信用卡的步骤
你可以通过访问aws.amazon.com开始
然后你必须点击
创建AWS账户 这将带你到这个页面
你只需输入你的电子邮件地址
让我输入d. d. g raju @ i t. in
然后我必须输入密码
我也必须从密码中输入
它说
密码不匹配 让我修复这个
你也可以提供账户名称
让我们说它是demo
然后你可以点击继续
一五
现在您可以实际提供此附加信息 它是商业还是个人
让我们说它是个人的
您可以点击此 然后您可以实际提供全名
电话号码
国家地址 等
然后它将完成注册过程 它还会要求信用卡
一旦您提供了所有此信息
您将获得AWS第二账户的访问权限
我不想深入探讨所有步骤
因为这些随时间而变化
在高层次上
只需访问aws
亚马逊.com 点击
创建AWS账户
开始填写表格
这将导致您获得账户
一旦您获得账户
您应该能够无问题使用服务
作为下一主题的一部分
我们将看看如何审查账单仪表板
以了解成本
这将帮助您在实际进行数据工程课程时控制成本
使用AWS分析
在下一主题中
我们将看到如何审查账单仪表板 以了解成本
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/006_Udemy - Data Engineering using AWS Data Analytics part1 p06 6. Logging in into AWS Account.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们了解如何登录到aws第二部分
一旦设置过程完成
您只需前往aws amazon com的“我的个人账户”
然后您需要单击aws管理控制台
这将在第一次时带您到此登录页面
您只能作为根用户登录
一旦您以根用户身份登录
一旦您开始创建 我的用户
您可以 然后啊
开始使用 我的用户
您还可以为其他用户设置账户
作为i am用户
我们将在课程中详细介绍
i am相关的详细信息
目前我们将仅使用根用户登录
在此情况下，根用户实际上就是这个
让我使用这个电子邮件地址
然后 让我点击下一步
我们需要输入这些字符
我猜这是六q六五四c
让我点击 提交密码不正确
让我实际上输入这个
我猜这次是正确的
不正确
这次应该能工作
上次我只输入了五个字符
所以没有起作用
现在密码已经输入
让我登录 如果您启用MFA
您甚至可能需要输入此账户的密码
我没有启用
MFA代表多因素认证，也就是说
一旦您登录到您的根账户
这就是它看起来的样子
您可以在这里搜索任何服务
或者您可以扩展此部分
您应该能够访问您想要的任何服务
这就是您如何登录
您可以通过访问适当的服务开始使用您的aws账户
随着课程的进行，我们将覆盖很多服务 但目前，这就是您如何登录到aws管理控制台 一旦账户设置完成
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/007_Udemy - Data Engineering using AWS Data Analytics part1 p07 7. Overview of AWS Billing Dashboard - Cost Explorer and Budgets.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分 让我们详细探讨与aws相关的构建细节
在右上角的第二部分
您有通知 关闭按钮
然后您有一个支持下拉菜单
然后您有一个下拉菜单
您可以实际查看所有我们拥有aws数据中心的区域
然后我们在这里有账户名称
账户名称就是R&D
如果您点击这个下拉菜单
您可以看到我的账户到我的组织
我的服务实际配额
我的账单仪表板 我的安全身份验证
这将给我们提供与该账户相关的账单详情
我可以点击它 我将获得我的账单详情
如果您点击它 您将获得您的账单详情
在这里您可以获取所有其他账单详情
您可以实际获取预测
本月末的账单
这是本月到目前为止的金额
到目前为止，本月我花费了262美元
在七月，我花费了0.02美元
在七月，我花费了2.64.50美元
这将是您应该能够看到的过去三个月的账单
这里有几件您需要记住的重要事情
尤其是预算
预算将帮助您设置警报
如果您超过设定的金额
您将开始收到警报
这将帮助您控制成本
您也可以点击成本探索
它将给您提供与服务级别或链接账户级别相关的成本详情
等等您可以在这里查看详情
这里有预配置的视图
我们也可以使用自定义视图
预配置视图就是服务级别的月度支出视图
月度支出链接账户视图
然后您会看到支出视图
当您第一次访问时
您可能会看到一个消息说您可能需要等待24小时才能看到这些视图
一旦您过了那个时间，您应该能够查看
这是按这些不同类型的视图计费
让我点击启动成本探索，看看它说什么
如果我点击启动成本探索
它说 因为这是您第一次访问
准备您的费用和用量数据将需要一些时间
请20分钟后回来查看
自从我设置这个账户
我还没有点击过这个费用控制器
这是我第一次 因此我才看到这条消息
我刚才稍微强调了一下
这也是这个话题的一部分
一旦完成
我们应该能够通过这些不同的角度到达终点
按服务视图 按关联账户视图
以及按账单结束视图
目前 如果您点击这些链接中的任意一个
它将带您到费用探索器的顶部相同的消息
与计费相关的重要方面无非是预算
如果您点击预算
您可以了解这是关于什么的
您可以创建一个预算
并且您可以实际设置限制
此外 当您超过限制时，它不会终止服务
但是您会收到警报
您应该能够利用那些警报
以便解决您花费更多钱的问题
如果您不小心忘记了一些服务正在运行
您可以进入这些详细信息
并且您可以实际关闭那些服务
并且您可以进一步进行
预算和费用探索器的结合
使用不同类型的使用将帮助您解决这些问题并关闭
终止那些服务以控制您的费用
随着我们继续深入探讨这些细节 您将理解我所谈论的内容
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/008_Udemy - Data Engineering using AWS Data Analytics part1 p08 1. Setup Local Environment on Windows for AWS.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我希望你正享受在aws上的数据工程课程
使用归类在aws analytics的服务
对你来说，拥有一个本地环境非常重要
可以用来通过aws cli命令与aws交互
以及使用基于python的代码
你需要在我们的任务上设置几件事
在这一部分 我们将详细介绍设置这些工具所需的步骤
以便从windows与aws交互
我们将使用称为wsl的东西，wsl代表windows子系统
Linux子系统 你将了解如何设置
你想要在Windows上使用WSL浪费虚拟机
一旦基于Ubuntu的虚拟机设置完成
你也将了解如何访问它
这就是它将看起来的样子
然后我们将看到如何使用适当的工具安装aws cli
一旦wi安装完成
你也将看到如何配置它
还将验证aws cli是否可以用于与aws服务交互
或者不是 这将会是像这样
在你完成aws航空公司的设置时
并且征服它与aws账户进行交互
在这种情况下，我正在尝试列出称为s三桶的东西从我的账户
这将证明账户可以从我的当地机器访问
使用aws cli
你将能够实现这一点
在本节结束时
在此基础上 你将了解如何设置基于导师的环境
安装所需的二进制文件并编写Python代码以与AWS服务进行交互
这将像这样
让我转到您将设置Gypter的工作环境
基于该环境与AWS进行交互
这只是项目
作为项目的一部分
我有内部训练营
然后是AWS数据工程
它有一个Python虚拟环境
这就是d hyphen v e和v
让我激活它
你将理解如何实现这一点
当你浏览这一节中的讲座时
现在 让我运行称为jupitter lab
它将启动笔记本环境
使用该笔记本环境
你应该能够编写所需的代码以实际从本地机器与aws进行交互
你应该能够复制这个
如果URL没有自动打开
现在已复制
让我转到浏览器
我在这里将使用chrome
如果你使用的是mac或你想要粘贴桌面
你可能会被自动重定向
但在这种情况下没有
我不得不只是复制粘贴URL
现在你可以看到我能够进入jupyter环境
我已经有了与aws交互相关的代码
使用python和auto three
你可以在这里看到
让我称之为内核
然后重启内核并运行所有单元
你将得到这份笔记
你应该能从你的角度进行验证
这将运行所有代码
你可以实际看到桶的名称
在这种情况下，我们使用了基于python的方法来获取桶的名称
我们能够与aws s three服务进行交互
然而一旦
所需的
sdk设置完成
你应该能够与任何aws服务进行交互
到课程结束时你将能够做到这一点
随着你继续前进
当你设置这些工具时
如果你遇到任何问题
请随时联系我们
我们将支持你，话说回来
享受课程
确保你有正确的环境设置
然后你应该能够进入与aws数据工程相关的模型
使用aws analytics 相关服务
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/009_Udemy - Data Engineering using AWS Data Analytics part1 p09 2. Overview of Powershell on Windows 10 or Windows 11.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在Windows上设置所需工具的过程中
你应该熟悉一个名为PowerShell的工具
PowerShell部分在Windows 10中内置可用
包括Windows 11以及更早版本的Windows
我将使用Windows 11进行演示
你应该能将其与Windows 10联系起来
此外，值得注意的是
作为一名软件工程师，了解PowerShell的重要性对你来说非常重要
以便你能够有效地使用它
如果你已经在Windows上工作了很长时间
你可能听说过DOS提示符
PowerShell实际上是DOS提示符的增强版
DOS提示符通常用于运行任何基于Windows的命令以导航文件系统
以及进行一些其他操作
与DOS提示符相比，PowerShell功能更强大
你应该能够使用PowerShell编写脚本
它在基于Windows的项目中使用
然而 如今，大多数应用程序在Linux上使用Shell脚本
你需要安装一些额外的工具
这将在相关课程中的相关部分进行覆盖
对于现在，我们将关注可能的事情
如何启动它
以及已经涵盖的一些关键特性
什么是PowerShell
它只是一个命令提示符 你可以在这里运行任何有效的Windows命令
值得注意的是
如何启动PowerShell
你应该能够点击这个搜索栏
或者像这样的应用
这是一个应用的图标
你可以点击它
它会打开这个搜索应用
我已经搜索了Windows PowerShell
所以我在这里看到了它
你可能看不到
你可能看到这样的东西
现在，你应该能够在这里搜索PowerShell
如果你使用的是Windows 10
你可能在这里看到一个搜索栏
你应该能够在那里直接输入PowerShell
你将看到几个选项
如果你使用的是Windows 10
你可能看到几个选项
你需要选择合适的选项
在这个例子中，我将在这里搜索PowerShell 你看
它实际上显示了几个选项
有四个选项，你应该点击Windows PowerShell，没有附加详细信息
比如我看到86和86
我们只需点击windows poweral
它会为我们启动power al
在windows ten
你可能会实际上
嗯 看到power cell
嗯 在windows eleven中，它们将颜色更改为黑色
他们改变了颜色为黑色
除了那个之外
其他大部分关键特性都与
至于使用Windows 10或Windows 11相关的包裹命令是相同的
如果你想在powershell中更改任何设置
你必须去顶部栏
这就是顶部栏
你可以右键 点击
你可以点击属性
你可以在这里看到很多设置
你应该能在这里更改设置
如果你想使用蓝色
你应该能去颜色
你应该能更改背景，你可以继续
类似地 如果你想更改字体
你可以在这里更改字体
这些是与如何自定义你powershell行为相关的详细信息
根据你的偏好，话说回来
让我们谈谈一些与powershell相关的关键特性
包裹最显著的功能之一是能够访问远程系统，无需安装任何额外软件
如果你已经在Windows上经验丰富，你可能正在使用称为PuTTY的工具来连接到远程系统
你不需要设置PuTTY
如果你有PowerShell，一切都在那里
你只需要获取用户名和主机名
等等
你应该能够利用这些信息连接到远程系统
等等 你应该能够利用这些信息连接到远程系统
使用 PowerShell 中可用的集合像这样
有很多其他功能
你将理解这些功能
并在必要时
一个突出的功能无非就是能够通过 SSH 连接到远程机器的能力
话虽如此 如果你想使用 PowerShell 列表文件
你应该能够使用名为 sdl 的命令
它就是 DOS 提示符命令
你可以看到那里的文件夹和文件
你也可以使用 mk 你的指令来创建目录
然而 如果你是来自Linux背景
一个 PowerShell 并不像 Linux 终端那样高级
或者 Unix 终端
它可以运行 Windows 命令
Windows 命令与 Linux 命令有显著差异
话虽如此 我们已经理解了什么是 PowerShell
如何启动 PowerShell
以及 PowerShell 的一些突出特性
我们也看到了如何自定义 PowerShell 的行为
这样你就可以改变行为
根据你的个人喜好
话虽如此，我们将在几门课程中使用 PowerShell，而不是在需要时 在几节讲座中
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/010_Udemy - Data Engineering using AWS Data Analytics part1 p10 3. Setup Ubuntu VM on Windows 10 or 11 using wsl.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这次讲座的一部分
让我们开始使用ubuntu在windows上设置
我们可以利用称为wsl或windows系统为linux的功能
实际上设置
您想在windows上设置
您想在windows上
使用wsl或windows子系统为linux
您可以从启动power cell开始
然后你应该能够进一步
在这种情况下，我有paral作为我的such结果之一
所以我点击了这个
如果您看不到这里 您只需点击这里并搜索
然后你可以进一步
如果您使用windows ten
您应该看到一个搜索栏
您可以在其中搜索power cell
然后你应该能够启动powershell
让我启动powerl这里
现在powershell已启动
您可以使用名为wsl的命令来查看wsl是否已设置
在大多数windows ten和基于windows的机器上
特别是如果您是个人机器
wsl应该已经设置
如果您使用的是办公室笔记本电脑
它可能没有设置
您需要联系IT管理员
您需要确保wsl已设置
他们可能会设置 或者他们可能不会，这取决于办公室笔记本电脑的政策
wsl可能没有预先为您设置
您只需记住这一点，说到查看
wsl是否已设置
您可以说wsl减v减v减版本
您应该能够看到它的使用情况
实际上没有给出版本详细信息
让我看看是否有其他命令可以实际给出版本
我可以使用减减帮助以获得更多关于wsl的信息
到目前为止 直到您安装某些东西
您将无法看到wsl的版本
现在您可以使用减减安装来设置第一个虚拟机
我或减减安装
它将默认安装基于ubuntu的虚拟机
还有其他一些选项可以获取可用选项的列表
您可以说wsl减减减在线或减o
减o只不过是减减在线的同义词
您可以在这里查看详细信息
两种方法都可以使用
我正在使用减减在线
你可以看到可用的分布
我们应该能够利用这些分布
以便根据我们的偏好设置虚拟机
让我们了解如何在Windows上设置Ubuntu 20.04虚拟机
使用WSL 如果你只说WSL啊
短划线短划线安装
它会默认使用Ubuntu
你可以看到这里的星号
它是默认的
它会使用这一个来设置虚拟机
它可能指向18.04
如果你想使用Ubuntu 24设置
你应该能够说WSL短划线短划线安装
短划线d或短划线短划线分布
你可以看到语法这里
之后你应该能够说你想要短划线20.04
这是敏感的 因此你应该在这里大写
然后它才会工作
我将使用Ubuntu 24设置虚拟机
即使你用Ubuntu
它可能最终使用Ubuntu 20.04设置虚拟机
在我的情况下我将使用这一个设置虚拟机
你可以选择并按Enter
它将被复制
你应该能够说WSL短划线i为短划线短划线安装
两者都是别名
或者 你可以说短划线i或短划线短划线安装
然后你应该能够说短划线d或短划线短划线分布
我已经复制到缓冲区
现在我粘贴
我刚刚右键点击
你可以看到它没有任何问题被粘贴
现在 我们应该能够按Enter
然而 它以某种原因失败
它实际上没有安装它
让我检查命令
它只不过是WSL短划线短划线安装
短划线d
我想没有安装别名
这就是为什么它不工作
我必须说WSL短划线短划线安装所以
让我删除这个
让我短划线
然后安装然后短划线
你想要短划线Ubuntu
现在您可以看到，命令正在运行中花费了一点时间
当命令运行时
我有一个积极的录音
现在命令已成功运行
让我们理解发生了什么
它安装了一个称为虚拟机平台的东西
一旦虚拟机平台安装完成
如果您已经安装了称为wsl的东西
wsl只不过是一个Linux子系统
尽管命令可用
实际的wsl并未安装
当我们尝试安装第一台虚拟机时
它将实际处理在机器上安装wsl
或者在您的Windows机器上一次
啊 wsl已安装
它处理了下载和安装wsl内核
一旦wsl内核安装完成
它已下载并安装了称为gui app支持
Gui代表图形用户界面
wsl也有一个图形用户界面
但我们不会使用它
如果您想 您可以探索它
在处理与wsl相关的所有组件后
然后它已下载Ubuntu 24图像供我们使用
现在必须安装
安装尚未完成
它说请求的操作已成功
因此命令已成功
然而 更改直到系统报告时不会生效
现在是我重启这台机器的时候了
以便处理使用此分发安装虚拟机的过程
如何重启此虚拟机
我们可以实际上点击它
如果您使用的是Windows eleven
那么在这里您可以看到电源按钮
您应该能够点击它
您应该能够重启
如果您使用的是Windows ten
您将在这个角落看到类似的图标
您应该能够点击它
并且您应该能够重启您的Windows机器
因为我使用的是Windows eleven
我可以看到电源按钮是此应用程序的一部分
让我点击它
您可以看到有一个重启选项
我应该能够通过点击它重启此Windows机器
现在Windows虚拟机正在重启
一旦Windows机器重启
我们将继续设置Ubuntu 20的过程 使用WSL在Windows 10或11上创建虚拟机
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/011_Udemy - Data Engineering using AWS Data Analytics part1 p11 4. Setup Ubuntu VM on Windows 10 or 11 using wsl - Contd.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在这个时间我们将详细讨论如何设置基于Ubuntu的虚拟机
使用Windows 10或11的WSL
在我们运行命令后系统会重启
名为wsl的命令 hyphen hyphen install hyphen d ubuntu twenty four
当系统重启时
它实际上已经恢复
它在停止的地方继续
你可以看到它已经在这个Windows机器上安装了Ubuntu 24虚拟机
Windows基于机器
现在正在提示输入用户名和密码
用于这个基于Ubuntu的虚拟机
在这种情况下，我给它起了个名字
就叫这个
这是用户名
这将在后续的时间点方便我们登录虚拟机
确保你记住用户名和密码
在这里我输入密码
第一次输入密码后
我也重新输入了密码
一旦重输入了密码
然后在Ubuntu 20的虚拟机上成功创建了用户
这是在Windows上创建的
你可以看到我已经在基于Ubuntu的虚拟机上
你应该能够看到你的名字-hyphen-a来确认声音详情
你可以看到它只不过是一个基于Linux的操作系统
这只不过是一个WSL CLI或命令
提示更改设置
你可以实际上去属性
这实际上只是DOS的一种风味
提示或力量本身
因此你会以同样的方式看到偏好
正如你在PowerShell中看到的那样
让我换个字体这里
让我改变成两四
让我点击一下 现在您可以在这里看到更大的文本
所以这就是你应该能够完成ubuntu设置过程的方式
在WSL上的基于24的虚拟机
现在这就是wsl ah界面
即使它是powershell的花朵
如果我退出
它将实际上完全退出应用程序
如果你必须再次登录到虚拟机
一种方法是利用power cell并再次将其推向前进
我正在启动power cell
只是为了演示如何连接到该虚拟机
该虚拟机现在已创建但power cell已丢失
你应该能够列出当前运行的虚拟机，通过说wsl -l -v
你可以看到，目前虚拟机处于停止状态，想要连接它
你只需说 wsl，它会自动连接到它
如果你有多个虚拟机
它会实际连接到默认的虚拟机
星星代表默认的虚拟机
在这个案例中我们只有一个
它将是默认的虚拟机
因此当我们说 wsl 时
它会自动将我们带入该虚拟机
让我退出这里
让我运行 wsl hyphen hyphen view 再一次
如果你有多个虚拟机
如果你想连接到一个虚拟机
你可以使用 wsl hyphen d 或 hyphen hyphen distribution
你应该能够给出分布的名称
这就是你想要的二十四
在这个案例中 你应该能够这样连接到虚拟机
通过明确指定分布的名称
使用该名称设置虚拟机
现在虚拟机已经设置
如果虚拟机处于停止状态
当我们运行 wsl 命令时
它会启动 然后它会将我们连接到虚拟机
你可以看到它已经进入 Windows 机的家目录
这就是 Windows 机的家目录在虚拟机中的表现
作为虚拟机的一部分
你也可以运行 on ldr
你应该能够看到所有在 Windows 机上的文件
在通常的家目录中
使用该目录我们登录到这个 Windows 机
你也可以说 exit
你可以运行命令
这里是有效的 on power 对抗 Windows
因此你可以运行 dear
你看到的所有文件夹
你将看到所有这些以及一些额外的隐藏文件夹
当你实际上运行 lsi on lt 命令作为虚拟机时
这是设置 使用 you want to lsi 是 linux 基于命令来列出文件和文件夹
你可以看到所有在家目录中的文件夹
其中一些是隐藏的，在 Windows 上运行命令时不可见
然而，当涉及到 Linux 时
当我们运行 lf 和 lt 时
它们不是 Linux 的隐藏文件或文件夹
因此它们会在这里显示
你可以实际上通过运行 cd 命令访问你虚拟机的家目录
这就是家目录
你可以运行 pwd 命令来实际查看家目录路径
这又是Linux或Unix命令
它会给我们提供当前工作目录或工作目录
这是用户的当前工作目录
Dga Raju
这个用户是从设置虚拟机时创建的用户那里来的
你在设置虚拟机时给的名字，在这里会显示出来
当我们运行wsl high on d时
你不会像这样连接到虚拟机
它会连接到我们在设置虚拟机时创建的用户
这就是你设置基于Ubuntu的虚拟机的方式
这就是你在Windows上使用wsl设置Ubuntu虚拟机的方式
我们会根据课程需要使用wsl
我们也应该能够根据课程需要使用它
你也应该能够根据日常活动使用它 除了课程
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/012_Udemy - Data Engineering using AWS Data Analytics part1 p12 5. Setup Python venv and pip on Ubuntu.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这次讲座的一部分
我将演示如何验证和设置所有必要的补偿以供Python使用
补偿给Python
在基于Ubuntu的机器上构建基于Python的应用程序
在此情况下，我将使用Windows上的WSL进行演示
使用WSL
我已经设置了一个Ubuntu 24的基础虚拟机
我将使用该虚拟机
但如果你有
你想要一个基本的桌面
你只需启动终端
你应该能够遵循作为本次讲座一部分将要覆盖的指令
为了确保我没有基于Windows创建一个基于Ubuntu的虚拟机
让我启动一个PowerShell
一旦我在PowerShell中，我应该能够使用WSL
Ubuntu-24
这将使我能够连接到使用特定分发创建的特定虚拟机
否则它将默认
现在正在启动，我很快就会进入虚拟机
我在虚拟机中
让我实际上上去
我在Windows的家目录
我通常通过运行cd命令在虚拟机中的实际用户家目录中导航
这是实际用户作为部分此虚拟机的家目录
这就是这个
因为我在家目录中
我应该能够验证Python说Python
我应该能够按Tab键，您将能够找到这些命令
Python.exe
Python3旋转
Python3.exe
如果你在使用...你
如果你不在Ubuntu虚拟机上使用Windows
当你实际上进入基于Ubuntu的桌面时，您将只能看到这两个
但由于我正在基于Windows的Ubuntu上使用
我实际上看到了这些Windows命令
您可以忽略这些两个
所以只有两个命令以Python开头
它们只是Python3和Python3旋转
如果我只说Python并按Enter
你看 这是一个命令
Python未找到
然而 我们应该能够使用Python3实际启动Python3
如果你想要 您可以实际上为Python创建Python3的软链接
您应该能够开始使用Python命令
但我将使用Python3
仅此而已
我应该能够说python三并按回车
您可以看到，它已经启动了一个使用3.8.2的python cli
python三无非是软链接到python3.8
无论您使用python三还是python3.8
实际上它会将我们带到相同的cla
在这种情况下我正在使用python三旋转
您可以看到它也为3.8.2
当我说python三时
它也是3.8.2
仅此而已 一些所需的额外配置
对于在基于ubuntu的系统上使用python是nothing but v and v
实际上用于创建虚拟环境
这是必须的
并且我们也应该有pip
除非或直到我们有一个虚拟环境和pip模块
我们不会能够使用那些东西
让我们验证我们是否有python虚拟环境模块以及pip模块
如果没有我们需要安装那些东西
在这种情况下我可以说python三
然后减m
v and v这就是你应该能够创建python虚拟环境的方式
让我命名为demo
减v e and v
这是虚拟环境的名称
如果我按回车
它正在抱怨
说虚拟环境没有成功创建
因为sup不可用
这意味着p没有安装
因此它实际上正在抱怨
它实际上给出了提示
说你需要安装python三减v and v包
使用以下方令
您可以在这里看到
如果您想验证p是否可用
您可以也说python三
减yam pip install
让我尝试安装一个叫做config parser的东西
即使是对于pip
它并不默认存在于基于ubuntu的系统上
只有核心python可用
我们应该能够使用这个命令
然而我们必须使用sudo
让我使用sudo这里
让我粘贴
我没有复制的方式
它没有起作用
让我选择它一次
现在让我按回车
让我右键点击粘贴
所以你可以复制粘贴
只需在这里选择字符串
然后按回车 它会复制到缓冲区
然后你必须右键点击实际粘贴
我已经右键点击并增强
命令在粘贴后会被粘贴
我尝试运行命令
它提示需要密码
我已经输入了密码
这是我们在设置虚拟机过程中为用户设置的密码
使用wsl
如果你在使用 你想要直接桌面
你应该输入你的sudo密码
你应该一切顺利
命令没有成功运行
它说没有这个名字
这是因为作为列表中的一部分，这些列表中有关于应用程序的
这个软件不可用，请确保安装这个软件
我们需要更新列表
默认列表可能不是最新的
首先 我们需要更新列表
然后我们需要安装所需的软件
如何更新列表，您只需说伪 apt update
这是您应该使用的命令
现在 你可以看到它在做某事
实际上正在更新列表
每当我们运行任何命令
它将遍历所有这些列表，看看是否有使用该名称的软件
我们试图安装
它将会从那些列表中尝试安装
现在列表已经更新了
我应该能够按上箭头键去公寓
获取安装命令以安装 Python 三杠
V E和v 现在，它实际上能够识别一些软件
它正在尝试安装
它正在提示我们是否继续或不继续
在这种情况下，你必须说y并按回车
或者只是按回车
如果你注意到y是大写
这意味着它是默认的
因此，它已经接受
它已经开始安装啊，所有后期所需的Python 3虚拟环境模块
现在您可以看到它正在按预期工作
我们必须等到它完成
然后我们可以继续
我们还将安装pip
以便我们可以利用pip来安装软件
然后当它被要求时
您可以这样安装pip而不是说python three
减号v和v
您只需说减号pip
它将会安装甚至pip与尊重python three
它正在提示确认
您可以按回车键确认现在正在安装pip
我们已经成功验证
在ubuntu机器上python的版本
然后我们实际上安装了v和v以及pip
这些不在盒子中
一旦这些被安装
我们应该能够创建虚拟环境ah
根据我们项目的要求
我们也应该能够利用pip来安装所需的软件
当我们想要探索某事时
让我们等到它完成
我们也将验证是否可以创建虚拟环境
以及pip是否可以安装任何基于python的模块
一旦验证完成
然后我们将实际结束这个讲座
现在npp已安装
让我们验证一个虚拟环境
然后我们将实际处理pip以验证虚拟环境
我们只需说python three减号m v和v demo减号
V e和v并按回车
它将会创建一个名为demo减号v e和v的文件夹
您可以实际运行lf和l命令
您应该能够看到此文件夹
以前它失败了
现在成功了
这足以验证v和v模型是否可用
作为python的一部分
在这种情况下，它作为基于ubuntu的机器上的python可用
现在要验证pip
我们可以使用pip install命令
但在进入这些细节之前
让我使用rm减号rf命令来实际删除此文件夹
现在文件夹已删除
现在我可以说pip install config parser
我正在安装一个非常基本的软件或模块
您可以看到它已成功安装
这就是您应该能够验证pip是否可用
基于这个基于ubuntu的机器
在上面
所以我们成功地安装了所有与Python相关的必需组件
这样使用Python的应用程序可以在此开发
您希望基于使用WSL在Windows上设置的信息
无论您在Windows上使用基于WSL的Ubuntu虚拟机
或者您希望直接桌面 步骤将保持不变
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/013_Udemy - Data Engineering using AWS Data Analytics part1 p13 6. Setup AWS CLI on Windows and Ubuntu using Pip.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在这个阶段，我们在设置aws的本地开发环境
我们应该能够利用像aws这样的工具
以及使用适当的模块的python来对aws服务进行工作
在这一课中 我们将专注于设置一个cli
我们将使用基于ubuntu的虚拟机，该虚拟机是在windows上设置的
使用wsl 如果你直接使用ubuntu桌面
你应该能够登录
启动终端 一旦你确认与Python组件相关
你应该能够使用AWS进行安装
关于AWS的详细信息
安装Python相关的会议作为前一节课的一部分被涵盖
你可以从那里继续
你应该能够处理设置AWS
例如使用pip
这只是Python包安装器
如果你使用的是Windows
如果你想进入
你想创建虚拟机
只需在搜索栏中输入
然后进入powershell
然后输入wsl
减号
Ubuntu 减号二十点四
现在我正连接到基于Ubuntu的虚拟机
现在我在基于Ubuntu的虚拟机中
我将进入家目录
如果你使用一个
你想要直接在桌面上
一旦你启动终端
你将进入用户的家目录
现在我们只需要说 pip install
然后 aws cli
它会为你在基于ubuntu的使命上安装一个cli
至于你是否使用ubuntu桌面
或者它是在windows上设置的虚拟机
使用wsl
现在aws cli正在设置中
因为它已成功安装到有效
你应该能够运行aws命令
然而您可能需要重新启动CLI
因此，在这种情况下我将退出
现在 控制权已返回给电源单元
我们必须通过使用这个命令再次进入Ubuntu CLI
如果您使用的是
您希望成为桌面
你只需要关闭终端
重新启动终端
然后你应该能够使用名为aws的命令
你应该能够看到命令的使用说明
如果cla没有设置
它会实际上抱怨说命令未找到
在这种情况下，命令已找到
因此它实际上显示了使用说明
忽略错误 因为我们只是说aws没有任何子命令
aws本身不是一个有效的命令
你必须使用额外的子命令来实际获取与aws相关的详细信息
与命令或aws相关的服务将在稍后的时间点提供详细信息
到目前为止，我们已成功安装
如果你想查看aws cli的版本
你可以实际上说aws减号
减号版本
你应该能够看到使用pip安装的aws cli的版本
这就是你应该能够安装aws ahi的方式
在基于ubuntu的捐赠上
使用pip 你需要确保在使用pip安装aws cli之前pip已安装
我们将实际上看到与模块相关的aws的相关性
随着我们进入课程
确保你设置并验证aws cli是否已设置
我们必须配置它，以便我们可以与aws交互 我们将在稍后的时间点看到这些详细信息
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/014_Udemy - Data Engineering using AWS Data Analytics part1 p14 7. Create AWS IAM User and Download Credentials.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在这个阶段，我们在设置aws si的相关细节方面进行操作
作为设置与空中客车服务交互的本地环境的一部分
我们已经在ubuntu上安装了aws
它是使用wsl在windows上设置的
现在是时候配置aws si了
然而，要配置aws ali
我们需要有一个有效的aws账户，带有访问密钥和秘密密钥
我们应该能够利用访问密钥和秘密密钥来配置aws like
在本次讲座中 让我们了解如何创建iam用户
我们还将了解如何下载该用户的访问密钥和秘密密钥
然后作为下一讲
我们将看到如何使用这些详细信息配置aws
现在我们将专注于通过登录到aws web控制台来创建用户
让我转到浏览器
然后我必须转到aws dot amazon dot com
现在你应该有一个有效的aws账户
假设你有一个有效的aws账户
你可以点击这个
分配到控制台以登录到aws控制台
我能够使用我的用户登录到aws控制台
这只是一个演示
这是一个管理员级别的用户
我现在没有账户
你可能需要使用root账户登录
无论你如何登录到aws web控制台
一旦你登录到aws web控制台
你应该能够搜索
我在这里
然后你应该能够转到 我在这里你应该能够创建一个具有所需权限的iam用户
我们还需要下载该用户的访问密钥和秘密密钥
然后，我们可以使用这些详细信息来配置aws your life
让我点击用户
现在我应该能够点击
添加用户
我给用户名为aws demo
我只给程序化访问
我们需要给用户程序化访问，以便他可以获取访问密钥和秘密密钥来配置aws
Uh 我们需要给用户程序化访问，以便他可以获取访问密钥和秘密密钥来配置aws
如果启用此功能
用户也可以登录到aws控制台进行配置 这足够了
所以我选择了访问密钥
程序化访问，对于这个用户
然后点击下一步权限
你可以通过直接附加现有策略来授予你想要授予的任何权限
然后点击下一步权限
你可以通过直接附加现有策略来授予你想要授予的任何权限
实际上你可以选择管理员权限
如果你的账户是个人账户
你应该能够进一步操作
现在 我在这里选择了管理员权限
税务审查现在
创建用户 它将处理创建
我是你的用户
不用担心与相关的细微差别
我现在是用户
现在你必须点击这个下载点 csv
这样包含访问密钥aa密钥的文件将被下载
如果你不想下载
实际上你可以通过复制
粘贴备份访问密钥和秘密密钥到你选择的文件中
记住，如果你未能下载这个
如果你关闭这个
你将无法再看到秘密访问密钥
你必须回收这个
为这个用户创建一个新的访问密钥和秘密密钥
然后你必须进一步操作
确保你下载 csv
这样你就有了访问密钥和秘密密钥的备份
现在应该下载了
我可以去下载这里
让我看看你可以看到有一个名为新用户凭据的文件
点 csv 让我点击在文件夹中显示
它将带我到文件夹
现在我们应该能够使用我们的织物编辑器打开这个
让我看看我是否能够使用一些其他工具打开
是的 在这种情况下，我没有使用notepad plus plus
我正在使用notepad plus plus打开这个csv
现在你可以看到用户名，这不过是aws demo
而这是访问密钥id
而这是秘密密钥
你需要使用这个信息来配置aws
因为我们成功地设置了aws账户具有管理员权限
让我们继续并处理配置
使用这些详细信息也会验证它是否设置得当 我们将在下一节课中处理这些事情
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/015_Udemy - Data Engineering using AWS Data Analytics part1 p15 8. Configure AWS CLI on Windows.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在这个阶段，我们在Windows上设置本地环境
为了与已经设置好的AWS服务进行交互，我们已经设置了AWS CLI
我们还设置了
我现在是user
现在是时候使用该用户的凭据来配置AWS了
我现在是user IAM用户具有管理员权限
因此，我们可以处理任何
我们需要处理的事情
使用该用户，那就是说
你需要把它变成一个条件
尽管我现在展示了访问密钥和秘密密钥
我将删除导师
因此即使你试图使用那个访问密钥和秘密密钥来管理我的服务
现在它对你不起作用
让我实际上说它是有效的
无论aws是否设置
你可以看到它现在设置好了来配置aws cli
这样你就可以与aws服务进行交互
你必须使用aws configure
但在深入细节之前
让我先运行一个名为aws s three的命令
它将实际列出我账户中的s three桶
如果我按回车 它会失败
因为我们没有配置
它说
请确保使用aws configure命令进行配置
我们应该能够运行aws
现在配置成这样，它已经要求我们的访问密钥ID了
我们已经创建了 我是名为
AWS演示 我们已经下载了访问密钥和秘密密钥
作为CSV文件的一部分
我们需要打开CSV文件
CSV文件已打开
您可以在这里看到 这是访问密钥
所以我现在不得不复制这个
我不得不来到这里粘贴
你可以看到它现在已经粘贴好了
它正在提示我们的秘密访问密钥
让我去编辑器这里
秘密访问密钥从这个逗号后开始，到前面这个逗号前结束
所以你需要确保中间的部分被复制了
否则它可能不会按预期工作
让我们粘贴它
它正在询问默认区域
让我留空并按回车键，它正在询问默认输出格式
让我留空
不必过于担心输出格式
您需要一些关于地区名称的基本信息
在这种情况下，如果您指定地区名称
如果您有默认的ah地区
并且如果您在所有地区创建我们的服务
每当您运行如s three等命令时
您不需要明确指定地区
如果您像这样留空地区
对于大多数这些服务
您需要使用连字符
在您的aws命令中使用连字符region
这就是默认的目的
您的名字在这里 然而
我们已经留空
让我们理解内部发生了什么
当我们运行aws configure命令时
它会创建一个隐藏的文件夹称为点aws
它会创建在我的家目录中
我现在在我家目录中
这就是这个一个在lf中我有一个点aws
列出文件
您可以看到这里有两个文件
在aws文件夹中
一个是credentials
第二个是config
每当aws configure命令
它会更新credentials
让我们打开credentials并看看它包含什么
如果我说cat 然后点aws
然后credentials并按回车键运行
我们应该能够看到文件的详细信息
您可以看到文件包含这些详细信息
它包含配置文件名称
如果您没有指定连字符连字符配置文件
在access key id和secret access key下输入的详细信息将包含在默认配置文件中
在aws access key id下输入的详细信息将包含在aws underscore access下
Underscore key和score id
在aws secret access key下输入的详细信息将包含在aws underscore secret下
Underscore access underscore key
您可以实际比较并查看结果
一旦我们配置了，两者现在都相同
对我们来说重要的是验证
您可以通过使用相同命令来验证
aws s three
它之前以服务器无法找到凭据失败
您可以通过运行aws configure来配置凭据
随着凭证被用于配置aws
我们应该能够无问题运行它
你可以看到所有属于我账户的桶
在你这种情况下，你可能在这个时间没有s三桶
它将只返回什么都没有
你也应该理解配置文件的相关性
当我们开始使用aws时，许多次
我们可能需要与多个账户互动
与多个ah
凭证 个人资料很有用
你可以通过说aws来利用个人资料
配置 然后连字符
连字符个人资料
让我们说一个演示
这是用户名 我们使用的
个人资料名称可以是任何内容，只是为了确保它与正在使用的用户相关联
我给个人资料名称命名为aws演示
你也可以指定账户详情
假设我想为it t账户创建aws演示用户配置文件
我可以说它是演示配置文件名称
现在 我可以按回车
你可以看到它正在询问访问密钥ID
我应该能够使用此访问密钥ID
我现在应该能够使用这个访问密钥ID
秘密访问密钥
我应该能够使用此秘密访问密钥
让我复制这个，然后让我粘贴到这里
我可以按回车键来实际配置在演示配置文件下
让我们再次访问cat命令，看看凭证
你看 这里有另一个条目在aws演示下
让我清理默认配置文件
这种情况下我手动删除那个配置文件，通过说vi.aws/credentials
或者我也可以完全删除文件
让我删除文件以保持简单
因为你可能不习惯使用变量
这就是我为什么现在要删除文件的原因
让我使用配置文件再次进行配置
让我复制粘贴访问密钥ID
然后让我复制粘贴秘密密钥
现在我们的秘密访问密钥让我按回车键按回车键按回车键
使用配置文件aws demo配置了凭据
如果我只说aws s three
它会尝试查找与默认相关的详细信息
目前没有默认配置文件
因此它将失败
实际上可以说 cat. aws
然后可以看到凭证
只有一个配置文件 配置文件名就是 aws demo 现在应该能够说 aws s three
短横线短横线配置文件
然后 aws demo 现在
会使用该配置文件下的凭证
只要我们有权限访问该账户
使用这些凭证 将能够根据我们运行的命令得到所需的结果
这就是你应该配置 cla 的方式
一旦啊 ai 设置完成
并且一旦我们到达了
我是用户已创建并且凭证已下载
现在 让我删除配置文件
我实际上在说 rm. aws credentials
让我使用默认配置配置配置文件
我们需要指定访问密钥和秘密密钥
让我复制访问密钥在这里
让我复制秘密密钥也
我现在只想在这个时间有一个配置文件
这就是我为什么这样做
演示结束后我会删除用户
这样你就不能用这些信息来玩弄我的账户
现在 cla 已配置
我应该能够说 a s three
我应该能够列出我 aws 账户中 s three 中所有桶
我希望你能够成功配置你的 aws
如果不行请随时联系我们 我们会在那里支持你
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/016_Udemy - Data Engineering using AWS Data Analytics part1 p16 9. Create Python Virtual Environment for AWS Projects.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


为了了解更多关于aws相关服务的信息
到目前为止，我们已经能够设置一个si
并且在设置本地环境的过程中，我们也进行了配置
现在是时候确保我们设置一个python虚拟环境
并且安装所需的库或模块
以便我们可以使用python作为编程语言
并构建应用程序以与aws服务进行交互
首先我们会处理设置虚拟环境的问题
然后我们会实际处理安装所需的库
我们也会验证我们是否能够使用python作为编程语言
与AWS账户进行交互，还是不交互，不管怎么说
方法 创建Python虚拟环境的方式是使用名为venv的命令
在Python3下
在进入之前我们应该能够进一步推进
让我们创建一个工作日志
然后我们会进一步推进
在这种情况下，我正在说mk dr
hyphen P项目
AWS内部数据工程训练营
这是我的工作日记
你可以为你的工作目录起一个你喜欢的名字
它不必与我现在的名字相同
让我复制这个
粘贴到这里以进入那个文件夹
这些是在Linux上可以运行的命令
在这种情况下，我们在基于Linux的系统上工作
即使你使用的是Mac
你应该能够遵循这些指示
你可以实际处理任何在mac上展示的内容
相同的命令将没有任何间隙地工作
现在要实际创建python虚拟环境
我们应该能够使用python三减m v e和v
减m代表模块
v和v实际上只是一个模块
它使我们能够创建和管理python虚拟环境
现在我们应该能够给python虚拟环境起一个名字
它会以该名字创建一个文件夹
在这个例子中我会说d e减v
E和v 它会创建名为md和v和v的文件夹
文件夹将包含一些与Python相关的文件
这将使我们能够为该项目创建隔离环境
让我说 离子ltr
您可以看到名为hyphen v和v的文件夹
您可以运行名为find de hyphen v和v的命令来查看它包含的所有内容
它包含许多文件夹和文件
一些重要的文件与Python无关
皮普 等等
实际上你可以滚动查看
你应该能够探索它包含的所有内容
如果你不想查看所有文件
你也可以使用siphon ltr在减号v和v上
实际上你可以看到此文件夹中的文件夹
称为f和v和v
这只是为虚拟环境创建的一个文件夹
用于在基于Linux的mac环境中激活
实际上你可以说source d减号v
E和v 为我们的虚拟环境创建的文件夹
然后bin中包含名为激活的脚本
你可以像这样运行激活脚本
现在虚拟环境已激活
你可以在这里查看详细信息
这就是 你应该能够为任何项目激活python虚拟环境
在这种情况下，我们将使用此虚拟环境与我们相关的aws项目
因为现在创建了python虚拟环境 让我们安装必要的python库以与aws进行交互
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/017_Udemy - Data Engineering using AWS Data Analytics part1 p17 10. Setup Boto3 as part of Python Virtual Environment.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在设置本地环境与aws服务交互的过程中
到目前为止，我们已配置了aws
并且我们也在本项目工作目录下设置了python虚拟环境
这个虚拟环境就是d hyphen v和v，它也已激活
现在我们需要安装基于python的sdk
以便我们可以使用python作为一门编程语言与aws进行交互
sdk的名称就是auto three
你只需说pip install auto three
然而 在运行此命令之前
您需要确保相关的python虚拟环境已激活
您可以通过查看这一点来确认，也就是说，现在
让我按Enter
它将为我们安装auto three
一旦auto three安装完毕
我们应该能够编写基于python的逻辑与aws服务进行交互
我将在下一节课演示这些
但现在让我们确保安装auto three
auto three已安装
您可以通过启动python来验证
在此情况下python丢失
我们应该能够说import auto three
以实际查看auto three是否已安装在此环境中
您可以看到已成功运行该命令
称为import auto three
这意味着auto three可在此虚拟环境中使用
现在 您应该能够说s three underscore client等于bottle to three dot client
然后传递一个字符串名为s three
它将负责创建一个实际作为s three客户端的对象，已创建
我们应该能够运行s three underscore client
点list underscore buckets
它将负责列出账户中的桶
您可以看到已写了大量输出
这就是您应如何设置bottle to three
作为虚拟环境
并且也使用python cli验证
然而，使用python cli与aws服务交互并不实际
使用python作为一门编程语言
通常我们有ids
并且我们使用ids进行开发，用于学习目的
我们可以实际设置jupyter
让我们了解设置jupyter环境的详细信息
并且也验证
我们将能够使用jule环境与aws服务交互
利用bottle to three
我将在同一虚拟环境中设置jupyter
因此，此虚拟环境不仅包含auto three
也包含jupyter 并且使用jupyter
我们应该能够通过自动三与aws服务进行交互 那些细节将作为下一节课的一部分进行覆盖
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/018_Udemy - Data Engineering using AWS Data Analytics part1 p18 11. Setup Jupyter Lab and Validate boto3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


是的 我们已经成功将两者设置为虚拟环境的一部分
与这个项目相关的工作目录
现在我们该安装jupyter了
以便我们可以利用jupyter学习所有细节
关于如何使用python编程语言与aws服务进行交互
在这个项目中安装jupyter环境非常直接
或者在这个ploy to工作目录的虚拟环境中
你应该能够使用pip命令说pip
安装jupyter lab并回车
这将会处理安装基于jupyter的环境作为此虚拟环境的一部分
一旦基于jupyter的环境被安装
你所需要做的就是运行一个名为jupyter space lab的命令
它将为你启动环境
然后你应该能够通过浏览器访问基于jupyter的环境
现在基于jupyter的环境已经安装
你所需要做的就是运行名为jupyter space lab的命令并回车
你可以看到jupyter笔记本服务器已经启动
你应该能够通过此url访问服务器
你需要复制整个url
包括令牌 否则一旦你选择，你将无法访问
你可以按回车键，它将复制到缓冲区
现在你应该能够打开浏览器
然后你必须去地址栏
粘贴 按回车键它也可能自动打开
你不需要将其复制粘贴到浏览器中
在我这种情况下，我必须这样做，话说回来
实际上你可以通过点击这个打开笔记本
我打开了 这就是为什么你看到这里有一个笔记本
让我双击它
我应该能够通过右键重命名它
点击它 然后说重命名
我可以说开始
现在 笔记本已经创建
我强烈建议你花一些时间
理解与笔记本相关的所有细微差别
这样你就可以舒适地使用笔记本环境
我将带你了解一些细节
它们展示了如何与aws交互
使用将使用这个笔记本开发的Python代码
让我关闭这个
我们可以实际构建它
我们说不定能用Python作为编程语言
通过说打印Hello World
这只是Python代码
你可以看到它按预期工作
你可以在这里看到输出，尽管如此
现在 我们应该能够验证auto three是否作为笔记本的一部分可访问
只需说import auto three
你可以看到它已成功导入
我们应该能够通过s three underscore client创建对象
我只需说bottle three dot client
是的 Three现在s three underscore client已创建
你可以通过说type of s three underscore client检查其类型
它只不过是protocol dot client dot s three now
如果我说s three underscore client
然后点并按tab
我们应该能够使用list underscore buckets列出所有桶
它将以字典形式返回一个json对象
你可以在这里看到 它包含一个名为buckets的属性
我们可以通过说buckets像这样获取所有桶详细信息
当涉及到buckets时
它是列表类型
如果你想要获取名称而不丢弃创建日期
你应该能够使用列表推导或map函数
或者使用for循环获取你想要的信息
在这种情况下 我将尝试获取桶的名称
使用列表推导
我现在清空输出
让我实际上说bucket等于
是的 客户端点list buckets of buckets now
我应该能够说bucket names等于bucket of name
全桶在buckets中
在这种情况下bucket是列表类型
让我添加一个单元这里
让我說bucket等于buckets of 0
所以我实际上只获取一个桶详细信息现在bucket是字典类型
你可以通过在这里粘贴bucket检查字典中的值
你可以在这里看到字典
我应该能够通过说bucket of name获取名称
像这样在方括号中
这种逻辑实际上会创建一个只包含名称的新列表
在这里指定的逻辑用于获取名称
在这种情况下bucket是每个迭代的字典对象
如果buckets中有十个条目
它将遍历十次
每次元素都是字典类型
并且该元素的名称是bucket
我们试图通过使用bucket of name获取桶的名称
现在我们应该能够运行这个
这里有一种类型
名称必须大写N
桶名称现在只有桶的名称
你应该能够通过说桶和分数名称来验证
你可以运行 你可以看到所有我账户的桶名称
这就是你应该与aws服务交互的方式
现在我们已经设置了自动三
我们已经能够获取桶的详细信息
使用auto three与aws服务交互涉及的步骤
使用python编程语言
你需要创建一个基于服务的客户端对象
然后使用该客户端对象
你应该能够使用与客户端对象相关的API
你应该能够获取你所寻找的信息
甚至你可以管理这些服务
我们没有在任何地方传递任何身份验证信息
你可能会感到惊讶
它如何能够使用aws账户进行身份验证并获取这些详细信息
它使用aws文件夹中名为credentials的文件
只要你有一个默认配置
它将使用默认配置的凭据
它将尝试与aws交谈并执行应执行的任务
基于涉及的API
它自动使用凭据
如果你没有默认配置
那么你必须设置环境变量，如配置文件
它将使用凭据
它将与aws交互，配置文件在这里扮演关键角色
因此，为您的aws cli配置非常重要
首先使用适当的ah配置文件
然后使用这种信息
你应该能够开发基于python的应用程序以与aws服务交互
到目前为止
我们已经成功设置了并配置了cli
我们还设置了python虚拟环境
并安装了to three
我们还验证了我们是否能够与aws交互 你非常 非常有必要注意所有这些步骤，以便您能有效地参加此课程
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/019_Udemy - Data Engineering using AWS Data Analytics part1 p19 1. Setup Local Environment for AWS on Mac.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在这个时间 您正在处理与学习aws分析服务相关的详细信息
以便您可以实际构建数据新应用程序
AWS 对于您来说，拥有适当的环境非常重要
以便您可以通过命令以及Python代码与AWS进行交互
在建立与AWS相关服务相关的数据和应用程序的追求中
在章节模型中
我们将实际了解设置以及配置CLI的详细信息
使用给定用户适当的凭据和适当的权限
还会详细介绍如何设置基于Python的环境
以便我们能够开发代码来与aws服务进行交互
这对你来说非常重要，不仅要设置
还要配置并验证你是否能够与服务进行交互
无论是使用命令还是基于Python的代码
在专题模型的结尾
你应该能够运行如aws s three等命令
列出与使用凭据配置的aws cli相关联的s three桶
设置aws cli的凭据
一旦AWS设置完成
你也会有一个基于Python的环境
以及基于Jupyter的环境
它还会集成Python SDK与AWS交互
它被称为auto three
你应该能够像这样启动基于Jupyter的环境
然后你应该能够像这样运行代码与AWS服务交互
在这个例子中我只是说内核
然后重启内核并运行所有单元格
如果你查看代码
这实际上是通过s three创建对象
使用Underscore客户端 该对象类型为bottle core client s three
然后我们能够调用list buckets
从创建的json对象中获取桶详细信息
我们应该能够提取我们需要的信息
在这种情况下，我提取了桶名称
你应该像这样运行代码
本节结束时
我们将使用管理或列出s three桶
无论如何，你应该能够管理任何服务
要么使用命令行实用程序，要么使用基于Python的SDK
我可能会从使用基于Ubuntu的操作系统开始演示，该操作系统运行在Windows上
因为Mac与Linux Unix相似
当谈到运行命令时
你应该能够理解
你应该能够执行所有这些任务
甚至在这个过程中，你应该能够在Mac上完成这些任务
如果你卡住了
请随时联系我们
会支持你
有任何需要支持时，随时联系我们，就这样
确保在章节结束时有合适的环境
我们将利用aa以及基于模式的方法 当我们进入课程中的实际模块时，如果有需要
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/020_Udemy - Data Engineering using AWS Data Analytics part1 p20 2. Setup AWS CLI on Mac.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在这个时间 我们正在设置本地环境
以便与armac的服务进行交互
如果你想了解与Windows相关的指令
有专门的部分，话说回来
让我们开始设置aws i
这样我们就可以在mac上运行aws命令与aws服务进行交互
这相当直接
你只需要安装一个叫做aws cli的东西
在mac上安装aws cli有多种方法
安装方式之一是使用pip
你可以利用python版本
比如python 3.60或3.70
3.8或3.9或3.9，你应该能够设置aws cli
使用随该python版本提供的工具
在我这里我有多个python版本
你可以看到我有python 2.7
python 3.6 python 3.8和python 3.9
我将使用python 3.8来安装aws sso
喜欢使用与这个Python版本相关的pip
现在 我应该能够说python three eight
hyphen m pip install aws sso
它会为我安装aws sso
你可以看到它已成功安装aws cli
现在你应该能够说aws并按Enter
如果a已成功安装
你应该能够看到这样的用法
你可以忽略服务器，不要太担心它
只要你能看到使用方法
你就可以开始使用 如果你想知道aws cli的版本
你可以说aws减号减号版本
它会告诉你aws cli的版本
你可以看到aws cli是两点一一点三一
这是用python三点八点八安装的
这就是你应该在你的mac上安装aws sso cli的方式
作为mac的一部分
一旦aws cli安装完毕
现在是时候配置它了
配置 我们需要有一个用户账户
我们也应该拥有用户账户相关的访问密钥和秘密密钥
我们将详细讲解如何创建iam用户
并下载与用户相关的访问密钥和秘密密钥
然后我们将看到如何使用适当的aws命令来配置它，在接下来的讲座中
让我们开始创建用户并配置aws
我们也将验证我们是否能够使用aws相关的命令与aws账户进行交互 或者不能使用
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/021_Udemy - Data Engineering using AWS Data Analytics part1 p21 3. Setup AWS IAM User to configure AWS CLI.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在这个阶段，我们在设置本地环境，以便与服务进行交互，使用命令和编程语言。
到目前为止，我们已经设置好了。
是的，我们现在应该创建一个IAM账户，
然后使用IAM账户的凭据来配置AWS CLI，
以便我们可以无问题地运行命令。 让我们详细讲解一下设置IAM账户的步骤，
并下载所需的凭据来配置AWS CLI。
AWS CLI的配置将作为下一节课的内容进行讲解。
我正在打开我最喜欢的浏览器，
那就是Chrome。
现在让我开一个新窗口。
Chrome已经打开。
让我访问aws.amazon.com。 到现在你应该已经有了AWS账户，
如果没有，你需要注册并确保你有账户。 我已经登录到我的AWS管理控制台。
我应该能够去，
我可以通过全局搜索栏搜索IAM。
我可以点击这个去IAM控制台。
我应该能够点击用户，
然后点击添加用户来创建新用户，
或者添加现有用户。
我们可以给用户起一个名字，
让我起名为aw demo。
我可以选择访问密钥，
选择程序化访问。
这将生成一个访问密钥ID和一个秘密访问密钥，
我们可以使用它们来配置AWS。
我们不需要为这个用户提供管理控制台访问权限，
因此选择这个选项就足够了。
现在，
你可以点击下一步，权限。
一种给用户添加权限的方法是使用策略，
你可以为用户附加现有的策略，
这些策略包含了用户所需的权限， 使过程变得简单。
我们正在授予管理员权限，
这将给用户提供账户的全部权限。
我们可以使用这些用户凭据来程序化地控制几乎所有的内容。
你应该能够附加现有的策略，
这些策略包含了用户所需的权限，
我们正在授予管理员权限，
这将给用户提供账户的全部权限。
我们应该能够使用这些用户凭据来程序化地控制几乎所有的内容。
作为第二部分，
我正在使用的IAM。
话说回来， 我应该能够点击附加权限，
然后点击下一步，审查，
最后点击创建用户
这将带你到这个页面，你可以在这里查看凭证
这是访问密钥ID，这个是秘密访问密钥
要么 你可以复制并粘贴这些东西到你喜欢的编辑器中
或者你可以点击这里下载CSV文件
一旦你下载了CSV文件
你应该能用你喜欢的编辑器打开它
我将使用mac的text编辑器打开
我在这里使用的是mac
你可以看到我使用的是textedit
这是访问密钥
这是秘密密钥
我们应该能用这些信息来配置aws cli
因为我们已经成功创建了用户
并且下载了CSV文件
其中包含访问密钥和秘密密钥
让我们了解一下conferaws的详细信息 并在接下来的讲座中违反它
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/022_Udemy - Data Engineering using AWS Data Analytics part1 p22 4. Configure AWS CLI using IAM User Credentials.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


目前我们正在设置本地环境
与aws进行交互
通过命令 到目前为止，我们已经设置好了aw
我和我们也创造了
我是具有管理员权限的用户
我们也下载了csv文件
包含访问密钥和秘密密钥
实际上你可以在这里审查那个文件，话虽如此，现在
现在是我们配置AALI的时候了
并且验证我们是否能够通过命令与aws进行交互，或者利用aws airline来实现这一点。
我正在打开终端，让我们看看是否能够与aws进行交互。
我正在打开终端。
让我确认一下。 输入aws s three并回车，系统正在尝试与aws进行交互。
你可以在这里看到错误信息。
它说： 无法找到凭证。
你可以通过运行configure来配置凭证。
一旦aws cli设置完成，我们就可以与aws进行交互了。
你应该能使用这个命令来配置aws cli
以便与ui进行交互
为此，您需要使用用户的访问密钥和秘密密钥
这是我们之前创建的
具有适当的权限
在我们的情况下，我们为管理员创建了用户
让我们复制并粘贴
先按回车键
它正在询问aws访问密钥ID
让我转到文本编辑
这是一个访问密钥ID
我已经复制并粘贴在这里
现在它正在询问AWS秘密访问密钥
你可以在这里看到
我们应该能够进入文本
在逗号后编辑这里直到逗号
我们必须确保选择了完整的文本
我们必须复制并粘贴
我们必须非常小心
在复制Airless时
一个秘密访问密钥
你不能只是双击来实际获取文本
你可以看到它只选择了文本的一部分
你需要确保你从逗号选择并输入东西
在访问密钥后面直到下一个逗号
这里你可以看到
然后你必须粘贴在这里
现在您可以按回车
它会询问默认区域名称
您可以忽略并按回车
你不需要过多担心输出格式
你现在可以按回车键
当你提到区域名称时，你的aws配置是正常的
它有一些相关性
你大多数服务将在默认区域创建
如果你不想使用短划线短划线区域来指定区域
当你尝试运行aws命令与aws服务交互时
你可以配置默认区域为拥有最多服务的区域
否则你必须指定区域
大多数aws命令与aws服务交互，说到这里
让我们理解内部发生了什么
当我们在主目录下运行该命令时
它会创建一个名为.dot aws的隐藏文件夹
让我称之为aws
我正在将alt到grep命令的输出管道到搜索它中的aws
你可以看到有一个名为.dot aws的隐藏文件夹
点表示隐藏文件夹
现在我应该能够说cd dot aws
然后运行ls和dr
你可以看到有一个名为credentials的文件和一个名为config的文件在这里
这些是当我们实际运行config时创建的文件
你也可以使用配置文件添加额外的凭据
然后当你运行less configure命令时
它将实际更新这些文件以使用有用的信息进行身份验证
与相关的aws账户，说到这里
让我称之为cat credentials
这样我们就可以审查credentials的内容
你可以看到在这里访问密钥ID以及秘密访问密钥详情
你也可以验证说aws s three
它将导致我所有的s three桶
如果使用配置的访问密钥和秘密访问密钥
并且less成功
你可以看到它现在按预期工作
有时你可能需要与多个aws账户合作
使用每个用户的多个用户
你可以实际创建一个配置文件
你应该能够使用配置文件进行交互
因此，在这种情况下 如果我想使用非默认配置文件来配置aws
我必须使用短划线
短划线配置文件 连同aws configure并指定配置文件名称
将使用该配置文件配置凭据
默认情况下
它是默认配置文件
只要你使用默认配置文件
你不需要指定短划线短划线配置文件并传递配置文件名称
让我删除这个credentials文件
让我称之为aws configure
然后配置文件
那么让我来说一个演示
你也可以在标识符前加上单词aws account
配置文件名可以是任何内容
它不必与用户名相同
在这个例子中，我正在使用用户名作为配置文件名
定义配置文件的参数无非是
在aws configure中以-hyphen-hyphen-profile定义的
现在 我可以按下回车
它正在询问访问密钥
让我进入文本编辑
让我复制访问密钥并粘贴在这里
让我复制秘密访问密钥
让我按回车 我现在按回车
使用配置文件配置AWS
AWS演示 如果我说查看凭证
你可以看到只有一个名为a demo的配置文件
如果我说AWS S3
它会失败，因为它会寻找默认配置
但没有默认配置文件
它抛出相同的错误
这是我们之前见过的
如果你想使用那个配置文件
我们可以说 s three hyphen hyphen profile
然后输入 aws demo
你可以在这里实际看到输出
这就是你应该能够利用配置文件来配置与多个用户和多个账户相关的凭据的方式
现在配置与多个用户和多个账户相关的凭据
让我切换回默认设置
我应该能够删除凭据文件
我也可以直接更新文件
但这不是一个好的做法
我只是想使用aws configure命令
所以让我输入aws configure
让我复制访问密钥ID我们的访问密钥
然后让我复制秘密访问密钥按回车按回车，现在它已经配置好了
让我输入cd到我的家庭日记
让我输入aws sls以确保默认配置正确创建
你可以在这里看到所需的输出
这是如何在你安装aws cli后应该能够配置它的方式
并且相关用户可供你使用，也就是说
确保在你安装并验证aws cli后配置它，仅此而已
然后你应该能够安装与编程语言相关的sdks
你应该能够使用同一配置文件与aws进行交互
这是你为aws cli配置的
确保aws cli不仅已安装，而且已配置和验证非常重要 但更重要的是，它也已配置和验证
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/023_Udemy - Data Engineering using AWS Data Analytics part1 p23 5. Setup Python Virtual Environment on Mac using Python 3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


现在，我们将讨论设置本地环境的详细信息
以便我们能够与aws进行交互
使用AWS命令行工具和Python编程语言进行编码
在这次讲座中 我将实际向你展示如何设置Python虚拟环境的详细信息
在mac上激活python虚拟环境
然后你将实际看到如何利用那个Python虚拟环境来处理它。
确保我们能够与aws进行交互之前，安装所需的库。
使用Python编程语言
讲座之后
你将会看到一系列使用ubuntu作为操作系统创建的讲座
你应该能够与mac联系起来
你应该能够运行相同的代码和命令来实际查看行为
这个视频之后的视频将不会
嗯 使用mac录制
相反 它们将使用ubuntu作为操作系统在windows上录制
这是在使用wsl设置windows后
让我们确保我们理解如何设置python虚拟环境
在mac上使用合适的python版本
然后你可以实际了解安装所需的详细信息
Python SDK与aws交互
也可以运行代码与aws交互
利用基于python的SDK
现在 让我转到工作日志，也就是内部项目
然后训练营
我有一个名为aws数据工程的文件夹
所以让我实际转到这个aws数据工程
它位于其材料之下
所以我去aws的数据工程
你可以选择你想要的工作目录文件夹
然后你可以继续
我在这使用这个名字
我将使用python3.8创建一个python虚拟环境
让我们验证不同版本的python
我在这个mac上有
我应该能够输入python并按tab
你可以看到我有python2.7
然后使用python三六
然后使用python三八
然后使用python三九
您可以利用任何Python版本，从Python三六到Python三九，以确保相同的行为而不会遇到太多问题
我将使用Python三八
我推荐使用Python三八点八
但是您应该能够适应甚至使用Python三六或三七
确保创建Python虚拟环境时，可以使用Python三七，三六或三九
使用Python三八点八
我必须使用Python3旋转
因为我有多个版本的Python
以确保我能利用Python3旋转
我可以使用这种格式使用Python38
然后我可以说-hyphen m，这意味着模块
然后v e和v
这什么都不是，虚拟环境模块
使用虚拟环境模块
我正在尝试创建一个Python虚拟环境
让我命名为d-hyphen v e和v，现在我按回车
它将为我们创建一个文件夹
文件夹名称将基于a Python虚拟环境名称本身
这什么都不是，d-hyphen v e和v
我应该能够说-a hyphon ltr
然后管道到grep
让我搜索d-hyphen v e和v
你可以看到当我们运行此命令时，它已创建了一个文件夹
此文件夹将包含与Python虚拟环境相关的所有详细信息
你应该能够说-a hyphlta
然后-hyphen v e和v
你可以看到此中有不同的文件夹和文件
名为has包含一个名为活动的文件
我们应该能够运行该文件以实际激活虚拟环境
所以要运行
激活以激活虚拟环境
我们必须说source
然后使用我们设置Python虚拟环境的文件夹名称
然后bin然后激活
你可以看到虚拟环境现在已激活
以验证 我们是否能够使用pip在此处安装基于Python的库
我们应该能够使用pip install命令
我们可以指定您要安装的任何库，例如
让我尝试安装config parcel
这是一个非常小且简单的Python库
你可以看到它已成功安装
你应该能够说people以实际查看config parser是否已成功安装
在这种情况下，它正在说要求已满足
因为名为d v e和v的Python虚拟环境在那里
在我运行此命令之前
我已经在其中安装了config parser
这就是为什么它说
uh 要求已满足
否则它将为我们安装config parser
这就是您应如何设置Python虚拟环境
并且使用source命令激活它
您应该能够关注于此，以查看适当的Python虚拟环境是否已激活
现在 本系列讲座的其余部分将使用Ubuntu演示
你应该能够跟随这些讲座，并处理安装所需的Python基于的SDK，以便实际与AWS交互
我也会提供代码库，你应该能够利用并运行它
以确认你是否能够与空管互动
使用Python作为编程语言
确保你仔细观看所有讲座
并确认你能够运行一个Python 基于的代码来与空管互动
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/024_Udemy - Data Engineering using AWS Data Analytics part1 p24 6. Setup Boto3 as part of Python Virtual Environment.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在设置本地环境与aws服务交互的过程中
到目前为止，我们已配置了aws
并且我们也在本项目工作目录下设置了python虚拟环境
这个虚拟环境就是d hyphen v和v，它也被激活了
现在我们需要安装基于python的sdk
以便我们可以使用python作为一门编程语言与aws进行交互
sdk的名称就是boto3
你必须说pip install boto3
然而 在运行此命令之前
您需要确保相关的python虚拟环境已激活
您可以通过查看这一点来确认，也就是说，现在
让我按Enter
它将为我们安装boto3
一旦boto3安装完成
我们应该能够编写基于python的逻辑与aws服务进行交互
我将在下一节课演示这些
但现在让我们确保我们安装boto3
boto3已安装
您可以通过启动python来验证
在这种情况下，python丢失了
我们应该能够说import boto3
实际上查看boto3是否安装在这个环境中
您可以看到它已成功运行了该命令
称为import boto3
这意味着boto3可在此虚拟环境中使用
现在 您应该能够说s3_client等于boto3.client('s3')
然后传递一个字符串's3'给它
它将负责创建一个实际上作为s3客户端的对象，已创建
我们应该能够运行s3_client
点list_buckets
它将负责列出账户中的桶
您可以看到它写了很多输出
这就是您应该能够设置boto3的方式
作为虚拟环境
并且也使用python cli验证
然而，使用python cli与aws服务交互并不实际
使用python作为一门编程语言
通常我们有ide
并且我们使用ide进行开发，用于学习目的
我们可以实际上设置jupyter
让我们了解一下设置jupyter环境的细节
并且验证
我们是否能够使用基于jupyter的环境与aws服务进行交互
利用boto3
我将在同一个虚拟环境中设置jupyter
因此，这个虚拟环境不仅包含boto3
也包含jupyter 并且使用jupyter
我们应该能够通过自动三与aws服务进行交互 那些细节将作为下一节课的一部分进行覆盖
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/025_Udemy - Data Engineering using AWS Data Analytics part1 p25 7. Setup Jupyter Lab and Validate boto3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


是的 我们已经成功将两者设置为虚拟环境的一部分
与这个ah项目工作目录相关
现在我们该安装jupyter了
以便我们可以利用jupyter学习所有细节
与使用python编程语言与aws服务交互相关的所有微妙之处
在这个ah项目中安装jupyter环境非常直接
或者在这个ploy to工作diis虚拟环境中
你应该能够使用pip命令说pip
安装jupyter lab并回车
这将会处理安装基于jupyter的环境作为此虚拟环境的一部分
一旦基于jupyter的环境被安装
你所需要做的就是运行一个名为jupyter space lab的命令
它将为你启动环境
然后你应该能够使用浏览器访问基于jupyter的环境
现在基于jupyter的环境已经安装
你所需要做的就是运行名为jupyter space lab的命令并回车
你可以看到jupyter笔记本服务器已经启动
你应该能够使用这个url访问服务器
你需要复制整个url
包括令牌 否则一旦你选择，你将无法访问
你可以按回车键，它将复制到缓冲区
现在你应该能够打开浏览器
然后你必须去地址栏
粘贴 按回车键它也可能自动打开
你不需要将其复制粘贴到浏览器中
在我这种情况下，我必须这样做，话说回来
实际上你可以通过点击这个打开笔记本
我打开了 这就是为什么你看到这里有一个笔记本
让我双击它
我应该能够通过右键重命名它
点击它 然后说重命名
我可以说开始
现在 笔记本已经创建
我强烈建议你花一些时间
理解与笔记本相关的所有细微差别
这样你就可以舒适地使用笔记本环境
我将带你了解一些细节
它们展示了如何与aws交互
使用将使用这个笔记本开发的Python代码
让我关闭这个
我们可以实际构建它
我们可能会使用Python作为编程语言吗
通过说打印Hello World
这只是一个Python代码
你可以看到它按预期工作
你可以在这里看到输出，尽管如此
现在 我们应该能够验证auto three是否作为笔记本的一部分可访问
只需说import auto three
你可以看到它已成功导入
我们应该能够通过s three underscore client创建对象
我只需说bottle three dot client
是的 Three现在s three underscore client已创建
你可以通过说type of s three underscore client检查其类型
它只不过是protocol dot client dot s three now
如果我说s three underscore client
然后点并按tab
我们应该能够使用list underscore buckets列出所有桶
它将以字典形式返回一个json对象
你可以在这里看到 它包含一个名为buckets的属性
我们可以通过说buckets像这样获取所有桶详细信息
当涉及到buckets时
它是列表类型
如果你想要获取名称而不丢弃创建日期
你应该能够使用列表推导或map函数
或者使用for循环获取你想要的信息
在这种情况下 我将尝试获取桶的名称
使用列表推导
让我清除这里的输出
让我实际上说bucket等于
是的 客户端点list buckets of buckets now
我应该能够说bucket names等于bucket of name
全桶在buckets中
在这种情况下bucket是列表类型
让我添加一个单元这里
让我說bucket等于buckets of 0
所以我实际上只获取一个桶详细信息现在bucket是字典类型
你可以通过在这里粘贴bucket检查字典中的值
你可以在这里看到字典
我应该能够获取名称说bucket of name
像这样在方括号中
这种逻辑实际上会创建一个只包含名称的新列表
在这里指定的逻辑用于获取名称
在这种情况下bucket是每个迭代中的字典对象
如果buckets中有十个条目
它将遍历十次
每次元素都是字典类型
并且该元素的名称是bucket
我们试图通过bucket of name获取桶的名称
现在我们应该能够运行这个
这里有一种类型
名称必须大写N
桶名称现在只有桶的名称
你应该能够通过说桶和分数名称来验证
你可以运行 你可以看到所有我账户的桶名称
这就是你应该如何与aws服务交互
现在我们已经设置了自动三
我们已经能够获取桶的详细信息
当涉及到使用自动三与aws服务交互的步骤时
使用python编程语言
你需要创建一个基于服务的客户端对象
然后使用该客户端对象
你应该能够使用与客户端对象相关的API
你应该能够获取你所寻找的信息
甚至你可以管理这些服务
我们没有在任何地方传递任何身份验证信息
你可能会感到惊讶
它如何能够使用aws账户进行身份验证并获取这些详细信息
它使用位于aws文件夹中的名为credentials的文件
只要你有一个默认配置
它将使用默认配置的凭据
它将尝试与aws交谈并执行应该执行的任务
基于涉及的API
它自动使用凭据
如果你没有默认配置
那么你必须设置环境变量，如配置文件
它将使用凭据
它将与aws交互，配置文件在这里扮演关键角色
因此，为你的aws cli配置非常重要
首先使用适当的ah配置文件
然后使用这种信息
你应该能够开发基于python的应用程序以交互aws服务
到目前为止
我们已经成功设置了并配置了cli
我们还设置了python虚拟环境
并安装了to three
我们还验证了我们是否能够与aws交互 你非常 非常重要的是，你必须注意这些步骤，以便你可以有效地参加这门课程
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/026_Udemy - Data Engineering using AWS Data Analytics part1 p26 1. Introduction to Cloud9.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为部分模块
我们将详细讨论官方
一个名为clan的想法
我们将看到如何设置云
我们也将看到ide和可用的工具
作为云九的一部分，我们将理解云和e之间的关系
C two 目前我们还没有涵盖e two
我们还在aws基础知识课程的开始阶段
我们将详细覆盖e
C two，稍后
一旦你通过了所有与e
C two相关的细节 我们强烈建议你回来再次复习这个模块
那样你就能理解与云九相关的所有概念
我们强烈建议你这样做
现在 我们将快速浏览所有小细节，如设置云
理解ide和可用的工具
以及云和e之间的关系
C two 作为云和e之间的关系
我们将执行一些任务来管理与e c two相关的会议
与云实例相关的 让我们深入研究
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/027_Udemy - Data Engineering using AWS Data Analytics part1 p27 2. Setup Cloud9.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们设置云九来设置云
首先我们将创建一个名为itv cloud nine的组
我们将添加一个管理员策略作为开始
一旦组创建完成
然后我们将创建一个用户
名为itv cloud的用户，并将用户添加到itv cloud nine组
一旦用户创建完成
我们将以用户身份登录
itv cloud和用户进入aws控制台
然后我们将进入云和控制台
然后我们将启动云实例
让我们深入细节，以便您了解如何处理所有事项
请记住，我们没有涵盖与
我现在相关的所有事项，只需遵循指示并尝试创建云
现在，当你实际进入iam模块时
你将会更多地了解
我是 如果你不明白
我现在完全
不要过于担心 话虽如此
让我进入aws管理控制台
我们必须进入iam
我们可以使用这个全球搜索栏搜索iam
然后可以点击进入iam控制台
一旦我们在控制台中
我们可以点击组部分
因此我们可以创建一个新组
通过点击这里
组名称只是itv cloud nine
现在我可以说下一步我们需要添加一个策略
我们将添加一个管理访问权限
这意味着被添加到此组的用户将拥有这个策略
用户将获得aws账户的完整管理访问权限
现在我可以说下一步
然后说创建组
现在以itv cloud nine的名称创建了组
由于组已创建
现在是时候为我们创建一个用户了
我们必须转到用户
我们可以说添加一个用户
让我们给用户起名itv cloud nine
将为此用户提供程序化访问以及aws管理控制台访问权限
我们将使用自动生成密码
然后我们需要选择权限
我们将此用户与组关联
我们想要使用的组名为itv cloud
现在itv cloud和用户属于itv cloud nine组
我们可以点击标签
然后审查并说创建用户，现在使用已创建
你可以在这里看到凭证
你可以实际查看密码
这是密码
让我复制这个
让我关闭它，现在我们可以点击这个
你看这里有一个a
你也会得到
你正在使用哪个
我们可以实际连接到第二个
让我转到这里仪表板
你可以在这里看到a
我们可以使用这个来实际登录账户并在使用uri之前
我现在粘贴密码
我现在粘贴了密码，我可以复制这个打开标签
或者让我使用隐私窗口打开
一旦我们使用隐私窗口打开并粘贴这个
它会带我们到登录页面
作为登录页面账户的一部分
ID会自动填充
用户名无非就是itv cloud nine user 密码无非就是whatever
我已经在我的谷歌文档中粘贴了
让我去这里
我现在选择这个
让我回到登录页面
我必须在这里粘贴它
点击登录以登录它正在提示我更改密码
让我此处更改密码
现在我正在将密码更改为另一个自定义密码
然后从密码更改中过来
现在我在aws控制台
使用新用户
强烈建议不要创建云九实例
使用root账户 我们应该使用IAM用户账户
现在让我点击
来到这里然后搜索云
这里它将带我们到云和控制台
一旦我们在云和控制台
我们应该能够通过点击创建云九环境
创建环境 这里
我们可以给这个名字
让我们说 AWS演示
让我往下滚动这里
下一步将被重定向到配置设置
作为部分会是配置环境类型实例
类型平台成本节省设置
有时网络设置也是如此
现在 关于环境类型
有三种环境类型
一种是易于实例化且具有直接访问
第二种 一种是无入口
通过系统管理器访问易于实例化
第三种 一种是在远程服务器上创建和运行
在这种情况下我们将使用这种
不用担心其他两种选项
当谈到实例类型时
你可以选择任何类型
然而，按默认显示t two dot micro
T three dot small和m i dot large
如果你想选择其他类型的实例
你可以点击这个，你应该能够搜索实例类型
你可以为你的云九环境选择你想要的任何实例类型
在这种情况下，目前你可以选择two micro
因为它是免费的
我们可以用这些平台之一来创建云环境和
从亚马逊Linux转换为亚马逊LinuxOne和Ubuntu服务器到4LTS
根据您的项目需求
您可以选择您想要的
然而 亚马逊Linux2对于AWS原生应用被强烈推荐
在这种情况下我们将使用亚马逊Linux2，现在来成本节省设置
您可以选择在30分钟后
周期时间或对我们来说1小时
一天一周
只有少数几个选项您将无法自定义
这意味着无论我们选择在这里的时间
云九在没有任何活动的情况下闲置了这么长时间
然后e 与云相关的e2实例将被关闭
你将在后续的时间点理解这些方面
选择在三十分钟后，以便你不必浪费金钱
但如果你正在积极使用它
并且在之间想要休息
你可能想将其更改为1小时后或4小时后
根据你的个人喜好
你可以选择你想要的任何设置
我将在三十分钟后根据网络设置选择
现在不用太担心
只需保留默认设置
然后点击下一步
现在你应该能够查看有关此云和环境的详细信息
然后你可以点击创建环境
它将为你创建云和环境
你可以看到环境类型是集成开发环境
集成开发环境的缩写
云九只是一个特定的AWS IDE
你应该能够非常有效地使用云原生开发与AWS相关的应用程序
这将需要一些时间来准备
一旦准备好 你应该能够使用与AWS相关的内容开发完整的应用程序
让我们等到环境准备好
你可以看到环境已经准备好
你可以在这里看到终端
这是你通常开发程序的地方 作为下一话题的一部分，会给你一个关于这个的概述
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/028_Udemy - Data Engineering using AWS Data Analytics part1 p28 3. Overview of Cloud9 IDE.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们在云和ide中获取音频
让我前往云和ide
它已经启动
你可以点击这里前往那里
现在 这只是一个终端
你可以通过点击这里添加任意数量的终端
你可以添加文件或终端
如果你想添加终端
你必须在这里点击新建终端
你可以看到新的终端已添加到现有终端上方
如果你想最大化
你可以点击这里最大化终端
如果你想再次折叠
你可以点击这里折叠
如果你想更改终端的设置
你可以在这里选择偏好设置
作为偏好设置之一
你应该能够转到用户设置
你可以滚动到终端
然后你应该能够在这里增加字体大小
你也可以与其他与终端相关的设置玩耍
例如文本颜色 背景
颜色选择 颜色
等现在 如果你想更改编辑器中文本的字体大小
你可以关闭偏好设置这里，也可以关闭这个并关闭这个现在
你可以说文件新建文件
你可以说控制器或指挥官
如果你是mac用户 如果你是windows用户
你可以使用控制器来重命名和保存文件
让我们说hello 世界
点回车
你可以看到它自动被选为python程序这里
我们可以说print hello world来开发一个简单的python程序
你可以通过点击这里运行这个
你应该能在这里看到输出
如果你想增加编辑器的大小
你可以点击这里
你应该能从这里增加字体大小
你不需要前往偏好设置
然后转到编辑器更改设置
你可以直接从这里增加字体大小
这就是你可以适应这个ide的方式
偏好设置在这里，你可以更改编辑器中文本的设置
你可以在这里更改文本设置
点击这个，还有一些其他内容
这是一个关于这个想法的简要说明
让我们回顾一些其他细节
我们已经讨论了更改设置后的细节
让我们验证可用的软件和工具作为此环境的一部分
如果你去其他页面
如果你去终端
如果你点击这个来展开
你可以像这样运行它来检查它是否存在
你可以看到它显示了它的用途
这意味着它已经存在，你也可以说 docker ps 来列出任何 docker 容器
没有运行的 docker 容器
但是 docker 已经在这个系统上设置好了
你可以看到它没有写任何容器
因为现在没有容器在运行
但是 docker 已经在这个系统上设置好了
你也可以说 docker ps 减去 a 来查看是否有任何创建的容器
现在没有任何容器在运行
但是 docker 已经在这个系统上设置好了
我们也可以通过说伪系统控制 l 状态 docker 来验证
你可以看到 docker 在这个 git 和 docker 的上面运行
它还有这个 http 安装在这个上面
你可以说伪系统 l 状态 httpd
这是 http demon
你可以看到它说死了
但是它已经安装好了
所以 http 服务器已经安装好了
但是它没有启动
我们将看看是否能够在随后的主题中启动它
关于编程语言
在这个环境中将设置多个编程语言
我们将验证 python 和 java
为了验证 python 的版本
我们可以说 python 然后我们可以按两次 tab
我们可以看到所有有关 python 的命令在这里
这里有两个主要的 python 版本
一个是 python 2.7
第二个是 python 3.7
python 2 只不过是 elias 2 python 2.7
python 3 只不过是 alias 2
python 3.7 python
在这种情况下是 python 3.7 本身
这就是为什么 如果我说 python 并按回车键
实际上启动了 python 3.7.9 cli
现在我可以通过说 exit 来退出
如果我想进入 python 2
我必须说 python 2 或 python 2.7
你可以看到，我们能够连接到 python 2.7 cli
关于java
golang和jdk都可以使用
你可以通过输入java -version来确认
你可以看到java版本为11.0.10 你也可以通过输入java -version来自jdk
golang和jdk都已经安装
jdk和golang的版本都是11.0.10
我们已经验证了很多工具和软件
所以我们已经验证了很多工具和软件
我们有它
Docker以及http已安装
Doc甚至支持多种编程语言
我们有完全有效的Python和Java
如果我们需要使用其他编程语言
我们将在必要时探索
但对于现在来说，这已经足够了
所以这是快速了解云和ID 现在我们可以进入下一个主题
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/029_Udemy - Data Engineering using AWS Data Analytics part1 p29 4. Docker and AWS CLI on Cloud9.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们开始使用Docker和AWS在云和实例中
两者在所有云和实例中都可用，我们之前已经见过了
我们将在这里深入了解一些默认设置
云实例从用户那里获取权限
如果你记得，用户包含管理员访问权限
你可以实际上在这里转到I控制台，转到用户
用户名实际上就是它云用户
如果你点击这个
你可以看到用户是名为它云组的一部分
你可以点击这个
你可以转到权限
你可以看到已将管理员访问策略附加到该组
这意味着用户
云用户继承了此策略的权限
称为管理员访问
这意味着用户具有完全的控制权
为了确认他是否具有完全的控制权
你可以实际上转到A Cloud 9环境
使用这个终端
你应该能够运行名为aws s three的命令
它将没有抛出任何其他东西地返回S3桶
你可以在这里看到所有3个桶
这意味着用户可以访问服务
现在补偿到AWS服务
当谈到Docker时 它已经在这上面设置好了
你应该能够通过说伪系统l状态docker来验证
你可以看到Docker不仅已设置
而且正在运行 你也可以说docker ps
由于目前没有容器正在运行
这里没在做任何事情
你也可以说docker images
以查看到目前为止我们有哪些图像
为了验证
我们可以实际启动hollow world容器
我们可以只是说docker one hello world
它将实际拉取hollow world图像
它将打印hello world
并且容器将自动停止
让我们运行这个
你可以看到图像已被拉取
并且它已从Docker这里打印了hello world
现在Docker将停止
你可以只说docker ps here作为容器正在运行
它没有显示任何容器在这里
然而
如果你说docker ps hyphen here 你将看到hello world在这里
你可以看到这容器的名字
容器的理念
这个图像就是hello world，等等
你也可以说docker images
你可以看到hello world的图像在这里下载了
如果你想清理 你可以说docker rm来清理
然后你可以给名字或者id
两者都可以使用
现在容器被移除了
你也可以说docker rmi hello world来移除图像
它会清理图像
因为我们能够运行docker容器使用hollow world图像
docker在这个任务中成功验证
所有的云和环境都带有aws cli不仅安装
而且基于使用的用户进行预配置
并且docker不仅安装而且启动
我们应该能够使用docker创建docker容器
docker已经作为云和环境的一部分运行
理解这些事情非常重要 这可以加速你的开发过程
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/030_Udemy - Data Engineering using AWS Data Analytics part1 p30 5. Cloud9 and EC2.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解云与EC two之间的关系
我们还没有深入探讨EC two
因此，您可能无法立即消化所有信息
一旦您了解了有关EC two的详细信息
我强烈建议您回到这个模块部分，重新学习这些主题
这样，您的所有疑问都将迎刃而解
关于云与EC two的关系
让我们进入EC two控制台，审查与我们的云实例相关的实例
进入EC two控制台
我们需要访问URL
为了做到这一点，我们可以转到仪表板
我们可以复制这个
然后，我们可以转到私人浏览器
我们可以点击这里以添加新标签页
让我粘贴到这里
它会提示我们输入用户名和密码
用户名无非就是itv
云九用户
现在我必须在这里输入正确的密码
我能够登录到aws管理控制台
从这里我们可以搜索e
C2 我们可以点击这里进入控制台
我们应该能够点击实例这里来查看实例
目前这个账户中只有一个实例
这就是与云和环境相关的实例
你也可以直接进入云九控制台
作为你的aws管理控制台
你应该能够点击这里
你应该能够获取关于与它相关的easy to实例的详细信息
你可以点击这里转到与云和环境相关的简单实例
你可以看到这把我们带到了相同的简单控制台
它将过滤此实例现在您应该能够点击此处查看名称
您可以看到此简单实例的名称为aws云和aws演示
Aw演示是云和环境的名称
然后我们有一些唯一ID
这就是EC
I Two实例将如何代表我们的云和环境
所以让我们回到材料并复习
让我转到另一个窗口
云九由e支持
C2实例 我们已经审查过了
如果你没有在预配置的时间内使用云和实例
EC two实例将被关闭
在我们这个案例中 我们创建了云和环境，设置了30分钟的不活动时间
这意味着如果我们的云和环境在30分钟内没有活动
云原生环境将被关闭
这意味着容易实例化
支持云和实例将被关闭，因为云九由E支持
C 两个实例 我们可以照顾到与易两实例相关的所常规任务，如下
我们应该能够添加安全组规则以打开端口以访问在云上运行的Web服务
你将在下一个主题中看到这一点
你也可以为云和实例分配静态IP或弹性IP
我们需要理解与此相关的问题
然后你将理解这一点的重要性
我将演示这一点
以及后续主题中的一节模块
我们也可以增加EBS卷大小以获得更多的存储容量到云和实例
此时你可能不知道EBS卷是什么
别太担心
那里有关存储的独立部分
我们将涵盖所有与UVs相关的详细信息
然后你将理解它
但对于这个部分，我将只演示如何增加EBS卷大小
现在只需按照说明并增加大小
如果你希望增加大小
也将演示其重要性
作为这个节模块中主题的一部分
这些都是我们在EC two实例上执行的典型任务
所有这些都可以在EC two实例上执行
支持我们的云和环境 这将为我们的云和实例或环境提供更多机会
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/031_Udemy - Data Engineering using AWS Data Analytics part1 p31 6. Accessing Web Applications.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


云霄九霄只不过是IDE的缩写，代表集成开发环境
无论是云九还是任何其他IDE
我们都使用IDE进行应用程序开发
我们可能会在日常工作中开发Web或移动应用程序
我们可能会开始开发Web应用程序
当我们开发时，我们可能会想要访问这些应用程序
让我们了解如何访问在云中运行的Web应用程序
使用IDE 默认端口是8080
如果他们的应用程序在8080端口运行，你应该能够通过访问预览来验证
然后说预览运行应用程序
它将实际在这里打开应用程序
默认情况下，它以8080端口进行配置
然而
如果你在另一个端口上运行了应用程序 你应该能够通过说预览来配置
配置预览URL
你必须在这里指定详细信息
我以前从未使用过这个
因此我不确定百分之一百
如果你想 你可以探索一下
让我关闭这些
另一种操作网络应用程序的方式是通过使用公共DNS本身
让我们理解如何利用这个
我先去终端
让我扩展这个
让我们验证我们的http服务器是否正在运行
为此 我们可以说伪系统l状态httpd
你可以看到它目前是关闭的
我们可以尝试启动它，通过说伪系统l启动httpd
我们可以验证它是否正在运行
通过再次说状态
你可以看到http服务器正在运行
你也可以通过说telnet来验证
localhost
telnet通常用于验证
我们是否能够监听在某个特定服务器上运行的网络服务
在某个端口上
但是telnet在这个云和环境中没有设置
我们应该有nc
让我验证一下我们是否有nc
nc也没有
我们可以通过说sudo apt-get install telnet来安装telnet
加上-y然后回车
telnet将安装在这个基于亚马逊的云环境中
一旦安装完成
我们应该能够说telnet本地主机
以确认我们是否能够从这个本地主机上运行在http服务器上
从本地主机本身
现在我可以说telnet本地主机a
你可以看到我们能够使用本地主机监听80端口
这意味着本地Web服务是可访问的
然而，如果我们使用与该Easy to实例相关的公共DNS
我们可以通过在这里转到详细信息来获取公共DNS
这是公共DNS
我们可以点击它
然后我们可以说http: / /
Slash 公共DNS然后默认隐藏http什么也不是
如果我们能够从远程机器听到80
这是我们的PC
将能够访问运行在默认HTTP服务器上的Web应用程序
你可以看到它没有启动
这意味着它不能从实际来源访问，要修复这个问题
我们必须通过转到与Easy to实例相关联的安全组来打开端口
你可以通过选择e
C两个数据实例与我们的云和环境相关联
然后我们应该能够来到这里的安全性
然后我们可以进入安全组作为安全组的一部分
我们可以说编辑入站规则
然后我们可以添加规则
然后我们可以说这里是http
你也可以使用自定义tcp并指定一个
但已经有http了
http只不过是tcp
你可以选择我的应用程序，以便您可以从自己的系统访问http服务器
不要使用零点零点零点零
你可能现在容易受到DDoS攻击
让我们现在设定规则
规则现已保存
我们可以打开标签，然后输入http列斜杠
斜杠公共DNS并按回车键
我们能够访问运行在我们基于亚马逊Linux的云和环境中的HTTP服务器
这就是你应该能够打开的端口
与在云上运行的网络服务有关
这就是你应该能够打开的端口
九个实例
我们经常会有多个网络应用程序在我们的云和环境中运行 我们需要打开安全组的端口以便访问它们
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/032_Udemy - Data Engineering using AWS Data Analytics part1 p32 7. Allocate and Assign Static IP.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分 我将演示如何为易用实例分配静态IP
与我们的云和实例相关联
当云实例停止并然后恢复时
它将获得一个新的公共IP地址和DNS
因为公共IP地址默认是fml
如果你们的意思是 它们将在EC two实例停止后停止存在
让我来演示一下，以便你们可以理解我在这里所说的
我将转到另一个易用管理控制台
让我转到实例
你可以向上滚动
你可以转到详细信息
这是公共IP地址
这是公共IPDNS
让我们选择这个易用实例
然后转到实例状态并停止
这是相关的云环境
你可以通过点击来验证
我们正在谈论演示云九环境
并且这是相关的EC two实例
现在让我取消
现在公共IP是18到21
19.1 25DNS来自这个
这就是为什么你看到18到21
19.125 即使是DNS的一部分
让我们等到完全停止
因为我们没有闲着30分钟
它将立即启动
但我们将看到新的IP地址
以及DNS
现在已停止
它将很快启动
一旦启动
你将看到一个新的IP地址
以及DNS
现在仍然停止
它将需要一些时间来启动相关的EC two实例
现在你可以看到它已启动
你可以在这里查看名称
它与AWS演示相关
公共IP地址是3.1.2.71
82 DNS来自这个
为了停止这个
我们必须为易用实例分配和关联静态 IP
如何做
作为方便访问的一部分
你需要去网络和安全设置
一旦你在elastic is
你可以点击分配弹性ip地址
你可以在这里分配一个新的ip地址
点击分配
一旦分配完成
你可以使用这个名称
让我命名为demo
只是为了确保名称相互关联
一旦选择了分配的IP地址
您可以转到操作
然后点击关联弹性IP地址
选择实例
我们只有一个实例
那就是这个
一旦选择
我们应该能够点击关联现在
分配的弹性IP与我们的Easy to实例相关联
Easy to实例与我们的云和环境相关联
这意味着我们环境的易用性总是可以通过弹性IP访问
记住，弹性IP会增加成本
成本正常
只要分配了弹性IP
你就需要向AWS支付费用
我强烈建议你使用弹性IP
这样你就不需要太担心IP地址的变化
因为我们会频繁停止和启动我们的云和环境，也就是说
让我们验证 我们是否能够访问我们的云和环境的http服务器
使用这个IP
V作为DNS 这就是静态IP
让我们复制这个
让我们打开另一个标签页
然后输入http://
然后你会看到DNS没有响应
这是为了演示IP地址会改变
每当我们停止并启动Easy Two实例与我们的云和环境相关时
http服务器不会自动启动
现在我们必须去云和环境
我们需要刷新这个
一旦它刷新了
我们应该能够验证http服务器是否正在运行
如果不行，我们需要启动它以验证
验证http服务器是否正在运行
我们可以说伪系统l状态httpd，你可以看到它已经死亡
你可以通过说伪系统cl启动httpd来启动它
现在我们可以来这里刷新这个
你可以看到我们的公共IP v通过DNS访问hp web应用是可用的
这就是你如何使用静态IP地址的方法
为了解决我们的云九环境重启时IP地址会改变的问题
如果你使用云环境和环境进行活跃开发，这对你来说非常重要
对于网页或移动应用程序而言
如果你只是学习一些命令，你不需要太担心这个问题
但如果涉及到网页或移动应用程序的开发
使用静态IP地址非常重要 对于网页或移动应用程序的开发而言，使用静态IP地址非常重要
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/033_Udemy - Data Engineering using AWS Data Analytics part1 p33 8. Changing Permissions using IAM Policies.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们了解如何控制云和实例的权限
通过将脉冲附加到组或从组中脱离
首先 让我们以root用户登录
并查看与用户相关的权限
itv云和用户
它是clan组的一部分
我在这里登录到iam管理控制台
我在这里以root用户登录
我可以转到iam
然后我可以转到用户
我们谈论的是itv云和用户
如果你点击这里
你可以看到组是itv clan
我们已经将管理员访问策略附加到该组
这意味着itv云和用户
继承了控制aws账户的所有权限
我们应该能够管理aws账户内的服务
现在可能太多了，我们可能想限制访问权限
例如 假设我们要为开发人员创建一个账户
他们只能使用ide处理开发工作
除此之外，他们应该没有访问任何其他aws服务或功能的权限
如果你想处理这一点
那么你可以实际上转到组这里
一旦你转到组
你可以实际上附加一个策略
你可以搜索cloud nine
你可以选择这个在选择这个之前
然后脱离其他策略
我正在尝试做的是
我只是想验证云和环境中的当前权限
我们可以说aws
S3这里
我们能够看到存储桶
因为我们有管理员访问权限作为s3
s3是一个服务
我们能够从s3访问存储桶
我们应该能够删除这些
添加新的
将文件复制到此
从删除此文件等等
让我回到iam控制台作为root用户
让我以aws云和用户附加此策略
现在 让我脱离此管理员访问权限
现在用户itv云和用户
它是itv云和组的一部分
只有云和环境的权限
为了验证开发，我们需要照顾发展
你可以在这里转到其他页面进行验证
我们现在在云和环境中
我们应该能够说aws s three并按下回车
你看它正在说
另一个记录 在调用list buckets时
操作访问被拒绝
因为我们已经从组中删除了管理员访问策略
如果你想给S3桶提供访问权限
但不对其他任何东西进行访问
你可以使用根账户访问管理控制台
然后你可以说附加策略
你可以在管理控制台中搜索S3
有一个S3全权访问策略
你可以选择这个
然后你可以说附加策略
现在我们已经将这个策略附加到了组中
我们应该能够运行aws s three并再次列出桶
让我转到其他页面
让我运行这个
我们应该能够看到桶
然而，我们不能管理除S3以外的任何东西
因为我们只在云九中为实际运行此环境提供了S3的全权访问权限
为了确保我们恢复到原来的状态
我将会从组中删除这两个策略并重新附加管理员策略
然后我会再次验证
然后我们将结束这次演示
让我回到IAM管理控制台
让我附加策略
管理员访问权限是超级集
因此我们应该能够删除这两个策略
对不起 我已经删除了管理员访问权限
我需要再次附加
一旦附加完成
我应该能够删除S3访问权限
以及云和用户
现在我可以回到这里
我应该能够运行此命令列出桶
此外 如果你想管理AWS中的任何其他服务
我应该能够这样做 因为我通过组使用管理员访问权限
使用管理员访问策略
这就是你可以控制使用云和环境的用户的权限的方式
如果你想给开发团队提供云九
你需要确定应该给予哪些权限
然后我们需要创建组
我们必须只附加相关的策略
然后我们需要将用户添加到该组中
这样所有应该使用云和进行开发的用户
在AWS资产上获得所需的所有访问权限
我希望你理解
如果不理解 当你进入高级主题时你会理解的
目前 你应该清楚我们可以控制克隆环境的权限 对于使用附加到组的IAM策略的用户
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/034_Udemy - Data Engineering using AWS Data Analytics part1 p34 9. Increasing Size of EBS Volume.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解如何增加与易用实例相关的腹肌容量
与我们的云原生环境有关
默认情况下，云和实例创建时具有10 GB存储
有多种验证方式
让我们去云终端
在这种情况下，我在云终端
我应该能说 df -h 并按回车
你可以看到，默认情况下，实例
分配10 GB存储
你也可以通过访问 EC two 实例来验证
让我们确认我们看的是正确的 EC two 实例
这个 EC two 实例与我们的演示云环境相关
这是正确的
一旦我们选择这个，我们应该能够访问
我们可以去存储的底部
然后我们应该能够滚动
我们可以点击这个卷
这个卷与 EC two 实例相关
与我们的云环境相关
我们可以给它一个名字
让我命名为 aws demo 并按回车
你应该能说操作修改卷
你应该能改变大小
让我们说，我想增加到 1000 GB
只要我们试图增加，
应该能成功
当我们试图减少时，
有时可能无法工作 但增加，
总是能成功
你可以改变卷类型
在这种情况下，如果你想进一步降低成本，
你可以选择磁性
但通用目的， SSD 也不贵
所以我选择通用目的，SSD
在我们的案例中， 如果你想改变， 你可以选择磁性
然后滚动，
然后你可以说修改这里
然后你可以说，是的，关闭
有时可能需要时间增加大小
你可以刷新以确认是否已增加
在这种情况下，尚未增加
我们需要等待
你可以看到它已增加
如果你去云环境
让我访问云环境
在这个云环境中
这是我们的云环境
如果我说df hyphen h ch
它仍然只显示10db，因为我们必须重启机器
一旦我们修改了卷的大小以重启
您可以在这里转到实例
您可以选择合适的实例
我们的云九环境无非是aws演示
我们选择了与aws演示云九实例相关的简单实例
现在我们可以说重启
点击重启 这将花费一些时间
一旦它重启
您可以看到它已更改为重新连接状态
因为简单实例正在被重启
E C 与我们云环境相关的e实例已报告
您可以看到云环境在这里没有任何问题刷新
现在 我们可以说df hyphen head
您可以在这里看到大小
它无非是gb
这就是您应该能够通过转到卷来修改卷大小的方式
然后单击操作
然后单击修改卷
只要您想要增加大小
减少很简单 可能无法工作
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/035_Udemy - Data Engineering using AWS Data Analytics part1 p35 10. Opening ports for Cloud9 Instance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为aws cloud nine的一部分
我们运行网络应用程序或开发和部署我们的网络应用程序是很常见的
每当我们运行我们的开发和部署我们的网络应用程序
我们希望连接到它
每当我们想要连接到在云上运行的网络应用程序
我们需要两个信息
一个是域名系统（DNS）服务器IP地址
第二个是端口号
说到DNS服务器IP地址
你可以实际上去
与这个云相关的两个实例
这是简单的实例
你可以查看详细信息
你可以在这里获取dns
让我复制这个
如果你回到这个标签，你也需要在这里运行一个网络应用程序
每当你从aws创建云和实例时
你会得到已经运行的apache
你可以通过说sudo system l status来验证
Apache已经安装并运行
不仅安装而且运行 你也可以通过说telnet local host a来验证
Apache默认运行的端口是80
所以我说
Telnet local host
我能听到这个
让我退出
要退出
你必须按Ctrl和关闭方括号
然后按回车 然后你必须输入quit作为telnet的一部分
现在让我打开一个私人窗口
然后让我说http colon slash slash
然后公共dn与运行云九实例的EC two实例相关
如果你按回车
你可以看到它没有连接到运行在云九实例上的apache
两个原因是端口没有作为安全组的一部分打开
我们必须打开端口
我们得打开端口
在这种情况下 我使用简单的Apache服务器进行演示，在未来
每当我们在这个云和实例上部署某物
如果我们想从我的系统连接到它
无论是通过浏览器还是其他客户端工具
你需要确保这个cc到实例的端口是打开的
现在我关闭了这个
我实际上进入这个标签来打开端口
你必须在这里转到安全
然后点击安全组
安全组在aws生态系统中就相当于防火墙
你可以向下滚动
你可以说编辑入站规则
我们正在尝试连接到Apache
服务器运行在该实例上
因此我们正在编辑边界
我们可以说添加
我们谈论的是HTTP
因此我们可以说自定义TCP并输入这里
或者我们也可以直接说HTTP
让我输入HTTP
你可以看到它已经填入80
我可以展开这个
然后说我的IP
它将从我的实例中获取IP地址
我正在访问这个网站
然后它将在这里填充
现在你应该能够通过点击保存规则来保存
一旦保存
你应该能够打开私有窗口
然后输入http://://paste
输入公共DNS并按Enter
你可以看到能够访问Web服务器
该服务器运行在云和实例上
即使我们能够访问这个，每当云和实例关闭和启动
由于活动不多
IP地址将更改为地址
IP地址更改的问题
我们需要启用弹性IP
我们将看看如何为这个易用实例启用弹性IP 作为下一主题的一部分
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/036_Udemy - Data Engineering using AWS Data Analytics part1 p36 11. Setup Jupyter lab on Cloud9 Instance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


这一部分的主题 我将演示如何在这个云和实例上设置jupyter lab
我们将验证是否安装了python 3
一旦我们确认安装了python 3
我们将查看可用的 我们将创建一个python虚拟环境
使用python 3创建python虚拟环境
一旦创建了python虚拟环境
我们将激活它
一旦激活
我们将使用pip命令安装duLap
一旦duptor lab安装完毕
我们将启动与duLap相关的网络服务
我们也将看看如何从我们的浏览器访问该网络服务
让我们一步一步地走完这些步骤
逐一验证
我们是否安装了python3
我们可以输入python并按两次tab键
您可以看到可用的所有python版本
我们有python2以及python3
说到python三
它只不过是python三点六
所以我们有python二点七和python三点六
你可以通过像这样运行python来验证
python指向python二点七
你可以像这样从python连接它
然后你可以说python三
你可以看到python三只不过是python三点六点九
我们将使用python三创建虚拟环境
这里是为此我们需要退出
然后我们可以创建一个名为de lab的文件夹
Mk是Linux命令，用于创建文件夹
一旦我们创建了文件夹
我们可以使用cd命令进入该文件夹
像这样，cd代表更改目录
现在我们在lab文件夹中
然后我们可以说python three
hyphen m v e和vv
并且使用python three中的虚拟环境模块
它将为我们创建虚拟环境
使用 Python 3.6.9
实际上可以给虚拟环境起一个名字
我给它起名为 d lab 斜杠 v e 和 v
现在我们可以按回车
它会为我们创建虚拟环境
你可以实际上说 找到 lab 斜杠 v 和 v 来验证所有文件夹和文件
在这个主文件夹下
与虚拟环境相关
你也可以运行 ln lab 斜杠 v 和 v 然后按回车
你可以看到python以及pip命令
现在我们必须激活这个
你可以看到有一个名为activate的命令在dlab中
我们和您可运行tacit的方式
使用像这样的linux源命令
然后你必须通过说the lab给出activate的路径
Hyphen v和v在activate中
你现在可以按回车键，现在虚拟环境已激活，因为虚拟环境已激活
如果我们在这里运行pip命令
它将在这个虚拟环境中安装dupta lab
现在我们可以像这样设置安装jupyter lab
它会在这个虚拟环境中处理安装dulab
每当我们想要访问dulab
我们必须激活虚拟环境
然后我们需要运行适当的命令来启动jupyter lab
让我们等待dulab安装完成
然后实际上我们会启动jupyter lab服务器
我们也会理解如何连接到它
现在jupyter lab已经设置完成
我们可以说jupyter lab
然后破折号破折号ip零点零点零点零
实际上启动drifter lab web服务器
现在您可以按回车
您可以看到jupyter lab服务器在八八八八端口启动
您可以在标签中打开
您可以通过说telnet localhost八八八八来验证它
您可以看到dulab服务器在这个端口运行
然而
如果我去e c two实例
如果我从这里选择公共ip v for dns
如果我打开另一个标签页
然后输入http://
输入dns
然后输入jupitter lab的ip地址，它会无法工作
原因在于端口号8888没有被打开
端口号8888没有被打开，是因为安全组的设置
如何打开它
你需要去easy2的实例中，找到相应的实例
然后 进行相应的设置
前往安全
点击这里的安全组
审查现有的入站规则
我们只有两个两八十已经打开
点击编辑入站规则
因为我们正在尝试连接到作为其一部分运行的Web服务器
两个实例 因此现在被视为入境流量
向下滚动 点击
添加自定义TCP
输入端口号8888
然后扩展这个
选择我的网络
然后说保存规则
规则已添加
我可以打开这里的标签
让我输入http:
斜杠斜杠 输入公共
我为dns
第八列8888按回车
你们可以看到我能够访问jupyter lab
我们在安全组中打开了它
我们能够访问jupyter lab
然而它正在询问密码或令牌
实际上你可以去云九的终端
你必须去启动dupta lab的标签页
这就是你要输入的令牌
让我复制这个
去这里粘贴
然后说现在登录
您正在Jupyter Lab中，它是我们云和实例的一部分运行
如果您想访问终端
您可以点击此以打开终端
您应该能够运行所有您的
您将在这里做注释
因为我们的云和实例使用
您想要作为操作系统
如果您想创建笔记本
你可以点击这里的python three
它会创建一个名为未命名的笔记本
如果你想要重命名 你可以说任何你想要的名字来重命名
在这个例子中我说开始
一旦jupyter笔记本被重命名
你应该能够在这里输入python three代码
你可以说打印hello world
然后运行这个来查看输出
你也可以通过说from platform来验证python的版本
Python 版本
然后你可以说 python 下划线版本像这样
你应该能看到 python 版本
这是用来启动这个导师实验室环境的
这就是你应该能够设置 tutor lab 作为云和实例的一部分的方式
并且访问它
你必须确保 jupyter lab 是用 i 开始的
P zero dot zero dot zero dot zero
并且也作为安全组的一部分打开了端口号
这样我们就可以使用浏览器访问了
要么你可以像这样直接运行jupitter lab
你可以对实验室说hyphen
像这样说hyphen ip zero zero zero zero
或者如果你不想使用你的终端
只是想运行tutor lab
你可以实际上在这个背景中运行
你可以通过使用no hub以这种方式运行这个背景
你可以说no hop jupiter lab
然后hyphen have一个ip zero zero zero或zero
然后ampersand并按回车
它会在后台运行tutor lab
当它在后台运行时
如果你想获取令牌
你可以实际上说tail
No hub点out
你可以在这里看到令牌
在no hub out
令牌将被写入
你应该能从那里获取令牌
如果你不舒适地运行tutor lab
使用no hub 只需直接运行duterlab
我早些时候使用此命令显示的方式
然而 你不能使用这个终端
你必须打开额外的终端
然后你必须在必要时运行命令
如果你想使用终端作为你的云和实例的一部分
你可能必须打开多个标签
你应该能够运行命令
这就是你应该能够设置tutor lab以使用它来学习新技能
跟随我的内容
无论我在jupyter中演示
如果你想使用类似的环境
你应该能够像这样设置tutor lab
duta lab 然后使用它进行学习目的
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/037_Udemy - Data Engineering using AWS Data Analytics part1 p37 12. Open SSH Port for Cloud9 EC2 Instance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


到目前为止，我们已经使用aws云和云设置了开发环境。
并且它什么都不是，只是e上面的id
C 两个实例 我们也将弹性IP与与这个云和环境相关的易用实例相关联。
这将使我们能够连接到运行在这个云九简单实例上的应用程序
使用相同的IP地址或DNS别名
尽管如此，事实就是如此
我们也必须访问终端
一种访问终端的方式就是使用 IDE 并访问终端。
通过点击这个 我们应该能够启动终端
我们可以实际上运行一些Linux命令
然而，有时我们可能想连接到与这个e相关的这个ah终端
C 两个实例 使用这样来验证
无论端口号二十二是否为我的PC或Mac打开
如果不这样 实际上会处理更新与这个易用实例相关的安全组的问题。
与这个云和环境相关
你可以实际获取公共DNS别名
所以你可以去环境
在这个案例中我正在使用实验室演示
你应该能够点击这个现在你可以滚动
你可以实际点击
转到实例 它会带你到相关的实例
与云和环境相关
我们可以实际选择这个
然后我们应该能够向下滚动
你可以看到公共ip v for地址
这里也有公共ip v for dns
你可以使用任何一种来验证
我正在使用ipv for dns
让我复制这个
让我转到终端
然后说telnet public das twenty two
如果端口号22对所有的ip地址开放
你应该能在这里看到一个提示
它只是悬挂着 它没有显示任何提示
这意味着端口号2222对所有人开放
让我们打开端口号
这样我们就可以将其连接到e c two实例
与云和环境相关联
为此我回到Web控制台
让我转到安全这里
我们必须转到适当的安全组
这是安全组
我们可以点击这里
然后你可以实际扩展这些操作
点击编辑入站规则
然后你应该能在这里指定我的p
这样我就能在服务器上使用ssh连接到这个mac
你可以使用这种方法
或者你可以说任何i
p v之前为搜索
选择任何i是可以的
P V four for your environment
如果你在一家公司工作
如果你与该公司相关的aws账户
你应该只使用我的ip
或者你必须使用目前称为隧道的概念
我现在实际上在任何地方使用
我p V for
然后我现在保存了规则
让我回到这里，然后通过说telnet公共dns来验证
然后22号，你现在可以看到它实际上显示了这个提示
这意味着我们可以与22号端口通信
使用公共dns
现在要退出
我们必须说控制关闭方括号
然后我们可以说退出
我们退出了telnet，因为22号端口已打开
现在我们应该能够尝试使用这样的连接
然而，我们还必须配置密钥
这样我们就可以通过简单的实例集连接到我们的本地机器 让我们进入下一个话题的细节部分
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/038_Udemy - Data Engineering using AWS Data Analytics part1 p38 13. Connect to Cloud9 EC2 Instance using SSH.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分
让我们配置一个h来连接到e
与云和环境相关联的c two实例
让我们使用浏览器进入终端
实际上可以进入云和这里，你可以在这里看到终端
它将有一个名为.set 的文件夹在 home 文件夹中
你可以实际上说 cd
你应该能够进入 home 文件夹
你可以说 pwd
你可以看到与这个易用性实例相关联的 home 文件夹
与云和环境相关
它将有一个名为.ssh 的文件夹
你可以说 a siphon 打开.ssh
你可以实际上看到有几个文件
最重要的文件是 nothing but other case to connect it to this easy to instance
一旦我们打开端口号
我们需要更新授权密钥与公共密钥
这将用于从我们的 mac 或 pc 连接到这台机器
因此，在这种情况下，作为 part of my mac
我有几个密钥
其中一个密钥是 nothing but itv
demo 或我可以创建一个新密钥仅用于演示
所以让我实际上生成一个新的新密钥 here as a keen
我可以现在按 enter
正在 my mac 生成公共或私钥对
你可以实际上处理这个
甚至在 windows 中使用 powershell 或甚至使用基于 git 的 windows
现在我需要提供私钥文件的完全限定路径
它 nothing but user
i t dot ssh
然后 let's say itv c nine demo
这是我的私钥文件名
我不想使用任何密码 here
让我按 enter 按 enter
如果我说 lt tilde slash dot h and then itv c nine
我们应该能够看到两个文件 here 一个是 itc nine demo
这是私钥
第二个是 itvc nine demo dot pub
这是公共密钥
我可以实际上获取 itv c nine demo pub 的内容并复制
一旦复制
我们需要在 e c two 实例中打开密钥与云和环境相关联
并将粘贴
在最后 你必须小心
如果你损坏了 author is the case
你可能会遇到一些与连接到云和环境本身相关的问题
因此要额外小心
让我演示如何将公共文件的内容复制并粘贴到 case 中
仔细观看并仔细跟随
我可以说猫然后复制粘贴这个
一旦复制粘贴
现在您可以看到这公共密钥文件的内容
让我们选择这个 您必须从ssh - a到最后一个字符选择
您不应该在选择字符串的最后一个字符之后的任何附加字符
您必须复制这个
然后您必须转到与云和环境相关的终端
您可以通过点击此按钮来最大化此
一旦最大化
你可以为家节省一个波浪号
日记 斜杠点
然后斜杠a并按tab
它应该自动填充授权密钥文件的名称
现在你可以按回车
它将带你到这个文件的第一行
你可以说shift g去文件的最后一行
然而它选择了最后一行的第一个字符
现在您可以说美元，应该带您到这一行的最后一个字符
我在这里按一个美元
现在您可以看到它已经带我到了这一行的最后一个字符
我可以说如果为您可以看到它已经更改为插入模式从命令模式
您应该注意这里
一旦它在插入模式
您实际上可以按
回车键进入插入模式
我输入了一个a
您不应该有一个字符
在这个字符后面输入
确保你现在注意这些事情
你可以说命令
我们可以按Ctrl + V来粘贴我们在电脑上复制的内容
这就是与itv c nine demo相关的公钥
现在可以说Esc来实际从插入模式回到命令模式
现在 插入模式已消失
它已经进入命令模式以保存并退出
你只需使用冒号和x，你应该处于命令模式
不在插入或武器模式
一旦你输入colin和x并按回车
它会实际保存我们粘贴在other keys文件中的内容
可以说tell然后减号1
然后波浪线斜杠点ssh
然后其他键它会实际显示
文件最后一行
你可以看到我们从pc复制的内容
现在粘贴在other keys文件中
让我们验证我们是否能够连接到这个easy to实例
与云和环境相关联
使用Mac或PC的一组
现在我要去Mac终端
我在Mac内核中
相关的密钥是波浪线点
然后itv c nine demo
我们必须在这里提供私钥文件名
我们将公共密钥的内容复制到e的其它密钥中
与云和环境相关联的c two实例
我们正在使用私钥文件名
它只是itv c nine demo
公共密钥文件名是itv c nine demo点pub，现在我们可以说e
c two-用户在率上，我们必须选择该的公共dns
我们可以回到易于管理的控制台
然后我们应该能够去到易于这里
让我们进入运行实例
让我们选择与云和环境相关联的易于
然后让我们实际去a公共dns
我们应该能够点击此复制
或者我们可以实际上选择此中心东西，出于某种原因
它没有正确选择
让我进入网络这里
让我刷新此页面
似乎有些问题
它没有按预期工作
我可以选择此
我可能现在应该能够点击此
作为它已经复制，现在
我应该能够说易于-
usal 它实际上是你想要
然后at the rate
然后公共dns并按回车
它会第一次提示你
你只需说yes
按回车 你应该能够进入e
c Two实例与云和环境相关联，没有其他问题
这就是你应该能够配置成这样，以连接到e c Two实例与云和环境相关联
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/039_Udemy - Data Engineering using AWS Data Analytics part1 p39 1. Introduction - AWS Getting Started.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在深入探讨aws分析服务之前
让我们先处理一些前置事项，如用户、角色和策略
我们将不会涵盖一个典型项目中所需的所有策略
目前 策略是我们授予用户和角色权限的方式
同时，你也会理解我所说的内容
随着我们深入探讨
我们将从创建一个s3存储桶开始
s3存储桶与权限无关
但我们会使用它来验证用户是否在aws中具有相应的权限
我们将创建一个s3存储桶，并将其用作测试环境
以实际验证用户权限
在存储桶之上
我们还将创建一个组以及相应的用户
并且使用aws web控制台进行设置
一旦我们创建了用户和角色
我们将配置aws cli使用配置文件
然后验证我们是否能够从相关测试存储桶中读取数据
在这种情况下，相关测试存储桶是我们在本模块中创建的存储桶
在继续之前
您需要确保拥有一个有效的aws账户 我推荐您使用个人账户或企业账户
如果您使用组织账户
您可能没有足够的权限
您可能会浪费一些时间与组织管理团队协商
话虽如此，为了验证
您是否有一个有效的账户
您只需访问aws.amazon.com
登录到控制台
输入用户名和密码
如果启用了多因素认证
可能会提示您输入多因素认证码
一旦您登录
您应该能看到这个页面
所有服务都会在这里显示
您可以点击s3进入s3，然后继续
我们将回来，创建一个s3存储桶
然后探索本模块应涵盖的其他内容
我们将继续探讨剩下的内容 作为本模块的一部分
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/040_Udemy - Data Engineering using AWS Data Analytics part1 p40 3. Create AWS s3 Bucket using AWS Web Console.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们使用AWS管理控制台创建一个S3桶
它将用于存储GitHub活动数据
现在我们需要登录
我已经登录了 我们可以通过点击这里转到S3
这只是最近我们服务
然而 如果你不能在这里看到
你只需要扩展这些服务
你应该能够转到存储
你应该能够点击S3以转到S3
一旦你点击S3
现在它提示我登录
让我这里登录
我有MFA
所以我需要输入代码
也让我输入代码
让我现在进行登录
我将创建一个名为itv-github的桶
你可以使用短划线作为桶名一部分
所以让我点击这里创建桶
然后输入itv-github
如果你使用账户
你可能需要根据区域进行具体说明
我使用的是北弗吉尼亚
这是我账户的默认区域，话说回来
一旦你给了名字
并且选择了适当的区域
你可以点击创建桶来为你创建桶
你现在不需要担心其他选项
一旦桶被创建
你应该能够像这样搜索它
然后点击它进入桶
然后你应该能够创建文件夹
我们将创建两个文件夹
登录和画 我会在稍后解释这些文件夹的目的
让我们点击创建文件夹并命名为登录
我还将创建一个名为画的文件夹
这是为了现在
让我们回到中间并了解这些文件夹的目的，登录区域
登录文件夹将用于从最大来源摄取数据
这将是我们数据湖的起点，数据湖是基于S3构建的
所以这个S3桶就是我们关于GitHub项目的数据湖
我们将进一步开发以深入了解AWS分析
这将是我们学习AWS分析的深度项目
通常在着陆区使用不同类的文件格式存储数据
但在我们的情况下，我们将使用JSON存储
因为我们将使用的GitHub活动数据以JSON格式存在
但根据您的组织和获取数据的来源
着陆区的文件格式可以是不同类型
取决于您从其他团队获取的不同来源
通常，着陆区的数据将被删除
它将作为临时存储区
我们可以删除比30天更旧的数据
或者根据SLA
法律区将用于存储遵循我们数据标准来源的数据
因此，我们可以从不同的来源获取遵循不同标准的数据
在复杂的项目中
我们可以通过定义一个称为raw的东西来实际将数据流化为标准格式
在小型项目中
将只有一个层次
将不会有两个层次
一个是着陆，另一个是raw
但在我们支持多个项目的复杂环境中
我们从多个源应用程序获取数据
将有着陆和raw之间的区别
着陆将被用作临时存储区
我们将吸收数据并按原样存储
然后将数据复制到raw并长期维护
它可以从7到10年不等
取决于组织
的偏好和SLA
我们已经创建了两个文件夹
一个是着陆，另一个是raw的一部分
我们将使用Parquet文件格式
并且将数据按日期分区，以便理解
当我们将数据放入层中的文件夹时
我们将使用AWS相关的分析和服务 学习使用我们的GitHub项目或GitHub数据集 当我们进入GitHub项目或GitHub数据集时
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/041_Udemy - Data Engineering using AWS Data Analytics part1 p41 5. Create AWS IAM Group and User using AWS Web Console.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们创建一个IAM组，以便用户可以访问GitHub
活动数据和相关任务
通常，这一步骤由组织的AWS管理员或DevOps团队处理
创建组的步骤
然后创建用户
我们需要登录AWS控制台
让我进入AWS控制台
当我提到控制台时
它是一个网页控制台
它也被称为管理控制台
一旦你在管理控制台或网页控制台中
你可以搜索IAM作为一项服务
然后你应该能够找到IAM控制台
点击这里，让我们进入IAM控制台
一旦你在IAM控制台中
你可以首先创建组
一旦组创建完成
我们可以向组添加用户
并附加策略到组
与策略相关的所有权限
附加到组的策略将继承给组的用户
这些是用户组的一部分
让我们在这里进入组，然后点击创建新组
我将使用ITV GitHub组的命名约定
所有后来加入ITV GitHub项目的用户都将成为该组的一部分
让我点击下一步
我们可以在此时附加策略
但不会这样做
我们将在进一步过程中附加策略
并在必要时进行处理
目前 我们将仅创建组
因此我们可以点击
点击下一步
然后说创建组 一旦创建了组
组将创建
你可以再次访问组页面
并应该能够搜索该组
让我复制此组名称
我错过了那部分
我可以直接通过说ITV GitHub组进行搜索
这是创建的组，因为组已成功创建
我们可以创建用户并将用户添加到组中
让我们转到用户以创建第一个用户
这样我们就可以将用户添加到组中
我可以在这个页面上说添加用户
我们可以添加一个用户或多个用户
我们还可以控制应给予用户的访问类型
一旦我们选择了这些
会有额外的选项
我将只创建一个用户
用户名只是itv
GitHub用户
如果你想添加更多的用户
你可以点击 添加和添加更多的用户
我们将为这个用户提供程序化访问以及管理控制台访问
但我们将不会使用这个用户通过管理控制台访问
管理控制台就是这个
这个用户将主要用于程序化访问
当我们实际创建用户时
它将为我们提供凭据
我们需要下载这些凭据
确保下载这些凭据
这将在我们稍后配置aws时对我们有用
以编程方式与aws服务进行交互
如果您选择aws管理控制台访问
它将要求您生成密码
您可以选择这些选项之一
并且你还可以强制用户在签署时重置密码
当他登录到管理控制台时
使用此用户名和密码组合
不管怎样我们不会使用这个用户登录管理控制台
但我只是随便选的
现在我可以点击下一步权限
我们可以将用户添加到组中
或者我们也可以直接将现有的策略直接附加到用户
在我们这个案例中我们选择走组这条路
组其实没什么特别的
Github 组
这就是我们将要使用的组
我们选择这个，然后说
标签旁边 你可以给标签一个键 project
值只不过是 github
然后说查看
然后你可以通过点击这里创建用户
现在会为我们提供一个应该下载的 csv 文件
它将包含访问密钥以及秘密密钥
可以用来配置aws cli或auto three
点击这个
以CSV格式下载访问密钥和秘密密钥
你也可以复制并保留这个
但我不会复制粘贴
我现在只下载这个
用户属于该组
附加到该组的所有权限
通过策略将由组内的用户继承
随着我们进一步深入 我们可能会向这个组添加更多的用户
我们也可能会在不同的组中设置不同的权限，尤其是在一个大型项目中
例如 开发者可能会有他们自己的组
测试人员可能会有他们自己的组
业务分析师可能会有他们自己的组
同样，DevOps或管理员可能会有他们自己的组，这样就可以了
我们应该能够为不同类型的用户组织权限
他们可能需要不同类型的权限
所以请记住这些事情 这样你就能真正理解在实际项目中是如何设置的
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/042_Udemy - Data Engineering using AWS Data Analytics part1 p42 7. Overview of AWS IAM Roles to grant permissions between AWS Services.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们已经成功地将用户设置为组中的一员
让我们了解有关角色的详细信息
让我们关注那些
它们通常与服务相关联
例如 E C
等 以获取其他服务的权限
对于在aws上的数据工程或数据科学项目
我们可能需要使用多个服务
例如glue 可以帮助mr at an等
这些服务通常与其他服务交互
授予一个服务所需的权限的标准方式是创建角色
通常，当我们实际开始使用服务时
我们会被要求创建角色
只要我们创建角色
它将继承服务之间的所需权限
在某些情况下 我们通常会使用政策和角色列表进行标准化
随着你继续深入 你将更好地理解这一点
我们可以使用
我在网页控制台中
你只需去角色
然后你应该能够创建角色
你可以说创建角色
你可以看到不同的选择
例如aws服务和aws账户
网络身份 sm to of federation
这是我们在iam角色方面拥有的选项
你可以在这里看到常见的用例
还有那些
所以你可以选择你想要的任何一个
然后你可以继续
假设我想要创建一个角色，我希望给予e全权访问
C 两份那个 我可以实际上选择e
C两在这里，然后说额外的权限
然后你应该能够搜索e
C两 它将提供所有与e相关的预定义策略
C两 如果你滚动下来
你将会发现容易到全权访问
你可以选择这个
然后你可以说标签，你可以进一步
你也可以创建一个自定义策略，然后进一步
而不是授予e上的完整权限
C two 使用这个策略
你可以创建一个自定义策略，你可以限制你想要给予的权限
然后你可以进一步
你也可以在这里以json的形式定义
这就是你通常创建带有策略的角色的方式
我们不会在此时创建角色
但每当它相关时
我会解释角色的相关性
以及如何将策略附加到现有角色
如果那时适用
请记住，我们既使用用户也使用角色
用户通常用于与服务交互
在以程序方式使用aws时
Cli 使用凭据 角色通常用于服务之间
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/043_Udemy - Data Engineering using AWS Data Analytics part1 p43 9. Create and Attach AWS IAM Custom Policy using AWS Web Console.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


到目前为止，我们已经创建了一个名为s的三个桶
它v GitHub
实际上，你可以去s三那里，你可以搜索它
现在我想要授予权限
仅向用户提交这个桶
我们作为创建角色和用户过程的一部分创建了它。
水桶的名字无非就是itv hyphen github
您需要对水桶名称的拼写极其小心
我正在使用破折号而不是下划线
正如我们所愿，我们要给予许可
仅在此桶中对用户
ITV GitHub用户
我们可以创建一个策略
将该策略附加到组
因为用户属于该组
用户的权限将由组继承
组名就是ITV GitHub组
让我们去 我在这里控制台
我们应该能够去
我来自最近访问的地方
如果你看不到 你可以实际搜索并前往
我是控制台 这里是你应该能够创建策略的地方
然后我们可以去策略
我们可以说创建策略
在这种情况下我们可以直接去json
然后我们可以实际指定这个json文档
然后我会详细说明
一旦我把它放在这里
你可以在这里看到
效果是黄色动作在三个对象的顶部
我们正在尝试提供所种类型的权限
此外，我们还需要记住一些额外的事情
我需要添加更多内容，以便能够为所有列表访问此对象
以及读取和写入权限
你可以通过说s three policy来实际在谷歌上搜索
读取和写入
一旦你搜索了这个
你可以点击这个链接
这来自官方文档
你可以与这个进行比较
然后我们可以继续
所以我们没有列表桶
我们也必须包括这一点
这样我们就能列出桶
所以我也必须复制粘贴这一点
所以我实际上要复制粘贴这些完整的东西
然后我们更改桶的名称
水桶名称无非就是itv hyphen github
你需要确保拼写正确
如果拼写错误
将实际显示拒绝访问
这可能有点误导
确保水桶名称的拼写正确
现在确实提供了对列表中的桶的权限
以及列表中桶中的对象
以及桶中的对象管理
我也必须更改桶名称
它无非就是itv hyphen github
我们有列表中的桶
以及读取对象
输出对象等
以对象结尾的实际权限无非就是获取对象
删除对象
提供读取访问
删除对象 提供删除访问
上传对象 提供将文件复制到s three作为对象的访问
所有这三个权限
以及与对象相关的一些相关权限，通过此策略授予
我们正在创建策略
我们还没有将此策略附加到任何东西
现在您可以查看策略
您可以实际查看详细信息
您可以提供用户名
有关策略的详细信息可以从这里查看
如果您需要 您可以点击并实际获取详细信息
一旦您审查了 您应该能够给策略命名
策略名称无非就是itv github s three full policy
仅在itv github s three桶中
我们提供完全访问权限
如果您需要 您可以提供描述
我现在丢弃那个
然后说创建策略，因为我们已成功创建策略
现在是时候将我们附加到用户策略了
通过组策略以及组已成功创建
让我们将策略附加到组中
这样，属于该组的所有用户将继承与策略相关的权限
您可以通过访问组来将策略附加到组中
查找组
组名称无非就是itv github group
您可以在这里看到组
点击这里，然后转到权限设置
你可以看到现有的策略
目前与该组无关的策略
我们可以通过点击附加策略来附加策略
我们可以搜索策略名称
策略名称是itv github s three全策略
让我们选择这个，然后附加策略
现在与该策略相关的权限
这些权限是管理s three桶
itv github将策略分配给组中所有用户
目前我们只有一个用户
这个用户是itv github用户
为了确保用户可以访问或管理s three桶
我们需要配置cli
然后我们必须运行几个命令来确认 让我们深入这些细节
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/044_Udemy - Data Engineering using AWS Data Analytics part1 p44 11. Configure and Validate AWS Command Line Interface to run AWS Commands.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


到目前为止，我们已经创建了一个名为hyphen github的三个桶
我们还创建了一个名为itv github的用户
我们已经为控制这个桶提供了权限
通过策略将权限提供给itv github用户
itv github的三全策略
这个策略附加到组上
并且用户也属于该组
附加到组的任何脉冲
所有脉冲都将继承到该组中的用户中，也就是说
到目前为止，我们只添加了一个策略
那就是itv github的三全策略
它将提供控制s three桶的权限
使用这个名为v github的用户
让我们验证我们是否能够控制这个桶
然而，在进入之前
我们应该配置aws cli
如果你能够配置aws cli
我们应该能够使用aws cli与three进行交互
目前 我们限制了配置aws cli的范围，以与这个桶进行交互
使用这个用户 另一方面
我们已经设置了docker
我们还在docker上启动了jupyter lab容器
让我们验证容器是否正在运行
为此我们可以说docker ps
并查看容器是否正在运行
没有名为aws analytics的容器
这是我们之前创建的 要启动它，我们可以说docker start aws analytics
一旦它启动
你可以实际上说docker locks来获取令牌
这是我们应该使用的令牌
现在
我们应该能够转到浏览器 然后到localhost
9999，这是我绑定到jupitter的端口
运行在容器lab上并按Enter 因为我们已经提前输入了令牌
它没有提示
如果它提示
我们只需粘贴令牌
现在我们应该能够在这里启动终端 并验证aws cli是否已安装
aws cli已安装
你可以看到它正在抛出一些错误
它期望一些参数
但它没有说命令未找到，因为aws在這裡已安装
它正在期望一些参数
但它没有说命令未找到，因为aws在這裡已安装
我们来验证一下运行这个名为aws s three s three column的命令
斜杠itv-github
我正在尝试列出我们在另一边创建的桶
你可以说它正在尝试说无法找到凭据
你可以通过运行aws configure来配置凭据
我们可以使用这个名为aws configure的命令
然而在大多数情况下
如果你已经在使用aws
我们可能已经为产品特定的凭据配置了一些凭据
我们可能想创建一个单独的个人资料
让我们创建一个名为itv github的个人资料
并使用该个人资料配置我们的项目凭据
每当我们运行aws命令时
我们必须使用短划线短划线配置文件来使用特定的配置文件
我可以说aws configure
然后短划线短划线配置文件
然后输入配置文件的名称
那就是itv github
在我这种情况下 一旦你输入'Enter'，你可以使用你喜欢的任何名字
输入后它会提示你输入访问密钥
同样也需要输入秘密密钥
当我们实际创建用户时
我们下载了凭据
我们需要打开它，并且输入访问密钥以及秘密密钥
在我这个案例中，它下载在我的下载文件夹中
右键点击这个，打开方式
我想使用视觉工作室代码打开
所以我在这里使用工作室代码
让我保存为打开
然后让我复制粘贴这些东西，密钥就是这个
确保你复制了整个内容
然后按回车，按回车，按回车，现在AWS配置已经创建
配置会在你的家目录下的.aws/credentials
这是凭证文件的路径
你也可以打开这个
你可以实际说cat
然后复制并粘贴到这里
你应该能看到访问密钥和秘密密钥
在itv github配置文件下
现在我应该能够说aws s three - profile
配置文件名称就是itv github
它将使用这些凭据与s three进行交互
让我运行这个，看看我是否能够列出文件
由于该用户的权限受到限制
它显示访问被拒绝
我们必须明确指定存储桶名称
存储桶名称就是itv-
github 让我们看看它是否能够列出这个桶
现在 你可以看到桶中的文件夹并绘制
这意味着我们对这个桶有控制权限
使用cli 我们应该能够将文件添加到这个桶中
从这个桶中删除文件等等
这意味着我们不仅成功设置了s三桶
而且还设置了用户以及组
连同凭据
这样我们就能够程序化地与我们的s三进行交互
我们将使用相同的方法来授予越来越多的权限
随着我们进一步学习和了解更多与aws相关的服务 作为课程一部分的分析
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/045_Udemy - Data Engineering using AWS Data Analytics part1 p45 1. Getting Started with AWS Simple Storage aka S3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分 让我们获取一个S3的体积
S3代表简单存储服务
它是一种低成本的基于云的永久存储，可以从任何地方访问
基于权限
启动非常便宜
您可以实际访问aws管理控制台搜索S3
然后单击此
您也可以通过访问服务访问S3
作为服务之一
您有一个名为存储的类别在存储下
您有S3 您可以单击此以转到S3控制台，因为S3被广泛使用
如果您想要瞄准
您可以开始 让我回到服务这里
您应该能够单击此以启动
无论您是否经常访问
它将添加到您的收藏夹中
您应该能够通过单击此轻松访问
在任何时间
要么 您可以单击此
或者您可以在搜索栏中搜索S3，正如演示的那样
然后转到S3控制台
这是S3控制台
与S3主要组件无关的是桶
您需要创建桶
将与桶相关的权限
一旦您创建了桶并提供适当的权限
S3桶或S3桶中的对象可以从任何地方访问
它是基于云的
只要您连接到互联网
您应该能够访问桶或桶中的对象
任何想学习云的专业人士
特别是AWS应该熟悉S3
S3用于存储文件为对象
通常测试人员
生产支持指南
开发人员 Devops工程师
所有这些人都必须处理一些其他文件
他们可能想要上传到AWS
其中一个选项就是S3
与S3的一些关键概念有关
您需要了解如何创建S3桶
如何将文件从本地文件系统复制为必要的对象
如何处理必要的版本控制
这样即使我们意外删除文件
我们应该能够恢复那些文件在版本控制上
还有一些你应该熟悉的关键概念
除了跨地区复制用于灾难恢复之外，别无其他
还有各种存储类别，这些是取决于你的需求的低成本存储替代方案
例如 有三种标准和s三冰川
s三冰川更便宜
然而 存在一些限制，这些与标准存储相比并不存在
在某些场景中，你应该能够使用它们，以显著节省成本
因此，你需要对不同存储类别有更深入的理解，何时使用何种存储，等等
管理s三桶和对象版本控制
跨地区复制存储类别
以及许多其他概念都是相关的
作为IT专业人士，了解s三的详细信息
在了解控制台方面的知识后，让我们开始学习s三
让我们处理设置数据集的问题
然后我们将实际了解如何使用网页控制台和命令行管理s三桶和对象
以及进行版本控制，跨地区复制等任务 等等
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/046_Udemy - Data Engineering using AWS Data Analytics part1 p46 3. Setup Data Set locally to upload into AWS s3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们在本地系统上设置一个数据集
以便我们可以将我们本地系统的文件作为对象上传到S3上
您可以从这里克隆仓库
您可以点击这个
然后点击这个
这将您重定向到不同标签页的此页面
您可以滚动向下 您可以按照这些说明进行操作
您可以通过运行此命令来克隆仓库
然而 在运行这个命令之前
我会创建一个文件夹，通过说mk或连字符
P
数据 这就是我想要克隆仓库的位置
你可以在任何你喜欢的位置克隆仓库
你不需要遵循相同的结构，就像这里一样
然而 确保根据你的结构更新命令，避免任何拼写错误
一个常见的问题是拼写错误
一旦你开始有打字错误
它会抛出非常通用的颜色
并且在那里调试会很困难
确保你没有任何打字错误
当你更新命令时
让我复制粘贴这个
以便我可以通过名称克隆仓库零售在得分数据库中
在这个位置它会创建一个名为零售在得分数据库的文件夹
我们可以进入那个文件夹
然后我们可以运行lf和lt
如果你使用的是Linux或Mac系统
你应该能够列出文件和文件夹
这里有几个数据库文件
然后是如类别
客户
部门 订单项目
确保你下载这些文件
然后我们会使用它们将其复制到S3作为对象
一旦我们创建了桶
现在我们回到这里，以确保我们没有错过任何内容
您可以克隆仓库
然后它会创建一个名为返回分数的数据库
它将包含六个文件夹
您可以在这里看到所有六个文件夹
一个两个
三 四
五六 请确保您检查这些文件夹所在的位置
你可以说pw d
这就是这个文件夹的全局路径，我们在这个文件夹里有这些子文件夹
如果你使用的是windows
一些这些命令将不工作
你也可以使用windows文件资源管理器
你应该能够使用文件资源管理器看到文件，话虽如此
既然我们已经设置好了数据集
现在是时候为我们创建s三个数据库和数据库内的对象
创建对象意味着我们必须从我们的本地文件系统复制文件到s三个数据库
这些文件将被复制为s三个数据库内的对象 他们将被复制为s三个数据库内的对象
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/047_Udemy - Data Engineering using AWS Data Analytics part1 p47 5. Adding AWS S3 Buckets and Objects using AWS Web Console.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们详细探讨一下S3的三个桶、文件夹和对象。
我们将使用我们名字的首字母创建S3桶。
例如，我的是dg零售。
在S3中，桶名称必须全球唯一。 因此，我们将使用我们名字的首字母作为前缀。
我们将使用连字符作为前缀。 我们将使用我们名字的首字母作为前缀。
在这种情况下，区域无非就是我当前账户的默认设置
我正在用它来演示
除了这些 你不需要太担心其他任何细节
你可以点击创建存储桶
只要存储桶名称是唯一的并且遵循所有规则
你将能够创建存储桶
你现在可以通过说dg hyphen retail来搜索存储桶
然后你可以点击它
你可以通过点击创建文件夹手动创建文件夹
或者你可以使用上传上传文件或文件夹
在这种情况下我们将使用上传
我们将从我们的零售上传文件和文件夹
我们可以说上传这里
你可以点击添加文件
你可以实际上去我的家目录
让我实际上去macintosh
Hd users itv
这是我的家目录，下面
我有研究 然后数据
这是我在创建这个零售
Db文件夹的位置
这是用git clone创建的
它包含子文件夹
例如cardepartments
客户等
现在我想要在a dj hyphen retail存储桶下有类似的结构
为此原因 我首先取消
我实际上点击取消后退回去
我以零售 underscore db命名创建文件夹
如果我上传在codb
我将上传规模文件
我不想上传规模文件
我只想上传子文件夹
现在我可以滚动文件夹名称
不能包含正斜杠
如果你正在尝试创建文件夹
你只需在这里指定名称
它将负责添加正斜杠
在最后
它将负责为我们创建文件夹 ldb是文件夹
我们可以点击这个
现在 如果你点击上传
有多种方式可以上传
你可以作为上传的一部分添加文件
只要存储桶名称是唯一的并且遵循所有规则，你将能够创建存储桶
你可以添加文件夹
如果你看到它说
添加文件 这意味着你应该能够选择多个文件并根据文件夹添加文件
它说添加文件夹
这意味着你只能上传一个文件夹
你可以点击这个
你可以尝试选择多个文件
如果你点击添加文件夹，它正在工作
如果你尝试选择多个文件夹
它不起作用 你只能选择一个文件夹
一旦你选择文件或文件夹，添加文件的下面在文件夹中
它会在这里列出它们
你应该能够通过点击这里上传来处理上传
在这两个选项之上
你也可以拖放文件或文件夹
所以在这种情况下我可以拖放
我可以去我的查找器
让我前往并说前往文件夹
我要去我的主目录，然后我有一个名为研究的文件夹
然后数据
然后零售db
这是我克隆的git仓库的文件夹
你可以看到所有子文件夹
其中包含文件
你可以在这里查看文件
现在你应该能够选择这些文件夹
你可以多选
你可以看到我选择了所有文件夹
然后我们应该能够拖放这些文件夹
你可以看到这些文件夹
我们可以选择所有这些
然后我们可以说上传
现在文件夹和文件正在上传
让我们等到上传完成
然后我们会继续
仍在上传
这将花费一些时间
现在已上传
总大小只不过是9.1b
你可以点击这个
你应该能够看到这些所有子文件夹
这就是你应该能够随时上传多个文件夹的方式
如果你尝试使用添加文件夹选项
在这里你只能上传一个文件夹和文件
你应该能够上传多个文件
然而 你应该能够直接将多个文件夹或文件拖放到这里
来自你的本地文件系统
到目前为止，我们已经创建了桶
我们已经将文件作为对象添加到S3中
包括文件夹
现在让我们进入下一个主题
这就是版本控制
我们也使用了AWS Web控制台 稍后我们将看看如何使用CLI将文件作为对象添加到S3中
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/048_Udemy - Data Engineering using AWS Data Analytics part1 p48 7. Version Control of AWS S3 Objects or Files.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为前一个主题的一部分
我们成功地上传了文件和文件夹
现在将db分数返回并作为对象上传到S3
让我们处理启用S3桶的版本控制
并且定义生命周期规则，以便管理旧版本以启用监控
你必须在这个桶的属性中
版本控制只能在桶级别启用
让我们转到属性
你可以验证当前版本的版本控制是禁用的
现在您可以点击编辑
您应该能够选择这个
然后您可以点击保存更改以启用版本控制
然而 确保您阅读此消息
它说 在启用桶版本控制后
您可能需要更新生命周期规则以管理对象的旧版本
如果您不这样做
您将不必要地花费太多存储费用
您将不必要地向AWS支付费用
确保您定义生命周期规则以管理旧版本
现在我们可以点击保存更改
它将处理为我们启用版本控制
您可以在此处看到桶版本控制已启用
由于在桶上成功启用了版本控制
让我们理解它的目的
我们可能会删除对象
或意外地更新对象，版本控制将使我们能够使用先前版本恢复对象
即使在我们的应用程序中
可能会有一个错误导致对象被破坏
我们可以通过使用对象的先前版本或文件来修复curobjects
这是版本控制的主要目的
这主要是为了应对灾难
这可能是人为灾难
作为那些灾难的一部分
对象可能会被破坏或删除
我们应该能够使用先前版本从灾难中恢复
现在一旦版本控制已启用
我们可以转到管理并添加生命周期规则
让我们添加一个基本的生命周期规则以删除比三天更旧的先前版本
我们限制范围仅返回到score db文件夹
我们可以使用它作为前缀
我们应该能够管理所有返回score db的旧版本
在dj-hyphen-detail桶中
让我们转到S3管理控制台
你必须在这个桶的管理中
然后你可以在这里看到生命周期规则
到目前为止，没有生命周期规则
您可以单击此按钮或此按钮
并且您可以开始创建生命周期规则
生命周期规则的名称只是归档旧零售文件
让我们复制并粘贴到这里
下一部分是规则的范围
它可以是一个过滤器
或者它可以应用于桶中的所有对象
如果您想将规则应用于桶中的所有对象
您可以选择这个
您可以选择适当的生命周期规则操作
然后您可以在这里查看并点击创建以创建规则
然而，在这种情况下，要求仅对那些键应用规则
这些键具有前缀 retail_underscore db others
我们不想触摸这些
当我们限制规则的范围时，我们需要选择这个
使用一个或多个过滤器
您可以使用一个前缀定义一个规则，并使用对象标签定义一个规则
在这种情况下，我将只演示使用前缀
因为我们只对零售 db 版本感兴趣
我们可以在这里输入 retail_underscore db
如果您回到大零售桶这里
您可以看到有一个名为 score db 的文件夹
如果您点击这个
它有这些对象
这些对象什么也不是，文件夹
您可以点击这些对象
并转到文件夹中的每个对象
这是低级别的对象
S3 中的每个对象都称为键
每个键都有一个前缀
前缀是对象的开始部分
在这种情况下 由于所有子文件夹中的零售 db
以及子文件夹中的所有对象都有 retail db 为主文件夹
我们可以使用它作为前缀
以将规则应用于管理与零售 db 对象的所有先前版本
这就是为什么必须在这里添加 retail_underscore db 作为前缀
现在您可以滚动向下
我们不会添加任何过滤器作为生命周期规则操作的一部分
我们的要求是删除先前版本
我们必须选择这个
一旦您选择这个
您应该能够看到永久删除对象的先前版本
在这里我们输入 3
因为这是我们的要求
现在您可以滚动向下
您可以在这里查看 它说当前版本的操作我们不会对先前版本的操作做任何事情
如果对象在三天后变得不再当前
删除它们
所有 比我们旧的三天前版本的先前版本将被删除
正如我们所确保的那样，规则是根据我们的需求定义的
现在我们可以点击创建规则来实际创建规则
它将为我们创建规则
然而，我们将无法验证
因为我们必须等待三天，以确保之前的版本已被删除
因此将无法验证
但让我们了解版本是否被创建
我们已经启用了恶化，并且创建了规则
但我们没有验证之前的版本是否已创建
每当我们添加同名文件时
让我们验证那一部分将无法验证规则，话虽如此
我们可以在这里转到桶
这是桶 我们可以转到and score db文件夹，在这个文件夹中我们有orders文件夹
让我们为那创建同名文件
我们只需点击上传
然后我们可以说添加文件，我们已经在零售db文件夹中
我们可以选择此文件
然后说用于上传的工具
我们上传同名文件
现在我们应该能够说上传
它将负责上传文件
一旦完全上传
我们可以点击此并转到此处的文件夹
现在您可以看到只有这一个对象
这正是这个
如果您想查看此文件的前一个版本
您可以点击此现在您可以看到此文件的前一个版本
在这种情况下，我们上传了同名文件
您将无法看到与文件相关的任何信息
除了版本ID
您可以看到此处大小相同
这就是您应该能够验证版本是否被创建的方式
每当我们将同名文件上传到S3时
正如我们所确保的那样，规则是根据我们的需求定义的
现在我们已经成功地在S3桶级别启用了版本控制并创建了生命周期规则
让我们进入下一个主题 这就是跨区域复制
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/049_Udemy - Data Engineering using AWS Data Analytics part1 p49 9. AWS S3 Cross-Region Replication for fault tolerance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们来详细讨论跨区域复制S3桶的细节
或者S3桶内的对象
在某些极端情况下
由于不可预见的情况，S3可能无法在某个特定区域可见
这可能会影响该区域内的数据中心和可用区
通过启用跨区域复制
我们可以有一个S3桶或桶内对象的副本
在某个其他区域
让我们启用我们的桶跨区域复制
这就是DG-RETAIL
我们必须转到控制台
我们可以实际上在名为DJ-RETAIL-COPY的区域创建另一个桶
让我复制这个
让我转到这里
你可以说在创建桶之前创建桶
让我检查DJ-RETAIL的区域
你可以看到它创建在US East下
这就是US-1-1
当我创建新桶时
我们必须在另一个区域创建桶
在这种情况下，我将在俄亥俄区域创建
让我选择俄亥俄
然后说真相桶
它将负责在俄亥俄区域创建桶
对不起 我不应该选择
选择桶那里
我必须点击 取消以返回
而不是选择真相桶
在这里输入区域后
我必须滚动并说创建桶以创建桶
现在桶正在创建
你可以看到有两个桶
DJ-RETAIL和DJ-RETAIL-COPY
DJ-RETAIL创建在USC East 1下
DJ-RETAIL COPY创建在US East 2下
这是不同的区域，因为我们已成功在此区域创建了这个桶
让我们转到内容并遵循这里的指示
下一步是创建一个名为
AWS S3 全访问角色
你可以给任意名称
但我将使用这个名称
我们必须将此策略附加到此角色
你将在某个时间点理解我们做这个的原因
我们必须去 我是控制台
你可以搜索
我在这里 点击
我在这里 然后你应该能够进入
我是仪表板 或者我在这里控制台
你可以实际上点击角色
说创建所有
我们必须为s三创建角色
因此让我们这样做 s三在这里
让我们选择这个
然后说下一个权限
说到权限
我们希望给s三全权
因此我们必须抛出这个
我刚搜索了s三的策略
你可以看到 有一个名为
亚马逊s三全权限 作为搜索结果之一
我们必须选择这个
然后说下一个标签
下一个审查
你可以给角色起名
名字就是这个
让我们复制粘贴这里
它将为我们创建角色
你会明白我们为什么创建这个角色
因为角色已成功创建
让我们去桶
dj has fun detail和配置此复制规则
我必须去s三这里
点击这个
一旦我们在s三控制台
我们可以搜索dg hyphen retail
这是源桶，我们希望定义复制规则
我们可以点击这个
我们可以去管理
如果你滚动
你可以在这里看到复制规则部分
目前没有复制规则要创建新的复制规则
你可以点击这个或者点击这个
让我们点击这个并去这个页面作为名称
让我们输入名称retail replication
我们必须粘贴这里
我们需要确保这已启用
源桶就是dj iphone retail
这是被自动为我们选择的
我们希望使用范围，通过一个或多个过滤器
我们将使用前缀来定义过滤器
前缀必须在score db中写入
因为我们希望对所有与retail db文件夹相关的对象在后端进行备份
这是dj-零售文件夹的一部分
现在我们可以实际将桶名作为目标的一部分输入
它只是dj-零售-副本
它不是零售-db-副本
它是dj-零售-副本
让我看看
它是加粗的 让我复制并滚动到这里
我们必须输入桶名
我们得说好
三斜杠斜杠然后桶名
你也可以通过点击这个来浏览
并搜索dj-零售-副本
你可以选择这个，然后说选择路径，这就是我输入的
所以它起作用
即使我们直接像这样输入
现在复制请求的目的是使目标桶可用
所以在目标处
我们必须确保复制是启用的
我们可以点击这个
以启用桶复制
一旦复制启用
我们必须在这里定义iam角色
那个iam角色 应该对试图写入的s3桶具有写权限
也应该对从哪个我们正在尝试读取的s3桶具有读权限
在dj-零售
角色应该对dj-零售-副本具有读权限
角色应该具有写权限
然而，我们之前创建了一个具有完全访问权限的角色
我们可以选择那个角色
角色名称是
但是，这个aws s3完全访问角色，我们之前创建过
我们可以选择那个
然后滚动
让我们看看是否需要选择其他选项
我们已经确保在目标处复制是启用的
我们选择了这个角色
就这样 我们不需要太担心其他事情
我们可以滚动
我们可以点击保存，以确保复制规则现在已定义
如果你在dj-零售对象上做了任何更改
这些将在dj-零售-副本上复制
现有的不会复制
在dg下划线详细信息中
我们有零售和score_db文件夹
它包含所有这些六个文件夹
然后你可以看到每个文件夹中都有文件
然而，现在如果你去dg下划线-hyphen复制，你将不会看到任何东西
只有新的更改才会被复制
源中现有的将被忽略
现在 如果我回到dj
有fun详细信息 如果我在这里点击订单
如果我删除这个
我现在已经删除它
让我点击这个
让我重新上传文件
通过点击上传
然后说添加文件
我在订单文件夹中
所以我应该能够选择这个文件进行上传
现在 我们可以说上传文件正在上传
一旦文件上传
我们应该能够去s3的主控制台
我们应该能够选择dg下划线-hyphen复制
它什么也不是，你将在片刻内看到文件
让我们等几分钟
你应该能看到文件
你可以看到文件夹
零售db在这里你可以点击这个
你可以看到订单文件夹
你可以看到对象在这里
如果你删除一切 如果你再次上传
所有这些都将在这里反映出来
如果你想你可以尝试
让我们去dg下划线详细信息
你可以只是删除中心文件夹
让我实际上只删除子文件夹
让我选择所有这些东西
让我删除
让我說
删除这里现在
当你删除删除操作将不会复制
即使你去dj下划线零售下划线复制
去零售db订单
文件现在将保持完整
让我们关闭这个现在
让我们点击上传和
让我们说拖放我们之前选择的所有六个文件夹
我们希望将这些文件夹中的所有文件复制到s3
我们去这里点击上传现在
所有文件正在上传
让我们等到所有文件上传完成
然后我们将实际前往目的地
那就是详细信息，你是否有副本和审查
文件是否复制
我们的对象是否复制
现在我们可以说关闭
点击亚马逊s3这里
转到g_零售_副本
点击零售_db
到目前为止它们还没有复制
让我们等到所有文件在这里复制完成
到目前为止有四个文件夹已经复制
五个那里应该有一个更多现在
所有六个都已经复制
如果你去订单文件夹
如果你查看文件
那里只有一个文件
如果你遵循事件发生的顺序
我们首先删除了订单中的文件
我们上传了它
我们确认它已复制到目标
然后我们删除了一切
并且我们上传了所有文件
即使这样所有文件都已复制到这里
或者所有对象都已复制到这里现在
如果你点击这里的选项列表
因为我们有两个文件
你可以看到两个版本在这里
这就是为什么它要求我们在目标桶上启用我们
因为它将维护所有正在复制的版本
我们必须确保删除已启用
这就是如何在s3桶上设置跨区域复制的方式
它将为我们提供s3桶上的高可用性
即使一个区域下线，使用第二个区域
我们的应用程序将没有任何问题运行
这也对负载均衡和其他关键方面有用
与高度可用和可扩展的应用程序有关
现在不用担心所有事情
只需确保跨区域复制是一个功能
它将使我们复制被上传为对象的文件
从源桶到
目标桶在 区域
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/050_Udemy - Data Engineering using AWS Data Analytics part1 p50 11. Overview of AWS S3 Storage Classes or Storage Tiers.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们回顾一下必要的不同存储类
你可以实际使用这个链接
你应该能够回顾这些事情
嗯 你可以回顾存储类
以及性能图表，以获得有关所有存储类的详细理解
这些是在say中支持的存储类
它们只不过是s3标准智能拆分标准，A1在冰川上，深档案前哨站
冰川深档案前哨站
你也可以点击这个性能图表
以了解这些t s三之间的比较，标准是最贵的
典型的冰川和冰川深档案
用于s三中文件不频繁访问
并且它比三标准便宜得多，以获取定价详情
你可以点击这个与标准有关
到50太字节，你必须支付这么多
从50太字节加到500太字节
你必须支付这么多超过500太字节
你必须按每gb支付这么多
这意味着每太字节
成本就是这个的千倍
这意味着每太比特23美元
高达50太字节，那是月费
那不是年费，话虽如此
当你降到其他存储类别
成本将会开始下降
如果你选择S3标准，不经常访问的存储
一个区域的成本是这么多
这比那更便宜
如果你向下滚动
如果你去冰川
你可以看到每太字节
只有4美元
因为它主要是为了不经常访问
它主要用于长期备份和归档
而不是那些应该立即可用的文件
如果你去性能图表和存储类别
你应该能看到这里的详细信息
第一咬合延迟以毫秒计相对于s三标准
但是如果你去冰川
在冰川深处，可能需要几分钟或几小时
这通常是我们
因此，我们需要一些时间来从s3冰川读取文件
或者s3冰川深度归档
它们主要用于备份和归档
不适合实时使用，尽管如此
在上传文件时，我们可以更改存储类别
可以通过管理控制台或aws cli命令进行操作
让我使用aws web控制台来演示
实际上你可以访问aws web控制台
然后在那里搜索s three并进入s three控制台
你可以选择一个存储桶
我将选择dg-hyphen零售
假设我想上传文件作为上传文件的一部分
我应该能够选择存储类别
如果我去附加上传选项
你会看到存储类别
你可以选择这些存储类别之一
你应该能够应用这些存储类别
文件上传时，眼镜放在文件之上
如果你想编辑现有文件，将此更改为类
你也可以处理这一点
你只需选择文件夹或对象
然后说操作在这里向下移动一点
你有一个选项 一个类在这里
你可以点击这个 然后你应该能够将此更改为类
你可以选择冰川或其他存储类
根据您的要求
您可以默认为现有对象更改存储类别
存储类别是标准
您可以更改为其他任何存储类别
您应该熟悉根据您的要求应该使用哪种类型的存储类别
我们可以将存储类别作为复制规则的一部分进行配置
当您使用复制进行低成本备份时，这也是有用的
您可以点击复制规则的编辑
让我们转到管理控制台
让我们点击这个
我们去管理那里
我们去复制规则部分
我们选择这个
然后说编辑规则
如果你往下滚动
你有目的地商店类别
你可以实际上选择这个
你可以更改目的地到类别到你想要的商店类别
在这种情况下 如果你使用复制备份文件将很少被访问
实际上你可以选择冰川存储或冰川深存
然后你应该能够点击
保存存储类别，对于那些正在复制到该位置的文件
根据这个规则，将被更改为冰川存储
在这种情况下，我们也可以将此配置为生命周期的一部分
我们可以更新我们之前创建的生命周期规则
并更改非当前版本的存储类别为冰川，零天
我们仍然可以删除三天后的世界版本
使用现有规则
让我们在这里看看 我们去桶里
我们去管理
选择这个并点击编辑
现在我们可以在同一个生命周期规则中拥有多种类型的规则
如果我向下滚动
你可以在这里选择不同的选择
你可以将对象之前的版本在不同的存储类别之间转换
这样之前的版本现在可以在低成本的存储中管理
我可以选择这作为存储类别的一部分
我在这里会选择冰川
我们可以实际上选择在多少天后存储类别应该为旧版本更改
在这种情况下我会说零
所以他们立即更改为旧版本
我们将更改此为类别
我们应该能够向下滚动
在这里你可以查看非当前版本的先前版本
他们将切换到冰川
在三天后立即
他们将被永久删除
现在你可以在这里保存
我们必须承认
然后我们可以点击
保存以保存 这就是你如何使用不同存储类别定义生命周期规则
这就是所有关于存储类别
你应该熟悉所有存储类别
还有如何配置低成本存储类别
在定义复制规则或生命周期规则时
取决于你的需求
你应该能够设置存储类别
并应用到正在存储在s three中的对象相关的存储类别
否则你将支付太多的钱给aws
这不是一个好做法
确保你对所有的s three存储类别都非常熟悉 并根据你的需求使用适当的存储类别
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/051_Udemy - Data Engineering using AWS Data Analytics part1 p51 13. Overview of Glacier in AWS s3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们详细探讨一下本地玩具的成本，这些玩具被称为冰川，在三个方面
如果你回顾所有商店的课程
我们有这些玩具，就像标准一样
在冰川和冰川深处，我们有这些智能标准
在标准或冰川深处之后，最重要的玩具
任何项目中最常见的要求之一就是备份文件
我们不会经常为那些场景请求那些文件
如果我们选择冰川或冰川深处
与标准相比，成本会便宜得多
让我们理解标准和冰川在定价方面的差异
你可以在这里查看定价
你可以访问50TB以内的每TB成本
与标准相比，每月成本为23美元
然而 如果你选择冰川
它只有4美元
在这里，你可以看到冰川的深度存档
它低于1美元
它只有每TB 99美分
使用冰川或冰川深度存档要便宜得多
与标准相比
在sls方面
如果你去商店
在这里，去性能图表
你可以比较标准和冰川以及冰川深度存档
与标准相比
当你尝试从s three读取文件时，第一口延迟以毫秒为单位
然而 与冰川相比
它要么是分钟，要么是小时
与dev相比
它总是us 这就是为什么这些比s three便宜得多
这些通常只用于备份
现在 让我们回到材料
冰川是s three的低成本存储
我们可以使用冰川来管理水或备份副本
以下是我们可以将存储类设置为冰川的最常见方式
你可以编辑对象或文件夹
以使用冰川 你可以实际上去管理控制台
你可以去你的桶
选择文件夹或对象
在这种情况下，我去订单
我们可以选择这个对象
我们可以实际上去操作
我们可以说编辑存储类
我们应该能够选择冰川或冰川深度存档
实际上将此类设置为此对象的存储类
正如我们之前看到的
我们应该能够到达桶
到达管理
你可以到达生命周期规则或复制规则
让我们选择生命周期规则
点击编辑 如果你想保持旧版本作为冰川的一部分在删除之前
你应该能够选择存储类作为转换的一部分
类似于这个 你也可以作为复制规则的一部分设置
你可以去管理并复制
如果你点击编辑规则作为本部分的一部分
我们在目的地有类别
我们应该能够选择这个来改变这个到我们的类别为复制的对象
我们应该能够选择像这样的冰川
我们已经作为前一个主题的一部分看到
因此我在这里不会深入太多细节
这些都是最常见的方式，我们可以实际设置存储类别
至于冰川或冰川深档案
与桶或桶内的对象有关
冰川比S3便宜得多
它通常用于我们文件的备份
文件不经常读取 读取那些文件的时间不是毫秒
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/052_Udemy - Data Engineering using AWS Data Analytics part1 p52 15. Managing AWS S3 buckets and objects using AWS CLI.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分 让我们了解如何使用命令行界面管理S3
我们有一个名为s3的子命令，位于aws命令下
我们应该能够使用它来实际管理与S3相关的所有方面
您可以使用aws s3命令获取帮助
您可以获取有关aws s3命令的完整文档 您可以进入隧道
然后您可以说aws s3 help
您可以获取有关S3命令的完整文档
您可以按空格键滚动
您可以了解每个命令的详细信息
它们如何用于结束所有
您可以按空格键进一步滚动到底部
您将获得一个支持命令的列表
我们有cp a b和v
我不确定关于prune的情况
我将使用rm sync
website通常用于当我们在实际上在S3上托管网站时
我们通常不使用它与文件管理
一旦您完成
如果您想退出
您可以说colon q并将能够退出
这就是您应该能够获取有关aws s3命令帮助的方式
让我们回顾一些S3中的重要命令
如果您想列出对象和文件夹
我们可以使用ls
让我也给您简要演示一下
我可以说aws s3
在这种情况下 我想获取有关dg-hyphen-retail的详细信息
指定协议不是强制性的
您可以直接说did you have fun detail
对于某些命令
它是强制性的
现在您可以按回车键
您应该能够看到此桶中的所有文件夹
目前我们只有retail db文件夹
如果您想获取此桶中的所有对象
递归地 您应该能够说hyphen hyphen recursive
您应该能够获取所有文件夹和对象递归地
如果您想获取有关命令的完整文档
您可以说aws s3 help
您应该能够获取帮助命令
您可以使用的控制参数来控制运行时行为是递归
页面大小 人类可读的总结和如此等等
根据您的需求
您应该能够解析这些并开始使用它们
我已经展示了递归的
总结是获取文件总大小
例如 在这种情况下
我可以说总结
让我实际上使用这个，我不知道为什么它没有工作
让我退出这个
让我按Ctrl + C
让我按上箭头
让我输入
一些第一 让我运行没有总结
它只显示名称
这什么也没有
现在 db
让我输入
总结
让我们看看它说什么
你可以看到 它提供了关于总对象和总大小的额外信息
不知道为什么它显示为零
我不确定
让我们深入研究
让我实际上说dg零售
然后返回代码db然后按Enter
让我们看看它说什么
你看它说总对象为1
总大小为零
因为它是文件夹 我认为它说为零
否则它将说文件的大小
让我输入递归
让我们看看输出
现在你可以看到所有文件的总大小
由于递归命令
它汇总了所有这些
它给出了文件的总大小
如果你想以人类可读的格式获取此信息
你应该能够使用人类可读
在递归和总结之上
我可以说人类可读
你应该能够以人类可读的格式看到信息
尤其是关于这个总大小
以前以空白给出
现在以兆字节给出
这更易于阅读，其他重要评论什么也不是
cpu将用于复制文件
在接下来的主题中，我们将使用CPU
因此，我在这里不会覆盖这一点
我们可以使用cp将本地文件系统上的文件复制到S3
S3到本地文件系统以及S3到S3
只要你在对象中指定了S3，I
这意味着它将尝试访问
否则，它将尝试访问本地文件系统
当我们演示使用cp作为接下来的主题时，我们使用cp命令
你将理解我说的话
Mv主要用于移动对象
从本地文件系统到S3或S3到本地文件系统或S3到S3
如果你想获取帮助
你可以说aws s3 mv help并按回车
你可以看到可以移动文件
从本地路径到S3或S3到本地路径或S3到S3
这些是额外的控制选项
可以用来控制mv命令的运行时行为
让我按q退出
下一个命令是rm
Rm主要用于删除S3中的对象或文件夹
你可以通过说aws s3 rm help来获取帮助 如果你看语法
它说你只需说aws s3 rm并指定S3
它将负责删除该位置的对象
你也可以传递文件夹并说-h
递归以删除文件夹中的所有文件和文件夹
在传递的S3中也可以 你应该能够通过包括和排除来选择并删除特定文件
如果你有这样的场景
你只需探索
包括和排除
你必须理解如何传递模式
你应该能够只删除所需的文件 如果需要
我们将在后续时间探索这些选项，目前
这对你继续前进已经足够了
因为我们已经理解了aws s3 rm命令的语法和语义
让我们谈谈b和rb命令
B主要用于创建桶
Rb主要用于删除桶
如果你想获取b命令的帮助
你可以说aws s3 b help
你应该能够说aws s3 b并指定S3
它将为你创建桶
桶名必须在S3中全球唯一
这不仅与你的账户有关
而且对所有全球S3用户来说也是唯一的
桶名必须在S3中全球唯一
这不仅与你的账户有关
而且对所有全球S3用户来说也是唯一的
你也可以通过按空格键查看更多信息，包括b和桶名
你还需要指定区域
如果你想在一个特定的区域创建桶
除此之外 没有其他选项了
如果你去rb
如果你查看帮助
我会删除一个空的s three桶
如果你已经在s three桶中有文件或对象
那么你将无法删除它
默认情况下 你使用短划线
短划线force用于删除桶中的非持久对象
在删除桶之前
所以你必须使用短划线短划线force
如果你想强制删除桶
关于rb命令，rb主要用于删除桶
我们已经理解了s three的所有重要子命令
让我们进入下一个主题
我们将使用cli匹配s three中的对象
这是一个实践任务
确保你尽可能多地跟随和练习 这样你就可以舒适地使用cli匹配f three
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/053_Udemy - Data Engineering using AWS Data Analytics part1 p53 17. Managing Objects in AWS S3 using AWS CLI - Lab.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为前一个主题的一部分
我们已经理解了与三相关的所有重要子命令
现在 让我们进行以下任务，以确保我们对使用cla管理对象感到舒适
我强烈建议你在这里暂停
仔细研究这些任务
自己写出注释
如果你无法写出注释
那么你可以回顾视频的其余部分
使用与你相关的命令并继续前进
但在这之前，你先尝试不看视频的其余部分
第一个任务是列出早先创建的dg hyphen retail桶中的目录
建议递归列出对象
以查看完整的对象 首先列出dg hyphen detail，然后列出detail下的子目录
然后列出子目录下一级目录下的子目录
你应该能够递归地获取所有数据
让我在这里开始写注释
我可以通过说aws s three来递归列出文件
除非桶名是dg hyphen retail，否则不需要指定s three
通常使用aws s three列出s three中的文件
但对于一些命令，必须使用s three
但对于大多数命令，不需要使用s three
我可以说hyphen hyphen recursive
这将实际列出此桶下的所有目录和文件
你应该能在短时间内看到详细信息
你现在可以看到所有子目录和文件
下一个任务是从早先创建的dg hyphen retail桶中删除零售db主目录下的目录
即从dg hyphen retail桶中的零售db目录
我们要删除该目录下的所有子目录
你可以查看dg hyphen retail下的零售db目录的详细信息
如果你说aws s three rm dg hyphen retail/retail_db/*，则将递归删除所有子目录
如果你说aws s three rm dg hyphen retail/retail_db/，则将删除零售db目录及其内容
它将会删除零售db文件夹
如果你没有弄错确保代码db文件夹不会被删除
可能你现在可能需要使用包括和排除
让我们试试看如果零售和得分db文件夹也会被删除
它说无效的参数类型
在这种情况下它要求我们使用s三个数组
因此对于它不是必须使用s三
但是使用rm是必须的
因此我必须说s三列
Dj有乐趣零售零售下划线db递归
我想它会删除零售db文件夹
如果它被删除
然后可能最好分开每个文件夹
让我们也看看
我们可以使用包括和排除
我们可以尝试不删除零售db
但是删除所有子文件夹
但是如果你只使用星
现在不会起作用
你可以看到甚至零售db现在也被删除
我们会继续 因为这是被删除的
我们应该能够去aws web控制台并查看
接下来的任务是去这个web控制台
并确认文件夹和零售db文件夹内的对象在dg
零售桶被删除
然而，我们的零售和db文件夹也被删除
你可以通过去dji下划线详情桶这里查看
让我们刷新这个
你可以看到这里没子文件夹
因为文件夹零售db被删除
如果你想要创建文件夹
你不能使用像mk这样的指令在s三中创建文件夹
例如 如果你尝试说aws s三mk d r s三列
斜杠斜杠dg下划线零售
然后零售下划线db
它会失败 没有像这样的命令
你可以实际上通过复制文件作为对象来创建文件夹
通过指定uri本身
让我们说我们想要复制部门文件夹
连同文件作为对象在必要的部门在我家目录中
然后数据然后零售db
然后我们有部门
让我们说我想将此复制到s三
我可以说aws s三cp
这是我本地路径相对于部门
我可以说研究数据零售db部门像这样
然后我应该能够说s三列斜杠
斜杠零售零售和得分db
然后斜杠并按回车
它会处理将部门文件夹复制到ui
让我们等到这被运行
你可以看到它失败了
因为它是目录
你可以通过使用递归来复制目录
如果我说递归像这样
现在这应该能工作
它已上传 你应该能通过说aws s three验证
让我们运行这个 然后说斜杠斜杠递归
好的 来自部门的文件已复制到零售db直接
这不正确
所以我必须清理这个
一旦它被删除，我必须删除
我必须像这样运行命令
我必须指定部门
我必须说斜杠在最后
否则文件部分-5个零将被保存为部门
为了避免这种情况
并将此文件添加到此文件夹中
部门在三中
我必须在最后使用斜杠
现在我们可以按回车
它将处理以此文件名创建文件
S three零售dp部门
然后部分-5个零
你可以在这里看到这样
你应该能够复制所有文件夹
我们已经处理了部门方面
现在你可以处理两个类别方面
在这里我们也必须更改
这将涉及大量复制类别文件夹
以及文件作为对象
对象名将是零售零售db类别-5个零
下一个是产品
让我们将此更改为产品
在这里我们也需要更改
现在研究数据
Db 本地文件系统中的产品将作为此密钥在s three或对象中复制
因为与产品相关的文件也已被复制
现在我们应该能够复制订单
在这里我也需要指定订单
一旦订单也被复制
我们应该能够复制所有项目
然后客户让我们等到这完成
然后我们将实际处理 ms 以及客户订购的算法，这是一个稍大的算法
因此它将需要一些时间
Hover 将等待直到我们的 ms 也被复制
然后我们将转到客户这里
我们正在谈论 orators
一旦我们的项目被复制
我们将复制客户的数据集
让我们等待直到它被复制
现在 我们应该能够在这里说客户
一旦它被更改
我们可以实际在这里更改
现在您可以按 Enter 这将处理从该位置复制文件到 s three 作为对象
一旦这完成 我们应该能够运行一个 s three 命令以递归列出文件像这样
我们可以说 s three 和 less dg 减去
零售 减去 减去 递归
它将处理列出所有文件夹和那些文件夹中的对象
您也可以访问 aws 控制台作为这部分的 web 控制台
您也应该能够访问 a retail dv 文件夹
您可以在这里看到所有子文件夹
您也可以访问这些子文件夹之一并查看这些文件夹中的对象
这就是您应该能够管理 s three 中的对象的方式
使用 cli 将有关将文件作为对象复制到 s three
如果您想排除某些文件
您应该能够使用包含和排除的组合
您实际上可以复制所有文件夹
在我们的情况下 我们遵循了一个繁琐的过程，我们分别复制了每个文件夹
但使用包含和排除
我们应该能够一起复制它们
让我们也看看如何使用单个命令复制所有六个文件夹
如果您去研究数据
零售 下划线
Db
您可以看到它不仅有子文件夹
例如类别 客户
部门或项目
订单和产品 它还有一些文件
以及一个 readme 点 md 文件
我们不想复制那些文件
但我们想复制其余的文件夹
因为我们是从 github 克隆的
我们可能会有一些隐藏文件
我已经删除了一个名为.git 的文件夹
叫做 us 但是，我们还是有一些隐藏的文件
例如，dot ds underscore store
你可能还会看到dot get
我们可以删除这些隐藏的文件夹
这些文件不再需要了
因为我们只需要克隆一次仓库并开始使用它
我们应该能够说
我是hyphen rf
如果你想删除dot get
如果它存在 将被删除
我们也可以删除这个点并将所有内容打分
如果它在那里
我不确定你是否能看到这些
啊，这些文件在你的系统中
这可能是因为我正在使用mac
这个文件被创建
你可能看不到这个文件
如果你看到这些隐藏文件
确保你通过说rm dot ds underscore store像这样删除
它将现在处理删除那个文件
我们应该能够通过说siphon alt现在来验证
让我说cd去家目录
然后说aws s three cp
这个文件夹的位置就是
研究数据零售_db
然后s three column斜杠
Dg 连字符 零售零售和滚动数据库
我想将此位置的所有子文件夹复制到此位置的s三中
我们必须使用破折号
连字递归
我们可以说破折号
连字符排除
然后我们可以说星星点灯
我们可以像这样有多个排除项
我们也可以说让我实际上删除这个
并且通过逐行递归断行使用额外的行
然后排除点续集
然后排除
现在阅读我点md
它应该能够复制这个位置的文件夹
到s三这个位置
然而 我们已经有了子文件夹返回得分db
让我们来这里然后删除那个文件夹
我只是选择这个文件夹并说删除
我们只需要说删除这里
它将处理删除零售和could db文件夹，以及其中的所有子文件夹
现在我们应该能够点击这个
你应该不会在这个桶中看到任何东西
这个桶现在是空的
我可以回到这里
我可以按回车键运行这个命令
它将处理从这个位置复制所有子文件夹
到s三中的这个位置
它将在dg下创建四个冒号score db
有一个尾桶在那
它会创建一些文件夹
例如部门 客户等
所有文件都将作为对象上传到子文件夹中
现在我们应该能够去是的
三台控制台 我们应该能够刷新这个
我们可以实际上点击这个
我们应该能够看到所有六个子文件夹
我们也可以点击这个
应该能看到这个子目录中的对象
这就是你应该如何使用一个命令
来复制我们感兴趣的文件
我们只复制了零售和score db下的文件夹
同时排除所有sql文件以及md文件
确保你对这些事情感到舒适
这样你就可以更有效地使用s three来管理对象
我们遵循了一个繁琐的过程，我们一次复制一个文件夹
现在我们已经看到了如何使用
排除 有时候甚至包括以确保文件按我们的期望复制 使用最少的命令
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/054_Udemy - Data Engineering using AWS Data Analytics part1 p54 1. Creating AWS IAM Users with Programmatic and Web Console Access.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解如何创建用户
我可以在这里搜索
或者如果它是最近访问服务的一部分
你应该能够点击这个
或者你也可以扩展所有服务
你应该能够转到安全
身份和合规性
你应该能够点击
我进去控制台
一旦你在控制台
你应该能够访问到用户
点击 添加用户来添加用户
你应该能够提供用户名
让我们假设itv had been是账户的名称
当涉及到访问类型时
它可以是程序化访问或管理控制台访问
管理控制台无非就是console.aws.amazon.com
这是我们正在使用的网站
目前 用户将能够使用密码访问管理控制台
如果你去查看关于程序化访问的详细信息
它为aws提供了访问密钥和秘密访问密钥
API CLI
SDK和其他开发工具
我们通常使用它来让我们的计算机与aws交互
并使用CLI进行管理
我们也使用它来在外部部署应用程序以管理aws资源
当你真正进入实际开发努力时，你会理解这些
目前 这是为了实际访问aws而必需的
CLI 让我们选择风险管理控制台访问
这样iv管理员就可以登录到aws控制台
amazon.com实际上管理aws中的资源，话虽如此
说到密码 它可以是自动生成密码或自定义密码
在这种情况下我选择自动生成密码
它会为我们生成一个密码
我们应该能够看到一旦用户被创建
如果你选择这个
用户必须在下次登录时创建一个新的密码
如果你不这样做
用户不需要这样做
我会选择这个，这样用户就可以重置密码
当他实际上第一次登录到这个账户时
用户会自动获得更改密码的政策，以便他们可以更改自己的密码
如果你选择这个，也就是说
让我们点击下一步权限
当谈到权限时
你可以将用户添加到组中
或者你可以复制现有用户的权限
或者你可以直接附加现有的策略
所以这是三种不同的方式，您可以将权限附加到用户
最常见的方式是将用户添加到组中
但现在我们还没有涵盖组
因此我不会使用这种方式
我将使用直接附加现有策略
策略只不过是与它相关联的一组权限
一旦您附加了该策略
与该策略相关联的权限将继承给该用户
例如 如果我选择管理员访问权
如果我展开它
您可以看到它为aws服务和资源提供了全权访问
因此用户admin将能够访问aws中的所有内容
无论是通过登录管理控制台还是使用命令行
这是对所有aws服务的全权访问
您可以查看详细信息
Cl 因此用户
Itv admin将继承对所有275项服务的全权访问权，话虽如此
您可以通过点击此按钮折叠此内容
如果您给予 您就不需要再给予任何其他策略
它将会正确
您将获得所有权限
因此我只选择了这个
如果您想要 您可以选择多个策略
例如 如果您只想给e c全权访问权
Two three 您可以搜索e c
那里有一个amazon
e c全权访问权
一旦您选择了这个
如果您想给s three权限
也可以使用全权访问权
然后您可以搜索s three
您应该能够通过选择这个来提供对s three的全权访问
您实际上可以处理向用户添加策略
到目前为止，我已经选择了e c two和s three
但我想给予全权访问权
因此我只选择了这个
然后您可以去审查
您可以暂时忽略税
您可以去查看
你看，它已经附加了管理员访问权限
有三种全权访问，并且容易全权访问
因为这种冗余
我想清理它
我可以回到这里
我可以搜索EC two并取消选择
是的 取消选择
然后我可以去到下一个选项
然后审查
你看 我们只有管理员访问权限
我正在使用更改密码策略来更改此用户
这是因为用户应该能够更改他的
嗯，一个密码
这就是为什么我们需要附加此策略
我不确定这是否会被提供
如果我们使用管理员访问权限本身，那就安全了
我现在留下这个
我应该能够创建用户
一旦你点击创建用户
它将负责创建用户
并将提供访问密钥和秘密
访问密钥用于程序化访问，密码用于Web控制台访问
如果你点击下载CSV
它将下载凭据为CSV文件
你应该能够展开此内容
在这里打开文本编辑
你应该能够看到用户名
密码，访问密钥和秘密密钥
这就是你应该能够生成用户凭据并使用它们的方式
无论是用于程序化访问还是管理控制台访问
你也可以通过点击此发送详细信息到电子邮件
然而，它将打开邮件应用程序
然后你应该能够发送电子邮件，目前
我没有发送电子邮件
你可以忽略这一点
你可以使用下载的CSV文件实际登录，话说回来
现在我们应该能够关闭此内容
用户已创建
用户有两个脉冲附加
一个是管理员全权访问
第二个是
我是用户管理策略访问或什么的
我不记得策略名称
如果你想要审查 你可以点击这个
你可以实际上去权限这里
你应该能够看到附加到此用户的脉冲
任何时间点
如果你想更改密码
或者如果你想为程序化访问生成访问密钥和秘密密钥
你可以去安全凭证
你应该能够管理访问密钥以及秘密密钥
点击这里 你可以使以前的密钥失效
点击失效
或者点击这里
你可以甚至删除
我认为你可以在这里生成密码
让我们看看
是的 你可以在这里生成密码
点击管理
你应该能够重置密码
这就是你如何开始创建用户的方式
确保你对此感到舒适 至少目前是为了学习目的
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/055_Udemy - Data Engineering using AWS Data Analytics part1 p55 3. Logging into AWS Management Console using AWS IAM User.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为前一个主题的一部分
我们创建了一个名为itv admin的用户
具有程序化访问以及管理控制台访问
让我们了解如何使用这个用户进行登录
使用管理控制台
我正在打开一个私人窗口
然后我说aws amazon dot com
然后我说我的账户
Aws管理控制台
在这种情况下，我们试图使用iam用户进行登录
我们必须选择这个 然而
一旦你选择了这个 它会要求你输入账户
因为我没有选择作为电子邮件发送
用户可能不熟悉账户ID
在这种情况下 它已经被
你应该提供与账户ID相关的信息
你可以通过转到用户创建的其他页面来获取账户ID
你可以点击仪表板
你可以在这里看到URL
这就是账户ID
你可以实际复制这个URL
并用这个URL进一步登录
使用iam用户 你可以将此链接与您创建的用户共享
然后他可以通过将链接粘贴到浏览器中访问该页面
您可以看到账户ID已自动填充
用户名实际上就是itv admin
密码实际上下载到CSV文件中
所以我必须打开CSV文件
我可以去查找器
去下载
你可以在这里看到CSV文件
你可以打开这个CSV文件以获取凭据
这就是你可以使用的密码
让我复制这个
然后到这里粘贴
然后说登录当我们实际上创建了用户
我们设置了一个策略
说用户应该在第一次登录时重置密码
这就是为什么显示此页面
现在 您可以输入世界密码
从CSV中复制并选择您熟悉的新密码
然后您应该能够点击确认更改密码
现在你能够登录到aws管理控制台
你应该能够访问iam页面这里
让我们去安全
然后点击 我是
你应该能看到用户
目前只有一个用户
那就是itv管理员
你应该能点击这个
你可以看到用户有管理员权限
这意味着用户应该能够管理这个aws账户的所有资源
因为我们已成功使用管理控制台登录 让我们了解如何将aws cli也配置好
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/056_Udemy - Data Engineering using AWS Data Analytics part1 p56 5. Validate Programmatic Access to AWS IAM User via AWS CLI.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们已经成功由itv管理员创建了一个账户
同时拥有程序化访问以及管理控制台访问
并且验证了登录功能
现在 让我们确保程序化访问也是成功的
这将会进行确认
使用之前下载的凭据来确保其正常工作
我们可以前往终端
在这种情况下，我启动了终端的一部分
您可以运行名为aws configure的命令
在这种情况下，我将使用名为itv admin的个人资料
我现在可以按回车
实际上正在运行现有的个人资料
我想那样做
这里显示的访问密钥是与itv bin个人资料相关的
我正在尝试用新账户替换
这是我们刚刚创建的
我必须去下载
然后我可以用文本编辑器或任何编辑器打开
这就是你想要粘贴的访问密钥
这就是秘密钥匙，现在我们可以按回车键了
配置文件已经用新账户设置好了，作为新账户的一部分
我们没有任何桶
也没有容易确认的两种实例，以确保我们可以运行命令
名为aws s three hyphen hyphen profile itv admin
你可以看到它什么也没写，确保我们看的是同一个账户
我们可以做的事情 我们可以去s three控制台
然后我们应该能够创建桶
让我们以名称创建桶
短横线演示现在
我应该能够说在这里创建桶
它已经存在
让我们说dg短横线itv演示现在
让我在这里创建桶
您可以看到名为dj的桶
短横线itv演示已成功创建，当我们尝试使用dj创建时
短横线演示 它失败了
因为桶应该在aws中唯一
在所有地区
现在当桶被创建
我们应该能够进入这个终端
我们可以实际上运行这个命令来列出这个桶
你可以在输出中看到桶的详细信息
这就是你应该能够对它进行程序化访问的方法
对aws second进行管理 这是我正在使用的
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/057_Udemy - Data Engineering using AWS Data Analytics part1 p57 7. Getting Started with AWS IAM Identity-based Policies.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解我是基于身份的政策
我们将专注于预定义的政策
目前我们将查看自定义策略在某个时间点
权限分配给策略
使用JSON语法
您可以前往IAM控制台
您可以点击用户
您可以看到有几条策略直接附加到用户
您可以展开一个策略
您应该能够转到JSON
你可以看到政策的JSON语法
脉冲通常附接到组或角色上
但是直接附接到用户上也是可能的
但更常见的做法是通过组将脉冲附接到用户上，而不是直接附接
用户、组和角色也称为IAM身份
我们可以将多个脉冲附接到IAM身份上
这意味着对于给定的用户
例如我 V min
我们应该能够为多个策略附加
同样我们可以创建一个名为v支持的组
我们应该能够为该组附加多个策略
我们有预置的策略我们可以利用
我们也能自定义策略
如果你查看itv管理员用户
我们之前创建的
我们附加了预定义的策略
管理员访问 我像这样更改密码
这里有很多脉冲
我们应该能够利用
这些来通过组为用户附加权限
通过选择我们感兴趣的一些策略
我们将进行一项练习
以便您能理解我所说的内容
让我们回顾以下策略
以便您了解权限和服务是如何定义的
首先我们将回顾aws s三全权访问
如果您点击这个
这将直接带你到政策页面
如果你已经登录
你应该能看到它 它可能会带你到政策概述页面
然而 如果你想查看json
你只需点击这里的json
你应该能看到json
如果你查看这里的json作为一部分声明
我们有三个重要的部分
影响行为和资源
你应该理解所有这些三个词的含义
我会在稍后讨论这些
在这种情况下，影响是黄色的
所以我们正在尝试允许所有与是的资源相关
我们说行动是三星
这意味着所有应该对三星执行的操作对所有东西都有影响
因为这是资源的一部分
我们有东西 我们会稍后再回来
我再解释一遍，你会理解得更多
详细一点
类似于那个 我们应该能够回顾这一点
附加的 啊政策
亚马逊s三读只访问
如果你看它的json
你可以看到这次就涉及到行动
它只有早些时候被列出
我们有星星 如果你审查这个
它已经做了 然而，在这里，我们只有得到一个列表
然而，我们能够在所有的s三资源上执行获取列表
s三中的资源除了桶和对象之外，别无他物
这里有些关键词，你应该熟悉
与脉冲相关的
它们只是效果
行动和资源效果就是无效
但这里是你通常定义低权限的地方，我不会在这里定义服务
我们会说
允许或拒绝，实际上指定应该采取的效果
操作是我们会定义操作的地方，连同服务
如果你看这些操作
我们有服务然后冒号
然后这里应该执行的操作类型
我们更明确
我们说 只执行get和list在s三上
所以我们定义了服务和作为行动一部分可以采取的行动本身
你可以看到它是一个列表
因此我们应该能够在这里定义多个行动
如果你只想定义一个
你可以直接这样定义
你不需要将其指定为列表
即使是在资源方面
你也应该能够在s3中指定多个资源
因为我们在这里谈论的是s3
如果你想传递多个资源
你现在必须将它们作为列表通过
让我们说执行与基于身份的政策相关的几项任务
我们将创建一个名为itv支持一的新用户
所以让我们关闭这两个
让我们去这个 我在管理控制台
让我们去用户
让我们添加一个名为itv的用户
支持一的用户将为此用户提供仅程序访问
让我们说下一步将直接附加现有的策略
我们将附加s三只读策略
这就是它
我们应该能说下一步攻击
然后审查然后创建用户现在我们已经创建了用户
我们已经将一个管理策略附加给了itv支持一用户
现在我们必须配置这一点
以便我们可以通过aws cli或其他程序化方法访问
在这种情况下我们将对抗aws cli
让我们说所以
让我们点击这个复制
然后让我们去这个终端
让我输入aws configure hyphen hyphen profile itv支持一按回车
我正在使用用户名创建配置文件
访问密钥就是这一点秘密
访问密钥就是这一点
现在配置文件已经创建
我们应该能在一会儿回到这一点
让我们关闭这一点
我们支持一的用户已经创建
他应该能列出桶
因为我们有只读访问
因此我们可以说aws s three a hyphen hyphen profile itv支持一
你可以在这里看到输出
它列出了作为第二部分的唯一天气桶
我用管理员用户登录
因此我可以实际上去s三
然后我应该能创建一个桶
让我创建一个名为dj零售的桶
我以前在另一个账户中有过
我已经删除了它
如果它没有完全从aws删除
它可能会因为与该名称的冲突而失败
让我们尝试使用dg零售
如果不行
我将使用不同的名称
你可以看到dj零售
桶已经定义现在我们应该能说创建桶
发生了一个意外的错误
一个冲突的条件操作
目前正在进行这项资源的操作
请稍后再试
删除操作正在进行中
直到操作完成
无法使用这个名字来欢迎这个问题
我将其更改为零售一
然后我会说创建桶
现在桶已经创建，因为桶已经创建
我想将文件复制到这个桶中
使用itv
支持一个只读访问的用户在s3上
让我们尝试运行这个命令
如果你在我的账户下查看此位置
你应该会在那个位置看到一堆文件夹和文件
你可以看到有六个文件夹
类别 客户部门或订单产品
有几个sql文件
还有read me md
我们要排除这些文件和空文件
只复制文件夹
这就是我们在复制命令中设置一些排除项的原因
确保设置零售数据库
在运行此命令之前先设置数据集
我在之前的主题中已经涵盖了这一点
你应该从我的github账户克隆仓库
你必须在某个位置保留仓库
基于这一点，你必须更新此位置
然后继续
在这种情况下，桶名是a dg hyphen
零售一 因此我需要更新这个
让我以零售一在这里说，现在我应该能够使用它运行这个命令
支持一个配置文件
让我们看看会发生什么
你可以看到它失败了
因为 它无法将上传文件放入s3桶的put对象请求
然而如果我只使用管理员账户
它将正常工作
相同的命令 我应该能够使用它v管理配置文件运行它
我以管理员用户mini的身份登录账户
因此，这个命令将没有任何问题地工作
现在 我正在使用它v管理运行
所有文件和文件夹都将上传到s3
一旦它们被上传 我们应该能够列出它们并从s3使用itv支持一个用户的对象
现在你可以看到文件已经上传
你应该能够使用它v支持一个配置文件来执行一个aws s three命令
假设指定桶的名称
桶的名称就是dg hyphen retail one
我应该能够像这样使用递归
这将列出所有文件夹和那些文件夹中的对象
让我们运行这个并看看是否能得到输出
现在你可以在这里看到输出
我们能够使用此配置文件在s three中列出所有文件夹和对象
它指向只读账户
这就是你应该能够给用户有限权限的方式
使用现有脉冲
我们也可以创建自定义脉冲
我们将稍后讨论那些事情
作为这个话题的一部分 我们已经详细讨论了身份脉冲，我们创建了用户
我们已经将只读脉冲附加到用户
然后我们尝试使用该用户复制文件
它失败了 然而
一旦使用管理员账户上传了文件
我们能够使用此账户读取文件
该账户在s three中有只读权限 所以我们已经完成了整个循环来理解政策是如何附加和验证的
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/058_Udemy - Data Engineering using AWS Data Analytics part1 p58 9. Managing AWS IAM User Groups.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个话题的一部分
让我们详细讨论一下IAM组
我们通常将用户添加到IAM组中
权限通常通过策略定义，策略可以附加或分配给组
组中所有用户将继承与该组相关的所有权限
让我们完成这个任务，以确保我们对组操作自如
首先，让我们创建两个组
我在管理控制台中
我可以去 我点击这个控制台
一旦我在控制台中
我应该能够通过点击这里转到组
然后，我可以通过点击
创建新组
在这种情况下，我将创建两个组
一个是itv管理员
所有管理员都将添加到此组中
让我们在这里说下一步
您可以在此处附加策略
在这种情况下，我想将管理员访问策略附加到此组
我能说下一步，然后我可以说创建类似的组
我想再加一个组
那就是itv
支持这个组
我将添加一个只读访问s3
我们应该能够通过选择这个添加只读访问a3
然后说下一步
然后说创建组，现在我们有两个组
一个是itv管理员，第二个是itv支持
我们应该能够通过点击相应的组来审查权限
你可以去权限那里
你可以看到附加到组的脉搏
目前这两个组都没有用户
我们可以向组添加用户
要么 你可以从这里添加用户
你可以说向组添加用户
在这种情况下，我将向itv admin组添加itv admin
所以让我选择这个，然后说添加用户，现在用户
itv admin已添加到itv in组
你也可以将用户添加到组中
通过转到用户
你可以选择用户
这里将选择支持 ITV 一个用户
我们将其添加到 ITV 支持组
让我们等到此页面加载完成
然后我们继续
现在页面已加载
我们应该能够点击用户
从这里你可以转到组
你可以说将用户添加到组中
实际上你可以在这里选择组
在这种情况下我们将选择v支持
然后我们可以点击添加到组
现在用户itv支持一已经被添加到itv支持组
在创建组本身时
我们已经添加了策略
因此我们应该能够从用户中删除策略
但是用户仍然会继承权限
让我们在这里转到用户
让我们转到itv min
你可以看到这里有权限策略
我们需要删除这些东西
以便权限由组继承
让我们等到空间加载
然后我们将实际处理删除管理员访问
我们可以点击这个
它将处理删除管理员访问
我们应该能够解绑现在
只有我是 你将直接更改密码
然后通过一个组
你可以点击这个以获取有关附加到此用户的权限详细信息
通过一个组我们对此用户有管理员访问
通过一个名为itv admin的组
类似地 我们应该能够转到itv支持用户
或我们支持一用户
然后我们应该能够点击这个以解绑此直接策略
现在s三只有直接访问被移除为此用户
它是由组抑制的
因为我们已经创建了ah组并将用户与那些组关联起来以具有适当的权限
现在 我们应该能够验证
以确认权限根据用户继承
符合我们的要求
itv admin应该有管理员权限
itv支持一应该只有只读访问权限s三以验证这一点
我们应该能够转到终端
让我们转到终端这里
在我这里我有两个配置文件
一个是itv admin配置文件
另一个是itv支持一配置文件
我将使用itv admin配置文件运行命令
首先首先 我将从dg hyphen retail中删除retail underscore db文件夹
一个桶 递归地
作为用户
itv admin有管理员权限
他应该能够删除这些文件夹从桶中
让我们运行这个 以确认
用户能够删除所有文件夹从桶
我们没有一个三个数组
在运行三命令时
这是强制性的 因此让我更新这个现在
让我复制这个
我应该能够粘贴这里并运行这个现在
它应该删除所有dg hyphen零售下的子文件夹并返回db
那是主要文件夹
我们从中我们正在尝试删除所有子文件夹
现在我们应该能够运行aws s three ls dg hyphen零售
hyphen hyphen profile
itv admin以确认一切已删除
它应该是dj iphone detail one
让我运行这个现在我们应该能够验证
你可以看到那个文件夹中没有任何东西
甚至零售和score db文件夹已删除现在
我们应该能够通过运行这个命令将文件从本地文件系统复制到s three
让我复制这个命令这里
也 我正在使用itv admin profile
因此文件应该作为对象上传到s three
让我们运行这个
然后我们将看文件是否已上传
现在你可以看到文件正在上传到s three one作为对象
它正在运行 我们应该能够运行aws s three l命令再次
我们应该能够看到已上传为对象的文件列表
我们只需等待所有文件上传到s three
现在文件已成功上传
我们应该能够运行a s three命令
使用递归以确保文件已上传
你可以看到已上传为对象的文件列表现在s three
作为itv support one profile
我将运行相同命令
然而这两个命令将失败
因为itv support one在这个s three桶中没有写入权限
他只有对所有s three桶的只读权限
让我们尝试运行这些命令
你将看到这些命令首先失败
让我运行这个命令
它说拒绝访问至于删除
文件同样适用于cp
它将尝试从本地文件系统复制文件到s three
并且用户在这个s three桶中没有写入权限
它将只说当调用put object操作时拒绝访问
但他们说less命令应该工作
在这种情况下 桶的名称就是dg hyphen retail one
让我更新这个 然后让我复制粘贴这个命令
你应该能够看到使用profile itv support one的所有文件
你可以在这里看到所有文件
这就是你应该能够创建组并将用户提升为组的方式
所有通过策略继承给组的权限都将传递给用户 所以组就是用户和通过策略传递的权限的咨询
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/059_Udemy - Data Engineering using AWS Data Analytics part1 p59 11. Managing AWS IAM Roles for Service Level Access.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分 让我们了解如何管理IAM角色
在设置AWS出版物时
我们可能需要使用多个服务进行多个服务之间的通信
拥有适当的权限
我们不需要创建用户
使用访问密钥和秘密密钥进行配置
然后进一步
我们可以使用IAM角色
这将简化我们应用程序相关多个服务之间的身份验证和授权过程
角色用于将一个服务的权限提升到另一个服务
我们通常创建角色并附上策略
与角色相关的权限由我们的策略继承
当我们将角色附上时
让我们执行此任务以了解如何定义和使用角色
我们将创建一个名为itv support的角色
并附上亚马逊只读访问权限
一旦角色创建
将启动Easy to instance
使用这个角色 我们将使用亚马逊Linux映像
因为它将带有预安装的AWS CLI
如果我们使用亚马逊Linux
我们不需要过多担心设置AWS CLI
在上面
此外 我们不需要配置CLI
因为权限已通过角色分配给此Easy to实例
记住 如果您使用其他操作系统而不是亚马逊Linux启动Easy to实例
则需要首先安装AWS CLI
但是一旦AWS CLI配置完成
您不需要再配置它
我们将通过SSH连接到EC two实例
并运行这些命令
以确认服务在S3中具有只读权限
而不是在S3中具有全部权限
让我们转到AWS管理控制台并创建角色
在创建角色时，请确保选择EC two服务
因为您希望将此角色附接到EC two实例
我在这里访问管理控制台
我应该能够说我在这里
我应该能够点击角色
然后我可以说创建角色
我们需要选择Easy Two
因为我们试图将角色附接到Easy Two实例
根据角色将附接到的位置
我们需要选择服务
让我们选择E C two
然后说下一个权限
当涉及到权限时
我们希望给予三个只读权限
因此我正在这里搜索s three
然后我实际上可以选择只读访问权限
然后说下一个标签
然后下一个评论
我们必须在这里提供完整的名称
让我命名为itv支持
这与创建角色的标准命名约定不符
但是，对于一个样本角色
我正在使用itv支持
确保你理解标准并开始使用标准名称创建角色
点击创建角色以创建角色
它将为我们创建角色
整个名称只不过是itv支持，总是成功创建
让我们创建一个易于实例
获取easy two实例时
我们需要确保这个角色已附加
不要太担心
如果你现在还不完全理解整个流程
无论我强调什么
只需确保你遵循我所说
确保你能够设置一个简单的实例来创建简单的实例
你必须搜索易用性
然后你可以点击这里进入易用性控制台
你可以实际进入实例
然后你可以说启动实例
你可以选择亚马逊linux二
然后选择
你应该能够使用免费试用
如果你是新手
你将不会被收取费用
如果你现在在使用这里你应该能够点击
在这个页面上配置实例详细信息
你必须记住你必须去
我是滚动并选择我们之前创建的我是角色
它只不过是itv支持
因为选择了我是角色现在
我们应该能够去下一个添加存储
我们可以将此设置为默认值
添加税 我们可以忽略配置安全组
我们可以将其设置为默认值
只要端口号22是开放的
我们应该能够连接到这个服务器
因此我们可以将其保留
然后我们可以说现在审查并发布
你应该能够点击启动
它将要求您创建一个密钥对
如果你已经有一对密钥
你可以选择那对密钥
因为这是我的新账户
我会扩展这个
并且我会选择
创建一个新的密钥对
然后我会提供密钥的名称
名称只是itv demo
一旦你定义了名称
你必须点击下载密钥对
以便私钥被下载
你可以在这里看到消息
你必须下载私钥文件
在你继续之前请将其存储在一个安全和易于访问的位置
你将无法再次下载文件
在它被创建之后
所以如果你未能下载
或者你意外删除
你将无法再访问该文件
你必须重新生成密钥对
并且你必须处理一个复杂的步骤来刷新实例
使用新的密钥对
不要进入那个
只需确保你有备份你的私钥文件
一旦你下载它
点击这里下载密钥对
它会下载一个名为keeper的文件pam
你可以在这里看到它
这是文件的名称
现在你应该能够说启动实例
现在实例正在启动
你可以点击它来查看实例的进度
实例正在启动
我们应该能够将pem文件复制到适当的位置
现在我可以进入终端作为终端的一部分
我可以进入下载作为下载的一部分
我已经下载了itv demo pem
你可以在这里看到详细信息
现在你必须将pem文件移动或复制到标准位置
一个标准位置是nothing but
点ssh文件夹在Linux或Mac的主目录中
你可能已经有它
如果没有 你可能需要运行ssh kn
以便点h文件夹被创建并具有适当的权限
如果你手动创建了点h文件夹
你应该检查点h文件夹的权限
你可以通过运行-a-l-t-l来检查
然后tilde tilde表示Linux或Mac的主目录
然后你实际上可以说grep点set
你应该能够给dot权限
文件夹的所有者有读权限
执行权限 其他人没有任何权限
包含此文件的文件夹应仅反映这些权限
然后从本地机器到远程机器的ssh身份验证将使用私钥文件工作
使用私钥文件
现在我们必须将itv demo dot pem文件移动到tilde slash dot ssh
我们应该能够通过说f nlttilde slash dot ssh来查看
您可以看到itv demo dot pm文件
然而 此文件的权限不仅限于读取
所有者也有写入权限 但也为其他人提供读取权限
我们必须从其他人中删除读取权限
以便我们可以使用此连接到e c two实例
您可以使用这个命令叫a ch mod six zero zero
然后tilde dot h然后itv demo
以便此pem文件的权限调整为仅允许所有者读取和写入
现在您应该能够运行li on ltr on tilde slash dot set
您可以查看itv demo pem文件的权限
现在只有我有读取和写入权限
我可以说cd到家目录
您可以返回aws web控制台
您可以点击此处获取连接详情
您可以点击此处连接
您应该能够获取此评论的参考信息
只要您在文件夹中
itp demo dot在那里
您应该能够直接复制并粘贴此命令
如果您在单独的文件夹中
您必须指定pem文件的完整路径
在我这种情况下，文件夹是data set
而我不在data set文件夹中
因此我必须说ssh iphone i tilde slash dot
Ssh itv demo dot pm
然后我应该能够粘贴easy to hyphen user at the rate
与e c two实例关联的公共dns
我应该能够运行此命令
然后说yes
现在我在easy to实例中，确认aws是否已设置
您可以说aws并按Enter 因为它已设置
您可以看到命令的使用情况
它没有抛出另一个
说没有找到该命令
因为我们已经有了aws
并且我们已经将角色附加到此
现在您可以看到aws的使用情况
并且我们也已经将角色附加到此
我们应该能够直接运行命令
让我们回到材料这里
让我们复制这个命令
我们正在尝试删除文件夹返回
score_db_from_dg_retail_one_bucket
它应该失败 因为附加到角色的权限只对s3有只读访问权限
让我们运行这个 你可以看到它说被拒绝访问
如果我运行这个 它会工作，因为角色对s3有只读权限
你可以在这里看到输出
我们还没有配置任何东西
我们只是运行了命令
这取决于这个实例继承的权限
因为它附加的角色
我们能够在这里看到详细信息，话说回来
如果你想更改角色
你可以实际上去aws管理控制台
你可以去实例页面
然后你可以实际扩展实例状态
我想它并不是更改iam角色的地方
你可以更改iam角色的方式是
你可以去实例这里
设置你要更改iam角色的实例
你可以通过去安全查看当前的
iam角色
你可以在这里看到iam角色
如果你想更改它
一旦你选择了这个
你可以去操作
然后去安全
然后说修改
iam角色
你将能够看到所有为EC two定义的iam规则
你应该能够更改iam角色为你选择的角色
你可以继续
这就是你应该能够更新运行中的EC two实例角色的方式
如果角色是为EC two创建的
EC two 这是关于iam角色的所有内容
在这一刻我们已经看到了如何使用特定服务创建iam角色
我们可以通过使用策略为角色附加权限
一旦角色创建
我们应该能够使用服务并创建资源
在这种情况下我们使用了ec
2 我们创建了一个ec
2实例 在创建EC two实例时
我们已经为角色配置了e
C 两个实例 并且我们在配置e c
两个实例 我们能够运行aws命令，我们可以从s三桶中读取文件
但我们不能从s三桶中删除文件
因为分配的权限只有三d只读 这就是你应该能够探索角色与服务的方式，通过将角色附加到服务
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/060_Udemy - Data Engineering using AWS Data Analytics part1 p60 13. Overview of AWS Custom Policies to grant permissions to Users, Groups, and R.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们对自定义策略有更深入的理解
我们可以在最终对任何服务和内容提供细粒度的权限
使用自定义策略
让我们做一个实验来理解如何使用自定义策略
为了给特定桶的用户授予权限
在这个例子中我们将在S3中实验，现在您可以进入管理控制台
您可以进入 我是作为I am的一部分
您应该能够进入策略
然后说创建策略，当涉及到创建自定义策略时
您可以选择一个服务并使用此向导创建自定义策略
或者您可以进入JSON
您应该能够使用JSON定义语法
您应该能够使用自定义语法授予权限
或者您可以通过导入现有管理策略来创建自定义策略
一旦您导入 您应该能够根据您的要求对其进行定制
在这个例子中我正在导入S3只读
让我选择这个
然后说导入要求是
我们应该能够执行不仅读取
还可以在dj-hyphen零售上进行上传和删除
一旦我们将此策略附加到用户或组
对于其余的桶我们应该能够列出
我们应该没有其他权限除了为其余的桶列出桶
但对于dj-hyphen零售文件夹
继承此策略权限的用户
应该在该文件夹上拥有所有权限
用户不应该在其他文件夹中对该桶有任何权限
dj-hyphen零售 让我们处理它
然后我们会继续
您可以直接复制粘贴
但我将演示如何使用现有管理策略作为参考
并在其上进行改进
因为我们已经导入了现有管理策略
我们应该能够进入JSON
您可以在这里看到语法
或完整的AWS策略
关于在所有sd桶上的只读
如果您想要在特定文件夹上获得所有权限
让我们删除这里的一个权限
让我们删除这个逗号
也让我们删除这个get
我们现在正授予资源上的所有操作权限
目前资源是star
这意味着我们将授予所有资源的权限
在这个例子中我们想要限制到桶中的单一文件夹 dg-iphone零售
以处理这个问题
我们必须获取一个名为arn的东西
关于我们想要定义这个政策的s3桶
为此我们需要进入s3控制台
让我们打开另一个aws管理控制台
让我登录
让我输入s3
让我进入s3
我们处理的桶什么也不是，只是dg-hyphen零售1
让我选择这个
你可以转到属性
你可以看到air和这里，and代表亚马逊资源名称
我们应该能够将这个作为政策的一部分指定
现在你可以说a和aws
s3 blah blah blah-hyphen详细信息1
它将拥有这个桶的所有权限
所有对象和文件夹都可以使用这个用户来管理
然而 我想限制为只返回on score db
我们可以提供文件夹的前缀
像这样返回for db是文件夹名称
任何在该文件夹下的都可以使用将这个政策附加到的用户来管理
现在我们应该能够说下一个攻击下一个审查
当涉及到名称时
我想使用在这里的名称
让我复制这个并粘贴在这里
现在政策将在我们点击创建政策时创建
如果政策已创建
我们应该能够将其附加到组
让我们转到组
在这种情况下我们希望将其附加到itv支持
让我们点击这个
让我们转到权限
让我们删除这个政策
我们可以说脱机
我们应该能够脱机这个政策
让我们说附加政策作为附加政策的一部分
让我们搜索itv支持
作为零售db
所有是我们创建的
我们可以选择这个
然后我们应该能够通过说附加政策来附加
根据这个政策分配的权限将分配给组的用户
itv支持 我们可以转到itv支持这里
用户什么也不是，只是itv支持1在这个时间
使用itv支持1
我们应该能够验证itv支持1在dg-hyphen详细信息1桶的on score db文件夹上有写入权限
而不是
为此我们需要一个桶
我们应该能够运行这些命令
这将确认权限是否按我们的预期继承
我正在清理db文件夹的所有返回
我应该能够将此命令复制并粘贴到命令行中
现在您可以查看评论
评论说as three r m s three列dj有详细信息
一返回分db
然后减减递归减减配置
配置与itv支持一个信用有关
现在我应该能够按Enter
当我们没有正确的权限时
它将失败现在它将成功
然而 它正在失败
因为我们没有列表权限
以确保我们在s three桶上有列表权限
我们需要改进我们的策略
为此我们可以转到管理控制台
转到策略如itv
这是我们正在尝试创建的策略
我们可以点击编辑策略以编辑此策略
我们可以转到json
我们应该能够复制并粘贴它这里
这些定义之间应该有逗号
您可以看到声明什么也不是列表
这是一个规则
这是第二个规则
作为第二个规则的一部分
我们希望在所有桶上授予列表权限
因此我们可以说像这样作为一部分操作
我们只需点击开始像这样
现在我们应该能够点击查看策略
然后保存更改
策略与所有桶的列表权限相连
权限 因此使用用户
我们应该能够处理我们本应处理的一切
根据验证现在
让我点击这里并运行此
现在文件夹将与文件夹内所有对象一起删除
它将处理递归删除所有对象因为它被删除
让我们运行cp以确保文件上传到s three作为对象
为此 我们应该能够使用itv支持一个配置运行此命令
让我们复制并粘贴这里
现在文件正在使用itv支持一个配置上传到s three
它正在失败 因为itv支持一个只有读取权限当我们授予时
或者当我们附加三只只读策略时
现在我们应该能够说aws s three像这样列出
它将递归列出与score db相关的所有文件夹
在dg连字符详细信息中
你现在可以看到
让我转到aws web控制台
然后让我转到元素控制台
让我转到对象
让我创建一个新的dg零售文件夹
我给它命名为零售演示
它不应该有返回分数db的前缀
在这种情况下，我说零售下划线演示
现在我说创建文件夹
让我们看看是否能够将文件复制到此零售和代码演示文件夹中
dg零售桶中的文件夹
使用itv支持一配置文件
我可以在这里
我应该能够说aws s 3 ls dg连字符零售一
我们可以验证文件夹列表
文件夹名称是返回代码演示
配置文件是itv支持一
让我们看看它说什么
它能够列出文件夹
让我们说cp这里
让我们使用cp命令
aws s 3 cp
我想复制的文件是数据零售和分数db订单
我将只复制一个文件夹
我将复制到dg连字符零售一零售和分数演示订单
这是文件夹名称
我想使用的配置文件是itv支持一
让我们看看现在，你看它说上传失败
然而 它说这是一个目录，以确保我们以正确的方式尝试
我们应该确实说递归这里
让我递归并按Enter
你可以看到上传失败，访问被拒绝，因为itv支持一没有对除返回分数db以外的任何其他文件夹写权限
在dg下有一个桶
它失败因为我们试图写入到dg的尾分数演示
有fun一桶
这就是你应该能够向用户或角色授予最终细粒度权限的方式
通过自定义策略
确保你对此感到舒适
很多时候你可能需要根据现有策略稍作修改
或者你可能需要从头开始编写
根据要求
你应该能够使用json语法快速创建自定义策略
并且你应该能够将其附加到角色或组中
并根据你的需求使用
了解自定义策略的详细信息非常重要
这不仅有助于你开发自定义策略
也有助于你解决复杂的问题
理解 有时 确保你对定制政策非常熟悉
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/061_Udemy - Data Engineering using AWS Data Analytics part1 p61 15. Managing AWS IAM Groups, Users, and Roles using AWS CLI.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


正如你已经理解如何管理
我正在使用Web控制台
让我们详细讨论管理
我正在使用CLI
我们应该能够管理 我正在通过AWS召开会议
我正在命令 你应该能够使用这个命令列出用户
让我们开始运行这些命令，以确保我们对此感到舒适
首先，让我转到这里并说aws
我的帮助
它将为您提供与我有关的所有帮助
您可以在这里查看所有数据，现在要使用此
您应该具有已配置适当的凭据的aws CLI设置
用户应该在我有所有权限
到目前为止，我们有一个名为itv admin的帐户
该帐户具有对AWS的所有管理员访问权限
我们已经使用itv admin配置了配置文件
我们应该能够管理
我没有任何问题
在这种情况下 我可以说aws
我有列出用户
破折号破折号配置文件
itv admin
它将处理列出用户
输出将以json格式显示
您可以在这里看到json输出
有两个用户 itv admin和itv support，目前只有一个
如果您想获取组
您可以说aws
我有列出组
破折号破折号配置文件
itv had been
它将以json格式列出组
您可以看到uh
组在这里 如果您想获取角色详情
您可以说aws
我有列出角色
破折号破折号配置文件
然后itv admin
您可以按Enter 这样您将能够获取角色详情
如果您想知道哪个组哪个用户
那么我们必须爆炸命令
让我们看看如何探索命令并验证
嗯 与组相关的用户
我们可以说aws
我是帮助，按回车
您可以在这里查看所有可用的命令
通常所有列表都以列表开始
因此我们可以滚动查看
您可以看到用户组的列表
用户组的列表，例如list groups for the user
我们有列表实例配置
列表策略等等
我们可以获取用户的组
让我们看看是否可以获取组的所有用户
这可能在列表上
短划线组 我们不能使用列表获取信息
短划线组 可能有一个称为get group的东西，get group
可能有关组的用户的信息
让我们检查get group的帮助
看看它是否会提供与组相关的用户详细信息
让我退出
然后我们可以说aws
我是get短划线组帮助，按回车
在选项方面
我们有get group组名称
看看所有输出
它将提供用户和列表
因此我们应该能够使用get group获取与组相关的用户
现在我们应该能够列出组，说aws
我是列表短划线
短划线短划线配置文件
itv 管理员
按回车 有两个组
一个是itv管理员
第二 一个是itv
支持获取名为itv管理员组的用户
我们可以说aws
我是get group
短划线短划线组
短划线名称 itv管理员
然后短划线短划线配置文件itv管理员
您可以按回车并查看有关此组的详细信息
包括与该组相关的用户详细信息
组就是这个，您会看到组详细信息
您可以在这里看到用户详细信息
这就是你应该能够从给定组获取用户的方式
如果你想获取组详情
那么你应该能够说aws
我是用户列表的组
破折号破折号破折号名称
让我们说a v admin
然后profile itv it
它将给我们提供用户的组详情
实际上是用户的组列表
不是用户的组列表
让我们说用户的组列表这里
因为用户可以属于多个组
你应该能够看到用户所属组的详细信息
到目前为止，我们已经看到了如何列出用户
组和角色
现在让我们检查如何列出脉冲
要列出脉冲
你只需说 Aws
我是列出破折号策略
然后破折号破折号profile
你可以给定配置文件名称并按Enter
你可以得到策略的详细信息
你可以看到这是一个列表
所有由aws以及自定义管理的策略
如果你想只获取自定义策略
那么你要说aws
我是列出策略
你必须定义范围
如果你想要帮助
你可以说aam列出脉冲
帮助作为参数的一部分
有一个名为范围的参数
你必须说local 来获取自定义策略的详细信息
让我们运行aws
我是列出破折号策略范围
Local破折号破折号profile itv
Admin 它将处理列出我们作为前一个主题创建的自定义策略
我创建了这个策略
叫做itv支持零售db
所有 这就是你应该能够获取自定义策略详细信息的方式
正如我们已经理解了所有列出命令来列出用户
组 角色和脉冲
现在 让我们谈谈创建用户
所以我们将创建一个用户
并且将其分配给一个名为itv支持的组
我们必须通过运行此命令创建用户
用户名是itv支持
我们使用itv admin作为配置文件
因为我们需要具有权限的用户
作为那个用户有一个包含管理员访问权限的策略
我们应该能够复制并粘贴这个
我们应该能够使用itv支持创建用户
您可以在这里看到输出
现在您应该能够列出用户
你应该也能看到这第三个用户
这个用户只是itv支持
如果你想将这个用户附加到一个组中
那么你可以说aws
我添加一个用户到组斜杠
然后斜杠斜杠组
名称itv支持
这就是组 我想将itv支持添加到
我可以像这样指定用户名
所以我们正在尝试为itv添加支持到itv支持组中
我可以说 配置文件
itv管理员
现在用户已添加到组中
itv支持
你应该能够使用此命令列出用户的组支持
你之前也见过
我们之前为其他用户使用过这个
我们也正在尝试为itv支持使用
你可以看到这位用户的组
它只是itv支持
你也可以使用名为aws的命令
我获取组
组名是itv
支持配置文件是itv
管理员 你可以点击和g
你应该能够作为组详情获取组详情
你将能够看到新用户
这里列出了ITV支持
这是此JSON中用户的一部分
用户只不过是一个列表
该列表将包含与该组相关的所有用户详细信息
我们已经理解了如何添加用户以及如何将用户与组关联，现在
让我们了解如何从组中删除用户，然后删除
当用户是组一部分时，我们不能删除用户
你必须使用从组中删除用户的命令
你应该能够指定组名和用户名
你必须从所有组中删除用户
然后你应该删除它
因为不是用户只属于一个组
所以我们要从组中移除
叫做b支持
一旦这成功了
然后我们应该能够运行这个命令来删除用户
你必须在aws下使用删除用户命令
是的 首先我们使用了从组中移除用户的命令
现在我们使用删除用户命令
它会处理删除用户的工作
现在你应该能够通过运行这个命令来验证
你可以在这里看到输出
你将不再看到它
支持任何更多
这就是你应该能够管理
我 用户或角色或组或策略使用命令行
你可以使用aws web控制台执行的任何事情也可以使用命令行执行
这只是曝光水平的问题
你必须确保你对aws cli也很熟悉
不一定与am有关
但总的来说，以便你可以快速获取与你正在工作的应用程序相关的信息
基于您的要求
理解aws cli对于提高您的生产力非常重要
确保你对它很熟悉
正如他们这里演示的那样
每当我提到一个新服务
我会创建一些与aws cli相关的内容 确保你练习并对aws cli感到舒适
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/062_Udemy - Data Engineering using AWS Data Analytics part1 p62 1. Getting Started with AWS Elastic Cloud Compute aka EC2.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在这个时间我们正在谈论e c two
让我们开始吧
我们将涵盖与e c two相关的一些关键术语
你可能无法理解这里的所有术语
但随着你继续前进，通过其他主题的部分模块
你将配置dc到实例
并逐步进行许多实际操作
你将熟悉作为本主题一部分使用的所有术语
不要过于担心 如果你不能理解所有术语，到本主题的结束时
他们将在后续的主题中被提及
到模块部分的结束时，你将对这些事情熟悉
谈到e c two
它代表弹性云计算
这就是为什么他们说e c two
它只不过是从aws数据中心为您提供的虚拟机
虚拟机位于区域中的可用区
aws有多个区域
如果我登录到我的aws控制台
如果我去我的主页
它正在要求我登录
让我在这里登录
现在 我已经登录了
你可以实际审查这个部分
你可以看到 在aws中又有这些许多地区
在每个地区中 我们也有可用性区域
通常我们在可用性区域中配置了两个实例
你将会回顾那些事情，就像我们进一步说的那样
并尝试从aws中轻松地实例化
E C 使用实例类型为两台实例配置了资源
有多种实例类型
例如通用型、内存优化型
CPU优化型、存储优化型
我们将根据需求选择实例类型
实例类型只不过是预配置的CPU、内存和实例存储的组合
实例存储无非就是CPU内存之上的存储
我们还需要选择操作系统
至少一个ABS用于根文件系统
VPC用于网络
安全组用于防火墙安全
并且用于登录系统
只有这些全部设置好
我们才能轻松地创建实例并使用它，如果你错过了这些任何一项
即使你创建了实例
你也无法使用它
在这种情况下 Ebr代表弹性块存储
它是实例存储之上的额外存储
Vpc代表虚拟私有云
我们已经覆盖了e
C Two E c two代表弹性云计算
一旦e c Two实例拥有所有这些
它们可以是运行状态或停止状态
只有在实例运行时，您才会被收费
除了存储
您可以终止简易实例
但是，当您终止实例时
如果您不想为存储付费
您需要确保卷也被删除
您将了解如何处理这些事情
随着我们进一步进行
您可以附加额外的EBS卷以增加存储
你可以定期为卷创建快照以进行备份
这些都是你应该熟悉以便开始的一些微妙之处
让我们继续前进，处理所有其他易于实例的配置
它们会慢慢完成
到本节模块结束时，你将能理解所有术语
你应该熟悉所有这些术语
如果有任何空白
你必须付出一些努力并确保所有那些空白都被关闭
如果你不理解声明 那么你的学习有点不完整或部分完成
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/063_Udemy - Data Engineering using AWS Data Analytics part1 p63 3. Create AWS EC2 Key Pair for SSH Access.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解如何创建易于维护的实例
这样我们就可以将其连接到易于实例，例如RPC或mac
一旦我们在AWS上创建了易于实例
我们需要连接到它们
通常，如果您是在数据中心设置
我们最终会使用密码来访问远程服务器
这不是一个好做法
我们应该进行无密码登录
易于实例在这里指的是AWS的无密码登录到远程实例
默认情况下 密码登录已禁用
我们只能无密码登录，易于保存在这里
我们可以创建一个密钥对或使用现有密钥对创建Easy to实例
在创建Easy to时不建议创建密钥对
C 两台实例 你将会有太多的密钥对
如果你有几百台服务器
你可能会有四到五个密钥对，一个用于生产，一个用于测试
为开发而设 如果你有多个正在设置的应用程序
可能每个应用程序开发
测试生产 你可能会有不同的保管者
这就是保管者通常如何创建
让我们转到创建保管者的指示
在创建易用实例时
稍后
我已经在AWS Web控制台
我们需要转到EC two
如果你看看这个页面的左边
这叫做左侧栏
如果你往下滚动
你在网络和安全下
你可以看到密钥
你可以点击保存在这里
然后你应该能够创建一个密钥对
这是一个保存者 我们之前已经创建了
作为部分的提供
我是角色演示
现在我们必须点击创建密钥来创建一个新的密钥
你应该能够输入密钥名称
让我们说itv 演示一
嗯 文件格式可以是peppk
ppk适用于Windows的派对
帕姆作为武器
它可以用于mac
Linux等 所以如果您使用的是Windows机器
请确保您选择这个
我正在使用mac，因此我选择这个
我应该能够滚动
我可以在这里点击创建密钥
您可以在这里看到消息
它已成功创建
如果文件已下载 您可以展开此内容
您应该在这里看到下载的文件
您可以单击此处转到下载的文件
然后您可以右键单击
然后您可以使用其他方式保存并打开
我将使用文本编辑器打开此文件
让我点击打开
这是此文件的内容
它只不过是私钥
相应的公钥将保存在aws存储库中
每当我们创建EC two实例时
公钥将复制到EC two实例
使用此私钥与公钥
将进行身份验证
我们将了解如何使用此密钥创建EC two实例
稍后我们将了解如何使用它
我们将将此文件复制到标准位置
如果您使用的是mac或Linux
您需要在某些标准位置复制此文件
标准位置通常是点h文件夹
让我转到终端
如果您查看home目录中的dot set文件夹
我已经有了这些文件
在做那之前，我想将此文件复制到此位置
我想审查女儿消息的权限
您可以像这样查看dot h的权限
您可以说a less hyphen
alt以查看隐藏文件
我在我账户的home目录中
在账户的home中，您可以pipe并搜索a set像这样
您可以看到有一个dot set文件夹
dot set文件夹的权限像这样
我有读写以及执行权限
小组的其他成员没有权限
其他人没有权限
在这种情况下，小组就是staff
不仅dot set的权限应该像这样
而且私钥文件的权限也应该像这样
我们应该只有所有者的读写权限
所有其他人现在对这个文件不应该有任何权限
让我移动文件
文件名无非是itv demo one dot m m
现在我想把它复制到dot set文件夹
如果我检查这个新文件的权限
这个文件无非是itv demo one dot pam
你可以看到，它不仅拥有读取
所有者的写入权限
还需要其他人的权限
我们必须禁用这个
你禁用此方法的方式是使用chmod命令
你可以说六零零
六在二进制格式中表示
一一零 这意味着这两个将被设置为
其余的东西将不会被设置
因为我们在这里指定了零
这意味着对于所有三个字符都会有横线
这意味着我们最终只拥有所有者的读写权限
文件名就是点ssh itv demo one 点 pem
现在你应该能够查看此文件的权限
确保你更改这些权限
这样你就可以使用此连接到远程机器
如果你不更改权限
即使你可以创建易用实例
使用密钥对组合
你将无法连接
它会显示权限被拒绝的错误信息
或者它会提示密码
因为它无法使用此私钥文件
并且私钥文件的权限应该像这样
包含这个私钥文件的文件夹的权限也应该像这样
确保您更改权限以使用此密钥对
这就是您应该能够创建密钥对的方式
您不仅需要创建并下载pem文件
您还需要注意权限
如果您使用的是mac或Linux与Windows
步骤会有所不同
我们将在另一段视频中看到，我会在Windows上演示
您已成功创建了密钥
让我们理解发生了什么
将生成一个随机私钥和关联的公钥
私钥文件将推送给您以供下载
它已经为我们下载好了
当您启动EC two实例时，公钥将被管理在AWS存储库的某个地方
EC two 使用特定密钥启动两台实例
该密钥的公钥
它将被添加到服务器上的标准用户下的所有密钥中
标准用户可以是亚马逊Linux或Ubuntu的默认用户
这是你想要的红帽
它可以是其他用户
根据操作系统
标准用户名会改变
你可以通过连接到器获取有关标准用户的信息
一旦easy to实例已定位
我们有一个easy to实例
让我来告诉你如何获取标准用户的详细信息
你可以去easy to去vending实例
然后你可以实际选择这个
然后你可以说连接这个easy to实例是使用亚马逊linux配置的
亚马逊linux的标准用户就是这个
你看到的就是标准用户
这就是我们成功创建的方式
Easy to保持 让我们继续看看如何使用这个密钥对来启动e C Two实例
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/064_Udemy - Data Engineering using AWS Data Analytics part1 p64 5. Launch AWS EC2 Instance or Virtual Machine.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们了解如何使用AWS网页控制台启动EC two实例
观看视频了解如何创建简单实例
使用Ubuntu
将有几个步骤
你应该熟悉几乎所有步骤
在配置简单实例时
一旦你在AWS网页控制台中
你可以实际访问EC two以实际启动EC two实例
如果你没有看到作为其中一个列出的服务
作为所有服务一部分，你有计算类别在其中，你有EC two
或者你也可以在通用搜索栏的全球搜索中搜索EC two
你应该能够点击这个
或者一旦你在这里，你可以搜索
你可以转到实例
目前有一个实例正在运行
如果你想给实例起名
你应该能够给这里起名
让我输入
我是演示
我正在创建新实例
我可以点击启动实例这里
让我们回顾这里我们有的不同选项
默认情况下 我们最终会在快速启动中
作为快速启动一部分
我们通常拥有最受欢迎的
以及由亚马逊提供的实例
你也可以创建你自己的
我是作为大型企业
你可能想根据不同类别为每个类别设置一些标准软件
他们将最终创建一个ms并且他们将使用这些ms启动EC
C两个实例 而不是使用由亚马逊或第三方提供的ms
然后你有AWS市场这里
第三方供应商将实际提供一个ms
通过安装软件并为您的使用进行预配置
你应该能够使用他们的软件启动EC two实例
并且你可以立即开始使用它们
在此基础上
我们还有一个庞大的社区 甚至社区提供了一个ms
你应该能够使用这些
在大多数情况下
你将为EC two以及软件支付费用
只要EC
C两个实例正在运行
可能会有一些AM I
C 两个
一旦EC two实例运行，可能会有一些AM I
他们将不会为操作系统收费
但可能会有一些误解，他们会为操作系统收费
要理解这一点，你必须去看价格
这是基于选择的实例
它会提供关于是否为操作系统收费的详细信息
如果你选择亚马逊Linux
很可能他们不会为操作系统收费
我将快速启动
在这里我们可能没有Ubuntu
或者我们实际上有
你想运行24
但我想使用18为设置，即使18为可用
我们可以实际上选择这个
如果你在快速启动中不看到AI
那么你必须搜索
AI作为社区或市场的一部分
我通常会使用快速启动或市场
我不会经常使用社区MS，现在你可以看到家族这里
家族和类型
家族只是这部分的类型t2或t代表通用
其他类型的家族是如果你滚动下来
有c c代表计算
计算优化 会有强调CPU
你可以看到如果你查看c4.大
你会得到2实例
与3.2GB内存 和3.75GB内存
如果你滚动下来
并且如果你选择m
它是内存优化
G为GPU
我不确定
我认为是内存优化
我认为是存储优化
有不同的家族
你可以实际上谷歌一下什么
这个第一个字符意味着
我用于ah
存储优化 用于内存优化
T用于通用
G用于GPU
优化 如果你查看m.大
或ami.大
你可以看到它实际上为我们提供了2GB内存和2vcpus
而与c
我们查看了c4.大
这就是我们有两个核心和4.75GB内存
与内存相比，CPU要多得多
内存只有3.1GB
5GB RAM 4.0
让我们转到c2.large这里，或者我们之前看到的任何内容
这是c4.xlarge
你可以看到这里有两个CPU
我们只能得到3.1GB内存的3.5GB内存
当我们转到内存优化的addb内存时
我们只能获得2个vCPU
因为它是针对内存进行优化的
因此，重点将更多地放在内存上
当涉及到C时
它是针对计算进行优化或CPU优化
因此，重点将更多地放在CPU上
现在，您也将在此处看到存储作为存储的一部分
一些EC two实例在配置时会为您提供免费的实例存储
让我们向下滚动，您可以在这里看到详细信息
如果您在这里没有看到EBAS
这意味着他们将为您提供实例存储
它将是免费的 它将包含在成本中
那是在您使用的实例类型上设置的限制
您还将获得免费的存储或包含在价格中
不免费但包含在价格中
然而 请注意，ebs和uh之间存在一定的差异
非ebs存储在这里，实例存储在这里
实例存储 EBS不是临时的
这意味着如果你只使用这个实例存储
如果你终止了易用实例
你将失去存储中保存的所有内容
但如果你用易存储你的文件
即使你关闭实例
你将能够找回你的文件
使用用于存储这些文件的EBS卷
我们将在后续时间点详细讨论存储级别
现在只需理解实例类型无非是CPU、内存和可能实例存储
现在你应该能够点击
配置实例详细信息
这将带你到网络设置这里
你也可以指定实例的数量
在这种情况下 我只获得一个实例
如果你想使用spot实例
你可以这样做 什么是spot实例
我们将稍后查看
在网络设置中
将创建一个默认VPC
我正在使用默认VPC
如果你需要 你可以创建额外的VPC，并且你可以开始使用这些额外的VPC
如果你想要自动分配公共IP
那么你必须选择这两个设置之一
如果你选择禁用
将不会为你分配公共IP
如果没有公共IP
你不能直接连接到该易用实例
从你的Mac或PC
或者你必须使用称为SSH密钥转发的东西，话说回来，目前我们将使用使用子网设置启用
和那是默认的
如果你需要分配
我是角色 你应该能够分配
我是角色 我们以前见过
我不打算分配任何
我是角色，目前
这些是你可以
嗯
审查其他 你可以忽略
并且你可以转到添加存储，当涉及到添加存储时 根据你正在配置的实例类型
你可能得到实例存储
或者你可能得不到实例存储
在这种情况下，我们使用的是t two dot micro，属于免费层
它还提供免费层下的GB的abs
因此我们应该能够使用ebs s
对于这种实例
没有实例存储
因此我们只能使用ebs s
在这种情况下，你可以使用tgb通用目的ssd或磁性存储
磁性存储就是其中一个
或者这两个中的任意一个，每月免费到GB
现在我们应该能够点击添加文本
如果你需要添加额外的ebs卷
你可以点击添加新卷
你应该能够添加额外的卷
我们将稍后查看那些细节，目前我们只有根卷
根卷是必须的
你需要做一些容量规划并为根提供足够的存储
通常它会在16GB到32GB之间
如果你需要额外的存储
我们通常添加新卷并为额外存储分配存储
然后我们可以点击添加文本
然后点击添加文本
税主要是用于建设目的
在这个情况下，我不使用税
我直接在这里配置安全组
你可以选择一个现有的安全组或者创建一个新的安全组
我们以简单的方式做的
甚至安全组所以需要一些规划
我们应该限制我们账户下的安全组的数量
目前 我将创建一个新的安全组
如果你想选择一个现有的安全组
你可以选择这个
已经有两个安全组
你可以选择其中一个
然而如果你希望
选择现有的安全组
你需要确保安全组的名称是正确的
然后你应该能够正确使用
否则他们将无法
目前 我将创建一个新的安全组
你想演示
群组名称是
在演示部署时创建了安全组
C 使用 ITO 默认创建了两个实例
规则将是这样的
只有资产可以从任何地方启用
根据安装的软件
我们需要自定义并添加一些更多规则
这样所有预期的流量都可以无问题进入这个系统
默认情况下，我们只能搜索那个
我们必须有保管者
没有保管者将无法这样做
如果你删除这个
你将无法登录到系统
即使你有相应的公钥的私钥
你用它创建了易用实例
现在 你可以点击审查并现在启动
你可以说在这里现在启动
我们询问是否选择现有的密钥对还是创建一个新的密钥对
我想要使用的密钥对就是itv
我选择了这个演示一
让我确认这里
让我点击启动实例
现在实例正在启动
您可以通过点击这里查看进度
您可以看到目前它处于待命状态
我们必须等待直到它处于运行状态
并且所有统计都已完成
如果你想回顾一个实例的健康状态将如何被评估，
你可以查看之前的实例，
这是我们配置的，
这就是它应该的样子，
它应该同时处于运行状态，
并且一旦实例的状态更改为待售，所有检查都应该通过，
以及检查通过，
然后我们应该能够使用pm登录到这个实例，
这是我们在创建守护者时早先下载的，
无论使用的是哪个守护者，
在这个实例中，
我们必须选择它来登录到这个实例，
让我们深入这些细节， 一旦统计更改为检查通过
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/065_Udemy - Data Engineering using AWS Data Analytics part1 p65 7. Connecting to AWS EC2 Instance or Virtual Machine using SSH.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


正如我们已经成功配置了实例
现在它已经运行起来了
现在是时候我们连接到它
为此我们必须使用正确的私钥
以便我们能够连接到这个实例
使用适当的详细信息
让我们理解如何照顾好连接到这个实例
让我重命名这个
我命名为e
C two demo
我现在保存它
确保我们选择了易于实例化
我们想要连接到
底部将显示详细信息
在详细信息标签中
在这些详细信息中，您应该能够滚动下来
您可以在这里实际获取密钥和名称
我们使用的密钥对只不过是itv
密钥对名称顶部的demo one
我们还需要理解公共dns或ip
V四地址 这样我们就可以实际将其连接到这个
我们可以通过使用这个公共ip地址或公共dns从我们的mac或pc来通信
确保您审查这些详细信息
您还需要理解您应该使用什么用户名来连接
在这种情况下，您可以选择这个easy to实例并点击连接
您可以在这里看到用户名详细信息
所以这就是用户名
这是公共ipv4dns
这是我们的参考私钥文件
我们不能直接复制粘贴
你可以复制这个
但是粘贴后
你需要为这个文件提供适当的位置
否则它将无法工作
所以在这种情况下，我必须说
因为我设置了短划线i
我们必须指定我们的pm文件的位置
使用短划线 我喜欢这个波浪线在Linux或Mac中表示家目录
然后我们可以说点ssh
然后是itv demo one点pm
然后你想要在那里
公共ip v for dns
我们应该能够通过去实例这里
这就是你可以复制的
你现在应该能够把它粘贴在这里然后按回车
你将不得不说yes
现在你已经在e c two实例内部
你应该能在这里查看详细信息
你可以在这里查看操作系统版本
你可以看到这台机器上的操作系统是
你想要18或4
如果你想要获取主机的完全限定名
你可以使用叫host name hyphen f
你可以看到这台主机的主机名
它基于私有ipv4地址
你也可以通过you name hyphen a命令获取操作系统详情
你可以实际查看操作系统详情
尤其是内核级详情，之前我们获取了ubuntu版本详情
现在我们实际查看内核级详情
它也在这里提供操作系统版本，你可以退出
如果你在mac或linux上运行host name
你会得到mac或linux的主机名
在e
C Two实例中，我们获取了e c two实例的主机名
这就是你应该能够连接到e c two实例的方式
使用密钥对连接
确保你使用适当的密钥对，具有正确的权限才能连接到它
否则你将无法连接到e C Two实例
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/066_Udemy - Data Engineering using AWS Data Analytics part1 p66 9. Overview of AWS Security Groups for firewall security of AWS EC2 Instance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分 让我们理解安全组的基本知识
AWS 创建或选择安全组以定义防火墙规则
为了阻止外部系统意外流量进入EC two实例，我们需要定义防火墙规则
在启动EC two实例时，我们需要选择一个现有的安全组或创建一个新的
EC two 默认情况下，EC two实例
SSH在基于Linux的EC two实例上运行
在AWS上运行EC two实例时，使用22号端口
默认规则作为这些安全组的一部分是打开22号端口，以便我们可以从远程任务中使用它连接
我们将能够使用h登录，除了使用h登录服务器
让我们假设我们想在其中设置一个Web应用程序
如果你想通过http或https访问Web应用程序
一旦它设置完成
我们必须确保端口已打开
否则你将无法连接到在服务器上运行的Web应用程序
让我们执行这项任务来理解安全组的相关性
我们需要确保我们可以连接到之前启动的实例使用se
让我们运行ssh命令
我们之前使用过它
我们已经验证过
我再次运行它
以确认 我现在能够使用这样的方式登录
让我们从这里退出
一旦我们验证过
下一步是
我们必须转到与EC two实例相关的安全组
并且删除与端口22相关的规则
所以我必须去aws网页控制台
让我们去实例这里
一旦它被选中
你应该能够点击安全
你应该在这里看到安全组的详细信息，你可以点击这个
你可以去安全组
一旦你在安全组
你应该能够展开这个并点击编辑入站规则
为什么我们在这里选择入站规则
无论我们试图将什么引入系统
或者我们试图访问系统中的某物
这叫做入站流量
在这种情况下，我们试图连接到系统
因此，这个集被配置为入站规则的一部分
至于任务 我们必须删除这个
让我们删除这个
现在保存规则
如果你试图与一个集连接
它将无法让您进入
因为它无法使用公共DNS与服务器通信
这里 因为规则已被删除
这意味着现在已被阻止，您可以说控制C以退出
再次回到这里
转到操作
说 编辑入站规则
添加规则
大多数端口是TCP端口
然而，这里有一些预定义的端口
例如 如果您要配置一个，无需说
自定义TCP22
您可以直接这样配置SSH
即使您说自定义TCP22
现在应该能工作，作为这里的一部分
我们正试图从任何地方连接到此服务器
因此我们必须扩展并选择任何地方
这将定义源为0.0.0.0/0
现在您可以说保存规则
一旦保存
我们应该能够回到这里
我们应该能够再次运行此命令
这次我们应该能够连接到它
现在 让我们后退并打开22
对于所有人并使用集验证
现在是时候在我们自己的机器上安装Apache了
我们必须登录并运行这些命令
以安装并启动Apache Web服务器
您应该能够像这样更新说sudo apt update
正在更新甚至内核
一旦更新完成
我们应该能够安装Apache Apache只是一个简单的Web服务器
我们应该能够启动它并验证看看
我们可以访问此机器上设置的简单Web服务器
您应该能够像这样安装Apache工具
您可以通过运行此命令来验证Apache是否已启动
默认情况下
当我们实际使用apt安装时，它会自动启动
让我们等安装完成
一旦安装完成
我们将运行该命令来验证
Apache是否正在运行
现在已安装
我们可以回到这里
我们可以复制它
我们可以粘贴在这里
你可以看到apache服务器正在运行
你也可以通过说telnet localhost来验证
从系统中获取信息
我们能够告诉启动中的网络服务器
当我们现在安装apache时
我们可以说control关闭方括号按回车键quit以退出
然而 现在无法从外部系统连接到此
如果我退出 我已经在我的mac上安装了telnet
我应该能够说telnet使用这些公共dns
然后说80
Apache将在80上运行
这就是我们使用a的原因
哦 这个系统上没有telnet
让我安装它
我必须说安装telnet
它将为我安装telnet
一旦telnet安装完毕
我应该能够使用telnet命令来验证我是否能够监听80端口
在我设置的Apache实例上
现在telnet已经设置好
我应该能够运行这个命令
它会像这样挂起
即使服务器在80端口上运行
我们无法连接到它
因为它在安全组中被阻止
我们应该能够使用telnet命令来验证我是否能够监听80端口
在我设置的Apache实例上
我们必须明确地打开它
我们也要用浏览器验证
复制这个公共dns
去浏览器
然后输入http://
然后输入公共dns并回车
你看 它卡住了
因为它无法与e上的第80个端口进行通信
C 现在运行的两个Apache 2实例
你可以关闭此以打开端口
你必须转到安全组
你可以说操作并编辑入站规则
或者你可以滚动到下方
确保选择入站规则
然后点击编辑入站规则
在这种情况下，Apache 2在E实例上运行
C 两个实例 我们正在尝试连接它
因此它就是进入简单实例的流量
所以我们需要为此定义一个入站规则，你可以在这里点击添加规则
你可以使用自定义tcp并输入端口80在这里
然而 对于像http这样的重要端口
Hgdps等
这里有预定义的规则
你应该能够选择http或https
如果你选择https
它将首先打开443端口
如果你选择http
它将打开80端口
我们正在验证http
因此我们必须确保我们选择80端口
当涉及到源时
选择任何地方都不是一个好做法，因为你容易受到DDoS攻击
而不是选择任何地方，你必须选择我的IP
它将选择I
P V 您的系统地址
并且只允许您的系统访问在易实例上运行的HTTP服务器
如果您在家办公室或其他地方工作
您需要在这里配置所有这些
您可以明确指定IP地址
您也可以转到浏览器
您可以搜索您的IP地址
您可以开始输入您的IP地址
为IP地址添加描述是一个很好的做法
确保不要向所有人开放
尤其是如果你的网络应用没有任何形式的身份验证
如果你开放
你将容易受到DDoS攻击
我会说回家
然后我会往下滚动
然后我会保存这个
记住我们的家庭IP地址不是静态的
因此这些IP地址会不断变化
如果你在家或办公室的IP地址发生变化
那么你将无法连接到连接器
即使有一项规则支持特定ip
你必须删除旧的并添加新的
这样如果你的系统生成一个新的ip
作为防火墙规则的一部分
这就是你应该管理的方式
正如我们添加了这项规则
我现在实际上可以进入终端
运行telnet命令
你可以看到telnet如预期工作
我们可以说控制关闭方括号
然后退出 离开这个
我们也可以复制这个
我p v四dns
然后转到浏览器
然后说http列
斜杠粘贴
它按回车
我们可以看到默认的apache为你渲染页面
没有任何问题
这就是你应该能够打开的安全组的端口
让只有预期的流量进入邪恶
作为easy to的一部分运行的应用程序
这就是关于安全组的基本
确保你理解这些基本知识
随着你构建应用程序，你可能需要定义一些复杂的规则
但这是一个很好的起点
确保你对安全组非常熟悉
这将帮助你在调试问题时
每当你开发和部署你的应用程序作为e的一部分 C 二实例
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/067_Udemy - Data Engineering using AWS Data Analytics part1 p67 11. Overview of Public and Private IP Addresses of AWS EC2 Instance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解与aws EC two实例相关的公共和私有ip地址的概念
C 两台实例 通常，每台aws EC two实例都会分配两个ip地址和对应的dns
为了回顾 你可以访问aws管理控制台
你可以选择你感兴趣的aws EC two实例
你可以在这里查看公共信息，在这里查看私有信息
这是公共ip v4地址
这是私有ip v4地址
公共ip v4地址的对应dns是这一项
私有ip v4地址的对应dns是这一项
公共dns以EC two开始
私有dns以ip开始
公共dns以EC two开始
你可以在这里看到
以EC two开始的dns，私有ip v4地址以ip开始
完整的dns实际上是对应ip v4地址的衍生物
你可以查看ip v4地址
它有54.67.115.36
当提到公共ip v4 dns时
你有EC two-54
然后-67
然后-115
然后-36
然后有你的区域
然后.compute
然后.amazon aws.com
当提到私有ip时
这是私有ip
这是dns
它也是这个ip
你可以看到地址和dns
它说ip 然后-1
72-31
然后-14
然后-130
然后.s
然后-然后-1
这是区域
compute internal
这就是私有dns的来源
公共dns或底层公共ip地址可以用来通过互联网访问EC two实例
C 两台实例或运行在上面的服务
来自aws外部
我们看到我们使用公共dns连接到服务器
使用一组
您可以查看assets命令，这是我们之前使用过的
这是我们用于连接到easy to实例的命令
您可以看到我能够登录一次
我在这个easy to实例上设置了apache two
我能够使用端口80连接到apache web服务器
无论是使用telnet还是
使用浏览器
让我复制dns在这里
然后我可以去这里然后说http column slash slash
您可以看到页面没有任何问题地渲染
私有dns作为底层私有ip地址可以在aws内部实例之间用于内部通信
ec two实例
vpc 所以如果您有两个
嗯aws实例
如果您想它们之间进行通信
首选方式
易于使用 私有tyas目前我有两个easy two实例
让我们看看这些两个easy two实例
我应该能够连接到这个easy to实例
使用这个公共dns
使用的密钥是nothing but这个itv demo dot pam
然后easy to hyphen user at the rate
公共dns现在
我现在在里面的机器
让我们看看是否我们能够能够访问ssh
以及远程服务器上的http
远程服务器
私有ip是nothing but
让我们确保我们选择这个
这是私有typ
这是dns
让我们复制这个现在
我可以回到这里
然后我可以说telnet paste
它然后说twenty two
现在 您可以看到我能够在远程服务器上监听到二端口
从这个服务器
当前服务器是on amazon linux
远程服务器是on even two
我可以说control closing bracket
然后quit来出这个
让我们验证端口80
如果验证端口80
您看到它挂起
它挂起的原因是如果你审查与服务器相关的防火墙规则
这是我们在这里试图使用的
如果我在这里进入安全组
你可以看到端口只对我家的系统的ip地址开放
私有ip地址或任何其他ip地址目前没有开放
我应该能够说编辑入站规则作为编辑出站规则的一部分
我可以说添加规则
然后输入http
然后我可以说这个系统的私有ip
这个系统的私有类型p是什么
我能说控制C
然后我实际上可以说ip addr l来列出IP地址
这是系统的私有IP
所以我应该能使用它
我们也可以获取系统的根目录
使用AWS控制台
你也可以验证这个私有IP地址是基于主机名这里的，两者应该匹配
如果他们不匹配
那么它将不会工作
所以这是我们应该使用的地址
这些为什么相同
是因为主机名与服务器相关的私有IP地址
这就是为什么这两个默认会相似
也就是说我们应该能够选择这个的私有地址
容易实例化
去这里输入那个加上斜杠32
你可以说我是demo
私有类型p然后保存，这种情况下你需要添加源系统的IP地址
源系统无非就是aws linux系统
这是我之前为
我现在是demos，我现在能来这里，然后我应该能够运行telnet
你可以看到它运行得很好
现在我们可以关闭这个然后退出
私有的dallas或底层的私有地址可以用于e的内部通信
在aws中的两个实例
虚拟专用云（Virtual Private Cloud） 我们已经展示了如何确保两者可以在端口上进行通信。
我们也为应用程序设置了它
默认情况下 公共dns别名或公共ip地址是临时的
这意味着如果你停止并启动一个简单的实例
很可能现在公共DNS别名和公共IP地址会改变
如果我实际上来这里
如果我去e c two
如果我去实例
如果我选择这个易用性演示
如果我说实例状态停止实例
然后停止当它停止时
公共IP将消失
让我们等到这个停止
然后我们将回顾这一点
您将不会看到任何公共IP
V为地址或公共IP
V为DNS 现在实例状态已停止
您还可以看到公共IP
V为地址和公共DNS IP也已消失
如果我再次启动此CC2实例
我将获得一个新的公共IP
V为地址和对应的公共DNS IP
这就是为什么公共DNS或公共IP地址被称为临时的
这意味着如果您停止并启动一个EC two实例
公共DNS和公共IP地址可能会改变
确保您对公共和私有IP地址的基本知识感到舒适
公共IP地址通常用于外部来源之间的通信
而私有IP地址通常用于AWS内部通信
可能会有一个 EC
两个实例上运行应用程序
可能会有一个RDS
其中数据库正在运行，以在两者之间通信
我们应该使用私有IP
而不是公共IP
确保您理解这一细微差别 随着我们进一步学习和了解更多关于AWS的知识，您将探索这些
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/068_Udemy - Data Engineering using AWS Data Analytics part1 p68 13. Understanding AWS EC2 Instance or Virtual Machine Life Cycle.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


我们来了解一下ECS的生命周期
两个实例 ECS实例会处于以下状态之一
只要没有终止
它将处于运行状态、停止状态或启动状态
如果你停止ECS实例
公共IP可能会重置，因为它是弹性IP的默认设置
你需要保留弹性IP并将其分配给ECS实例
以便公共IP不会改变
我们将在下一个主题中详细探讨这些细节
只要这两个实例处于停止状态
你将不会为实例付费
但如果你使用EBS存储
你将要为此付费
让我们深入了解一些细节，以便你理解我所说的内容
如果你进入ECS控制台
你应该能够看到实例列表
目前有两个实例
如果我们选择ECS demo
你可以看到没有公共IP
V为地址或公共IP V为DNS
因为状态是停止
这就是它会变成的样子
如果你没有使用静态IP
如何确保实例的静态IP
我们将在下一个主题中详细探讨这些细节
现在要更改状态
你可以实际上扩展这个
你需要选择ECS实例
你可以像这样选择多个
然后你应该能够选择实例状态
你应该能够启动实例
我们启动实例
停止实例
终止实例 以及休眠实例
让我们选择一个来启动
你只需扩展并点击启动实例
现在它将处于等待状态，直到变为运行状态
等待状态是暂时的
它将在启动时处于等待状态
一旦启动 它将变为运行状态
但你需要等待状态检查通过
只有状态检查通过
你才能连接到实例并做你想做的事情
有时即使状态检查未通过
你也可能能够连接到实例 但大多数功能可能无法正常工作
一旦用于应用程序
所以你必须等到状态检查通过
让我们等到统计通过
现在状态已经改变
它处于运行状态，状态检查仍在初始化状态
我们需要等到它说二对二
所有检查通过 让我们刷新这个
我们需要一些时间来看到统计通过
让我们等到统计通过
现在 你可以看到状态检查的状态
它说二对二检查通过
现在so正在运行
我们应该能够连接到它
使用a 如果有任何应用程序在它上运行
我们应该能够访问那些等等
如果你想停止实例
你只需扩展这个并说
停止实例 你也可以重启实例
如果你重启实例
itu与公共相关的地址将不会解关联
它们仍然与这个实例相关联
例如 现在
公共 Ip
V 地址是54.151.253.194
即使你重启
公共ip将被保留
让我们点击重启
你看到这里的消息已成功重启
重启很快
你可以看到公共ip地址仍然是54.1
53.125.194
公共dns iv不过是ip的衍生
V地址 因此它也不会改变
这就是在报告上管理公共ip的方式当你停止实例时
公共ip地址将被解关联
当你再次启动实例时你将看到一个新的ip地址
这些都是e
C Two e two的生命周期详情
e two将处于运行状态或停止状态
或重启状态
取决于你执行的操作
在这些之上
你也可以通过选择实例来终止实例
然后点击终止实例
这将确保实例从您的账户中移除
然而 与实例相关的EBS卷可能会保留
这完全取决于您如何配置卷
我们将在后续的时间详细讨论这一点
当我们详细讨论卷时
目前 只需关注ECS的生命周期
两种状态ECS可能处于
也可能处于 也有休眠选项 很少会使用休眠选项
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/069_Udemy - Data Engineering using AWS Data Analytics part1 p69 15. Allocating and Assigning AWS Elastic IP or Static IP address to AWS EC2 Inst.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分
让我们了解如何配置静态弹性IP地址，以便于实例管理
这样当我们停止和启动公共IP时
IP将不会改变
我们需要访问AWS网页控制台
然后转到EC two控制台
我已经在EC two控制台或EC two管理控制台上
在左侧你可以看到有一个叫做网络和安全的选项
在网络和安全下
你需要转到弹性
IP这里你可以点击弹性IP
目前我的账户中没有弹性IP，无法分配新的IP地址
或者释放新的IP地址
我们需要点击分配弹性IP地址
你可以点击分配弹性IP地址
你可以看到有一个选项叫做亚马逊的
IP地址池
我们应该选择这个选项
其他选项目前无法使用
因为我们是学习者，可能无法使用
它们可能现在已经可用
你可以向下滚动 你可以说分配，它会分配一个新的IP地址
让我们给这个IP命名
我将使用它进行EC two演示
因此我给它命名为EC two演示
然后保存，这就是你更新IP地址名称的方式
一旦分配了弹性IP地址
你需要选择它
然后点击操作
然后你需要点击关联弹性IP地址
分配是释放IP地址
关联是实例与IP地址关联
你需要选择实例
网络接口
我现在不确定，选择实例
然后你可以选择实例
你可以看到
有一个实例叫做EC two演示正在运行
命名时非常重要
可能会有多个私有IP地址
如果你想将公共IP与特定的私有IP地址关联
你需要这样做
然后选择IP地址
因为我们只有一个 我选择那个IP地址
让我们理解自由关联的概念
目前我们只是分配了IP地址并关联它
有时候我们可能有已经与某些EC
关联的IP 两个实例 并且那
C 两个实例可能被停止
你可能想将该IP地址重新关联到其他实例
这被称为关联
将一个实例的IP地址关联到另一个实例称为关联
在我们的情况下我们没有重新关联
因此无论我们选择与否
都无关紧要 我不选择
我只是点击关联
现在弹性IP将映射到该EC two实例
现在我们必须使用这个
IP V为地址
V为DNS以实际从外部客户端连接到该实例
让我们通过设置验证
我们是否能够使用该新关联的静态IP地址连接到EC two
C 两个实例 使用此新关联的静态IP地址连接到EC two
V为地址 让我们获取连接信息以获取正确的信息
我们可以滚动并转到实例
我们可以选择实例
然后点击连接
当你从弹性IP到此
立即在关联后
你可能不会看到IPV4 DNS
刷新为IPV4地址
确保IPV4地址和IPV4 DNS不一致
你可以看到两者一致
IPV4地址是
541771886868
DNS是EC two
连字符54
然后17177
然后188
然后668
然后区域点计算点亚马逊点com或亚马逊aws点com
这意味着它是正确的
你应该能够点击连接
让我们审查连接信息
它也反映所关联的
Elasticp到CC2实例
你应该能够复制
然后你可以到这里
然后我们必须说连字符
我切换 ITV DEMO ONE
这是应该使用的 pem 文件
然后你需要设置 DNS 指向公共 IP 地址
这是基于新的关联公共 IPv4 地址生成的
我们必须说 yes
然后按回车
你可以看到我能够登录到这个 easy to 实例
这就是你应该能够分配和关联静态 IP 的
你有一个 easy to 实例并且已经登录
如果你回到 e
C two 控制台 如果你点击实例
如果你选择这个实例
然后说实例状态停止
点击停止后
它将在几分钟内停止
即使 easy to 实例状态更改为停止
你可以看到公共 IP 地址和公共 IPv4 DNS 仍然存在
它们没有从这个实例解关联
如果你再启动它
它将保留这个公共 IPv4 地址和 DNS
这就是使用弹性 IP 的优势
我们只需要为 e
C two 分配和关联 即使你停止一百次每次
你启动相同的 IP
IPv4 地址和 DNS 将与该 easy to 实例关联
你应该能够使用相同的消息命令连接到 tc to 实例
了解弹性 IP 的目的非常重要
也请记住弹性 IP 与之相关的成本
在使用弹性 IP 进行学习之前，请确保您了解这些成本
然而
成本非常微不足道 在使用弹性 IP 地址时，成本不会太高 然而，成本非常微不足道
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/070_Udemy - Data Engineering using AWS Data Analytics part1 p70 17. Managing AWS EC2 Instances or Virtual Machines Using AWS CLI.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


当我们对如何管理EC two有了一些理解，我们可以通过AWS CLI轻松地让一些人理解这是如何工作的。
C 使用AWS CLI创建两个实例
我们应该能够处理与管理所有与EC two相关的任务。
通过AWS CLI轻松管理两个EC two实例
这里有一些你可以创建或使用现有密钥对的示例。
你可以创建两个EC two实例
你可以将安全组附加到EC two实例，你可以管理安全组的规则。
你可以停止或启动实例。
你也可以停止或终止实例。 你可以为EC two实例分配和附加弹性IP。
你可以描述实例以获取与实例相关的所有元数据。
这些都是你可以执行的几乎与EC two实例相关的所有任务。
使用命令行，让我们先复习一下
让我们复习一下如何在AWS CLI中获得帮助。 你可以使用AWS CLI获得帮助。
你可以使用aws cli help命令获得帮助。
让我转到终端。
你可以使用aws EC two help命令获得帮助。
这将为您提供有关EC two的所有文档。
你应该能够按空格键。
你应该能够看到AWS CLI中的所有可用命令。
你可以查看这些大量的命令。
至少有100到200个命令。
我没有数过。 但是有很多命令。
根据你的需求，你应该能够探索。
你应该能够选择所需的命令并进一步操作。
让我们离开这里。
你也会看到示例。
但是，如果你想了解EC two中特定子命令的帮助，
你可以说aws EC two help。 例如，describe instances命令。
你可以说aws EC two help describe instances。 你将看到有关describe instances命令的文档。
但是，如果你想了解describe instances命令的帮助， 你可以说aws EC two help describe instances。
你将看到有关describe instances命令的文档。
describe instances命令本身就非常庞大。
你需要查看不同的选择。
你还需要了解与实例相关的元数据。
话虽如此，让我们通过执行一些基本任务来预热EC two实例。
使用AWS CLI，我们将使用itv_admin角色作为用户帐户。
你可以看到与实例相关的元数据
它位于主要标签下
称为保留
它是列表中的列表
你又有了实例
这是列表的一部分
你将获得我们环境中所有实例的信息
你可以按空格查看所有元数据
这是因为描述实例的命令
然而 元数据中有实例ID
如果你想获取实例ID
你所需要做的就是
你只需抓取和获取实例ID
还有一种方法
也作为替代方法的一部分
我们可以使用查询 我将在下一节中讨论查询
我将详细介绍
E C 二在下一节中
也在一个主题中
我将演示如何使用查询并仅项目您感兴趣的字段
如果你熟悉Linux
你可以将一个命令的输出管道到另一个命令
在这种情况下，第一个命令什么也不是
但这一个
它将实际描述实例
输出，也就是JSON，将管道到这个group命令
并且我们正在查找实例ID
我们使用连字符i
这样它就可以不关心大小写进行比较
现在我应该能够按Enter
你可以看到实例在这里
这就是你应该能够获取实例ID的方式
现在你可以使用一个实例ID并获取实例状态
你应该能够使用描述实例状态来获取一个或多个实例的状态
在这种情况下，你可以实际上复制这个
然后转到终端
粘贴它 然后说帮助
你应该能够查看文档
按空格滚动
你可以看到它接受实例ID
这意味着你可以传递多个实例ID，而不仅仅是一个
然而 我将只演示一个实例，那就是说
让我们离开这个
你应该能够运行这个命令来获取这个易用性实例的状态
让我们在终端复制并粘贴
按回车 你应该能在这里看到实例状态
之所以写成列表是因为我们可以用这个命令处理多个实例
现在您可以在这里看到详细信息
实例正在运行
它是可访问的
所有检查都通过了
因此您可以看到与当前实例状态相关的所有详细信息
现在我们可以退出
我们应该能够为另一个实例运行相同的命令
另一个实例就是
这个所以我只需要说
aws 描述实例状态的简单方法
然后实例ID
让我复制并粘贴这个
然后空格
然后这个实例ID
然后我必须指定配置文件
当涉及到EC two命令时，我必须指定区域
我们必须指定区域
如果区域没有作为配置文件一部分设置
因为我的EC two实例在us west one下
我在这里指定了us west one作为区域
现在你应该能够按回车，因为实例已关闭
它没有显示任何状态
有时它会显示
有时它不会显示
当你刚刚停止时
它会在一段时间内显示信息
一旦它完全停止
它不会显示任何信息
既然我们已经理解了如何获取实例状态，让我们进行一些更多任务
下一个任务就是
停止实例并验证实例是否已停止
要停止实例，您应该能够运行此命令
所以这种情况下啊
实例零七c blah blah blah正在运行 我们已经验证了
我们也可以转到aws管理控制台
我们可以确认这个实例仍在运行
我们应该能够刷新这里
您可以看到它正在运行
我们可以回到这里
我们可以粘贴此命令
它会处理停止实例
您可以在这里看到详细信息
它处于停止状态
现在让我们停止另一个实例
我们必须等到它完全停止才能再次启动
然而，当它被停止时
我们应该能够通过在这里运行describe instance status命令来检查状态
所以让我们运行这个命令来查看实例状态
让我们在这里粘贴并按Enter
你可以看到目前没有写入任何实例数据
因为实例已经停止
你应该能够访问aws管理控制台
你可以实际刷新此页面以确认实例已停止
这就是你应该如何使用aws停止实例
在命令行中使用E c two命令
让我们启动实例并验证实例是否已启动
为此 我们需要使用启动实例命令
所有这些命令可以同时操作多个实例
您可以将实例ID或实例名称作为参数传递
这两个实例的状态在这里
我在E c two控制台
您可以在这里点击实例查看其状态
他们两个都在状态中
我们已经添加了这个实例ID
作为启动实例命令的一部分，现在我也想添加这个
我可以点击它 我可以点击这个来复制到剪贴板
然后我应该能够在这里粘贴它
您可以通过实例ID参数在命令中传递多个实例
例如启动实例
停止实例
等，通过它们之间使用空格
所以在这种情况下，我已经传递了两个实例ID在这里
它们之间用空格分隔
让我们也格式化这个实例ID
以便它与其他实例ID看起来相似
关于要传递的实例，参数可以是
你可以说实例ID或实例ID在这里，现在我们应该能够复制这个
回到隧道
粘贴 它按了回车
请求启动
现在开始启动它们
我们可以从这种状态中解脱出来
我们可以去aws
我们应该能够转到实例
你可以看到他们处于待命状态
现在很快它们就会被启动
如果你想获取两个实例的状态作为实例id的一部分
你应该能够像这样指定两个实例id
使用describe instance status命令
你应该能够获取两个实例的状态
让我复制这个并运行它
你可以看到这台实例处于运行状态
并且这台实例也处于运行状态
现在我们可以退出这个
你也可以去aws easy管理控制台
你应该能够查看状态
现在它们都处于运行状态，其中一台实例有弹性IP
如果你想列出弹性IP
你应该能够使用称为describe addresses的命令
让我们运行这个命令并看看它是否会返回弹性IP
或否 我已经复制了并粘贴在这里
我可以按回车 我应该能够看到分配给实例的弹性IP
一零七 blah blah blah
这就是你应该能够通过命令行获取易二实例详细信息的方式
这只是一个热身
随着我们继续学习和了解易二实例，我们将使用其他几个命令
e C 二实例
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/071_Udemy - Data Engineering using AWS Data Analytics part1 p71 19. Upgrade or Downgrade of AWS EC2 Instances or Virtual Machines.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分
让我们了解如何升级或降级EC two实例
使用AWS管理控制台
增加内存或CPU或两者都称为升级
EC two实例
减少内存或CPU或两者都称为降级
EC two实例 这里我们谈论的是垂直扩展
升级或降级
具有不同配置的同一实例，除了垂直扩展之外，没有其他
增加更多的服务器是将一些服务器从一个服务器集群中移动到另一个服务器集群。
被称为水平扩展
我们通常谈论横向扩展，比如emr等更简单的情况。
让我们一步一步来升级
除了不要获取e c two实例
是的 您必须登录到aws管理控制台
我已经登录了
我也很容易安慰
一旦你进入了e c two控制台
转到实例状态并停止实例，选择我们要升级的实例
在这种情况下，我想使用easy to demo作为示例
所以我必须选择这个
您可以在这里转到实例状态
您可以停止、重启或终止实例
在升级或降级实例之前，您必须停止实例
如果您转到操作
如果您转到实例设置
目前更改实例类型功能已禁用
因为这台实例正在运行
那么我们通过选择实例状态来停止它
然后点击停止实例
一旦我们停止了实例
然后我们可以去操作
然后选择实例设置并点击更改实例类型
让我们回到易于管理的控制台，看看实例是否已停止
它还在停止中
你可以通过点击这里刷新
我们必须等到它完全停止
让我们等到它停止
然后我们尝试将其升级到两微米，这是最低的配置
因此我们将其升级到两中
在此实例停止后
现在易演示实例已停止
我们应该能够选择这个
转到操作 转到实例设置
点击更改实例类型
你可以看到它是t two点微
我们应该能够扩大这个
在选择实例类型之前，我们应该了解每种实例的配置，以便根据我们的需求选择合适的类型
在决定选择哪种实例之前，我们应该了解每种实例的配置，以便根据我们的需求选择合适的类型
目前只是为了演示
我将其升级为t2.medium
我必须打电话
选择t2.medium
然后点击现在应用
您可以看到实例类型已更改为t2.medium
我们只需选择这个
然后我们可以说实例状态
开始
它会处理启动实例
一旦实例启动
我们应该能够登录到e c two实例
我们应该能够验证内存和cpu
我也会演示如何登录到这个
然后运行几个命令来理解实例的配置
从实例自身的角度理解cpu和内存
你也可以在谷歌上搜索t two medium
你应该能够得到关于t two medium配置的详细信息
但我们应该熟悉理解实例本身配置所涉及的步骤
我将演示这一点
一旦实例启动
让我们刷新一下，看它是否正在运行，它是正在运行
但我们必须等到状态检查更改为过去
然后我们将实际登录到易实例
现在您可以看到实例正在运行
统计数据也已过期
我们应该能够选择这个
我们可以滚动查看 到达公共区域
Rpv for dns
然后转到终端
然后我们可以说ss它-
I ~
斜杠 点它
Itv demo
让我看看这里的键
我认为键是itv demo而不是itv demo
但我们会看到它是一个演示版本
所以我必须在这里选择itv demo one dot m
然后你想添加粘合剂
这里的公共dns输入现在您已经进入了易于实例
我们可以运行一个名为自由破折号的命令
实际上获取内存细节的钩子
你可以在三点看到记忆
八 db 带有 t 两个小圆点 medium
如果你想获取CPU的详细信息
你可以运行名为cpu的命令
你可以按回车
你可以在这里查看详细信息
它有一个2核虚拟核心和3GB内存是t2.medium的配置
这就是你应该能从系统中获取详细信息的方式
因为我们已经这样做了
让我们回去 正如你已经理解如何从系统中获取内存和CPU详细信息
让我们回到材料
让我们了解如何使用命令行升级或降级
如果你想停止实例
你可以像这样使用停止实例
让我运行这个
它会停止实例
让我回到这里
我可以粘贴这个按回车
我正在使用itv管理员配置文件
因为我在我的账户上有管理员权限
现在你可以看到状态正在停止
我们必须等到它完全停止
我们可以回到aws管理控制台
我们应该能够刷新这里
你可以看到状态正在停止一旦它停止
我们应该能够运行这些命令
下一个命令是mod
对于实例属性
像这样 我们应该能够修改
因为实例已经升级到t2.medium
我将其更改为t2.micro
我将使用命令行降级
一旦降级
我们应该能够描述实例作为描述实例命令的一部分
我们应该能够获取实例类型的详细信息
然后我们将实际启动实例
让我们从命令行运行describe instances来确认它是否已经完全停止
让我粘贴这里
让我们这里滚动一下
现在它停止了
我们可以回来
我们也可以从浏览器确认它现在已停止
如果你回到文档
我们应该能够获取到这个命令叫做修改实例属性
我们应该能够将实例类型更改为t2.micro
让我更改这里
然后让我复制粘贴这个命令
现在属性已修改
我们可以退出这个
我们应该能够运行这个命令
叫做describe instances
粘贴这里按回车
你可以检查实例类型
在这里，它在预订实例下
然后实例类型
它只不过是t two dot micro
因为你成功地降级了
我们应该能够通过运行这个启动实例的命令来开始
这就是你应该能够通过命令行升级或降级的方式
现在我可以离开这个，也可以去aws
易于管理的控制台
让我们刷新一下
你可以看到它正在运行
并且实例类型是t two dot micro
我们已经看到了如何垂直升级或降级
无论是使用浏览器中的简单管理控制台，还是命令行
确保你对这两种方法都感到舒适
并且当你想要执行一系列步骤时
你需要理解流程
然后你应该能够构建命令
并用这些命令来处理流程
你需要首先理解工作流程 然后你需要用命令来处理它
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/072_Udemy - Data Engineering using AWS Data Analytics part1 p72 1. Understanding AWS EC2 Instance or Virtual Machine Metadata.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


到这时候你应该已经熟悉了如何创建一个EC two实例
C 两个AWS实例
让我们了解有关EC two实例的元数据详细信息
C 两个实例 创建实例时执行的所有操作都视为元数据
有一些默认的附加信息
关于EC two实例的一些关键方面
C 选择实例类型，即EC two实例
即内存、CPU和实例存储
为防火墙配置安全组
C 密钥对 登录
私有和公共IP地址
以及DNS CSS
以及VPC和子网
我们可以以JSON格式获取所有元数据
通过运行describe instances命令
你可以实际使用这个命令生成JSON
你应该能够查看这些信息，以了解有关实例的所有信息
让我复制这个命令
让我进入我的终端
在这种情况下，我将在本地终端中运行此命令
现在应该已经创建了一个名为that instances的文件
点json 你可以实际说y on lt
然后instances点json
你可以看到文件已经创建
我应该能够使用view命令打开此文件
如果你使用的是Mac或Linux终端
如果你使用的是Windows
你可能需要用一些高级编辑器打开它
例如notepad++或其他你想要使用的
不要使用notepad，话虽如此
让我们运行这个view
你可以实际看到这是一个JSON
文档包含一个大的JSON
它只有一个JSON记录
这个JSON记录的键什么也不是reservations
值什么也不是列表
这是一个一列
一个记录的JSON
这个JSON记录的键什么也不是reservations
值什么也不是列表
你可以看到这里有一个方括号
这意味着它开始reservations列表的列表
你将会收到实例的详细信息
要获取特定实例的详细信息，你必须说预订
然后实例作为实例的一部分
这里有实例的详细信息
您可以查看监控详细信息
放置详细信息
私有DNS详细信息 私有IP地址详细信息
状态 实例当前处于停止状态
您可以向下滚动以获取更多信息
您可以获取EBS的详细信息
这是实例对应的存储卷
如果有多个EBS卷
您将拥有多个块设备映射
这就是为什么这里有列表
这就是所有与实例相关的详细信息
我们还有网络接口
所有这些都与一个特定的实例相关
我们还没有进入第二个实例
这是我们所有的元数据，让我们向下滚动
我们在预订中的第二个元素
作为这一部分
这里有实例的详细信息
第二个实例与这个相同
它是在t two点medium之后
密钥名是itv demo two
它实际上已经终止
你应该能看到状态已经终止
然后你应该能够滚动
理解这种嵌套相邻结构非常重要
否则您将无法有效地使用命令行提取您正在查找的信息
现在我们进入了第三个实例
在实例中我们有实例的详细信息
这也是t two点micro类型的实例
密钥名是itv demo one
让我们检查状态
我们可以实际上滚动
状态是运行
我们获得了关于第三个实例的详细信息
如果你回到airless管理控制台
你应该能看到三个实例在这里
一个是停止的 一个是终止的，一个是运行的
这就是我们在jason中看到的
现在您可以退出这个了
而不是像这样反应两个实例.jason
我们应该能够过滤信息
我们正在寻找 处理方式是
我们可以删除这个重定向
然后管道将其提取为破折号
我想获取实例信息
因此我可以说
实例ID像这样 我们应该能够获取只有实例信息
这就是如何提取信息的方式
然而 这不是描述实例时最合适的方式，实例有额外的控制参数
例如过滤 查询
等 使用这些额外的控制参数
我们应该能够以我们想要的方式提取信息 让我们进入这些细节作为后续主题的一部分
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/073_Udemy - Data Engineering using AWS Data Analytics part1 p73 3. Querying on AWS EC2 Instance or Virtual Machine Metadata.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解如何从元数据中获取特定的属性
在描述实例时
使用aws简单命令
我们可以使用短划线 短划线查询来投影与特定属性相关的元数据
由于元数据以json形式表示
我们需要使用完全合格的json路径来指定属性
例如 如果我想获取实例sidetails
我必须使用reservations星号像这样
然后点星号instances像这样
然后我必须像这样指定实例id
如果你想给这个添加一个别名
你必须使用这个
如果你想使用相同的名称
你必须说列实例id实例id
然后你将只获取实例id的信息
根据你的需求
你可以甚至给一个这里
这不必与这一样
让我们看一些例子
以便您了解如何使用查询以提取您正在查找的信息
那 我正在进入终端
你应该能够说aws easy to describe hyphen instances
然后帮助
如果你进入describe instances帮助
你可以看到有过滤器
还有查询
我想查询在这里没有突出显示
但你应该能够使用
查询几乎对所有命令都有效
我想那是为什么这里没有显示查询现在
你可以实际上滚动
如果你想看一些例子
在这些文档的末尾有一些例子
你可以实际上去查看它们
你可以尝试他们提供的一些例子
这里有一些与查询相关的例子
还有与过滤器相关的例子
你现在可以看到查询这里
如果你回到我们之前创建的json
你可以看到实例
id在reservations中
这是列表的一部分
我们有与实例相关的多个条目
每个条目都包含实例
它又是列表的一部分
我们有与特定实例相关的属性
如果我想访问实例id
我必须说，星号在方括号中的保留
因为它是列表 然后点实例中的星号在方括号中
因为它是列表类型
然后你应该能够通过直接指定
关于实例ID，实例类型等
然而 如果它是嵌套的json
你必须这样做
我们使用点表示法来进一步
进入嵌套数据
例如 如果我想获取状态
我必须说，星号点
实例中的星号点在花括号中
监控点状态
这就是我应该能够获取到的状态详情
我们将看一些例子 以便您首先理解
让我们理解如何获取实例本身
为此 我们只需说aws
易于描述-实例
然后连字符-查询作为查询的一部分
我们必须在查询逻辑中指定单引号像这样
因此在单引号中我们必须说星号
因为它是列表类型
然后实例中的星号
然后你必须说点
然后在花括号中像这样
你必须说星号的别名首先
然后冒号
然后您要获取的属性
在这种情况下，我只想获取实例ID
这就是我应该能够获取与实例ID相关的详细信息输出
json是默认的
即使您没有它，也没有关系
但我以json格式输出 然后配置文件itv
管理员
区域s-西-一
让我们按Enter键，它说null
这意味着某种类型的某个地方
让我离开这个
他们在保留字中有一个拼写错误
这就是为什么它没有抛出任何其他东西
但输出说null与变化，现在将起作用
您可以看到只有实例现在是
而不是只获取实例
让我们假设我们也想获取实例状态，让我们理解状态是如何表示的
然后我们将实际改进获取状态的命令
让我退出这个
让我们打开实例.jason
如果你进入实例.jason下的预订
在实例中我们有实例ID
这就是实例ID
如果你想获取状态
它是运行 终止或停止
有一个嵌套的jason叫状态，在那里
我们有代码和名称
这个状态.名称实际上会告诉我们它是停止还是终止或现在运行
如果你想获取此信息
我们必须说预订的星点
实例的星点状态名称点
然后我们应该能够获取此实例的状态
让我们退出这个
让我们回到之前在这个中我们使用的命令
我们只需说在实例实例ID上
我们可以指定
状态设置别名
然后状态.名称获取状态
你现在可以运行
你可以实际上看到详细信息
这个实例处于停止状态
这个实例处于终止状态
这个实例处于运行状态
这就是你应该能够使用查询来获取你正在寻找的元数据
你将能够获取元数据
你从这里所有的实例中寻求的任何内容
我们可能想获取仅停止实例或终止实例或运行实例
为此我们需要使用过滤器
让我们了解如何使用过滤器来根据某些过滤条件获取实例信息 基于某些过滤条件
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/074_Udemy - Data Engineering using AWS Data Analytics part1 p74 5. Fitering on AWS EC2 Instance or Virtual Machine Metadata.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分 让我们了解如何过滤数据
在描述实例时，首先使用ais很容易
让我们看看describe instances的帮助
我们可以使用aws EC
来描述实例
帮助像这样 我们应该能够给您提供帮助
作为describe instances的一部分，我们拥有的一个控制参数就是过滤器
它是可选的 这就是为什么它用方括号指定
您可以将值传递给filters
当涉及到值时 您必须使用名称
以及作为本名的值
您可以实际传递这些值
这里突出显示的值
亲和力架构等
在这种情况下 如果我想获取特定类型的所有实例
有一个名称
实例类型 您可以在这里看到
我必须说名称是实例类型
作为值
因此我们可以指定它是t two dot micro还是t two dot medium
所以等等 这就是您应该能够获取特定类型的实例的方式
您可以滚动到下方
您应该看到示例在这里
让我们滚动到底部
让我们回顾这一部分的文档
这就是您应该能够传递过滤器的方式
您可以传递多个过滤器
您也可以说名称等于实例类型,值等于t two micro
然后您可以指定其他名称和相应的值
您应该能够进行过滤
这将作为结束，那就是这么说的
现在让我们转到文档的结尾示例
如果您查看示例
与过滤器相关的示例有很多
您只需浏览这些并理解那些的含义
也会在这个主题中执行一些与过滤器以及查询相关的任务
但如果您想看到更多示例
您可以实际上转到文档的末尾
与过滤器相关的示例有很多
让我们离开这个，让我们获取所有易二实例
这些是t two dot micro类型的
命令的方式必须是这样
你必须说aws e c two describe hyphen instances
然后hyphen hyphen过滤名称
这是有敏感性的
你必须只输入名称像这样
我们正在寻找t two dot micro实例类型
因此名称必须为实例类型
然后逗号
然后作为值的一部分
你可以指定任何实例步骤
你可以使用逗号分隔符查找您正在查找的实例
在这种情况下，我正在寻找只有t two dot micro
因此我可以说t two dot micro像这样
然后我可以说profile itv
管理员区域s hyphen west hyphen one按回车
您可以在这里看到实例详细信息
这里有两个t two dot micro实例
您应该能看到两个实例详细信息
一个是这个
好的 我想这里没有显示输出
这不是正确的一个
这里有些地方出错了
让我离开这里
是的 实例类型有拼写错误
这就是为什么它现在确实没有显示任何东西
我现在可以实际说实例类型
您可以按回车 您应该能看到输出
这是一个实例，类型为t two dot micro
还有其他实例
如果我滚动
我应该能看到其他实例详细信息
现在我们有两个实例，类型为t two dot micro
让我们离开这里
如果您回到文档
下一个任务说仅获取t two dot micro实例的实例类型和状态
我们需要使用过滤器来获取
或者微实例在过滤器之上
我们还必须使用查询来仅获取实例id类型和状态
我们应该能够运行此以仅获取实例
我类型和状态为t two dot micro实例
让我复制这个
然后转到终端并粘贴它
我可以按回车 我应该能看到关于实例实例类型和状态的详细信息实例id
实例类型是实例类型
状态是状态
我们得到了状态的名称
对于该实例，状态为停止，对于该实例，状态为运行
这就是你应该能够使用查询在过滤器上的方式
以获取你想要在过滤数据上获取的属性
现在让我们离开这里
让我们去文档
让我们在任务中执行
任务说只获取两个点微实例的实例ID类型和状态
所以在这种情况下我们必须检查两个点微以及top
它将像这样工作，作为过滤器的一部分
我们必须说名称等于实例类型
值等于两个点微实例
然后空格名称等于实例状态名称
然后逗号值等于停止
这将首先处理过滤
顶部实例以及两个点微实例
这将作为布尔值工作
现在你应该能够复制这个
你应该能够获取ID类型和状态
微实例在停止状态
让我粘贴在这里并按Enter
我们只有一个实例的ID
I-hyphen-零-零-blah-blah-blah
这是类型两个点微
这是在停止状态
你应该能够去易于管理控制台
并且你可以从这里来
这就是我们看到的实例ID
这是类型两个点微
在这里也是停止状态，我们也只获得了那个记录
我们没有获得其他两个
这就是你应该能够使用过滤器过滤数据的方式
然后在其上使用查询以查询你想要查找的属性
确保你真的对这些两个舒适
这样你就可以使用aws cc来描述实例
命令为你的自动化
也请记住，重要的控制参数是命令，例如过滤器
查询可用
不仅限于易于描述实例 可能有其他几个命令支持这些东西 语法将几乎相同
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/075_Udemy - Data Engineering using AWS Data Analytics part1 p75 7. Using Bootstrapping Scripts on AWS EC2 Instance or Virtual Machine.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解如何照顾安装额外的库或软件
就像这样容易 第一次创建和启动两个实例或启动
我们将终止现有的easy two演示文稿，
我们将使用启动脚本创建一个新的
启动没有什么，执行某些指令
当实例第一次启动时提供的指令
让我们去easy two管理控制台
终止这个实例
我说实例状态终止实例
它将被终止因为它已经终止
我将启动一个新的实例
实例的类型将是ito十八四
这就是我想要使用的
我想使用t二点微
我们可以去配置实例详细信息
我们应该能够在这里提供说明
我们将稍后再回到这里
我将在这里不添加任何说明启动实例
然后我们将实际上看到使用引导脚本的区别
或者不使用引导加载
在这种情况下 我以不使用引导加载的方式启动实例
我可以说在这里添加存储
保留为8添加标签
让我们点击添加名称
标签 名称无非就是
E c two demo配置安全组
我将使用现有安全组
我会选择这个，端口80和2222都是打开的
然后我应该能够点击审查并发布
然后说发布
让我们使用看守的演示
我承认 然后点击启动实例
使用itv看守演示
启动这个实例
让我们等到它启动
我们将连接并实际上看看是否能看到我们的软件
这些被突出显示作为这个的一部分
将审查apache到python pip
以及也aws cli
让我们等到这个实例启动并运行
现在实例正在启动
让我们选择这个 我们应该能够获取公共
IP v之前dns
让我们复制这个
让我们回到频道
让我们说 ssh 斜杠
我 ~ /.ssh / itv-demo.pam
然后你想获取粘贴这个公共 DNS 并按回车
让我们说 yes
我们现在在 easy to 实例内部来验证 apache 是否设置好了
我们只需要说 sudo system l status apache2
你可以看到服务无法找到
这意味着 apache 在这个机器上没有设置好
我们也实际上可以说 python3 -m pip
安装 config parser
你可以看到它说没有找到模块 pip
原因是 p 在这个机器上没有安装
我们也可以说 aws
EC two 我们应该能够说 describe instances 如果 aws 设置好了
也如果 aws 配置好了
这种情况下甚至没有设置好
但这是为什么它说 and not so
在这个时间在这个机器上我们没有任何软件
如果你想要安装 我们应该能够复制粘贴这些命令
它会处理安装 apache2 python3 pip
以及 aws cli
让我们运行这个 我们应该以 sudo 运行这些
让我说 sudo su - root
然后我运行这些命令
它会处理更新 ubuntu 内核
然后它会处理安装 apache2
以及 python pip 以及 aws cli
一旦所有命令运行
我们应该能够验证
来确认 apache2 设置好了
以及 aws cli 设置好了
我认为它只安装了 apache2
它没有运行所有命令
让我们运行这个
即使我复制粘贴了所有命令
它只运行了前两个命令
现在正在运行下一个命令
主要是安装 python pip
一旦完成 我们将会安装 aws
我们可以在 linux 上安装 a 的一种方式是使用 python pip
所以使用 python pip
我们应该能够安装 a wi
让我们运行这个一旦 pp 设置好
这将验证 pp 也安装在这个机器上
然后在运行那个命令后
我们将会使用 aws 命令来验证 aws 是否设置好了
现在
AWS 已经使用 pip 安装
我们应该能够说 aws
容易描述实例
因为我们没有配置
AWS cli
它将会抛出一些错误
在这种情况下，它已经抛出说您必须指定区域
即使我指定了区域
仍然不会工作
因为我们必须配置凭据
但我们已经安装了所需的软件
我们已经安装了 apache 到 pip
并且使用 pip 我们已经安装了 aws si，现在我希望将其作为我所有 easy two 实例的一部分
这就是 where bootstrapping 发挥作用的地方
让我退出这里
让我退出 让我清除屏幕
让我到这里来
让我终止这个实例
我正在终止这个实例
以及它已经终止
让我们点击启动实例
我们再次选择 you to eighteen of four
让我们选择 ito eighteen four
让我们选择 t two dot micro 配置实例详细信息
让我们滚动
这就是你应该指定的地方
所期望作为 part of the bootstrapping 执行指令
确保您将其作为第一行添加
否则它将不会解释为命令
并且您不需要指定伪这里它将自动运行为伪
即使您不空格
空格 sudo 因此不需要指定伪在这些注释之前
让我们复制这些注释
然后说添加存储
然后添加 tax name 什么也不是 e
C 两 demo 配置安全组
选择现有安全组
选择这个
然后说审查并启动
使用 itv demo
确认启动实例
现在实例正在创建
让我们等待实例启动并运行
然后我们将实际登录和有效
是否所有那些指令都已执行作为 part of the bootstrapping 的这个实例
现在实例已经启动并运行
让我们在DNS之前复制公共IP
去终端
就像我说的那样 连字符
我tilde斜杠点它是
然后itv demo
这是我们在创建实例时使用的密钥
然后我们可以说我们希望为DNS添加公共IP v
我们必须手动安装Apache
然后Python论文
然后使用Python一个
现在他们已经被照顾
你可以通过说伪系统l状态apache到你可以看到它在运行
你也可以说python三- m pip安装config parser
你可以看到config parser已安装
你也可以说aws描述实例容易
aws已设置
因此它将不会说没有找到
但它会抛出其他错误，因为它没有配置
我们所寻找的所有软件都作为引导程序的一部分安装
通常在组织中
会有多个类别，每个类别都应该预先安装所有软件
你必须识别出所有那些类别
你必须构建脚本
使用这些脚本 你应该能够为实例分配资源
这样软件就可以预安装
基于类别 你也可以使用命令行创建实例
作为命令行一部分
你应该像这样指定用户数据
你应该能够传递一个shell脚本
它将为你处理初始化
有什么指令在那里
作为脚本的一部分，将在实例为您准备时执行
所以请确保您了解如何使用命令行创建实例
以及如何通过命令行传递用户数据
我不会运行这个
但我只想在这里给你展示一个示例
这就是自举的全部内容
你实际上可以
传递给实例在首次启动时执行的指令 或者启动
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/076_Udemy - Data Engineering using AWS Data Analytics part1 p76 9. Create an Amazon Machine Image aka AMI using AWS EC2 Instance.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解如何为我们现有的e c two实例创建ami或亚马逊机器镜像
e c two实例的卷 在我们的情况下，e c two实例易于演示
我们将这个镜像命名为e c two演示镜像，image代表亚马逊机器镜像
让我们访问aws管理控制台
让我们访问e c two
让我们点击实例
让我取消过滤器
我们可以看到有两个实例
一个是名为e c two演示的
第二个名为我是演示
无论你选择哪个实例
如果你向下滚动
你会看到相应的ID
这就是用于创建该实例的I
如果我值得这个，然后选择这个
你可以看到此实例相关的
现在这些都是公共图片
因此当我们点击这些图片时
在这里不会获取详细信息
但是如果你有一个自定义图像
你应该能够通过选择你使用的图像来查看关于你自定义图像的详细信息
你现在应该能够看到你用于创建实例的图像详细信息
如果我去实例
如果我点击启动实例
我们会进入快速启动
在这里你看到的启动部分，实际上使用的是这些实例
我们应该能够进行配置
E C 两个实例 如果你选择亚马逊Linux AMI
那就是这个
如果你尝试通过easy to instance启动实例
我们不仅会得到Linux操作系统
还会得到AWS管理工具，如AWS CLI，我们在之前已经见过
同样，如果你选择这个
我们会得到easy to instance
带有工作1到18
它会实际上给我们一个基础ah
你想使用一些与我们相关的工具来与aws进行交互
但我们不会获得如aws这样的软件
所以，这里是快速开始的地方
这些是快速开始的内容
如果你去aws市场
你会看到第三方软件，这些软件是由第三方公司提供的
通常它们不仅包括操作系统，还包括在easy two实例上的软件
一旦我们使用mis进行配置
我们还有一些软件工具
例如 在这种情况下，如果我选择使用由Bitnami认证的WordPress，它会自动
如果我用这方便快速创建实例
它将不仅包含操作系统
它还将为我们预装WordPress
我们只需配置并使用它
这就是如何构建虚拟机的
它们不仅包含操作系统
而且还包含预装软件
如果有第三方相关软件
这就是说现在
让我们回到易于使用的仪表板
我们必须去服务
点击易于使用
然后我们实际上可以去e
C 两个仪表板 我们也可以有自己的
在公司里
通常我们将实例分类为应用程序服务器
数据库服务器等等
可能有十到十五种类型的服务
我们可能需要定位它
取决于环境的复杂性
对于每一个类别
我们可能想要拥有基于基础软件的基础实例
所以每当我们想要创建一个易于实例化并部署的Web应用程序时
我们可能想在操作系统之上有一些软件
为了做到这一点，我们可以创建一个mi，然后我们可以启动我们的实例
使用我们定制的
将会有更好的控制
使用我们定制的
因此 我们需要了解如何创建我们自己的ami
在创建之前 我
让我们理解步骤
我们必须选择易于实例化的
我们必须去适当的卷并取其快照
一旦快照创建
我们必须去那个快照
我们必须从中创造mi
让我们在这里采取行动
我正在选择这个 E c two实例
我们必须去存储
您可以在这里看到所有设备
我们必须选择根设备
那就是dev s d one
我们必须转到根设备的卷
即使您有多个设备
你可以从这里获取根设备的详细信息
你必须选择与该根设备相关的卷
你可以点击这里
你应该能够转到该卷
当我们有其他卷时
我们可能会使用其他卷来安装软件，因为我们正在尝试创建mi
使用此卷将获取作为本系统一部分的系统
以及安装在该卷上的任何软件
当我们创建此实例时
我们使用了bootstrap
我们传递了多个指令
其中之一是安装apache
另一个是安装aws python pip
第三个是使用python pip安装aws
所有这些都将直接安装在根卷上
因此，作为快照的一部分，将包含所有这些
如果我们创建图像
使用该快照将获得所有软件
让我们在这里为该卷创建快照
我们只需选择卷
展开操作
创建快照
我们需要为快照提供描述
我将提供有意义的描述
说易于演示快照，因为我们正在为易于演示创建快照
我正在使用此描述
我可以滚动 说
创建快照 它将为我们创建快照
现在我们可以点击此链接转到快照
现在快照已完成
我们需要等待快照完成
因为它只有1gb
快照非常快
一旦完成
你可以实际选择快照
让我们给此快照起个名字
我说易于演示快照
我们可以选择此快照
转到操作
然后我们可以说创建图像
我们可以实际为该图像提供名称
它只是易于演示图像
如果你想预配置根卷大小，你可以配置
但我们将保持默认
这是一个b
这个b是从快照继承的，我现在可以说创建
它将为我们创建图像
我们可以通过点击此链接获取操作状态
现在可用，图像现在可用我们
我们应该能够根据它创建一个实例
我们应该能够验证e
C 两个实例都包含预安装软件，这些软件是图像的一部分
它们只不过是apache到aws cli和python pip 我们将在下一个主题中处理验证部分
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/077_Udemy - Data Engineering using AWS Data Analytics part1 p77 11. Validate Amazon Machine Image aka AMI - Lab.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为前一个主题的一部分
我们创建了一个名为easy to demo的镜像
使用easy to demo
让我们了解如何创建实例
使用这个i并首先验证
让我们去a is here
您可以通过点击此按钮列出mis
这叫做i仪表板
作为仪表板的一部分
我们只有一个图像
那就是这个
即使我删除过滤器
我只会看到一张图片
一旦您选择了合适的图像
您可以转到操作并说启动
这将直接带您到实例类型
它将不告诉您实际选择ami
因为我们已经选择了
作为ms仪表板的ami
如果您想转到不同的mi
您可以从这里点击到mi
您应该能够选择您想要的任何东西
您也可以直接点击启动
作为实例仪表板的一部分
在这种情况下您可以像这样转到easy to
您应该能够转到实例
您可以点击启动实例
您可以去我的is这里
您可以在这里看到您的ami
然后您可以选择
然后您可以继续
让我们使用t two dot micro
让我们配置实例详细信息
只有一个
我们不会改变这里的其他任何东西
然后您可以点击添加存储
我们不想改变任何存储
添加标签
在这种情况下将加载名称
为e c two demo one
我们可以去配置安全组
让我们选择一个现有安全组
那就是这个审查并启动
让我们与itv demo一起启动
一旦我们选择了图像
其余这些步骤与我们以前看到的相同
在提供其他
e c two实例时，我们现在应该能够点击此
让我们看看进度
它处于运行状态，状态检查仍在初始化
但是，我们仍然应该能够连接到这个
让我们选择这个
让我们复制公共ip v for dns
让我们去终端
我们可以说 ssh iphone
I tilde slash dot
Ssh itv demo dot pem ubuntu at the public
Ip for dns here
然后说 yes
现在我们在实例中
一旦我们进入实例
我们应该能够说伪系统控制状态apache
你可以看到它正在运行
由于图像包含apache，因此它作为e的一部分包含在内
C 默认情况下，两个实例也是如此
默认情况下，Apache被添加到启动脚本中，当实例启动时
即使apache to正在运行，也应该能够验证aws命令
我们应该能够验证甚至aws命令
C 在两个描述基于aws的实例上
它会尝试另一个因为我们还没有配置
但你可以看到它按预期工作
它没有说没有找到命令
因为aws cli是作为easy to instance的一部分设置好的
我们使用其构建了ami
你也可以通过说python three hyphen m pip install来验证
比如pandas
它会在这上面安装pandas
因为我们也把人员作为实例的一部分
使用这些我们创建了ami
这就是你应该能够验证已配置的简单实例的方式
使用ami
你应该在ami中有所有软件作为部分
我们展示了e c两实例
使用那个mi
所有这些软件都将作为实例的一部分安装
我们应该能够根据我们的要求进行配置和使用
你应该对is有一个基本的理解，因为在企业中，我们通常使用自定义is来处理特殊情况
如果你需要解决一些问题
我们必须记住
我们的实例可能是使用mis创建的
如果问题需要修复
我们需要在ai中修复它
因此，对is有一个良好的理解是非常重要的
无论你在组织中的角色如何
在之前的话题中，aws被用作一部分
在本话题中，我们已经看到了如何使用现有的easy to实例来创建i
如何使用ami并创建一个新的EC two实例
验证软件是否被正确传播到新的EC two实例中 基于ami验证软件是否被正确传播到新的EC two实例中
EC two实例 基于ami验证软件是否被正确传播到新的EC two实例中
一旦验证完成，EC two实例被正确创建
EC two实例 使用自定义ami创建的EC two实例
我们应该终止它，以便我们不会不必要的被收费
让我确认这个实例被终止，然后再继续 我点击了终止，实例正在终止
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/078_Udemy - Data Engineering using AWS Data Analytics part1 p78 1. Hello World using AWS Lambda.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们使用Python编程语言创建第一个Lambda函数
你必须访问管理控制台
然后你应该能够搜索Lambda以进入Lambda Web控制台
创建Lambda函数的一种方法是使用Web控制台
现在我可以点击这个以进入Web控制台
一旦我在Web控制台中
只要你在函数中
你应该能够看到这创建函数选项
然后你可以点击这个来创建函数
让我们将名称设置为hello world
让我们将运行时选择为python三八
让其他的就这样
现在应该能够点击创建函数来创建函数
创建函数需要一点时间
一旦创建完成 我们将详细探讨如何部署和测试这个hello world函数
然后我们将详细探讨其他细节
现在函数已经创建完成
你应该能够向下滚动并查看默认创建的内容
你可以看到使用lambda函数的名称
有一个文件夹叫做hello world
在里面有一个名为lambda underscore function的程序
Py 如果你双击它
你可以看到有一个名为lambda handler的功能
这就是lambda handler应该看起来的样子
我们应该能够部署并测试它
我们将稍后详细讨论这些细节
你需要记住与lambda函数相关的一些重要方面是
首先，自定义处理程序
在这个时间它使用的是默认程序名称
这除了lambda函数之外没有其他功能，功能就是lambda处理程序
有时你可能想要提供自定义答案
你必须来这里并更改程序名称以及函数
这样你就可以使用自定义处理程序
当我说 自定义处理程序
我说的是处理程序的名称
而不是函数 函数必须像这样
函数的名称可以不同
但它必须接受两个参数
第一个与事件相关
第二个与上下文相关
我们将在后续的时间点理解这些方面
现在不必过于担心这些事情
它们对于运行Hello World Lambda函数并不重要
与Lambda函数相关的另一个重要方面就是环境变量
有时 我们可能需要为Lambda函数传递运行时变量
这就是你应该能够传递运行时变量的方法
也可能有其他替代方法
但这是最常用的方法之一
你应该能够配置键值
然后你应该能够使用声图书馆作为lambda函数的一部分来读取
随着我们进一步深入，我们将看到这些详细信息
然后是基本的设置，默认情况下
它需要一到b来实际运行lambda函数
如果你想要增加内存大小
如果你处理一些内存密集型任务
你应该能够再次处理这个数字
随着我们进一步深入，我们将看到这些详细信息
与lambda函数相关的另一个重要方面
我们通常必须担心的事情没有什么权限
例如 如果你想从s三桶中读取或写入s三桶
与lambda函数相关的角色将具有适当的权限
从s三桶中读取或写入s三桶或写入s三桶将与角色一起玩耍
随着我们进一步深入 这些都是你应该记住的事情
随着我们进入稍微高级一点的东西，我们将探索那些方面
运行这个hello world lambda函数后
现在您可以转到函数，然后单击hello world
我们应该能够部署并运行它以进行测试
以验证hello world是否按预期工作
目前更改未部署要部署
您可以单击部署
它将负责将lambda函数作为airless基础设施的一部分部署到测试中
首先，您需要创建测试事件
您可以通过单击配置测试事件来实际创建测试事件
即使您单击测试
如果没有测试事件
它将实际带您到测试事件
现在我给它起了个名字叫hello world test
然后我应该能够创建这个
一旦创建完成
我们应该能够单击测试以进行验证
您可以在这里看到输出
一切都按预期运行
因此创建hello world lambda函数、部署并测试它已成功
现在我们将进入稍微高级一点的内容
我们将从设置项目开始
然后我们将实际看到如何将其作为完整项目部署
其中还依赖国家图书馆 让我们深入探讨这些细节
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/079_Udemy - Data Engineering using AWS Data Analytics part1 p79 3. Setup Project for local development.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们为我们的jh下载设置项目
我将项目命名为jh活动下载器
在这种情况下，我们将直接从github档案网站下载文件到s3
首先
我们将从设置项目开始
然后我们将逐步进行开发lambda函数的过程
并且我们将在后续时间处理部署
让我创建这个文件夹
然后我将进入这个文件夹
现在我将为这个项目创建虚拟环境
虚拟环境的名称将是g h a hyphen v e和v
所以我必须说 Python三hyphen m v e和v g h a d v e和v
所以这是我的虚拟环境名称
一旦创建 我应该能够通过说source shady来激活它
我们和we in activate
现在 虚拟环境已激活
我们应该能够设置所需的库来处理本地开发
它们只是请求
我们需要请求库来从hk网站下载文件
使用这个原因使用get api
我正在安装请求
也会安装底部三个在这里
我们需要底部三个的原因
是为了实际开发将数据上传到s3的代码
我需要同时拥有底部三个以及请求
当我们尝试在aws基础设施中部署为lambda函数时
我们不需要拥有auto three
我们只需要请求，这样我们就可以从档案中下载
使用get api 底部三个是AWS基础设施中Python运行时环境的一部分
为了验证我们可以做什么
我们可以去我们之前创建的lambda函数
这是创建的hello world lambda函数
你可以实际上去函数本身
然后你可以说导入bottle three
然后说部署一旦部署
我们可以实际上点击测试来测试它
你可以看到，测试成功确保我们有可用的请求
作为aws环境的一部分
我们可以实际上说import requests as well
然后我们应该能够部署和测试
现在失败了
因为请求不可用作python三运行时环境的一部分
这将作为aws基础设施的一部分获得
这意味着在本地用于开发目的
我们需要有三以及请求
但当我们将应用程序上传到aws lambda控制台以部署lambda函数时
我们不需要将自动三包含作为其一部分
我们只需要请求在其中
我将创建一个名为g hj lib的文件夹
所有应该部署在aws的库
Lambda控制台将进入这个文件夹，安装依赖项的一种方法是
例如quinto
这个文件夹是通过说pip install requests
这是您要安装的库
然后-hyphen t然后lib现在
请求将安装到该文件夹
别担心太多 如果你不明白
确保将请求库安装到该文件夹
你也可以有效说a-hyphen
Ltg hl lib
您可以在这里看到
所有与请求相关的库都下载到此文件夹
我们需要将其作为zip的一部分包含
可以上传至aws lambda控制台
你将在后续时间理解这些方面
目前我们有所有需要为本地开发库
我们也将库移至稍后用于部署的这个文件夹
称为hb
所以基础项目已设置
你应该能够使用pie chart打开它
然后我们可以从那里实际处理开发
让我们去pie charm
这里 我正在搜索python
我正在使用python专业版
这些步骤与commutates也相似
你应该能够处理这些步骤
即使与commutation
让我移动弹出窗口相对于python到这个显示器
然后我说新建项目
实际上 它是现有项目
因此而不是说新建
我必须点击打开
我应该能够去设置项目的位置
它只不过是diversity项目
内部训练营
夜间材料
然后转到aws
然后duty下载器
我可以点击打开
它将实际在pie char中打开项目
一旦打开
我们将尝试配置适当的python解释器
我们应该指向解释器到虚拟环境
这是刚创建的
这就是g hd hyphen v
E和v 我们点击这个
然后转到解释器设置
我们看看指向的是哪个虚拟环境
如果你不确定你可以实际点击这个
然后说显示所有,这就是它指向的
它实际上指向正确的
如果不指向正确的
你应该能点击加号
你应该能创建项目运行时环境
或者因为运行时环境已经存在
你可以选择现有环境
你应该能继续
如果你遇到任何问题
告诉我 我会尽力支持你
为了确保你的产品配置正确的运行时环境
你需要确保运行时环境指向你创建的环境
在你创建文件夹后
在我这个案例中,这就是hcd
V和v,这就是hv后的样子
在我们的产品日记中
那里有一个bin文件夹,里面有python3
运行时环境应该指向那
我点击取消
然后取消确保为这个项目选择了适当的运行时环境
我们可以点击隧道
我们应该能看到运行时环境
到目前为止我们已经成功设置了项目
我们将实际开始hello world程序
然后我们会应用它来下载文件从jo
org和上传到s3
让我们深入这些细节 随着我们进一步
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/080_Udemy - Data Engineering using AWS Data Analytics part1 p80 5. Deploy Project to AWS Lambda console.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们从hello world开始
然后我们将进一步创建hello world程序
你可以做 你可以写
点击这个 然后你可以说新
这将创建一个名为lambda_函数的python文件
我们将创建一个名为lambda_handler的函数
你可以做 你可以去aws lambda控制台
然后转到lambda函数
清理这个导入语句
复制这个并粘贴在这里
现在lambda_handler在本地定义以进行单元测试
我将创建一个名为lambda_valdate的东西
我将开发一个函数来在本地验证
然后我也会作为aws lambda控制台的一部分部署
以确保函数按预期工作以创建lambda_valid
我正在写一个新的python文件
然后我说lambda_validate.dot p
现在我想调用lambda_handler来验证我的方式
是这样调用的
我可以说from lambda function import lambda handler
然后我可以说lambda handler
它接受两个参数
目前 我们不确定
事件和上下文是什么
而且他们也不相关
所以我将传递none以满足两个参数
如果你看handler
它以json格式编写
我将字符串
所以这里我说s等于
然后我将打印那个地址
rest代表响应
打印of less现在
我应该能够保存这个
让我再放大一点
这样对你来说会更清楚
我想放大功能没有按预期工作
所以我将去我的跳转偏好设置
然后编辑器字体
我将其增加到24
我说应用和确定
现在应该没问题了
让我运行这个，说run lambda valid
你可以看到输出
这意味着函数在本地成功验证
现在我们应该能够在aws lambda控制台上部署它，然后我们可以继续
你可以这样部署它
你可以去隧道
然后你可以说 zip 连字符 r
然后我会将其命名为活动连字符下载器点
拉链 目前我唯一包含的程序
作为这个zip的一部分，除了lambda函数点py之外别无他物
所以我说的是 lambda 函数点 py 并且 p 是为我们创建的
现在我们实际上可以去aw
Lambda 控制台
我们可以说行动
我们可以说上传点zip文件
然后我们可以点击上传
我们可以去我们的产品正在开发的位置在那个位置
我们已经有这个活动下载
压缩 我们可以选择那个
我们应该能够点击工具上传
然后我们可以说保存
我们应该能够看到这项功能正在上传在这里
你可以去lambda函数
现在 这就是上传的内容
这与我们有的程序没有区别，所以你什么也看不到
如果你想要做什么，你可以
你可以实际上更新说hello from lambda from gdownloader
让我们保存一次，你说了这个
你必须更新zip文件
你可以实际上说zip hyphen g来更新现有的zip文件
然后按回车键，现在它已经更新了
我可以来这里，然后说我要上传一个zip文件
然后我应该点击这里
说真实的上传
保存点击
好的，现在去lambda函数
你可以在这里看到
它已经更新了我们的代码
这是我们从pie charm添加的
现在更改已经部署
当我们上传zip文件
它会自动部署
我们不需要做额外的事情来实际部署
我们可以直接进入测试并点击它
我们应该能在这里看到输出
这就是你应该能够设置项目的方式
同时了解如何构建一个基本的zip文件
上传它并运行
既然我们已经理解了如何本地启动，现在
让我们来制定一个逻辑，从jhk org网站下载文件 然后上传到s三
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/081_Udemy - Data Engineering using AWS Data Analytics part1 p81 7. Develop download functionality using requests.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们开发一个程序来验证名为请求的库
将进行一次GET调用并记录状态码
在这种情况下，我将在我的项目文件夹中创建一个新文件
这就是下载活动
右键点击它 然后说新
然后Python文件
脚本名为下载.py
我将开发一个名为下载_文件的功能
它将实际下载我们传递给该函数的任何文件
所以我只将文件名设置为文件
然后我只是说这是请求
所以我们必须导入请求库
这样我们就可以使用它
让我说import requests
我们已经在本地安装了库
使用pip install命令
我们也已经下载到jhl中
它将用于实际上传至aws lambda控制台，稍后
使用此请求库
我们应该能够说，获取链接无非就是这一个
https://column-data.g-h.archive.org
如果你去这个网站
它会实际上显示URL是如何的
至于下载文件
让我们去这个网站并审查它
我认为这不是实际的网站
它将会给我们提供详细信息 我们只需要去jhq.org
这是宪章的主页
你应该能看到这里的url
url结构看起来像这样
我们可以实际上复制这个
然后粘贴到这里
我想返回这个的响应
GET请求 因此让我们说这是
这个响应将不仅包含url的内容
它还包含状态码和一些其他信息
我们将了解这些细节
随着我们继续在本地进行验证
你可以首先做的事情是
你可以从这里调用下载文件
你可以实际指定文件名
在这种情况下，我将文件名指定为二零二一年一月二十一日
第二十九日 连字符
零点json点gz
我们正在尝试以这个名字下载文件
我们应该能够运行这个
我将这个捕获到一个名为地址的变量中
然后我们可以说打印west点状态码
让我们在本地运行这个
这将花费一些时间来下载此文件
因为它大约有48B
一旦下载完成
你将在这里看到输出
你将看到状态码为200
如果它是200 那是成功的
如果我输入像这样的二十二点一月一号
这是一个未来的日期
当我制作这个材料时
它将实际返回404
因为文件在那个名字下不可用
如果我运行这个
它将失败
它将不会失败 但现在它将返回404状态码
我们应该能够从这个lambda handler调用此函数
让我从这里删除这个
也让我从这里删除这个
让我转到lambda handler
它是作为lambda函数的一部分
我们应该能够在这里改进代码
所以在这种情况下我说下载_等于下载文件
下载文件是下载Python脚本的一部分
我们可以导入并说from download import download file
我应该能够使用此download file函数
到目前为止，它只是下载传递给它的文件
我现在是硬编码的
我在这里硬编码了文件名
我将从该响应对象打印此状态码，我说download_.status_code
我还将说download status作为该消息一部分
我将下载状态码作为该消息一部分现在我应该能够保存这个
然后我应该能够运行这个来运行
我必须去lambda valid然后我应该运行这个
它将处理调用下载文件函数
它作为lambda handler的一部分硬编码
无论返回什么
它将实际打印文件状态码在这里
你可以在这里看到
状态码是200，body downloads状态码
你现在也可以用无效文件名测试它
让我们说2021
二月二十八日
让我保存这个
让我转到lambda valid这里
正确 点击这个 然后说大约lambda有效
你可以看到当前的状态是404
我们已经在本地验证了
现在我们应该能够将代码上传到aws lambda控制台
我们应该能够在aws lambda控制台中运行它
然而，为了验证由jdownloader构建的lambda函数
我们需要使用build函数来构建所有依赖项
包括第三方依赖项
也就是requests库 首先我们需要安装它
我将使用正在开发的代码构建ZIP文件
代码只是一个lambda函数
Python和下载点py会将ZIP文件上传到AWS Lambda控制台
我们将看看是否能验证函数
我们将实际到达解决方案
它肯定会失败
因为请求没有被包含
我们将了解如何将请求库作为lambda web控制部的一部分进行部署
我们已经有了文件
要么 我们可以通过删除它来重新创建它
或者我们也可以用适当的坐标更新zip文件
在这种情况下，我将删除并重新创建它
让我删除zip文件
我们可以说rmdh活动-下载的zip
它将处理删除zip文件
我可以说zip-are jh活动-下载的zip
我必须包括lambda函数以及下载，现在该文件包含两者
我们应该转到aws lambda控制台
我们可以实际点击创建函数
我们可以给这个名字起一个名字
这个名字无非就是活动下载器
我们需要将运行时更改为python 3.8
然后我们可以说创建函数来创建函数
一旦函数创建完成
我们应该能够将文件上传到其中
我们应该能够进行验证
现在lambda函数已经创建完成
我们应该能够上传这个lambda函数的zip文件
通过去操作 然后点击这个
然后我们可以说上传
我们应该能够点击这个
然后说真实的上传
然后说保存 它会负责将zip文件上传到aws lambda控制台
你可以通过这里验证，然后通过展开这个
你可以看到下载点py以及lambda函数py
这是作为python项目开发的一部分
现在测试这个
实际上你可以去测试并配置测试事件
然后你应该能够测试它
在这种情况下我已经有了保存测试事件的选项
我也会使用它
改变这一点并不重要
你可以给它起一个名字
然后你应该能够保存它
一旦你保存了它 你应该能够点击测试来测试它
你可以看到它失败了
说 无法导入模块 requests
它主要是由于请求失败
现在我们必须包括 requests 作为包的一部分
这无非就是文件
然后我们必须重新上传 zip 文件
然后我们应该能够继续前进 然后你应该能够继续前进
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/082_Udemy - Data Engineering using AWS Data Analytics part1 p82 9. Using 3rd party libraries in AWS Lambda.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


当我们的lambda函数因为缺少requests模块而失败时
让我们了解如何将requests作为我们lambda函数的一部分
相关的文件 我将在python中
我删除了这个活动
在下载点zip顶部的lambda函数
点py和下载点py
包含与我们的lambda函数相关的代码
我们还需要包括请求库，它是jhlib的一部分
我们不能使用虚拟环境本身
因为虚拟环境包含底部的三个
如果你记得关于设置项目
当我实际上设置这个项目时
我安装了auto3和requests作为虚拟环境的一部分
我安装了requests作为此lib的一部分
所有在aws上执行的库
Lambda控制台将安装在此文件夹本身
什么也没有 但现在我们需要将此文件夹的内容打包成zip文件
我们还需要包括我们开发的源代码
在追求从hr k org下载文件
你可以这样构建zip文件，这些子文件夹在jl
Lib中，你必须首先进入该文件夹
所以我进入jhlib
然后我将使用zip命令
我将在父文件夹中创建zip文件
因为文件保持在项目目录中
这就是jh活动下载器
如果我只说下载zip
它将尝试在此目录中创建zip文件
通过说dot dot slash
我实际上在父文件夹中创建了这个zip文件
我将zip文件名
它将负责在父文件夹中创建此zip文件
如果你在文件夹中创建了文件
你可以将文件移动到父文件夹
文件创建后
你可以按照你喜欢的方式做
你可以遵循 在这种情况下，我直接在父文件夹中创建了这个文件，而不是当前文件夹
这就是dhb
现在我必须包括此文件夹中的所有内容到此zip文件中
让我点并按回车，现在zip文件已创建
它没有在此文件夹中创建
它实际上在父文件夹中创建
我应该能够运行on
我们应该能够在这里看到zip文件
这个zip文件
所有gb中的子文件夹
不要尝试直接从这里构建zip文件
说zip python r
然后jdownloader zip
然后你会遇到lib
它会实际上破坏文件夹结构
你将会有i作为那个基本日记
它会包括其余的并不是
那些本应存在的东西
我们必须只有db的子文件夹作为zip文件的一部分
这就是为什么我们要进入lib
运行zip python r到父文件夹
包含该文件夹的所有内容
点代表当前工作目录
gb中的所有子文件夹
那些将被包含在这个zip文件中
我将展示如何验证
一旦我们将文件上传到aws lambda控制台
现在我们在所有lib中有所有这些文件夹
我们没有开发的源代码
那些只不过是lambda函数py和download py
我们应该能够通过说zip hyphen g来更新这个zip文件
然后是zip文件名，那就是这个
然后lambda function
点py和also download py
这两个是唯一的python程序
那些本应上传到lambda控制台以验证我们的逻辑
现在文件包含甚至这两个
现在我们应该能够刷新zip文件
已经上传到的zip文件说actions
上传zip文件上传
然后上传这个truthful upload
然后保存
当我们说 选择上传并保存
它将实际将zip文件上传到aws lambda控制台
一旦zip文件上传到aws lambda控制台
我们应该能够通过点击测试来测试它
这次不应该抛出错误
让我们看看它是否会抛出其他
或者它将实际显示成功消息
它仍然抛出错误
我们必须解决与这相关的问题
然而，我们可以看到其余的东西看起来不错
我们有所有所有安装到jl lib的库
但直接位于这个downloader文件夹下
以及我们也有download py以及lambda function py
让我再次通过说测试来测试它
它仍然失败
说任务超时后三秒
我将解释为什么它失败
这就是这个内存配置的地方
Lambda函数需要更新
它正在耗尽资源
因此它给出了这个错误消息以修复它
你应该做的事情 你可以滚动到下方
你可以去基本设置
点击编辑
然后你可以增加它
2到5 6和b或fight会
然后你可以进一步
让我说我会在这里
它必须在1到28b到10gb之间
你可以给10gb
在这种情况下我给了半gb
让我说在这里保存
现在保存了
我们应该能够点击测试来测试它
现在你看到状态码是200
它显示作为程序一部分创建的消息
它没什么就是下载状态码
我们成功地上传了请求库并验证了我们的Lambda函数
它遇到了内存问题
我们已经将内存设置增加到半gb
并且我们已经成功验证了Lambda函数，到目前为止
它没有保存文件任何地方
我们只是调用GET API
我们捕获了状态码
现在是时候了解如何将文件上传到S3了
然后我们必须连接这两个点
下载Jala网站上的文件并将其上传到S3
让我们详细了解如何将文件上传到S3 使用Lambda函数 然后我们将实际看到如何将下载的文件上传到S3
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/083_Udemy - Data Engineering using AWS Data Analytics part1 p83 11. Validating s3 access for local development.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解如何将lambda函数与AWS相关服务集成
作为地方开发一部分
如果你记得 我们创建了一个名为github用户的用户
我们已经将必要的权限授予了该用户
然后我们为该用户创建了配置文件
我们可以使用itv github用户的凭据与它进行交互
使用itv github用户的凭据
它作为名为itv github的配置文件一部分
我们可以通过在终端中说aws s three s three colon来验证
Slash itv - github
这是正在和我们互动的桶
然后我们可以说 - - 个人资料名称就是itv github
您可以在这里看到输出
我们应该能看到桶的详细信息
作为使用配置个人资料的凭据的用户
在这个桶上有完整的权限
我们能够看到桶中的对象
对象在这个桶中就是文件和文件夹
现在我们应该能够使用相同的配置文件进行本地开发
然而，当我们实际上在aws lambda控制台上部署时
我们可能不需要使用任何配置文件
我们可以直接使用角色
因此，当我们在aws lambda控制台上部署时，使用配置文件并不相关
只有对于本地开发
我们需要使用配置文件
否则我们不需要
所以我们实际上可以使用配置文件的方式
作为本地开发的一部分，通过使用环境变量
被称为aws下划线配置文件
然后我们应该能够进一步扩展
探索s三
我将要做的是
我将创建一个新文件
文件名为上传
所以我们有一个新的程序称为上传.py
我将直接开发脚本
一旦我们验证了脚本
然后我将实际转换这两个函数
我能验证的方式
首先我需要导入 os 模块，然后设置 os 的默认值。
然后，我们需要设置一个名为aws default的环境变量，指向itv github
这就是我们实际上可以设置的方式
一旦配置文件设置完成
我们应该能够为那三个客户创建服务
我们需要导入三次瓶子
所以让我在这里导入瓶三
然后我可以说s three underscore client等于四到三点client
我应该能够把它传递给它
现在我应该能够说s three underscore client dot list objects
我应该能够使用名为bucket的关键字参数传递桶名称
桶的名称就是它v-hyphen github
让我說s three underscore objects等于
这样我们就可以将其分配给s three on score objects
然后我将实际打印s three objects contents of zero
这将处理打印一个对象详细信息
让我们运行这个以确保使用pie charm
我能够使用配置文件与s three进行通信
itv github
然后我们将进一步
让我们运行这个并看看会发生什么
您可以在这里看到输出
这意味着它已成功使用配置文件执行了列表函数
并且它已成功打印了输出，正如您已成功验证了读取部分一样
现在我们必须关注写入文件到s three的权限
我们有一个名为put object的功能
put object接受多个关键字参数
它们只不过是桶键和身体
这些都是我们上传文件到s three时需要使用的三个重要参数
使用put object
还有其他参数
但对于现在，这三个足够了
如果您需要帮助
您可以实际上说help on s three underscore client
点put underscore object
我不认为您在这里能看到帮助
或者这可能是可能的
我也通常使用数字环境
但对于这个演示
我没有使用jupyter环境
获取帮助的一种方式是
您可以在这里启动终端
作为终端的一部分，您可以启动python 然后您可以说import auto three
您应该能够在python cli中执行这些事情
让我们也运行这两行代码
然后我们可以说help on s three underscore client
点put underscore object
如果您想获取put object的帮助
您可以在这里看到详细信息
它接受多个参数
但是对我感兴趣的参数是nothing but
bucket key和file key是名称
我们将在s three桶中使用作为key的文件
源文件作为body传递
让我们运行这个两行代码
然后我们可以说help on s three underscore client
点put underscore object
如果您想获取put object的帮助
你可以看到详细信息
所以，关于这里的键盘参数，你有键
应该有主体
而且rollop不知道为什么没有工作
让我看看payo是否会在上方工作
这里正在工作 你可以在这里看到主体
主体可以是字节或文件
我们将使用主体
桶和键
所以它可以这样使用
我可以说 S three underscore client dot
Put underscore object bucket equal to itv
Hyphen Github
我将给键名设置为这个
我们为下载文件使用的名称将作为键名在这里给出
我们可以去lambda函数
从这里获取文件名
然后作为部分的键使用它
我将指定body为rest.dot.content现在我们必须定义rest
我们可以像这样定义rest
我们可以说rest等于requests
我们在这个程序中必须导入requests
所以让我说import requests
然后我们可以说request.dot.get和URL就是这个
所以让我去下载.py
让我复制这个
然后让我去上传.py
粘贴在这里
我必须定义文件在这里
文件就是硬编码的名称
让我们去lambda函数这里
复制这个然后粘贴在这里
现在它会做什么
它将实际获取这个rest apa呼叫的pads
它将包含内容
内容将以字节流的形式包含文件的实际内容
因为body实际上可以接受字节流
我们应该能够像这样直接将其传递给body
内容将包含文件的内容或rest apa呼叫的输出
这里 现在我们应该能够运行这个
然而，我想捕获这个响应
让我说upload underscore等于rest of the code snippet
最后 我想打印upload underscores
让我们快速回顾一下代码
然后运行它
所以我们只设置了环境变量
AWS 默认为 itv
GitHub 我们已经创建了客户端
我们可以删除这段代码
我们不再需要列出对象
我们已经验证了这一点
然后我们定义了一个变量
名为文件，包含文件名
然后我们调用了 quest
使用此
是的 URL 通过传递文件给它
它将负责将文件下载到内容中
并且状态代码也会作为状态代码的一部分
内容以及状态代码都将作为响应对象的属性一部分
这将由此 ah aa 调用写入
然后使用 rest. content
以及桶名和文件名我们调用了
put object 来实际验证
我们是否能够将对象放入 s three 中
让我们去 s three 控制台并验证该位置是否有文件
一旦我们在 s three 控制台中
我们应该能够搜索 itv github
让我们在这里搜索 itv 杠 github
点击这里
有一个文件 但文件名为 2021 年 1 月 28 日
没有文件
与 2021 年 1 月 29 日相关的
现在 运行此之后
该文件应该在此处创建
让我们返回这里
然后右键点击此
然后说 运行上传并查看文件是否成功上传到 s three
您可以在此看到输出
状态码为 200
这意味着成功
您也可以访问 AWS s three 控制台
您应该能够刷新此内容
我们应该看到额外的文件
您可以看到文件 文件大小为 6.6 MB，因此文件已成功上传到 s three
使用 put object
利用 itv github 个人资料
所以，在本地我们可以使用itv的github配置文件
我们应该能够管理itv github bucket中的对象
因为我们现在已经成功验证了
让我们重新组织代码
以便我们可以使用适当的函数来处理功能
将文件上传到s3
我们还需要对lambda函数中的代码进行重构 以便下载和上传过程集成
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/084_Udemy - Data Engineering using AWS Data Analytics part1 p84 13. Develop upload functionality to s3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为前一个主题的一部分
我们已经成功验证了从本地开发环境访问s3的访问权限
现在让我们重构代码以实现功能
将文件上传到s3
我将导入auto3
然后我将定义一个名为get和score client的函数
以获取s3客户端
该函数将像这样
在上面 我们还有上传s3函数
我们已经看到了如何使用s3客户端put object实际上传文件
我正在复制粘贴函数
它将处理将文件上传到桶
文件内容将通过body传递
文件将具有文件名
这将用于在调用输入对象时使用该名称
以在s3中使用该名称
然后bucket就是s3桶
一旦我们完成了上传功能
作为upload.py
我们需要更新lambda_function.py以实际调用函数以上传至s3
首先我们需要导入函数
它只是来自upload程序的upload_s3
一旦文件下载完成
我们应该调用该函数
该函数调用将像这样upload_s3
等于upload_s3
我们需要传递三个参数
它们是body bucket和文件
我们将稍后定义那些东西
为了可读性目的让我重构一下
然后我们将继续
让我们修复这些其他内容并传递适当的值
这些参数中
我将定义变量在某些情况下
在某些情况下我将使用现有对象中的衍生属性
让我们处理文件
并且在此之前
让我们验证 参数的顺序与实际upload_s3相同
我可以点击这里
你可以看到第一个参数是body
第二个参数是bucket第三个参数是file
如果我去lambda函数
我传递body bucket和file
让我们处理文件
我将复制这个
然后我将将其分配给一个名为file的变量
我将使用相同的变量来处理下载
因此它将处理从hr下载文件并使用相同的名称
它将实际上传到S3
这已经考虑到了，因为它是以此命名的
现在当它涉及到桶时，会使用称为环境变量的东西
因为开发环境中的桶可能在开发环境、测试环境和生产环境中不同
控制这些对象的运行时行为，可以使用环境变量
在环境中可能不同的这些对象运行时行为的一种控制方式是使用环境变量作为lambda函数
Lambda函数支持我们传递桶名作为环境变量
当我们在AWS Lambda控制台部署时
我们也可以在本地使用它
目前 我将要做的是
我将会设置一个变量名为bucket，并且从os模块中导入os模块
在这里导入os模块
它可以帮助我们使用os.environ['BUCKET_NAME']读取环境变量
获取环境变量名为BUCKET_NAME的值，它就是bucket_name本身
它将根据我们运行这个程序的环境来获取相应的值
在这个例子中，我们将使用itv-github作为AWS Web Console以及本地环境的BUCKET_NAME
以及本地环境 但我只想展示Lambda函数如何一次性处理环境变量
使用称为环境变量的东西
然后是主体
如果你去下载文件这里我们在做请求
获取将返回响应
响应内容内容无非是我们在这里传递的文件内容
我们可以直接将其传递给s three是put对象
这样字节流就可以作为文件存储在s three中
在这种情况下我们只需要说下载下划线点内容
然后我只想将上传响应返回到这个json的位置
因此我替换了这个
现在函数已经更新了适当的变量
然而 为了确保它使用适当的连接到sd存储桶并上传文件
我们必须设置aws配置文件
我正在硬编码当我们实际部署时
我们不能在aws lambda控制台中使用aws配置文件
我们可能需要为此重构
我们将在后续时间看到那些细节
只是为了继续前进 我正在说voice dot envion dot set default
然后 aws 下划线 profile
这个配置文件名称就是 itv github
现在我们需要将存储桶名称作为环境变量传递
如果你想用 python 传递环境变量
你可以直接在命令行中运行
然后编辑配置
这里是添加环境变量的地方
你可以点击这里
点击加号
然后输入存储桶名称
这就是我们的环境变量的关键名
值就是 itv 杠 github
当你复制粘贴时啊
值 确保你没有额外的字符
尤其是值周围的空格
如果你有空格
你会遇到问题
这可能有点难调试
让我说 好的 这里应用
然后点击确定
因为我们已经完成了代码的重构
以便从jr ve获取文件的功能
然后上传到s三
现在是时候在本地验证了
验证一种方法是去这个lambda_验证
我们实际上调用了lambda处理程序
lambda处理程序具有完整的功能来下载文件并上传到s三
让我们运行这个，看看整个功能是否按预期工作
看起来成功了
你可以实际访问http状态码
这是200 这意味着成功了
你也可以访问s three
刷新这个，看看文件是否已上传
可以看到文件已上传
现在时间是一二七
可以看到是一二六
当谈到这个文件的时间戳时
这就是你应该能够想出功能的方式
实际上将内容上传到s三
现在我们必须重构这以确保只有在本地运行时才设置这一点
当我们实际上在aws lambda控制台运行时
我们不应该为这设置它
我们将要做的是
我们将设置额外的环境变量
实际上告诉环境本身
如果它有会设置这
如果不会设置这个
所以这种情况下我可以说enon等于s点
Envelon点get
让我们把它命名为envelon本身
然后我们实际上会说
如果我们run等于de
那么我们实际上会设置这个配置文件
否则我们不会
这就是你应该能够构建一些智能的方式
是否设置配置文件
现在您可以实际选择这个时间
我将提供一个不同的文件名
让我们说一个 让我保存这个
让我转到lambda有效并让我运行这个
您可以看到，即使这次运行也成功了
您可以返回并刷新
它成功的原因
即使我没有设置环境变量，也是因为我正在使用root凭据
并且它按预期为您工作
它可能会失败 如果它失败
您应该做的
您可以转到lambda函数这里
然后转到运行编辑配置
您必须设置附加的环境变量
让我命名为envion这里
然后我必须说dev
然后确定
应用确定
现在我们应该能够以不同的文件运行
我们也可以打印说
我们在正确的环境中
我正在说在运行环境中
所以这将处理打印一条声明
它将确认它实际上正在处理设置配置文件
让我们运行这个 之前的运行对我来说也是
但它可能会失败，因为它可能没有root凭据
并且他们有默认的root凭据
现在我应该能够运行有效这次
我正在尝试下载并上传到s three
使用这个文件
这就是什么 2021
一月二十九日
您可以看到它已打印出
它正在运行在dev环境中
所以这已打印出
这意味着这成功了
一旦上传完成
您可以在这里看到响应
然后您可以实际转到s three控制台并且您应该能够刷新这里
我们应该能看到一个新文件这里
然而它仍在运行
我们必须等到运行完成，现在已完成现在
我们应该能够刷新这个
并且我们应该能够看到一个新文件
因为我们已成功配置了本地开发环境
并且开发了代码以下载文件并上传到s three
让我们理解如何在aws lambda控制台部署
并在aws lambda控制台上运行它 让我们深入了解
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/085_Udemy - Data Engineering using AWS Data Analytics part1 p85 15. Validating using AWS Lambda Console.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


在我们在本地成功验证了代码之后
让我们看看是否能将其作为AWS的一部分进行部署并运行
Lambda控制台
我不会做任何更改
我将部署并尝试解释其行为
因此，您可以在此处转到终端
让我退出这个
让我此处说一个短划线
我们已经有这个zip文件
如果它已经包含所有属于jhlib的库
我们没有添加任何新内容
因此我们应该能使用它们
然而，Lambda_function.py中有更改
并且我们还添加了upload.py
现在我们必须将这些作为部分包含在内
文件中已经有文件
我们只需更新它们，然后再进行更新
我们可以使用zip -g然后文件名
它什么也不是g activity downloader zip
我将添加所有三个Python脚本
download.py
Lambda_function.py和upload.py
让我指定所有这些在这里
download.py
upload.py和then lambda function p
现在文件已更新了这三个程序
我已经添加了upload.py并更新了download和Lambda_function.py
现在我们可以转到AWS控制台
然后应该能够通过单击操作上传zip文件
单击上传zip文件
单击上传此zip文件
然后选择上传
它将进行大量上传
将更改此zip文件上传到AWS Lambda控制台
一旦上传完成 我们只需点击测试以验证它是否按预期工作
让我关闭这个并运行测试在这里
它将失败 说访问被拒绝
实际上 它说期望的字符串或字节对象
它出错的原因是因为我们没有传递桶名称
我们应该通过传递环境变量来传递桶名称
我可以在这里编辑
然后点击添加环境变量
我可以指定键
它什么也不是bucket_name
值什么也不是itv-github
让我们保存现在环境变量已设置
您可以在此处转到环境变量并查看
那么我们应该能够通过点击这个来测试
即使这次会失败
它会抛出一个不同的错误
你可以看到它正在抛出错误访问错误
因为对于lambda函数来说，没有直接与s3桶交互的权限
要么我们得明确给予权限
要么我们需要更新现有的角色，以便通过策略继承权限
让我们处理那些记账活动 然后我们将实际看到如何再次上传并验证
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/086_Udemy - Data Engineering using AWS Data Analytics part1 p86 17. Run using AWS Lambda Console.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


当我们尝试验证lambda函数
该函数从存档中下载文件并上传到s3
它说访问被拒绝
我们需要确保lambda函数有权限
来处理将对象上传到s3
处理这个问题的一种方式
是给与与lambda函数关联的角色权限
要获取角色的详细信息
你可以滚动并查看权限
你可以查看角色的详细信息
你可以给角色添加权限
这是授予lambda函数处理s3权限的一种方式
如果你需要将s3作为你的lambda函数的一部分
让我点击这个
这将打开iam控制台
在这个案例中我们有一个名为s3 full on itv的政策
github将给与该角色该政策
我们可以说添加政策
然后可以搜索itv github
你有一个名为itv github s3的政策
它包含了itv github bucket的所有权限
让我选择这个 然后说添加政策
那么与该政策相关的权限现在将授予给lambda函数
现在你应该能够运行这个
它将会成功
让我运行这个
一旦我们验证
我们将对代码进行更多的更改
以便验证更加合适
让我输入测试
现在你可以看到它成功了
你可以转到s3控制台
你可以刷新这个
你应该能看到文件
时间戳是144
这是当前的时间戳
我想要给这些文件添加前缀
最终这些文件将进入landing
但现在我们将创建一个名为ah sandbox的前缀
并将文件复制到那里
让我创建那个文件夹
我可以说创建文件夹sandbox然后创建文件夹
让我删除这个zip文件
一旦删除
我想要回到代码并重构以使用前缀
我将这样做
我将创建一个名为file_prefix的变量
然后os.dot.environ.get(file_prefix)
获取文件前缀
现在我想同时使用文件前缀
以及文件名代替文件这里
我可以说 yes
然后单引号
然后花括号花括号
第一个花括号将包含文件前缀
第二个花括号将包含文件名
我可以去运行编辑配置
添加一个更多的环境变量
这就是文件下划线前缀
你可以看到沙盒
然后说好的
然后应用 然后好的
你可以在本地机器上验证
如果你希望在这种情况下
我将只是更新文件
我可以去这里
我可以更新压缩文件现在我实际上可以去lambda控制台
然后说操作上传文件
上传到文件
然后真实上传保存
确保你审查代码
以确认更改反映为部分lambda控制台
让我们等到这被保存
然后我们实际上去适当的程序
这就是nothing but lambda函数
点py 你可以看到与前缀相关的代码
这里现在你必须去环境变量
点击编辑
添加环境变量文件
下划线前缀沙盒
现在你可以点击测试以确认它是否按预期工作
这次文件应该进入沙盒文件夹
在其中itv github桶
这似乎是成功的
你可以在这里看到详情
现在你可以去管理控制台
点击沙盒
你可以在这里看到文件到目前为止
我们已经实现了基本的功能来从hit归档下载文件并上传到s三
现在我们必须构建围绕它的智能
所以我们应该检查是否有新文件添加
如果yes 我们就只需下载新文件并上传到s三
我们必须跟踪下载的最新文件
这样我们就可以实际检查增量文件
然后确保下载那些并上传到s三 让我们进入详细信息关于实现那些功能的
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/087_Udemy - Data Engineering using AWS Data Analytics part1 p87 19. Validating files incrementally.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们理解如何实际验证新文件是否已添加
我们将使用Python的datetime实用程序进行验证
我正在创建一个名为little.py的新文件
然后我导入datetime中的datetime
我将使用elias作为dt，现在我将使用一些基线数据
我们的基线文件
让我命名为基线文件
基线文件无非就是
2021 29 01 00. json. gz
这是我们可以用来验证的文件格式
你可以通过访问AWS控制台来确认
你可以在这里看到 所以从这个文件开始
我们将逐个检查是否有新文件
我们将逐个验证
我们将检查，直到实际验证完所有文件后才停止下载
并在此时将文件上传到S3
让我实际上将日期和时间转换为日期
你可以这样做
你可以说dt_part
然后基线文件在此情况下分割
我们可以按点分割
然后说零
它将实际给我们日期部分
你可以打印以确认
让我运行这个
你可以看到日期和时间部分
我可以说dt.strip_time
A tlp time
我可以将dt_part传递给这个
然后我可以说y
它应该是大写的y-大写的h- -大写的h
如果你打印这个
它将实际以日期格式打印
你可以忽略这个 目前你不需要太担心这个
一旦你得到这个
你可以实际增加分钟、小时或天
使用称为时间差的东西
作为datetime t
我们也有称为时间差的东西
让我导入这里
我可以说time delta as td
然后在打印语句中
我应该能够说加上td的小时等于1
现在我们应该能够保存并运行这个
你可以看到r增加了1
这就是你应该如何增加1
然后使用这个你应该能够验证文件是否存在
直到你验证或下载完所有文件
如果你想下载，
让我们详细讨论一下，
这样我们就可以验证文件是否存在，
现在我们使用这个日期来构建文件名，
并且我们需要进一步处理，
你可以这样构建文件名，
通过使用一个叫做tf_time的功能，
所以在这种情况下，我可以实际上说dt点sdf_time，
然后我可以传递center作为第一个参数，
然后我应该能够说，逗号，y m d
现在我可以保存这个
我应该能够运行这个
现在你可以看到文件名只是2021
2029-01-01
然而你不能像这样使用01
因为你实际上查看文件名时
r部分要么是一个数字，要么是两个数字
它是一到九的一个数字
然后是两个数字
所以这种方法行不通
我们需要确保它以单个数字格式显示
在mac或linux上，如果时间在10点之前
你可以说连字符
然后你应该能够运行这个
它会实际上删除开始时的零
如果时间在10点之前
如果是windows 你可能必须使用这里的井号
尝试使用井号 如果不起作用
在Google上搜索并尝试找到解决方案
关于Windows在Mac或Linux上的使用
这个方法现在应该能行
我们从这个文件开始
获取列表并检查文件是否像这样
我们将使用request
来实际检查
然而 首先 让我们为前两个文件构建文件名
然后我们再继续
所以在这种情况下，我在说对于24个dt_part进行循环
等于基准文件
点分割 这是基准文件
然后下一个文件等于
我们可以实际复制粘贴这段代码
然后我们应该能够与点json连接
点gz 这将实际给我们下一个文件名
实际上你可以说'是'
然后你可以将其作为双引号的一部分包含在内
我将用单引号替换这个
这样它就能按预期工作
然后我实际上可以在花括号中包含代码的核心部分
现在我可以说点json点gz
像这样
我将能够生成下一个文件
至于dt_部分
我们需要将文件时间戳传递给dt_部分并继续
即使这一个我也会将其命名为下一个文件
然后我将用这些信息更新下一个文件
新的下一个文件将放在这里
然后它将实际给我们时间戳
作为dn_score部分，现在让我们打印下一个称为文件在这里
以确保我们能够以增量方式获取文件
现在是否文件名现在是增量方式现在我可以保存这个并运行这个
您可以在这里查看详细信息
所以它从2021年开始
二十九零一零一因此等等
这就是你应该能够得到文件名的方式
如果文件命名约定应该在月份或日期开头使用零
我们必须按照命名约定使用
在这种情况下应该是2021
零一
然后日期
我们必须使用这个
我们必须将其进一步扩展
我使用了不合适的
现在我已经修复了它
让我运行这个现在应该能工作
您可以从2021年开始获取详细信息
一月 二十九日第三十日零
我们可以通过request点验证
获取文件像这样
我们可以实际获取状态码并打印状态码
在这种情况下我必须导入requests
然后我可以说request点get
我必须指定该URI
我可以去下载点py
让我获取这个a
让我转到dot py并粘贴在这里
代替文件 我必须使用下一个文件
我们可以说打印状态码
文件
下一个文件
res点状态码
保存并运行
这将需要一些时间
必须下载整个文件
即使我们不会实际保存任何内容以获取状态码
因此我们必须等到所有事情完成
您可以看到第一个文件已处理
您可以看到状态码为200像这样
我们可以按顺序处理所有文件
每当状态码不为零
我们可以停止它
我们将深入探讨这些细节
一旦我们验证了这一点
因为它对我工作正常
让我暂时停止这个
因为它浪费了太多时间
让我更改基线数据
因为
现在而不是说在24的范围内
我将说while true
我实际上开发了一个无限循环
如果状态码为200
我想继续
如果状态码不为200
我想从循环中退出
所以这将是这样的方式
在提取日期部分后
甚至在提取日期部分之前
我们可以实际处理执行这两行代码
因为我们必须处理基线文件
因此这必须在日期部分之前
然后如果响应代码不为200
我想退出
所以这将是实现的方式
之后等于blah blah blah
我只需要说 如果s. status code不等于200
然后从while循环中退出
否则 只是打印状态码并继续到下一个文件
现在我可以保存这个
我正在使用2021年1月30日作为基线文件
我们将看到何时实际退出
让我运行这今天2021年
通常30
实际上打破这个循环不会花太多时间
即使它说下午2:21
因为我在印度
存档中可用的文件可能至少是8到9小时旧
让我们看看 我们将实际获取文件到多久
直到
我们可能仍然无法获取文件
印度当前的时间是十四
你可以看到文件可以一直追溯到2021年1月37日
没有文件 我们可以将其用作处理文件的实用工具
然后当有文件时
我们可以下载和上传至S3 否则我们就会忽略并等待到下一次计划
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/088_Udemy - Data Engineering using AWS Data Analytics part1 p88 21. Reading and Writing Bookmark using s3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


为了增量方式拉取文件并上传到S3
我们需要维护书签
让我们理解我们如何利用S3
实际上处理关于将文件复制到S3的最新文件详细信息
作为后续运行的一部分
我们将尝试拉取已经拉取过的文件之外的文件
话虽如此 让我们假设这是我们的基础文件
我将其命名为2020-03-00
Jason Gz
我想确保已经下载的文件名被保存在
S 三 让我们看看S三中是否已经有该文件
我将实际访问S三管理控制台
我将实际访问ITV的GitHub部分
GitHub存储桶 有一个名为沙盒的文件夹
我们将使用沙盒进行验证
如果你去沙盒
已经有一个书签
让我删除这个
让我选择永久删除，以确保文件能够无问题删除
现在文件已经删除
我应该能够回到python
我正在使用称为草稿板的pyjam的一部分
你应该能够创建草稿板或草稿文件
你应该能够进一步
书签内容将被写入s three的是这个
我们可以将这个转换为字节
然后我们应该能够使用put object上传到s three
我们将在后续的时间点讨论put up
让我们深入了解get object的细节
如果你想要获取关于get object函数的帮助
你可以说help
s three_client.
get _object
你应该能够运行这个
你可以实际看到关于get object函数的详细信息，用于获取对象
你必须传递bucket
然后，键键无非就是我们内容的文件名
目前我们没有这个文件
因此，当我们尝试使用桶和键运行此操作时，它会失败
让我们看看
我可以说
s3_client.get_object
桶名无非是itv_github
文件名可以像这样传递
在这种情况下，我必须说key等于sandbox_bookmark
目前没有这个名称的文件
因此它将失败
让我运行这个
你可以看到它正在失败
实际上它会抛出一个名为无此键的异常
我们可以像这样捕获它
你可以在try块中说try
我们必须在异常部分运行这段代码
特别是为了捕获这个异常
你可以说那里有一个叫做客户端错误的东西
我们必须导入它并且我们要继续
客户端错误是bottle到核心l工厂的一部分
让我们导入它
我可以说导入bottle核心协议也是bottle三本身的一部分
一旦安装了bottle三
它将负责安装bottle核心
我们可以说bottle到核心是工厂
然后
错误实际上我们应该说从协议错误工厂导入客户端
现在我们应该能够用e捕获它
然后实际上我们可以捕获错误代码，那就是无此键
我们可以像这样捕获错误代码
如果e. 是客户端的别名
作为如果e. response of error
然后 chord equal to nauset
我们可以捕获异常
我们应该能够做我们想做的任何事情
通常我们会实际上在这里有基础线
如果你在s3中没有书签
我们必须从基础线开始
基础线可以捕获在这里
我们将实际上作为最终代码的一部分在后一点时间看到
我们现在将只使用这个
然后我将只说pass
它将处理传递异常
现在将不会抛出任何其他
让我分配给它一个变量
变量名是无书签文件等于so
即使文件不存在
它将不会只是抛出异常
它将为我们现在实际上写入内容
那就是这个到s3
我们可以使用s3 client. put object
让我们看看如何处理
让我注释这
我可以看到s3 _ client. put object作为对象
我们必须传递三个参数
第一个是bucket
桶名是itv - github
我们可以将文件传递到s3中，你想写入的文件作为key
我们应该能够复制粘贴这段代码
然后我们可以使用一个名为as body的关键字参数
作为身体的一部分
我们可以传递文件名
我们也可以直接传递内容本身
但当我们尝试传递内容时
我们需要将其作为字节流传递，以将书签内容转换为字节流
我们可以使用encode函数
它位于字符串之上
我们可以像这样说uf hyphen eight
它将处理将内容转换为书签
下划线内容转换为字节流
一旦转换为字节流
我们应该能够使用put object并将此内容写入文件
现在我们应该能够运行此命令
运行管理书签
书签内容将写入文件
我们可以通过访问s3 web控制台进行验证
让我刷新一下
你应该能够看到文件
现在让我取消注释，我想从文件中读取内容
这次我们说书签下划线文件
当我们运行这个
它将不会抛出任何其他
让我在这里评论这一段
因为文件现在已经被写入
如果我运行这个
书签文件会有些东西
让我们看看那是什么
让我说出书签下划线文件的打印
然后让我运行这个
你可以看到，dict是字典的一部分
你有几个属性
你可以用来读取内容的主要属性就是body
如果你一直往下看
有一个叫做body的东西
你应该能够说print type of body来实际获取body的详细信息
在这种情况下我们可以说body的bookmark文件像这样
这样我们就可以获取关于body的详细信息了
让我运行一下这个
你可以看到body的类型是streaming body
如果是一个小文件
你可以做的就是
你可以直接在流体上使用read
你应该能够读取内容
内容将是字节流类型
我们可以通过使用decode函数将其解码为字符串
现在让我实际说打印
然后标记文件体
然后说点read
它将处理读取内容
让我们看看输出会是什么样子
你可以看到输出以称为b的前缀打印出来
因为它是字节或比特流的类型，为了解码它，你需要将其转换为字符串
你可以说点解码uf iphone eight
现在我们应该能够运行这个
我们可以看到输出
它是字符串类型
这就是为什么它没有在开头显示b
这就是你应该能够从书签文件中读取内容的方式
然后我们可以实际上增加一小时
获取下一个星 然后我们应该能够从github档案中下载文件并上传到s3
三会使用这段代码作为最终应用程序的一部分 我们将自动化获取文件的过程，以增量方式上传至s3
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/089_Udemy - Data Engineering using AWS Data Analytics part1 p89 23. Maintaining Bookmark using s3.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们了解一下我们如何实际在s三中维护书签的步骤
我们已经理解了如何从s三中读取和写入书签
现在是时候在我们在s三中维护书签方面增加一些智能了
长时间间隔后的过程
有文件可用
我们应该能够处理这些文件
增加书签并保存到s三中
一旦文件不再可用
我们只需从循环中退出并退出
让我们在这里详细说明
在这种情况下，我们有所有这些
如何使用datetime来实际增加时间戳
或日期一小时
我们可以使用相同的逻辑
只要我们能够增加文件，就应该能够增加
从基准开始
一旦文件不再可用
我们只需从循环中退出
我们需要维护一个无限循环并检查文件是否可用
然后当文件不再可用时
我们只需从循环中退出
如果文件可用
我们只需处理文件
在s三中维护书签
这样在下一次运行时，我们可以从我们停止的地方开始，所以首先
我们需要导入所有必需的库
让我处理在这里导入所有必需的库
我正在替换这里的一切
这些是我们需要的库
我们需要datetime
datetime time Delta requests
Auto three 我们还需要导入这个client double
以便我们可以处理异常
我们从基准文件开始
基准文件就是最后一个文件
在这个文件之后，有很多文件
因此，而不是使用这个基准文件
我在材料中使用了这个
我说2021年
1月31日
作为基准 我们从那里开始
我们必须确保使用适当的配置文件
并创建s三客户端
这将创建s三客户端
使用适当的配置文件
现在我们可以实际使用这个try accept块
这将实际检查
如果书签存在
如果书签不存在
它将直接进入异常处理
我们实际上使用基线文件作为参考
我们希望处理该文件并将书签设置为该文件
所以现在如果我向你展示与这个try catch块相关的逻辑
是这样的
我们已经讨论过这些
我在这里重申
我们正在使用获取对象并传递桶名称
以及这个键
如果文件像这样
我们实际上是从书签文件中读取内容
并将其读取到名为previous_underscore_file的变量中
否则我们将previous_file设置为baseline_file
baseline_file实际上就是这个
我们需要确保baseline_file设置为最后成功复制的文件
并将其复制到s三
因此下一个文件必须被确定
我们必须下载下一个文件
上传到S3
更新书签
这就是循环 这是我们必须遵循的方式
它将看起来像这样
所以我们已经看到过这段代码了
让我复制粘贴这段代码
现在可以先删除这两行
我们将在后续的时间点回来处理这些
使用文件名
实际上我们从文件中获取日期部分
它是用于前一个文件
它已经在s three中
然后我们实际上使用日期时间函数
如tlf_time和sdlp_time来生成下一个文件名
我们必须增加一次并获取下一个文件
然后我们应该能够使用此方法下载下一个文件
一旦下载了下一个文件
我们应该做的是更新书签
我们也必须将此文件上传到S3
这次我们不会覆盖如何将文件上传到S3
尤其是文件的实际内容
我们将在主要代码中看到
假设文件已成功上传到S3
让我们专注于书签
让我实际复制所需的代码行
这将负责在S3中更新书签
这就是我们所说的代码行
书签内容等于下一个文件
这就是已经处理过的文件
文件的处理将在这里进行
就是把它上传到s three
然后我们想将书签内容设置为下一个文件
我们希望将这些内容添加到书签文件中
这将处理这个问题，现在这必须写入循环中
因此我们必须使用这种while循环
同样的内容必须放入while循环中
这必须在为真时循环
我们需要在if条件中添加break
当我们想要break时
每当没有以下一个文件名称的文件时
所以如果请求的状态是404
那么我们必须break，否则
如果它是200
那么我们必须处理，所以if条件将放在这里
我们可以说rest.status_code不等于200
然后break如果你愿意
你可以具体一些 也
嗯 你可以说404
这就是一个文件未找到或请求未找到
你应该能够break
当它是404时
你可以实际上有一个if条件
并且如果它是仅200
那么你实际上可以升级书签
是的 你可以实际上写异常
我现在不会覆盖所有不确定性
我只处理200
只要status_code不等于200
你应该继续跨越文件
一旦它是200
我们应该从中退出以验证这一点
让我只打印
在这种情况下我说打印
是的 下一个文件的状态码是rest.status_code
我应该能够保存这个
所以每当我们实际上获取一个文件时
它将打印这个消息 然后它将在s three中更新书签以开始
让我清理书签
这是作为s three的一部分已经存在的
这是由于之前的主题生成的
现在我删除这个
我必须说永久删除
这样它就可以被删除
让我退出
然后让我在这里
然后让我运行这个
现在正在运行
你可以通过打开终端来验证
然后说 aws s three s three columns
斜杠斜杠 itv 斜杠 github
沙盒书签配置文件
itv github
你可以按回车
我们已经删除了书签
让我们看看它是否实际显示书签或否
它正在显示 这意味着使用终端验证新书签已生成
同时使用python运行
你可以实际说 aws s three cp
然后复制这个s three 路径
我们的s three 实际上我们应该使用 hyphen hyphen profile
之前的命令中没有e
但依然有效
它起作用的原因是我正在使用默认的root凭据
因为root凭据对这个桶有权限
你将能够获取详细信息
你可能无法看到这些
如果你在argument profile中有拼写错误，现在我应该能说tilde
斜杠 downloads
然后书签和profile itv github按回车
它将实际将文件保存到此位置
一旦成功复制，我们应该能够查看详细信息
我可以说cat downloads bookmark
我们应该能够看到这些详细信息
让我们检查程序是否仍在运行
我们可以转到run console
它已经完成
它实际上已经完成
这就是我们应该能够开发智能，继续尝试
只要文件可用
如果文件可用
为每个成功过程处理它们
确保更新书签
这样作为后续运行
我们知道我们实际上在哪里
我们可以从那里继续
因为我们已经制定了逻辑
让我们模块化并实际部署到aws Lambda控制台并验证功能是否按预期工作
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/090_Udemy - Data Engineering using AWS Data Analytics part1 p90 25. Review the incremental upload logic.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


让我们回顾一下最终代码，该代码将从存档中下载文件到s three
作为这个过程的一部分
我们需要有一个存储桶名称文件
前缀 书签文件和基线文件
让我们了解这四个不同的环境变量，我们将使用它们来配置我们的工作
第一个是存储桶名称 in
在我们的情况下，它只是itv  -
GitHub将跟踪所有书签文件
连同实际文件本身
与GitHub有关在这个存储桶中
文件的位置将基于文件前缀
它将类似于着陆
Geh活动或我们想要给的任何名称
当我们谈到我们的主文件时
它将是着陆活动
我们将在同一位置创建书签文件
并将其命名为书签作为这个环境变量的一部分
我们将实际设置书签文件的名称，因此作为部署过程的一部分
我们将说存储桶名称
环境变量为itv
GitHub文件 前缀为着陆 jh 活动
书签文件为书签
我们将设置的重要环境变量是基线文件
当我们首次引入源时
我们将实际进行基线复制
通常我们会从任何我们想要获取的源获取数据并将这些文件复制到数据湖中
这将与之相关联的基线
在我们的情况下 因为我们有文件名年份月份日期
并且是jason和gz扩展名
我们需要确定基线文件是什么
之后我们需要处理增量加载
并将该值设置为基线文件
这四个变量的重要性现在作为while循环的一部分
它将一直检查直到文件在 jhrk 网站可用
如果文件不可用
它将退出
您可以看到它实际上获取了先前的文件名
如果您查看获取前一个文件名的逻辑
我们有相同的 try
Accept 块
它正在检查 书签文件是否存在
如果书签文件存在
它将实际从书签文件中读取内容
如果不 它将将基线文件作为前一个文件
我现在已经定义了一个函数
如果你再次访问lambda函数
在获取前一个文件名之后
我想要获取实际应该下载的文件
如果你查看获取下一个文件名的逻辑
它包含日期函数
这将实际负责提取日期部分并增加1小时
以及文件名
文件名将是我们拥有的任何文件名
加上一或点json点gz
所以，如果基准文件是2020-31-01-00.json.gz
下一个文件将是2020-01-31-01.json.gz
下一个文件将递增
如果你在获取下一个文件名后到达lambda函数
我们正在尝试下载文件
如果状态码是404
我们声明文件名无效或下载已赶上至前一个文件名
然后我们打破循环
如果状态码不是404
在我们这种情况下我们只能得到两个状态码
截至现在，一个是四或四，另一个是两百
因此我们可以安全地假设所有不是四的力都是两百
如果你得到的状态不是四零四和两百
你可能需要处理任何其他状态代码而不是四
四和两百
你需要捕获异常并锁定异常
以便你可以调试并修复这些问题
如果状态码不是四或四
那么我们将上传使用此下载文件函数下载的内容到此位置
首先 让我们回顾下载文件的逻辑
然后我们将实际上传至S3
上传至S3也是功能
下载文件也是功能
如果你查看下载文件
它只是在文件名上做GET请求
文件来自下一个文件
如果文件存在
它将包含内容以及状态码
状态码将是200
如果文件不存在
它将不包含任何内容
它只会包含状态码404
如果状态码不是404
我们将调用上传3
我们传递内容
内容是来自这个
它只不过是字节流
然后我们传递桶名和文件名加上前缀
所以无论使用 get next file 生成的文件名是什么
使用前缀 ah 的文件将是相同的文件
内容将被复制到其中
实际上您可以查看上传_s_three
它只包含获取 s three 客户端的逻辑，并使用 s three 客户端
现在将内容放入桶中的文件
如果您去查看 lambda 函数
在上传文件后
我们正在说打印文件名成功处理
然后我们上传书签
你可以点击这里查看逻辑
在这种情况下，我们将书签的内容复制到书签文件中
这个书签内容是什么
如果你去查看lambda函数
我们传递的书签内容实际上就是文件名
作为第四个参数
我们实际上传递了文件名
这被认为是书签内容
文件名被转换为字节流
并且使用该字节流
我们在将文件上传到s三
这就是我们更新书签的方式
这就是逻辑看起来的样子
你可以看到 逻辑是无限循环的一部分
只要你有文件它就会工作
它会下载文件
将文件上传到s三 更新书签
如果文件不可用
它将很快完成
因为我们已经准备好了代码
正如我们理解的那样
这个代码正在做的 现在是我们上传至aws lambda控制台并进行验证的时候了
以确认文件下载没有遇到任何问题
我们可以在本地验证
也从本地
有点慢
我将演示如何上传和验证在s three
我在本地通过验证
我们已经在本地验证方面看到了这些细节
在过去的几次中
如果你觉得不舒服
如果太多人提出担忧
那么我可能也会展示如何本地验证 但现在我会继续
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/091_Udemy - Data Engineering using AWS Data Analytics part1 p91 26. Deploying lambda function.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


当我们准备好代码时
让我们在aws lambda控制台中验证这段代码
我将在终端中操作
我正在删除这个zip文件
我可以说rmg活动下载器
点zip 它会完全删除文件
然后我可以去jhlib
我们在这里有所有有关这个应用程序的库
这里只包含应该上传到aws lambda控制台的库
实际库
包括auto three 实际上是虚拟环境的一部分
在这种情况下 因为我们只对requests感兴趣
并且requests已经下载到这个文件夹
我现在进入这个文件夹
我应该说python r
让我输入文件名
然而，必须创建在父文件夹中
因此我说点点斜杠
jh活动下载器点zip
文件将创建在一个文件夹上
这意味着它将创建在这个文件夹下
而不是这个文件夹
因为我们使用点点斜杠
现在我们要说点
当前目录中的所有内容都将添加到此zip文件中
现在我们应该能够运行这个
现在我们可以到上一层
然后说less iphone我们可以在这里看到文件
我们必须更新这个zip文件，包括所有相关源代码
从h归档中下载文件到s3
为此我们必须说zip- g g活动下载器.zip
然后与我们相关的文件是lambda function.py
upload.py和download.py
这些是我们需要的四个程序
我必须包括这四个程序
下载lambda function上传util下载.py
这四个程序包含了完整的源代码
我现在必须包括这四个程序
下载lambda function上传util
现在创建了这个文件，这些四个文件
我们应该能够使用aws lambda控制台上传
让我进入aws lambda控制台
我说s3然后lambda进入lambda控制台
我也会打开
和s3标签的lambda控制台已启动
让我完全删除这个
这样您就可以清楚地了解如何创建并重新开始这些步骤
我现在删除这个，lambda函数已经删除
我也要去itv的github桶这里
作为itv github的一部分
我们将复制文件的位置就是我们将要复制文件的位置
我想删除这个书签
让我永久删除
在这里删除 这不是我创建书签和文件的地方
这就是着陆点
然后活动
让我们看看书签是否已经存在
这也是一部分
让我清理一下
它会处理删除书签
我想从2021年1月30日开始
所以我让我退出
让我删除所有从2021年1月30日添加的文件
所以这些都是我想要删除的文件，以确保这些文件再次添加
让我删除这个
让我永久删除这里
现在 您没有这些文件
从一月三十日开始
您将有世界文件，那就是十三
十四和十五
如果您想要 您可以实际说2021
一月 第十五日九点在基线文件
它将从那里开始下载
然而，我将使用2021年
一月三十日零点在基线文件
我们将看看这些文件是否会成功下载，还是不会
我们已经清理了书签以及文件
并且我们也删除了lambda函数
现在 让我们创建一个lambda函数
新鲜的 我正在说
创建函数 然后下载gh活动
这是函数名称
您需要确保运行时只使用python
3.8 您可以实际审查权限，我们不会在此时修改这些内容
我们将在后续时间探索如何修复权限
目前 我们将定义函数名称
然后运行时
然后我们可以点击创建函数来创建函数
一旦函数创建完成
我们应该将文件上传到这个函数中
然后我们必须处理一些活动
以确保函数可以无问题执行
我们将从顶部开始处理权限
我们需要确保与该lambda函数相关联的角色
具有对s3桶的权限
我们试图操作文件使用此桶
在这种情况下，桶名无非就是itv github
我们需要确保该角色对itv github桶具有读写权限
github桶 我们可以点击此
这将带我们进入iam控制台
您需要附加额外的策略
我们为github全权访问创建了自定义策略
我们可以搜索它
它无非就是itv github
s3全策略 我们需要选择此
然后附加策略
它将处理授予s3桶所需的权限
以便lambda函数实际上可以复制文件
并且更新书签
现在我们可以实际上转到lambda函数
因为我们已经处理了权限
让我们审查其他详细信息
但在那之前，我们必须将文件上传到这里
您可以通过再次访问配置，然后说操作来上传zip文件
并说上传zip文件
然后您可以点击上传
您可以选择zip文件
说truthful上传
然后保存它将处理上传文件
到目前为止，我们已经上传了文件
我们已经处理了权限
并且我们已经上传了文件
一旦文件上传完成
我们需要确保代码是最新的
您可以在这里查看代码
您可以在这里查看所有python脚本，您可以看到download.py
lambda function pi upload.py和digital pi
如果您转到lambda function.py
您可以看到代码是最新的
如果您看这里
我们需要定义四个环境变量在此列表中
它们无非就是桶名
书签文件 基线文件文件前缀
让我们设置这些环境变量，为此我们需要滚动浏览
转到环境变量
点击编辑
点击添加环境变量
第一个是桶名称
桶名称是itv hyphen github
然后处理环境变量书签文件
这是书签本身
然后下一个环境变量是基线文件
我们将使用2021年1月30日作为基线文件
让我看看我在这里是否有
我没有 让我此处输入
这是2021年1月30日零点json.gz
这不是零 实际上是零点json点gz
然后另一个环境变量，这就是文件
下划线前缀
当我部署为lambda函数时
特别是在生产中
类型情况
我想使用实际文件夹结构
文件夹结构是着陆
然后在itv github桶中的活动
这意味着我必须说着陆
然后g活动
这是我想复制文件的文件夹
这是运行此所需的四个环境变量
让我们说保存
我们现在几乎准备好测试这个lambda函数
然而 我们必须配置测试事件
您可以点击此 这将打开测试事件
我只是将其命名为活动测试
然后说创建 您可以现在给任何名称
如果您运行测试
如果一切配置正确
它将成功运行
但它会失败 让我们修复问题
如果它失败 它正在失败
说任务超时三秒后
它超时的原因是默认
超时是三秒
如果执行lambda函数需要超过三秒
它将仅以此级别失败
我们要设置超时设置
你可以向下滚动这里
你应该能在这里设置超时时间
我们可以说编辑
然后我们实际上可以给出像六十秒这样的东西
让我数六十
如果执行时间超过六十秒
它将失败 否则它将继续运行
让我们说这里一和零
所以我们实际上是把它设置为六十秒了
我们现在应该能保存这个
我们应该能测试它
我们只需要点击这个测试
让我们看看这次是否会成功
它似乎正在运行
你可以通过访问三管理控制台来验证
这可能需要一些时间
因为我们有很多文件需要处理，自2021年1月30日起
你可以刷新这个
你可以实际查看文件是否正在下载
你可以向下滚动 你可以在这里看到详细信息
有三份文件已下载
你也可以在这里查看书签
让我们回到这里，看看现在失败了
我认为它失败了
因为它遇到了内存不足的问题
然而它已经取得了进展并令人高兴
它实际上已经处理了保持书签跟踪以修复这个问题
你能做的事情
你可以实际上增加内存
你可以将其更改为5B，现在你应该能够保存这个
然后你可以说测试来测试它到目前为止
我们已经修复了权限
以便Lambda函数可以开始写入S3存储桶
我们也已经处理了配置环境变量
我们已经处理了配置基本设置
尤其是从内存和超时角度
现在似乎仍在运行
它在运行 你可以来这里
你应该能够刷新以查看文件是否正在下载
或者你可以向下滚动
你应该能够看到
文件正在无问题下载
与2021年1月30日相关的文件已成功下载
你可以点击此以排序文件并查看所有文件都在那里
没有缺口
与2021年1月30日有关
你也可以说2021年1月30日13:01
像这样搜索它
你可以看到有23个文件
之所以只有23个文件，而不是24个，是因为基准是2021年1月30日13:01
它将不会下载那个文件
它将实际获取下一个文件并从下一个文件开始下载
它假设已经将文件上传到S3，直到那个文件
现在我们可以实际上清理一下
让我转到这个lambda函数页面
你可以看到所有事情都已经下载和上传成功，一旦它赶上了
它实际上抛出错误
说文件名无效或下载已经赶上到这个文件
之所以显示是因为我们打印了这个如果状态码是4或4
所以这实际上处理了我们的lambda函数验证
作为这个话题的一部分
我们已经看到了如何上传lambda函数 如何处理所有与运行这个lambda函数相关的任务
并且我们已经成功运行了它来确认lambda函数按预期工作
因为你已经上传了lambda函数并且成功验证了
现在是时候为我们安排
让我们深入了解如何安排这个并验证它
我们将使用称为亚马逊事件桥或亚马逊事件桥的东西
实际上定期调用lambda函数 实际调用lambda函数的时间
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/092_Udemy - Data Engineering using AWS Data Analytics part1 p92 28. Schedule Lambda Function using AWS Event Bridge.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


到目前为止，我们已经开发了一个名为活动下载的应用程序
它将负责从jhr下载活动，并将其增量上传到s3
我们还将活动上传到aws lambda控制台并进行了验证
现在是我们安排时间表的时候了
我们可以使用称为aws事件桥的工具来安排
你可以这样开始
你可以在这里打开另一个标签页
然后转到aws amazon dot com
在这里搜索事件桥
点击亚马逊桥
一旦你进入亚马逊桥
你应该能够通过点击这里创建规则
在创建规则和安排规则之前
让我实际上清理文件
我将删除书签
让我选择一本书签
然后说删除
然后我必须说永久删除
作为这个文本框的一部分删除
这样书签可以被删除
让我清理文件
如果你记得 当我们实际定义lambda函数时
我们已经将基线设置为2021年1月30日
让我实际上去环境变量这里并审查基线文件
它只不过是这个
所以它实际上会下载
从2021年1月31日的.json.gz开始
我想删除所有文件
从2022年1月1日的jason.gz开始，直到最后一天
我可以在这里访问aws管理控制台
让我选择所有与30和31相关的文件
然后让我点击删除
让我点击永久删除
然后点击删除对象
它将处理删除2021年1月30日的所有文件
最后31天
现在清理工作已完成
我们应该去创建工具页面
让我命名为it v github hourly
即使我现在命名为hourly
我将每5分钟安排一次
如果你想防止描述
你可以在这里提供描述
我们将安排 让我点击安排这里
你可以使用表达式
或者你可以说分钟然后五
这样它就可以每五分钟运行一次
其余的东西让我们留下默认值
除了lambda函数
在这种情况下，目标无非是lambda函数
还有其他类型的目标
因为它已经被选择
Lambda函数 我们只需要转到函数并选择适当的函数
不用担心这里的其他事情
我们只需要确保配置了适当的函数并配置了时间表
根据我们的要求
我们应该配置其他人
只是为了确保它现在快速验证
我现在安排在每五分钟
一旦时间表定义并选择了函数，给定名称后
你可以实际上说创建
它将为您创建角色
然而 我们需要等待五分钟以确保在五分钟后成功运行
我们可以实际上转到对齐控制台
然后刷新此页面以查看是否添加了书签和新文件
一旦规则配置在任何时间点
如果你想查看矩阵
你可以转到规则页面
这是规则页面
你可以点击此矩阵以角色
一旦你点击此
它将实际上带你到云观察矩阵
你应该能从这里监控
你可以在这里看到详细信息
到目前为止，云观察图表是空的，因为它还没有触发
即使它被触发，因为有很少的触发器
你很快就不会看到太多的活动
让我们等五分钟
然后让我们去s三
并验证事件是否触发
现在事件应该被触发
让我转到s三管理控制台并点击刷新
让我们验证是否创建了书签
并且从2021年1月31日开始的所有文件
点json 点gz已成功从hu归档网站下载并上传到s三
这就是你应该能够利用书签 来处理数据的增量注入
在这种情况下，我正在使用s三作为书签
你可以选择任何与你相关的技术
在这种情况下，我正在使用s三作为书签
你可以选择任何与你相关的技术
我正在将文件上传到S3
我不想引入新技术
所以我使用S3
但是 如果你愿意 你可以使用DynamoDB或MongoDB
或者Postgres作为我们的想法的一部分
无论你选择哪种技术
你可以负责跟踪书签
使用该技术
关键在于你应该有书签，以便处理增量注入
我们也可以利用事件总线
比如事件桥接 这是生态系统的一部分，用于安排它
啊 定期处理摄入
当源文件添加新文件时
你可以为多种用例实施这种策略
不仅仅是这一个
只需确保你深入思考问题
确保你捕获了书签
并以增量方式捕获更改 并以增量方式将数据摄入到目标
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/093_Udemy - Data Engineering using AWS Data Analytics part1 p93 1. Setup Virtual Environment and Install Pyspark.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


这是我们如何开始使用Spark进行数据工程管道本地开发的方法
目前 最流行的Python版本应该是
你将只会使用Python3.7
根据你的项目
你可能需要选择不同的Python版本
这可能是Python3.6或3.7
首先，我们需要使用Python3.7创建一个虚拟环境
然后，我们需要激活它
一旦Python虚拟环境被激活
我们需要安装适当的Spark版本
你可以安装Spark2.4或2.3或3.4.1
这是最新的版本
截至今天 一旦完成
我们可以实际上使用Python打开
我们需要确保通过它们适当的虚拟环境
然后，我们可以实际上创建一个名为app.py的程序
并输入这段代码并验证
让我们详细看一下这些细节
然后，我们将实际上改善它
以确保我们有适当的本地开发环境，以构建使用Spark的数据工程管道
话虽如此
我现在在我的家目录
现在我要进入叫做projects的东西
然后在这个文件夹内
我想创建一个项目
项名称只是itv活动
所以我创建了一个名为itv g活动的文件夹
这是我的当前位置
我在这创建了一个子文件夹
该文件夹的名称是itv have活动
我必须进入该文件夹
然后我应该在这里创建虚拟环境
虚拟环境的名称是itvg
连字符v和v 你可以在这里看到
这就是我们应该能够在这个文件夹中创建虚拟环境
使用Python3.7
所以我可以复制这个并粘贴在这里
它将实际创建具有该名称的子文件夹
在这个文件夹中
你可以实际上创建一个iphone
你应该能够看到详细信息
我已经使用了创建命令
在当前目录中创建虚拟环境
你可以实际上在中央位置创建虚拟环境
也根据你的项目设计
你可能需要向你的主架构师咨询
你应该找出你应该如何为整个项目创建虚拟环境
现在您可以在这个文件夹本身上运行lf l
它有子文件夹，如bin lib included等
如果您查看bin文件夹
您将看到与Python 3.7相关的可执行文件
如果您查看lifolders
它将有Python 3.7
七点依赖项，这些作为部分此虚拟环境安装
实际上可以说Python 3.7侧包
这些是从这些设置之外的
在这个环境中没有设置额外的Python相关库
我们已经设置好了一个Python虚拟环境
现在是时候激活它了
激活 你需要运行一个名为activate的命令
这个命令在这个文件夹的bin下可用
你可以在这里看到activate
如果你是在Windows上
方法可能会有所不同
你可以通过谷歌搜索来了解
或者在mac上，或者你希望
你应该能够通过运行这个激活命令来激活它
使用一个叫做源的命令
你只需要说源itvg
短横线 V和v bin激活
实际上你可以激活虚拟环境
一旦激活
你会在这里看到什么是你的环境被突出显示
它会实际上告诉你它连接到哪个虚拟环境
就是这样 正如我们已经成功将python虚拟环境附加
现在我们应该能够处理安装
为我们的开发
您根据需要选择spark
现在 我正在使用spark2.4
到目前为止 我开发的任何代码在spark2.3
2.4 以及3.2.1之间兼容
你应该能够通过安装其中一个来练习
在这种情况下，安装spark2.4
可以说pip install pi spark等于等于2.4点星
它会处理安装2.4版本中的最新版本
你可以按回车键，它说没有匹配
我想在我的mac上，很多情况下我需要使用反斜杠
即使你没有反斜杠
它会工作 但在我的情况下，我必须使用所以与反斜杠
如果不起作用 然后切换到只使用星号，不加反斜杠
现在 Spark已经安装
你可以在这里运行一个管道
Itv G
短划线 V和v lib
然后python三点七
安装一些包来确保我们有文件夹来支持pi spark
到目前为止，我们已经设置了python虚拟环境
激活它 并在这个虚拟环境中安装了pi spark
既然我们已经完成了这一步
现在我们应该能够打开python并使用python来配置我们的项目
以便我们能够真正处理开发
使用id如python
让我们了解如何使用python来处理开发 在这个文件夹的上面
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/094_Udemy - Data Engineering using AWS Data Analytics part1 p94 3. Getting Started with Pycharm.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为前一个主题的一部分
我们已经成功创建了虚拟环境
并激活了它，同时也安装了它作为其一部分
现在是时候使用那个位置与Python进行进一步的应用程序开发
Python只不过是一个集成开发环境（IDE）
作为项目 我们通常使用Python进行应用程序开发
使用Python作为编程语言
甚至用于基于Spark的数据工程管道
如果编程语言是Python
我们最终会使用如Python这样的IDE
其他流行的IDE包括Visual Studio Code或Spyder
无论你使用哪种IDE
步骤几乎相同
我正在搜索PyCharm
在这里 你可以看到
让我点击这个
它会为我打开Python
一旦它打开
因为我们正在尝试打开已经设置好的文件夹
带有适当的虚拟环境，点击新项目
我们需要使用打开
一旦你点击打开
你应该能够转到位置
你应该能够选择文件夹并保存打开
它会为我们打开该文件夹作为项目
在我的情况下，它位于项目内部
然后它活动
你可以在这里看到虚拟环境
现在我们应该能够点击打开
它会为我们打开文件夹作为Python项目
现在你应该关注右下角
你看到虚拟环境在这里
它必须选择适当的虚拟环境
如果我把我的鼠标悬停在那上面
它实际上显示了位置
位置只不过是项目内部boot camp i material blah blah blah
那不是我想要使用的虚拟环境
我想要使用我刚创建的虚拟环境
实际上配置到新的虚拟环境
你应该做的事情
是你只需点击这个
说添加解释器转到现有环境
即使它选择新环境
然后点击这个
位置只不过是它项目在内部
我们有一个名为内部的文件夹
作为内部的一部分
我有一个名为itvg activity的文件夹
我必须做出选择 所以我实际上需要去确保我正在正确的文件夹中
我不应该在训练营中
所以我必须关闭这个
现在我必须向下滚动到父文件夹，因为这只是内部文件夹
所以在内部文件夹中 我需要转到itv
在这个中有活动
这是虚拟环境文件夹
其中包含bin
你可以在这里看到python可执行文件，你应该可以选择这个
点击 然后说好
它将实际处理为这个项目的虚拟环境
一旦完成
你可以验证使用命令行安装的所有库是否可用
使用pycharm或不仅仅是去pycharm首选项
如果你使用的是windows
你可以在文件下的产品设置中
这是文件
如果你展开那个 你应该能够在窗口中看到项目设置
然后你实际上可以去到这个项目
然后Python解释器
现在你应该能够在这里看到作为由虚拟环境安装的依赖项
正如我spark在这里可用
我们应该能够利用Python来开发数据工程应用程序
使用spark 让我们点击
好的，现在轮到我们开发一个hello world程序
确保派符文可以被利用进行进一步的应用程序开发
开发一个Hello World程序
你可以实际上 点击然后说新
然后说Python文件
确保你正确
点击项目文件夹
活动性
不是虚拟环境
永远不要在虚拟环境中创建任何程序
现在非常重要
你可以实际说在新的python文件在文件夹
然后说应用
它会处理创建程序
一个名为应用点py的文件在它的-h活动下
应用点py和itvg-h-v和v有相同的父文件夹
这就是itv活动
你也可以通过命令行验证
然后说alphon从父文件夹或plot基文件夹
这就是itv-h活动
你可以在这里看到app点pi
现在你应该能够在这里说打印hello world
右键点击这个
然后你可以看到输出在这里
这就是你可以实际开始使用pie charm的方式
在现有的文件夹结构上
有时候我们可能想要用pie charm直接创建一个新项目
我们可以利用pycharm直接处理这个问题
但另一种方法是使用现有的文件夹结构来打开
使用python并进一步发展开发努力
我已经覆盖了它的第二部分
我用命令行设置了虚拟环境
激活它，安装spark
然后我使用pycharm打开了那个文件夹作为项目
我已经验证了
这也是一种常见的方式 对于使用python进行基于python应用程序的开发
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/095_Udemy - Data Engineering using AWS Data Analytics part1 p95 5. Passing Run Time Arguments.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


正如您已成功设置PyCharm用于应用程序开发
并且通过运行这个Hello World程序进行了验证
现在让我们了解如何将这些运行时参数传递给这些基于Python的程序
有一个名为argparse的库
我们应该能够利用argparse库
你需要像这样导入它
它作为Python核心引擎的一部分提供
你不需要安装任何额外的东西来使用它
一旦导入
我们应该能够利用argparse
让我们说打印类型argparse
让我们了解argparse类型的类型
我们应该能够右键单击此
然后说运行 您可以看到argv是类型列表
让我们尝试访问argv
我可以说打印这个点零
当我们运行此时，让我们运行此
它实际上显示用于运行此程序
所以我们正在使用app.py运行此
您可以在此看到程序名
Rb将程序名作为第一个元素
现在您可以传递其他运行时参数
如果我说argv of one
它会失败，因为我们没有传递任何运行时参数
让我运行此
它会抛出异常
列表索引超出范围
到目前为止我们已经验证了
使用Python 我们应该能够使用命令行进行验证
所以首先让我更改为our
我们零
让我保存此
您可以单击此处的终端
它将打开像这样的终端
一旦打开了终端
然后我们应该能够运行称为python
然后app. p
您在当前文件夹中有app
我们可以实际上验证为说as an ldl
您可以在这里看到
即使您可以从终端使用CLI
如果我说iphone在这里
我们有一个either
我们可以说python
App. py从这里
或者我们也可以从这里说
两者相同
通常提供访问终端的权限
这样您可以直接从ID本身验证，而不必在mac上进入终端
或者您想要，甚至对于Windows，话虽如此，现在
您可以看到pi被打印出来
当我们实际上使用pycharm进行验证时，会有所不同
直接使用python wizard
我们看到了程序名称的完全合格路径在这里
当我们使用命令行时
它只显示路径
它只显示程序名称
现在并不显示完整的路径
如果我说六选一
然后python app. p
它实际上抛出了相同的级别
这就是列表索引超出范围
让我们理解我们如何传递一个参数
以便我们可以打印它
您只需设置python app. py
然后一些字符串值
在这种情况下，我正在传递它
你可以在这里看到它
假设我想从我的多样性中打印一个hello world
或者任何传递的参数
我可以说从这个点打印hello world
像这样的一个点。现在我应该能够保存这个
环绕这个，你可以看到消息hello world from my
我们也可以直接使用pycharm验证
有时你可能只想使用pycharm并确保所有这些参数都被保存
你可以随时运行它
你必须使用称为运行时配置的东西
使用Python 实际上可以通过转到运行来访问它们
在到达那里之前，点击编辑配置
让我运行这个看看会发生什么
它失败了 说索引超出范围
因为我们没有配置任何运行时参数作为Python的一部分
IDE没有设置运行时参数
你可以实际上转到运行
然后说编辑配置
你需要确保有一个指向你试图运行的程序的应用
名字可以是任何
但这时更重要
我们在验证ABP承保活动
因此脚本路径必须指向那里
如果你看不到这个
这可能是这样的
你可能需要点击加号
然后你应该能够去这里的python
然后你实际上可以配置文件
我们在谈论tab py
我们必须点击打开
你可以在这里看到它
现在我们应该能够进一步
所以，你可以使用这种方法
或者你只需尝试运行一次
然后选择合适的应用程序
然后进一步
现在你可以通过实际在这里输入值来传递参数
无论你在这里输入什么，都会作为程序的运行时参数
使用python
我们可以说应用
你可以实际点击创建配置来给它一个名字
它自动从我们的python程序名称中提取了名称
这就是为什么你在这里看到的原因
如果你想改变它 你可以在这里改变它
你还需要确保工作目录是我们实际开发程序的基目录
在我们实际开发程序的基目录中
所以这种情况下，它只是itv
G h活动 我可以说现在申请
好的 现在
配置已经为我们的pie设置好
配置巫师 我们应该能够正确
点击并说
点击运行，你可以在这里看到输出
如果你有多个参数
你可以实际将多个参数作为参数本身传递
在编辑配置中，你需要确保选择适当的脚本
然后你可以使用空格作为分隔符，传递任意多的一次性参数
这就是你应该如何将运行时参数传递给你的程序 你也可以通过终端或PyCharm进行验证
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/096_Udemy - Data Engineering using AWS Data Analytics part1 p96 6. Accessing OS Environment Variables.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为前一个主题的一部分
我们看到了如何传递运行时参数并使用此库访问它们
尽管它被广泛使用
通常我们只传递少数运行时参数
当我们来说到典型的应用程序时，我们将能够使用这些参数来访问它们
我们可能有几十到几百个一次性属性
这些需要得到执行
通过参数传递所有事情并使用此来访问它们并不实际
有一种称为环境变量或属性的东西
我们现在将利用这些方法
让我们了解如何访问在操作系统级别设置的环境变量
使用正在开发的应用程序
有一个额外的库称为voice
您可以实际将voice作为os的一部分导入
有一个称为envelon的东西
它暴露了一个称为get的函数
它只是它下面的一个属性有一个称为get的函数
我们可以实际使用get来访问在操作系统级别设置的环境变量
因此，在这种情况下，您可以实际打印voice enon的类型
让我们运行这个
它是os dot underscore envellon类型
它是此库或程序中的一个属性
现在，它暴露了一个称为get的函数
我们应该能够使用
使用get来访问在级别设置的运行时属性
因此，在这种情况下，假设我去到隧道
然后我说export u equal to bars
我想访问这个
现在您可以实际说print voice dot并且我们get的键是nothing but foo
您必须传递完整的这里
它将实际获取与此相关的值four
这就是bar
您应该能够打印出那个
让我保存这里
然而，如果我使用pie charm运行
它将不会打印出任何内容
它将只打印none
但是，如果我使用终端运行
因为我在终端级别设置了环境变量
我应该能够说python app dot py
您可以在这里看到bar
您也可以说wise dot on dot get foo
让我保存这个
现在让我们运行程序并说app
主要的是在这个占位符中的单引号
我正在传递full在双引号中
您可以在这里看到输出
让我删除这个
这就是您应该能够访问运行时环境变量的方式
如果你想要验证
这是用pyon
你可以实际说运行编辑配置
你必须转到环境在环境
你有环境变量
你应该能够实际处理设置你的程序运行时环境变量
然后使用python验证
你必须点击这个
然后加和条
让我们说好应用
好的现在
如果我运行这个
你可以看到来自条的你好世界
当环境变量没有被设置时
在运行中使用编辑配置
我们看到none现在
我们看到一个条
通常 我们使用这种方法来传递数据库凭据和其他常规信息
这被广泛使用
你应该真的很熟悉这个
确保你理解如何从操作系统将环境变量传递给程序
你必须使用neuron get
你必须传递键如果是数据库
你有称为主机端口
使用名称 密码
也有数据库名称
你必须设置所有这些作为环境变量在运行编辑配置
你可以实际在这里设置那些东西
你应该能够使用waste in one get访问那些东西
你应该能够将其用作程序的一部分当你实际部署到生产
我们通常使用命令行运行
我们使用一些调度程序安排
我们部署到Web应用程序服务器当我们部署到生产
我们通常使用终端验证
你可以实际使用终端验证使用这种方式首先设置环境变量像这样
使用export命令
如果是Linux或mac
然后你应该能够使用此方法运行程序
作为最后话题
我们看到如何访问运行时参数使用这个 现在我们看到如何使用环境变量访问
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/097_Udemy - Data Engineering using AWS Data Analytics part1 p97 7. Getting Started with Spark.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分
我将演示如何实际运行一个使用Spark库的程序
这将实际处理验证Spark
这是在项目虚拟环境中设置好的
项目已经使用PyCharm打开
让我转到Python
这里 你可以看到app.py
我们已经运行了Hello World程序
我们还探索了如何传递运行时变量
以及如何传递环境变量
现在是时候进入与Spark相关的内容了
我现在可以删除这个
我们将使用适当的库
例如这个voice等
随着我们进一步深入
我们现在只需导入Spark Session
我们需要构建称为Spark的对象
使用Spark Session相关的apt导入
你可以说from pyspark.sql import SparkSession
然后定义一个名为spark的变量
然后Spark Session. builder
你必须记住这些事情
不要太担心这是什么builder
最后 它将实际创建一个称为Spark的对象
与相关的Spark Context
在builder之后
你需要指定应用程序名称
让我命名为a
活动获取
启动
你还需要指定主
现在我们将使用本地模式运行
然后你可以说get all create
这就是你应该能够创建Spark对象的方式
它是Spark Session的
你可以实际上说print spark的类型以获取该对象的类型
现在你应该能够运行app
你应该能够看到Spark的类型
你可以看到它是pyspark.sql.session的Spark
Spark Session
这就是你可以实际使用Spark作为这个环境的一部分开始的方式
为了确保你可以实际利用Spark提供的API
你也可以说print spark.sql
选择当前日期
它将实际打印当前日期
我可以删除打印语句
Spark sql返回称为数据框
数据框暴露了一个称为show的功能
我们应该能够使用这种方法打印出当前日期
让我写 点击这个
然后在应用程序中
你可以在这里看到当前日期
这就是你可以开始构建数据工程应用的方式
使用基于spark的api
使用python编程语言实际上会深入探讨现代化
随着我们进入与用例相关的实现 我将使用演示课程完整开发和执行生命周期的部分
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/098_Udemy - Data Engineering using AWS Data Analytics part1 p98 8. Create Function for Spark Session.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


您可以使用不同执行类型或模式运行Spark应用程序
其中之一是本地
当我们通常处理开发时
使用本地环境
我们使用本地执行类型进行验证
或者mo 当我们部署创新生产时
它可能在多节点集群上
它可以是YARN 它可以是Databricks
这可能是一个cm和等等现在
就我们运行的环境而言
我们可能想以不同的方式构建spark
因此，在这种情况下，我将使用本地运行
当我在演示模式或开发环境中运行时
我只想确保我创建了一个函数
这个函数最终将包含构建这个spark对象的逻辑
根据我们运行的环境来传递
让我们详细看一下
我们必须定义一个函数
我将在这个名为it的程序中定义这个函数，因为这里会这样
我必须去python
点击我的产品目录
新建python文件
确保它不会进入你虚拟环境
我看到很多人犯了这个错误，创建这些程序
作为虚拟环境的一部分
确保它们属于目录
itvg活动本身
你可以看到我是p和小圆点py
与itvg连杆v和v并行
现在我们应该能够包含这种逻辑
我可以做的就是
我可以右键点击这个，然后说重构
重构是IDE的关键特性之一
与IDE有关
它将负责对我们的代码进行更改
无缝的 在这种情况下，我必须说提取方法
然后我必须给方法起一个名字
方法名无非就是获取spark session
我可以说好的
你可以在这里看到创建的函数
我可以复制这个
转到util py粘贴
我可以删除这个
我可以说从pi spark dot sql import spark session
它必须返回spark对象数据
所以我们必须使用这个
然而 我想将这个函数传递两个参数，一个是
第二个是 app_name 代替这个硬编码的值
我想使用 up 和 score name
这是作为参数传递给这个函数
与 master 相关的 get spark session 函数
根据我们运行的环境，master 可能需要改变
根据环境，master 可能需要改变
在这种情况下 我将说，如果 e 和 v w 等于 dev
那么 master 应该是 local
我在这里可以按tab键
现在保存
我必须去app点pi作为应用程序的一部分
dot pi可以完全删除这个
我甚至可以删除这一行
然后我可以说
从util导入get spark session
然后spark等于get spark session
它需要两个参数
第一个是e v
我将在v中通过
第二个只是应用程序的名称
让我看看这里我使用的值
我在这里传递相同的值
这只是获取开始的GitHub活动
现在根据e
V 我将其设置为语音环境变量
我可以说e和v等于点nvion
点获取 然而 我在这里需要导入os
现在导入os
我可以说 e v i 或 o n 和 on
然后我可以将其作为第一个参数传递给这个
这就是你可以实际模块化创建Spark会话对象的方式
根据你将要传递给这个的环境
现在你应该能够运行这个并且可以看到输出
然而它失败了
因为我们还没有设置环境变量
如果你在使用终端
你可以直接说 export e 和 v i r o n 等于 dev 像这样
然后你实际上可以说 python app. py 并按回车
这将会创建 spark context 并写入数据
现在打印数据
如果你想用 python 来处理这个
你需要说 one edit configurations
点击这个 你可以删除这个环境变量
它无关紧要 我可以说加号然后说然后运行然后说好应用好然后运行它现在正在运行
因为使用python设置环境变量
一个巫师
让我们确保我们将此代码放在主函数部分
我只需要说def main
然后冒号
然后我只需在这里按tab
我必须调用这一点
我只需要说if _ _ name
==_ _ main
然后调用main函数
因为我们已经定义了main函数
让我们确保它得到验证
每当我们对代码进行更改时
我们必须运行和有效
以确保它按预期工作以验证
我可以实际上说正确
点击运行应用程序
它应该能够调用此main函数
我们应该能够看到当前数据
由于这一点
您可以在这里看到输出
您还可以转到终端并应该能够有效说python pi
像这样 您可以看到它实际上创建了这个spark context
您还可以在这里看到日期
这就是您应该能够开始的方式基于spark的数据工程管道
应用程序开发 使用python作为编程语言作为部分数据
新管道 我们通常从源读取数据
处理它 并根据我们需要现代化要求写入目标
我们将进入那些细节当我们进入开发 根据我们假设用例的要求
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/099_Udemy - Data Engineering using AWS Data Analytics part1 p99 10. Setup Sample Data.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


作为这个主题的一部分
我将演示如何设置抽样
这就是为什么我们可以验证我们的应用程序
随着我们进行这方面的开发
我们需要创建一个文件夹
这是创建一个文件夹结构的命令
我将在这个工作目录中创建它
我的工作目录就是这个
我们需要创建一个文件夹
在数据中调用数据
我想让这个文件夹在github上的结构性活动
让我运行这个 它会为我们创建文件夹结构
你可以实际上说查找数据
你应该能在这里看到它
你可以实际上说cd
然后复制粘贴这个
它会处理让你进入那个文件夹
一旦你在那个文件夹
你应该能下载这三个文件
这些文件有一个叫做github活动数据的东西
github数据是由一个叫做github arwebsite发布的
你可以实际上去jq
Org 如果你想要了解关于这个数据集的更多信息
让我访问我的浏览器然后说gehrk org
你可以在这里看到详细信息
这将处理下载与2021年相关的文件
一月十三号零
这无非就是中午
让我复制这个
然后让我作为派字符的一部分去终端
然后粘贴到这里
这个文件在下载时会自动处理
在下载完成后让我复制这个
粘贴并按回车
第三个也是一样的
我们需要等待这个下载完成
我们应该能够粘贴
这取决于你的网络速度
这可能需要一些时间
因为文件有几十兆字节
一旦所有文件都下载完成
你应该能够运行一个名为 lsi ta 的命令
如果你使用的是mac或者你想要
你应该能够看到这三个文件
如果你使用的是windows
只需运行 da 或者命令来列出该文件夹中的文件
现在我们回到工作目录
我们可以实际上点击这个
然后说复制路径
确保你复制绝对路径
然后你可以说cd
然后粘贴路径
然后你应该能够去到工作目录
现在你应该能够说查找数据
你可以实际上看到三个文件在这里
我们已经成功设置了样本数据，现在 现在是时候探索如何将这些读入数据框
```

### /content/drive/MyDrive/bilibili/Udemy-DataEngineeringusingAWSDataAnalyticspart1/100_Udemy - Data Engineering using AWS Data Analytics part1 p100 11. Read data from files.ai-zh.srt

```
【角色设定】
你是一位精通 AWS 认证知识,Snowflake,Airflow的中英双语技术编辑兼讲师。
你的任务是：纠正、润色并整理我提供的 AI 机翻中文字幕内容，使其成为既自然通顺、又符合 AWS, Snowflake和Airflow等专业表达的学习资料。

【内容背景】
输入的文本是从英文 AWS 等技术课程自动机翻而来，存在以下常见问题：
- AWS 等专业术语翻译错误或不一致；
- 缺少中文标点，语序不自然；
- 不符合中文技术教学风格。

【执行要求】
收到内容后，请严格按照以下步骤输出：

---

### ✅ 修正版讲解段落（自然语言版）
- 用自然、流畅的中文重新叙述整段内容；
- 修正所有 AWS 等专业术语，使其与 AWS 等官方文档一致；
- 语气应贴近日常教学讲解风格；
- 结构清晰，标点完整。

---

### 🧠 AWS 认证笔记版（复习整理）
请将上述内容转化为适合复习的笔记格式，包括但不限于以下要素：

#### 📘 一、定义与功能
简要说明服务或概念的核心定义、作用及常见用途。

#### 🧩 二、核心要点或组件
用表格或列表列出：
- 关键资源对象
- 检测/运行逻辑
- 触发条件

#### ⚙️ 三、运行机制 / 工作原理
解释该服务的扫描机制、自动化流程或数据来源。

#### 🧠 四、考试提示 / 常见考点
总结考试中可能涉及的重点、易混概念与对比。

#### 🪙 五、优势与特点
列出服务优势、特点与常见集成方式。

#### 📌 六、总结表（如适用）
使用“项目/内容”表格形式总结要点。

---

【输出格式要求】
请严格按照下列排版样式输出：

好的 👍 以下是对你提供的 **AI 机翻内容** 进行的完整修正版本。
我首先输出一段 **通顺、准确的讲解版本**（贴近日常理解与 AWS 等官方表述），
然后提供一份 **AWS，snowflake, airflow 等认证笔记格式总结版**，方便复习与记忆。

（接着输出上文两个部分的内容）

---

【执行】
收到以下内容后，严格按照上述要求输出，不需额外解释或总结。


读取刚刚设置好的数据
让我们创建一个名为read.py的程序
该程序将创建一个名为from_underline_files的函数
它接受四个参数
Spark作为一个对象
在这个例子中 我将其命名为spark
数据目录
我们文件所在的目录
文件模式，也就是2021
一月 十三 十四
十五 等等 然后文件格式
在这种情况下，文件格式现在是json
让我回到python这里
让我创建一个名为读取的新程序
因为程序文件已经创建
让我们理解我们为什么做这件事
在任何必要的数据工程管道中
我们通常从源中读取数据
处理它并将其写入目标
我们应该将整个管道现代化至少分成三个模块
一个用于读取 一个用于处理和另一个用于写入
首先 我们可以实际上有这样的三个程序
但随着我们扩大规模，我们需要开发大量的代码
我们可能需要从程序转向模块
在那种情况下 我们只需要创建名为读取、处理等的文件夹
然后将逻辑放入这些文件夹中 话说回来，目前
这将有一个名为从文件的函数
它将有四个参数
一个是名为spark的Spark会话对象，然后数据目录
然后是文件模式
让我检查一下augment名称
这只是文件模式
然后是文件格式
然后我们需要在最后添加一列
我会在这里写上
让我转到app.py
一旦我们创建了这个spark对象，将从文件中调用它
我们将传递适当的参数
我们应该能够导入，通过说from read
导入从文件
然后你可以说df等于df代表数据框从文件spark
我们现在必须传递额外的参数
如果你回到读取
现在从文件的读取没有逻辑
它什么都没写
这意味着它写了类型的none
因此，如果你回到app.dot.pout of nodf是类型的none
现在 当它来的时候，which is
在spark session之后 它暴露了一个叫做读取的东西
读取是数据框读取器的属性
使用读取 我们有访问APIs
例如json Parquet
等等 实际上读取数据从特定格式的文件
我们也可以使用一个叫做格式的东西
我们应该能够指定使用哪种文件应该读取的格式
在这种情况下，因为我们的文件是json类型
我们应该能够说spark
点json或spark或reformat of json
在实施之前，让我们理解如何使用我们的本地开发环境探索APIs
我们可以说pi spark这里
我们应该内部第一
然后运行这个由spark命令
它将实际启动python与基于spark的库
以及为我们预先创建的spark对象
你可以看到spark系统是可用的作为spark这里
因此，使用此spark
我们应该能够探索读取APIs的数据从文件
当涉及到spark
它有一个属性叫做读取
你可以看到它是数据框读取器的
并且这个spark类似于我们程序化创建的作为这部分的
获取spark session函数现在当我说spark点读取点并按tab
它将实际列出在这个数据框读取器属性上可用的功能
我们有jason读取json文件
Parquet读取parquet文件 Csv读取用逗号分隔的文本文件
我们也有称为格式的东西，这是一个通用函数
我们可以实际说spark格式并传递json到它以读取json文件
或者我们可以说spark点读取点json对于我们的情况
或我们可以说spark点读取点格式of json
因为我们的文件是jason
在我们的情况下
我们将使用spark格式
在我们的情况下 我们将使用spark格式
这就是我们为什么将文件格式作为参数传递的原因
要获取关于spark dot format的帮助
你可以说help of spark dot read dot format
然后按回车
你应该能在这里看到文档
这就是你应该如何读取json文件的方式
如果你想将格式作为函数使用
我可以实际上转到read dot py并按回车
我会说df等于spark dot
Read dot format json当它涉及到路径
这条路无非就是数据
所以我必须说加载是
这些是下划线
斜杠
文件和分数模式
然后我只需要返回df
这就是我们应该能够探索api的方式
我们可以实际上开发所需的函数从json文件中读取数据到一个数据框
然而，而不是像这样硬编码文件格式
我想使用这个参数
让我以参数作为逻辑来替换这个数据框中读取文件和写入文件的部分
现在准备好了
让我们去应用 点p中定义附加变量并使用这些变量从文件中自动读取
我们需要源目录
源文件模式和源文件格式
所以我在这里创建这三个变量
源_等于os点environ点get
获取_src_
正在定义
这些是环境变量本身
然后我们要说source_underscore
File_underscore pattern
在这种情况下 我说是的
然后
Envion. get source_underscore
File_underscore pattern
到目前为止，我们只设置了一个文件
一月十三日
2021年1月14日和1月15日
当我们进入生产时
我们将为每一天有两个四文件
我们希望使用模式
我们不仅要完整的文件名
所以我说的是连字符
它将处理给定模式的所有文件
这就是为什么我命名为模式
而不是文件名
Ssc_文件_格式
这只是一个点，然后是一个点
获取
Ssc文件格式
让我们用我的代码来审查这一点
现在完全一样
我们应该能够将这些作为参数传递给这个从文件函数
我可以在这里复制并粘贴none
一旦我们从文件中获得了数据框
我们应该能够通过打印模式来验证
我们也可以通过从数据框中选择一些记录来打印模式
我们可以像这样预览数据说df. print schema
我们说df.
选择报告. 星号在数据框中只是一个嵌套的json
我只是从那个嵌套的json中选择属性
这就是我为什么在这里说报告星号，然后点show
我们可以保存这个来验证
我们需要设置额外的环境变量
我们可以去运行编辑配置
我们需要传递三个wise level环境变量
并且我们必须说source _ the
我将在片刻内更新这一点
然后source _ 文件模式
这只是2021年01月13日
然后source _ 文件格式
这只是jason
当涉及到路径时
让我同意
然后应用
让我转到终端这里
让我离开这个
让我离开python cli
路径只是这一点
它在这一点的上方
我可以复制这个
然后去运行编辑配置
粘贴在这里
让我们说ok ok
然后，我们必须复制这一点到这里
然后去运行编辑配置
点击这个，然后转到末尾
粘贴现在
我们可以说ok
应用ok
然后我们应该能够运行这个来确认我们开发的函数
按预期工作
我们可以只说右边 点击然后运行上
现在正在运行 让我们等到它运行
我们应该能够看到这些数据以及这里的模式
你可以在这里看到模式
这就是模式，我们也能看到数据
这就是你应该能够想出的逻辑
将文件读入数据框 现在是我们处理和写入的时间
```